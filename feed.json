{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "HSAIO",
  "home_page_url": "https://hsaio.codenoob.top/",
  "feed_url": "https://hsaio.codenoob.top/feed.json",
  "description": "Happy Study - Knowledge, Notes, documents, and more all in one.",
  "author": {
    "name": "MIFSH"
  },
  "items": [
    {
      "title": "Git",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/Git.html",
      "id": "/Hardware/DevOps/CI-CD/Git.html",
      "content_html": "<h1 id=\"git\"> Git</h1>\n<p>：一个流行的版本控制工具。</p>\n<ul>\n<li><a href=\"https://git-scm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 C 语言开发。2005 年由 Linus Torvalds 发布。</li>\n<li>特点：\n<ul>\n<li>分布式管理。每个服务器、客户端都存储一份完整的代码仓库，可以相互同步。</li>\n<li>支持将每次修改后的文件提交为一个版本，允许用户将文件回滚到任意历史版本。</li>\n<li>支持创建多个分支，进行分支切换、合并，便于多人合作开发同一个项目。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装\"> 安装</h2>\n<ol>\n<li>\n<p>在 CentOS 上安装 git ：</p>\n<div><pre><code>yum <span>install</span> <span>git</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>在 Windows 上推荐再安装 git 的 GUI 工具，比如 Tortoisegit 。</p>\n</li>\n<li>\n<p>初始化配置：</p>\n<div><pre><code><span>git</span> config --global user.name <span>\"name\"</span>\n<span>git</span> config --global user.email <span>\"you@example.com\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>每次执行 <code>git commit</code> 时都会自动备注提交者的用户名和邮箱。</p>\n</li>\n</ol>\n<h2 id=\"基本用法\"> 基本用法</h2>\n<ol>\n<li>\n<p>用户进入项目根目录，执行 <code>git init</code> 命令进行初始化。</p>\n<ul>\n<li>这默认会在当前目录下创建一个 .git 子目录，作为 git 仓库，存储 git 的相关文件。</li>\n</ul>\n</li>\n<li>\n<p>用户执行 <code>git commit</code> 命令，将项目文件提交为一个版本，让 git 记录。</p>\n<ul>\n<li>git 默认会记录项目目录下的所有文件，可以在 .gitignore 文件中声明不想被 git 记录的文件。</li>\n<li>git 会将这些文件拷贝一份到 git 仓库中，根据哈希值识别它们。</li>\n<li>git 会记录当前时刻所有文件的哈希值，记作一个版本。</li>\n</ul>\n</li>\n<li>\n<p>每次用户修改文件的内容之后，都应该执行 <code>git commit</code> 命令，将当前时刻的所有文件提交为一个新版本。</p>\n<ul>\n<li>如果文件的哈希值发生变化，git 就认为文件的内容已经改变，会将改变之后的文件拷贝一份到 git 仓库中。不改变的文件则不会拷贝。</li>\n</ul>\n</li>\n<li>\n<p>用户执行 <code>git checkout xxx</code> 命令，切换到历史版本。</p>\n<ul>\n<li>git 会找到该版本对应的所有文件的哈希值，根据哈希值将这些文件从 git 仓库拷贝到项目目录下，从而将项目目录还原到历史时刻。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"版本\"> 版本</h2>\n<h3 id=\"查看\"> 查看</h3>\n<div><pre><code><span>git</span> status                <span># 显示当前 git 仓库的状态（包括当前的分支名、缓存区内容）</span>\n\n<span>git</span> log <span>[</span>refs<span>]</span> <span>[</span>path<span>]</span>     <span># 显示 commit 历史日志（按时间倒序），不指定 refs 则选中当前版本，不指定 path 则选中所有文件</span>\n        -n                <span># 只显示 n 个 commit</span>\n        --show-signature  <span># 增加显示 GPG 签名</span>\n\n<span>git</span> <span>diff</span> <span>&lt;</span>refs<span>></span> <span>&lt;</span>refs<span>></span>    <span># 显示从第一个版本到第二个版本的差异，包括差异文件、文件内增删的每行</span>\n        --stat            <span># 只显示统计信息，包括差异文件列表、增减的行数</span>\n        --name-status     <span># 只显示差异文件列表、文件动作的缩写（比如 A 新增、D 删除、M 修改、R 重命名）</span>\n        --name-only       <span># 只显示差异文件列表</span>\n        --no-renames      <span># 不自动识别 rename 动作，直接显示 create、delete</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><h3 id=\"修改\"> 修改</h3>\n<div><pre><code><span>git</span> <span>add</span> <span>&lt;</span>path<span>></span><span>..</span>.               <span># 将指定文件加入缓存区。如果指定一个目录，则递归加入其下所有文件</span>\n        -u                      <span># 如果有文件不匹配 path ，但已被 git 管理，则也加入缓存区。与 git add . 相比，git add -u 能发现已删除的文件，但不能发现新增的文件</span>\n        -A                      <span># 相当于 git add . 加 git add -u</span>\n<span>git</span> <span>rm</span> <span>&lt;</span>file<span>></span>                   <span># 删除某个文件</span>\n      --cached                  <span># 从缓存区删除</span>\n<span>git</span> <span>mv</span> <span>&lt;</span>src_file<span>></span> <span>&lt;</span>dst_file<span>></span>    <span># 移动文件</span>\n\n<span>git</span> rev-parse --show-toplevel   <span># 返回 Git 项目的顶级目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>被修改的文件建议先加入 git 缓存区（称为 stage、index），以便之后提交成一个版本，永久保存到 git 仓库中。\n<ul>\n<li>也可以不加入缓存区就直接 git commit 。</li>\n<li>如果一个文件相对上一版本未被改动，或者被 .gitignore 文件忽略，则不会添加到缓存区。</li>\n<li>用 git rm/mv 做出的改动会自动加入缓存区。</li>\n</ul>\n</li>\n<li>在 Windows 上重命名一个文件时，如果只是改变了文件名的大小写，git 默认不会发现该改动，此时建议通过 git mv 重命名文件。</li>\n</ul>\n<h3 id=\"提交\"> 提交</h3>\n<div><pre><code><span>git</span> commit                      <span># 将当前缓存区的所有文件提交为一个版本</span>\n          -m <span>\"initial version\"</span>  <span># 加上备注信息（该选项为强制要求）</span>\n          -a                    <span># 提交从上一个版本以来被改动的所有文件</span>\n          --amend               <span># 将当前的缓存区合并到上一个版本（不过时间戳依然是上一个版本的）</span>\n          -S                    <span># 添加 GPG 签名</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>每提交一个版本时，会自动生成一个 SHA-1 哈希值，作为 commit ID、version name 。如下：<div><pre><code>commit 86e696bd125aa895e067c2216ae8298289ab94d6\nAuthor: Leo <span>&lt;</span>leohsiao@foxmail.com<span>></span>\nDate:   Thu Dec <span>10</span> 09:15:19 <span>2020</span> +0800\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>该哈希值的长度为 40 位，不过用户只使用前几位也能定位到该版本，比如 git checkout 86e696 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"撤销\"> 撤销</h3>\n<div><pre><code><span>git</span> clean <span>[</span>path<span>]</span><span>..</span>.     <span># 删除指定目录（默认为当前目录）下，所有未被 git 版本控制，或不在 .gitignore 中记录的文件</span>\n          -d            <span># 递归子目录</span>\n          -f            <span># 强制删除</span>\n          -x            <span># 将 .gitignore 中记录的文件也删除</span>\n          -e <span>&lt;</span>pattern<span>></span>  <span># --exclude ，排除一些文件，不删除</span>\n\n<span>git</span> reset <span>[</span>refs<span>]</span>        <span># 将当前分支指向目标版本（默认是最近一个版本）</span>\n          --soft        <span># 不改变工作目录的文件（即依然处于原版本），将与目标版本不同的所有文件添加到缓存区</span>\n          --mixed       <span># 不改变工作目录的文件，清空缓存区。默认采用该方式</span>\n          --hard        <span># 改变工作目录的文件（即变为目标版本），并清空缓存区</span>\n\n<span>git</span> revert <span>&lt;</span>refs<span>></span><span>..</span>.    <span># 自动提交一个新版本来抵消某个历史版本的变化（这样不会删除历史版本）</span>\n          -n            <span># --no-commit ，只是修改文件并加入缓存区，不自动提交。默认会为撤销的每个历史版本，提交一个新版本</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>撤销文件的常用命令：<div><pre><code><span>git</span> checkout <span>.</span>            <span># 将文件复原到当前版本</span>\n\n<span>git</span> clean -dfx            <span># 清理未被版本控制的文件</span>\n<span>git</span> reset --hard          <span># 复原项目文件，清空缓存区</span>\n\n<span>git</span> revert HEAD           <span># 撤销最近一个版本</span>\n<span>git</span> revert HEAD~5<span>..</span>HEAD   <span># 撤销一连串版本，即还原到 HEAD~5 版本</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>通过 git checkout 可以将 HEAD 分支切换到历史版本，此时可新建分支来修改。而通过 git revert 可以将文件还原到历史版本，可作为新版本提交，继续在当前分支工作。</li>\n</ul>\n</li>\n<li>从 git 仓库的所有版本中永久删除某个文件：<div><pre><code><span>git</span> filter-branch --force --index-filter <span>'git rm --cached --ignore-unmatch &lt;文件的相对路径>'</span> --prune-empty --tag-name-filter <span>cat</span> -- --all\n<span>git</span> push origin --force --all --tags    <span># 强制推送，覆盖远端仓库</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h3 id=\"gitignore\"> .gitignore</h3>\n<ul>\n<li>不受 git 版本控制的文件主要有两种：\n<ul>\n<li>新增的文件，尚未加入版本控制。</li>\n<li>被 .gitignore 忽略的文件。</li>\n</ul>\n</li>\n<li>可以在项目根目录下创建一个 .gitignore 文件，声明一些文件让 git 不进行版本控制。如下：<div><pre><code>/test.py        <span># 忽略项目根目录下的指定文件</span>\n/log/*.log      <span># 忽略 log 目录下的一些文件</span>\n__pycache__/    <span># 忽略所有目录下的指定目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>.gitignore 根据文件相对于项目根目录的完整路径进行匹配，可以使用通配符 * 、? 。</li>\n<li>以 / 开头的路径，是从项目根目录开始，匹配方向是明确的。不以 / 开头的路径，可能匹配到多个目录下的文件。</li>\n<li>以 / 结尾的路径，是强调匹配目录，不匹配文件。</li>\n<li>如果一个目录为空，或者只包含空目录，则会被 git 忽略，相当于该目录不存在。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"引用\"> 引用</h2>\n<ul>\n<li>因为 commit 版本的哈希值不方便记忆，git 支持创建以下几种引用（Reference ，refs），用于指向某个版本。\n<ul>\n<li>分支（branch）：指向某个版本，且可以随时改为指向其它版本，相当于指针。常见分支：\n<ul>\n<li>master ：git 仓库初始化时，默认创建的一个分支，通常用作主分支。</li>\n<li>HEAD ：git 仓库内置的一个特殊分支，指向用户当前所处的版本。还可通过 HEAD~n 的格式指向倒数第 n 个版本，比如 HEAD~0 相当于 HEAD 。</li>\n</ul>\n</li>\n<li>标签（tag）：指向某个版本，且创建之后不能改为指向其它版本，相当于某个版本的别名。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"branch\"> branch</h3>\n<div><pre><code><span>git</span> branch          <span># 显示所有本地分支</span>\n        -a          <span># 增加显示远端分支</span>\n        -v          <span># 显示每个分支所在的版本</span>\n        <span>&lt;</span>branch<span>></span>    <span># 新建一个分支</span>\n        -d <span>&lt;</span>branch<span>></span> <span># 删除一个分支</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><h3 id=\"checkout\"> checkout</h3>\n<div><pre><code><span>git</span> checkout\n        <span>[</span>refs<span>]</span>          <span># 将当前分支切换到某个 refs 指向的版本，如果不指定则选中当前版本</span>\n              <span>&lt;</span>path<span>></span><span>..</span>. <span># 不切换，而是将指定路径的文件改为目标版本的状态</span>\n        -b <span>&lt;</span>branch<span>></span>     <span># 切换到指定分支，如果该分支不存在则自动创建</span>\n              <span>&lt;</span>refs<span>></span>    <span># 切换分支之后，再将该分支切换到 refs 版本</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>如果用 <code>git checkout</code> 切换到一个 tag 或 commit ，则不会绑定分支，会提示：<code>You are in 'detached HEAD' state.</code> 。此时可以执行 <code>git fetch</code> ，但不能执行 <code>git pull</code> ，否则会报错：<code>You are not currently on a branch</code></li>\n</ul>\n<h3 id=\"tag\"> tag</h3>\n<div><pre><code><span>git</span> tag                 <span># 显示已有的所有标签</span>\n        -a v1.0 9fceb02 <span># 给版本 9fceb02 加上标签 v1.0</span>\n        -d <span>&lt;</span>tagName<span>></span>    <span># 删除一个标签</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><h3 id=\"merge\"> merge</h3>\n<div><pre><code><span>git</span> merge <span>&lt;</span>branch<span>></span>  <span># 将指定分支的所有版本合并到当前分支</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>合并时，如果目标分支不包含当前分支没有的版本，则合并后当前分支不会变化。否则，合并后会产生一个新版本，以解决两个分支的差异。</li>\n</ul>\n<p>示意图：</p>\n<ol>\n<li>\n<p>用户提交的历史版本会按先后顺序排列成一条线，如下：</p>\n<p><img src=\"./git_branch01.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n<li>\n<p>如果用户想重新修改某个历史版本，就创建一个 dev 分支，指向该分支，如下：</p>\n<p><img src=\"./git_branch02.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n<li>\n<p>用户在 dev 分支上提交出另一个版本，则版本树就从一条线分叉成了多条线。如下：</p>\n<p><img src=\"./git_branch03.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n<li>\n<p>用户可以将 dev 分支合并到 master 分支，从而将版本树合并成一条线。如下：</p>\n<p><img src=\"./git_branch04.png\" alt=\"\" loading=\"lazy\"></p>\n<p>合并两个分支时，如果两个分支包含不同路径的文件，则会自动合并。如果包含相同路径的文件，但内容不同，就会产生冲突，必须解决冲突才能合并。</p>\n<ul>\n<li>如果 master 分支中包含文件 1.txt ，dev 分支中不包含文件 1.txt ，则 git 会保留文件 1.txt ，自动合并。</li>\n<li>如果 master 分支中文件 1.txt 的内容全为大写，dev 分支中文件 1.txt 的内容全为小写，则用户需要手动确定合并之后文件 1.txt 的内容是什么。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"rebase\"> rebase</h3>\n<div><pre><code><span>git</span> rebase\n        <span>&lt;</span>branch<span>></span>          <span># 将当前分支以变基方式合并到指定分支，这会产生一个新 commit</span>\n        branch1 branch2   <span># 将 branch2 以变基方式合并到 branch1</span>\n        branch1 branch2 --onto branch3  <span># 将 branch2 相对于 branch1 的变基应用到 branch3 上</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>\n<p>如下图，通过变基（rebase）方式将 C3 合并到 master 时，会先找到 C3 与 C4 的共同祖先 C2；然后删除 C3 ，将从 C2 到 C3 之间的所有变动应用到 C4 上，生成一个新版本 C3'；最后将 master 分支快进到 C3'处。</p>\n<p><img src=\"./git_rebase.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n<li>\n<p>merge 方式与 rebase 方式最终生成的版本都一样，但是 rebase 方式会删除次分支，将版本图简化成一条线。</p>\n</li>\n</ul>\n<h3 id=\"cherry-pick\"> cherry-pick</h3>\n<div><pre><code><span>git</span> cherry-pick <span>&lt;</span>commit_hash<span>></span><span>..</span>.  <span># 将指定的多个 commit 的修改内容提交到当前分支，支持提交到其它 Git 仓库</span>\n        -n                        <span># 只更新文件，不提交</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><h2 id=\"配置\"> 配置</h2>\n<p>git 的配置文件有三种，局部的配置会覆盖全局的配置：</p>\n<ul>\n<li>系统的配置文件：保存在 <code>/etc/gitconfig</code> 。</li>\n<li>当前用户的配置文件：保存在 <code>~/.gitconfig</code> 。</li>\n<li>当前项目的 git 仓库的配置文件：保存在 <code>.git/config</code> 。</li>\n</ul>\n<p>配置文件为 INI 格式，下方是一个项目的 git 仓库的配置实例：</p>\n<div><pre><code><span><span>[</span><span>core</span><span>]</span></span>\n    <span>repositoryformatversion</span> <span>=</span> <span>0 # 仓库格式的版本</span>\n    <span>filemode</span>   <span>=</span> <span>true           # 是否保留文件权限中的可执行位</span>\n    <span>bare</span>       <span>=</span> <span>false          # 该仓库是否为裸仓库</span>\n    <span>ignorecase</span> <span>=</span> <span>false          # 是否忽略文件名的大小写</span>\n\n<span><span>[</span><span>remote \"origin\"</span><span>]</span></span>               # 定义一个远端仓库，名为 origin\n    <span>url</span>    <span>=</span> <span>https://github.com/LeoHsiao1/test.git</span>\n    <span>fetch</span>  <span>=</span> <span>+refs/heads/*:refs/remotes/origin/*    # 格式为 [+]&lt;src>:&lt;dst> ，声明让本地的 src 分支跟踪远端仓库的 dst 分支</span>\n\n<span><span>[</span><span>branch \"master\"</span><span>]</span></span>\n    <span>remote</span> <span>=</span> <span>origin</span>\n    <span>merge</span>  <span>=</span> <span>refs/heads/master</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><p>可以直接修改配置文件，也可以使用以下命令进行修改：</p>\n<div><pre><code><span>git</span> config\n          --system      <span># 使用系统的配置文件</span>\n          --global      <span># 使用当前用户的配置文件</span>\n          --local       <span># 使用当前 git 仓库的配置文件</span>\n\n          -l            <span># --list ，显示配置文件的全部内容</span>\n          -e            <span># --edit ，在文本编辑器中打开配置文件</span>\n\n          <span>&lt;</span>key<span>></span>         <span># 显示配置文件中某项参数的值</span>\n          <span>&lt;</span>key<span>></span> <span>&lt;</span>value<span>></span> <span># 设置配置文件中某项参数的值</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><h3 id=\"submodule\"> submodule</h3>\n<p>：子模块，用于在当前 git 仓库中以子目录的形式引用其它 git 仓库。</p>\n<ul>\n<li>相关命令：<div><pre><code><span>git</span> submodule\n              <span>add</span> <span>&lt;</span>repository_url<span>></span> <span>[</span><span>&lt;</span>path<span>></span><span>]</span> <span>[</span>--name <span>&lt;</span>name<span>></span><span>]</span> <span>[</span>-b <span>&lt;</span>branch<span>></span><span>]</span>   <span># 添加 submodule</span>\n              update        <span># 更新 submodule ，这会从远端仓库 pull 它的最新版本</span>\n              <span>sync</span>          <span># 将 .gitmodules 文件中的配置同步到 .git/config 中（默认不会自动同步）</span>\n              status        <span># 显示所有 submodule 的 commit、path、branch 信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>添加了 submodule 之后，会在项目根目录生成一个 .gitmodules 文件，用于保存其配置信息。如下：<div><pre><code><span><span>[</span><span>submodule \"python_utils\"</span><span>]</span></span>                            # submodule 的名称\n  <span>url</span> <span>=</span> <span>https://github.com/LeoHsiao1/python_utils.git # submodule 的仓库地址，会通过 git clone 命令下载</span>\n  <span>path</span> <span>=</span> <span>submodules/python_utils                      # 将该 submodule 下载到哪个目录</span>\n  <span>branch</span> <span>=</span> <span>master                                     # 引用的分支</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div>还会在 <code>.git/config</code> 中记录 submodule 的信息，如下：<div><pre><code><span><span>[</span><span>submodule \"python_utils\"</span><span>]</span></span>\n  <span>active</span> <span>=</span> <span>true</span>\n  <span>url</span> <span>=</span> <span>https://github.com/LeoHsiao1/python_utils.git</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>如果想移除一个 submodule ，需要在上述两个配置文件中删除它。</li>\n</ul>\n</li>\n<li>进入 submodule 的目录之后，就相当于处于其 git 仓库下，可以执行 git checkout 等命令。\n<ul>\n<li>当前 git 仓库会引用 submodule 的某个 commit 版本，不会自动更新，需要手动更新：<div><pre><code><span>cd</span> submodule_dir/\n<span>git</span> pull\n<span>cd</span> <span>..</span>\n<span># 以上命令可简化为 git submodule update --remote --merge</span>\n\n<span>git</span> <span>add</span> <span>.</span>\n<span>git</span> commit -m <span>'Updated submodule'</span>\n<span>git</span> push\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"远端仓库\"> 远端仓库</h2>\n<p>拥有一个 git 服务器之后，就可以将本地的 git 仓库推送到服务器存储，或从服务器拉取 git 仓库。</p>\n<ul>\n<li>一个本地仓库可以配置 0 个或任意个远端仓库。\n<ul>\n<li>配置之后，通过 URL 或 name 即可指定远端仓库。</li>\n</ul>\n</li>\n<li>将本地仓库推送到远端时，会自动推送所有分支，并让本地分支与远端分支建立一对一的关系（称为跟踪）。\n<ul>\n<li>如果已有被跟踪的远端分支，则让本地分支与它合并。（如果发生冲突则不能直接推送）</li>\n<li>如果不存在被跟踪的远端分支，则自动创建它。</li>\n<li>如果选择强制推送，则相当于清空远端仓库后再上传本地仓库。</li>\n<li>默认不会推送标签，要手动推送。</li>\n</ul>\n</li>\n<li>远端仓库有两种传输方式：\n<ul>\n<li>基于 HTTPS 协议：\n<ul>\n<li>先在 git 服务器上创建账号</li>\n<li>然后在本机连接到 git 服务器，输入账号、密码进行认证。</li>\n</ul>\n</li>\n<li>基于 SSH 协议：\n<ul>\n<li>先生成一对 SSH 密钥，将密钥保存在本机的 ~/.ssh/id_rsa 文件中，将公钥保存到 git 服务器上。</li>\n<li>然后在本机连接到 git 服务器，使用私钥进行认证。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>常见的 git 服务器：\n<ul>\n<li>GitLab ：提供了代码托管、项目管理、Wiki、CI 等丰富的功能，比较繁重。可使用公网版、私有部署版。</li>\n<li>GitHub ：功能比 GitLab 少些。只可使用公网版。</li>\n<li>Gogs   ：只有代码托管功能，轻量级。可使用公网版、私有部署版。</li>\n<li>Gitee  ：从 Gogs 分叉而来，功能更多，页面像 GitHub 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"相关命令\"> 相关命令</h3>\n<div><pre><code><span>git</span> clone <span>&lt;</span>URL<span>></span> <span>[</span>dir<span>]</span>           <span># 将一个远端仓库克隆到本地，默认是保存到一个与仓库同名的子目录中</span>\n        -b <span>&lt;</span>branch<span>></span>             <span># 切换到指定分支，默认是远程仓库的 HEAD 分支</span>\n        --depth <span>&lt;</span>n<span>></span>             <span># 浅克隆（shallow clone），只下载最近的 n 个版本的文件，默认会下载全部版本</span>\n        --recursive             <span># 递归克隆所有 submodule ，默认不会克隆 submodule</span>\n\n<span>git</span> remote                      <span># 显示已配置的所有远端仓库的名字</span>\n        -v                      <span># 显示各个远端仓库的 URL</span>\n        show <span>&lt;</span>name<span>></span>             <span># 显示某个远端仓库的具体信息</span>\n        <span>add</span> <span>&lt;</span>name<span>></span> <span>&lt;</span>URL<span>></span>        <span># 添加一个远端仓库，并设置其名字</span>\n        <span>rm</span> <span>&lt;</span>name<span>></span>               <span># 删除一个远端仓库</span>\n        <span>rename</span> <span>&lt;</span>name<span>></span> <span>&lt;</span>name<span>></span>    <span># 重命名一个远端仓库</span>\n\n<span>git</span> fetch <span>[</span>name 或 URL<span>]</span>         <span># 拉取远端仓库的最新内容（包括分支、标签），但只是下载到本地仓库，并不会改变本地分支</span>\n        --all                   <span># 拉取所有远端仓库（默认只是 origin 仓库）</span>\n        --tags                  <span># 拉取标签</span>\n\n<span>git</span> pull <span>[</span>name 或 URL<span>]</span>          <span># 先 fetch 远端仓库，然后将跟踪的远端分支合并到本地分支，但并不会合并到之前不存在的本地分支</span>\n\n<span>git</span> push <span>[</span>name 或 URL<span>]</span>          <span># 推送本地仓库到远端仓库</span>\n        --force                 <span># 强制推送</span>\n        --all                   <span># 推送本地仓库的所有分支</span>\n        <span>&lt;</span>tag<span>></span>                   <span># 推送一个标签</span>\n        --tags                  <span># 推送所有标签</span>\n        --delete origin <span>&lt;</span>refs<span>></span>  <span># 删除远端的分支或标签</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br></div></div><ul>\n<li>git clone 之后，默认将远端仓库命名为 origin ，并让本地的 master 分支跟踪 origin/master 分支。\n<ul>\n<li>执行 git pull、fetch、push 时，如果不指定远端仓库，则使用默认的 origin 仓库。</li>\n</ul>\n</li>\n<li>拉取、推送代码时，默认每次都需要输入 git 服务器的账号、密码。\n<ul>\n<li>可以在远端仓库的 URL 中写入密码：<div><pre><code><span>git</span> clone http://leo:******@github.com/LeoHsiao1/Notes.git\n</code></pre>\n<div><span>1</span><br></div></div>但这样会将明文密码泄露到终端。</li>\n<li>或者执行以下命令，将以后输入的凭证都自动缓存起来：<div><pre><code><span>git</span> config --global credential.helper cache   <span># 将凭证在内存中缓存 15 分钟</span>\n<span>git</span> config --global credential.helper store   <span># 将凭证持久保存，实际上是以明文形式保存到 ~/.git-credentials 文件中</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>例：推送一个本地分支到远端仓库<div><pre><code><span>git</span> push origin master <span>:</span> origin/master <span># 推送分支 master 到远端仓库 origin ，并与远端分支 master 合并</span>\n<span>git</span> push origin <span>:</span> origin/master        <span># 推送一个空分支（这会删除指定的远端分支）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>如果在远端仓库创建了一个 test 分支，则可以执行以下命令，拉取到本地仓库：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># git branch -a                # 查看当前分支，此时没看到 test 分支</span>\n* master\n  remotes/origin/HEAD -<span>></span> origin/master\n  remotes/origin/master\n\n<span>[</span>root@CentOS ~<span>]</span><span># git fetch                    # 拉取远端仓库</span>\nFrom https://github.com/LeoHsiao1/Notes\n* <span>[</span>new branch<span>]</span>      <span>test</span>       -<span>></span> origin/test\n\n<span>[</span>root@CentOS ~<span>]</span><span># git branch -a                # 此时可看到远端的 test 分支</span>\n* master\n  remotes/origin/HEAD -<span>></span> origin/master\n  remotes/origin/master\n  remotes/origin/test\n\n<span>[</span>root@CentOS ~<span>]</span><span># git checkout test            # 切换到本地的 test 分支，会自动创建它，并跟踪到远端的 test 分支</span>\nSwitched to a new branch <span>'test'</span>\nBranch <span>'test'</span> <span>set</span> up to track remote branch <span>'test'</span> from <span>'origin'</span><span>.</span>\n\n<span>[</span>root@CentOS ~<span>]</span><span># git checkout test2           # 切换到本地的 test2 分支失败，不会自动创建它</span>\nerror: pathspec <span>'test2'</span> did not match any file<span>(</span>s<span>)</span> known to <span>git</span>\n\n<span>[</span>root@CentOS ~<span>]</span><span># git branch -a                # 查看此时的分支</span>\n  master\n* <span>test</span>\n  remotes/origin/HEAD -<span>></span> origin/master\n  remotes/origin/master\n  remotes/origin/test\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br></div></div></li>\n</ul>\n<h3 id=\"裸仓库\"> 裸仓库</h3>\n<ul>\n<li>执行 <code>git init --bare</code> 会创建一个裸仓库。\n<ul>\n<li>它不会创建 .git 子目录，而是将 git 仓库中的文件直接存储到项目根目录。并且通常将项目根目录加上扩展名 .git 。</li>\n<li>它不支持提交 commit ，只能通过 push 的方式修改，因此常用于在服务器上存储远端仓库，供多人推送修改。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"lfs\"> LFS</h3>\n<ul>\n<li>Git LFS（Large File Storage）：Git 的一种插件，用于存储大文件。\n<ul>\n<li>原理：将一些大文件存储在 Git 仓库外部（位于 <code>.git/lfs/</code> 目录下），只在 Git 仓库内通过指针引用。在 pull 远端仓库时，默认只拉取当前版本的大文件。</li>\n<li>相关命令：<div><pre><code>yum <span>install</span> git-lfs     <span># 安装 lfs</span>\n<span>git</span> lfs track <span>\"*.jpg\"</span>   <span># 将文件标记为大文件，被 lfs 跟踪</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<h3 id=\"scm\"> SCM</h3>\n<p>Git 属于软件配置管理（Source Code Management ，SCM）工具，同类产品包括：</p>\n<ul>\n<li>Subversion ：简称为 svn 。\n<ul>\n<li>集中式管理。代码仓库存储在服务器上，用户需要通过客户端连接服务器，才能拉取代码或提交代码。</li>\n<li>以多个子目录的形式管理代码仓库，目录结构如下：<div><pre><code>repository/\n├── branches  <span># 存放各个分支的项目代码</span>\n├── tags      <span># 存放各个版本的项目代码</span>\n└── trunk     <span># 存放主干分支的项目代码</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>支持只拉取或提交指定路径的目录、文件，而不必拉取整个代码仓库。</li>\n</ul>\n</li>\n<li>Mercurial ：采用 Python 开发。</li>\n</ul>\n<h3 id=\"git-flow\"> git flow</h3>\n<p>：一种流行的 git 使用策略，适合管理复杂的项目。</p>\n<ul>\n<li>在 git 仓库中至少使用以下两个分支：\n<ul>\n<li>master 分支：用于保存正式发布的版本。</li>\n<li>dev 分支：用于保存开发环境的版本。平时的代码都提交到 dev 分支，发布稳定版本时才合并到 master 分支。</li>\n</ul>\n</li>\n<li>可以视情况创建以下临时分支：\n<ul>\n<li>feature 分支：从 dev 分支创建，用于开发一个新功能，完成之后就合并到 dev 分支。</li>\n<li>hotfix 分支：从 dev 分支创建，用于解决一个 bug ，完成之后就合并到 dev 分支。</li>\n<li>release 分支：从 dev 分支创建，用于发布一个新版本，测试通过之后就合并到 master 分支，并加上一个 tag ，声明版本号。</li>\n</ul>\n</li>\n<li>对 git 仓库加上权限控制，比如：\n<ul>\n<li>禁止对 master 分支 push -f 。甚至禁止直接 push ，只允许将其它分支的代码通过 PR 合并到 master 分支。</li>\n<li>提出合并到 master 分支的 PR 时，必须经过其他人 review 同意，才能合并。</li>\n</ul>\n</li>\n<li>建议在 commit comment 的开头声明该 commit 的大致类型，便于分类整理。例如：<div><pre><code><span># 宽泛的分类</span>\nAdd       <span>function</span> test1<span>(</span><span>)</span>\nDelete    <span>..</span>.\nModify    <span>..</span>.\n\n<span># 更准确的分类</span>\nUpdate    <span>..</span>.     <span># 少许改进、增加内容</span>\nOptimize  <span>..</span>.     <span># 明显优化</span>\nRewrite   <span>..</span>.     <span># 重写部分内容，比如函数</span>\nRefactor  <span>..</span>.     <span># 重构整个或部分系统</span>\nFix       bug 20200101_001\n\n<span># 加上 [] 的分类</span>\n<span>[</span>CI<span>]</span>   <span>..</span>.\n<span>[</span>DOC<span>]</span>  <span>..</span>.\n<span>[</span>TEST<span>]</span> <span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h3 id=\"gpg-签名\"> GPG 签名</h3>\n<p>GitHub、GitLab 等平台支持生成 commit ID 的数字签名，保存在 commit comment 中。步骤如下：</p>\n<ol>\n<li>用户生成一对 GPG 私钥、公钥，在其中记录自己的用户名、邮箱地址。</li>\n<li>用户使用私钥签署每个 commit 。<div><pre><code><span>git</span> config --global user.signingkey ******\n<span>git</span> commit -S -m <span>\"...\"</span>\n<span>git</span> push\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>用户在平台的设置页面登记 GPG 公钥，平台会自动验证各个 commit 的签名是否有效。\n<ul>\n<li>如果有效，则显示一个 Verified 标志，证明该 commit 是由该用户提交的，并且 commit 内容没有被篡改。</li>\n</ul>\n</li>\n</ol>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "GitHub",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/GitHub.html",
      "id": "/Hardware/DevOps/CI-CD/GitHub.html",
      "content_html": "<h1 id=\"github\"> GitHub</h1>\n<p>：一个 Web 网站，用于托管 Git 仓库。</p>\n<ul>\n<li><a href=\"https://docs.github.com/en\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>只能访问公网上的 GitHub 官方网站，不支持自己部署。</li>\n<li>2018 年被微软公司收购。</li>\n</ul>\n<h2 id=\"actions\"> Actions</h2>\n<p>：GitHub 提供的一种 CI 功能。</p>\n<ul>\n<li><a href=\"https://docs.github.com/en/actions/reference\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>使用时，需要在 GitHub 仓库的 <code>.github/workflows/</code> 目录下创建工作流文件。\n<ul>\n<li>工作流文件采用 YAML 格式，描述了要执行的 CI 步骤，相当于 Jenkins 的 pipeline 脚本。</li>\n</ul>\n</li>\n<li>GitHub 免费提供了一些虚拟机，用户可以直接在其中执行 workflows ，而不必自己准备主机。这是与 GitLab、Jenkins 相比的一大优点。</li>\n</ul>\n<h2 id=\"runner\"> Runner</h2>\n<ul>\n<li>\n<p>执行 workflows 的主机称为 Runner 。</p>\n</li>\n<li>\n<p>GitHub 免费提供了一些虚拟机作为 Runner ，供用户使用。规格如下：</p>\n<ul>\n<li>配置都为：\n<ul>\n<li>2-core CPU</li>\n<li>7 GB of RAM memory</li>\n<li>14 GB of SSD disk space</li>\n</ul>\n</li>\n<li>可用的操作系统包括：\n<ul>\n<li>ubuntu-18.04 、ubuntu-20.04 等</li>\n<li>macos-10.15</li>\n<li>windows-2019</li>\n</ul>\n</li>\n<li>取消了权限限制，比如使用 sudo 时不需要输入密码。</li>\n</ul>\n</li>\n<li>\n<p>用户也可以添加自己的主机作为 Runner ，这需要在 Github 仓库的 <code>Settings -&gt; Actions</code> 页面进行配置。</p>\n<ul>\n<li>作为 Runner 的主机要保持运行一个客户端进程，连接到 GitHub 仓库，接受控制。\n<ul>\n<li>该进程必须使用非 root 用户启动：<div><pre><code><span>useradd</span> github\n<span>su</span> - github\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>使用自己的 Runner 时，要小心 workflows 中执行了恶意代码。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"workflows\"> workflows</h2>\n<h3 id=\"用法示例\"> 用法示例</h3>\n<div><pre><code><span>name</span><span>:</span> Test                        <span># 该 workflow 的名称。如果省略，则赋值为当前文件名</span>\n\n<span>on</span><span>:</span> <span>[</span>push<span>,</span> pull_request<span>]</span>          <span># 触发该 workflow 的事件</span>\n\n<span>jobs</span><span>:</span>                             <span># 该 workflow 的任务列表</span>\n  <span>job1</span><span>:</span>                           <span># 第一个任务</span>\n    <span>runs-on</span><span>:</span> ubuntu<span>-</span><span>18.04</span>         <span># 运行该 workflow 的虚拟机</span>\n    <span>steps</span><span>:</span>                        <span># 该任务包含的步骤</span>\n    <span>-</span> <span>name</span><span>:</span> checkout              <span># 第一个步骤</span>\n      <span>uses</span><span>:</span> actions/checkout@v2   <span># 调用一个动作，用于检出该 GitHub 仓库</span>\n    <span>-</span> <span>name</span><span>:</span> Test                  <span># 第二个步骤</span>\n      <span>run</span><span>:</span> <span>|</span>                      <span># 在终端执行命令</span>\n        pytest <span>-</span>v\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>在 GitHub 个人账号的 <code>Settings -&gt; Notifications</code> 页面，可以设置在 GitHub Actions 执行失败时发送邮件通知。</li>\n</ul>\n<h3 id=\"on\"> on</h3>\n<ul>\n<li><code>on</code> 参数用于声明触发该 workflow 的事件。如下：<div><pre><code><span>on</span><span>:</span>\n  <span>push</span><span>:</span>                 <span># Push 时触发，包括在 GitHub 网页上提交 commit 的情况</span>\n    <span>branches</span><span>:</span>           <span># 只对指定分支触发</span>\n      <span>-</span> master\n    <span>tags</span><span>:</span>               <span># 只对指定 tags 触发</span>\n      <span>-</span> <span>'v1.*'</span>          <span># 可以使用通配符</span>\n\n  <span>pull_request</span><span>:</span>         <span># 提出 PR 时触发</span>\n    <span>branches</span><span>:</span>\n      <span>-</span> dev\n\n  <span>release</span><span>:</span>              <span># 在 GitHub 网页上发布版本时触发</span>\n    <span>types</span><span>:</span>              <span># release 分为 created、edited、deleted、published 等多种情况，如果不指定 types ，则每种情况都会触发一次</span>\n      <span>-</span> created\n\n  <span>workflow_dispatch</span><span>:</span>    <span># 允许在 GitHub 网页上手动触发</span>\n    <span># inputs:           # 可以定义在手动触发时传入的参数</span>\n    <span>#   ref:            # 定义一个名为 refs 的变量，可通过 ${{ github.event.inputs.ref }} 的格式调用</span>\n    <span>#     description: ''</span>\n    <span>#     required: true</span>\n    <span>#     default: master</span>\n\n  <span>schedule</span><span>:</span>             <span># 作为定时任务触发</span>\n    <span>-</span> <span>cron</span><span>:</span>  <span>'*/15 * * * *'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br></div></div></li>\n</ul>\n<h3 id=\"env\"> env</h3>\n<ul>\n<li>\n<p><code>env</code> 参数用于定义一些环境变量，加入终端。如下：</p>\n<div><pre><code><span>env</span><span>:</span>                            <span># 全局的环境变量</span>\n  <span>VAR1</span><span>:</span> A\n\n<span>jobs</span><span>:</span>\n  <span>job1</span><span>:</span>\n    <span>runs-on</span><span>:</span> ubuntu<span>-</span><span>18.04</span>\n    <span>env</span><span>:</span>                        <span># 作用于 job 的环境变量</span>\n      <span>VAR1</span><span>:</span> Hello\n    <span>steps</span><span>:</span>\n    <span>-</span> <span>name</span><span>:</span> Test\n      <span>run</span><span>:</span> <span>|</span><span>\n        echo $VAR1 $VAR2</span>\n      <span>env</span><span>:</span>                      <span># 作用于 step 的环境变量</span>\n        <span>VAR1</span><span>:</span> $<span>{</span><span>{</span> env.VAR1 <span>}</span><span>}</span>   <span># 在 shell 之外，也可以用模板的语法调用环境变量</span>\n        <span>VAR2</span><span>:</span> World\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n<li>\n<p>GitHub 会自动加入一些内置的环境变量，例如：</p>\n<div><pre><code>GITHUB_WORKFLOW     <span># 当前 workflow 的名称</span>\nGITHUB_WORKSPACE    <span># 工作目录</span>\nGITHUB_RUN_NUMBER   <span># 当前 workflow 执行的编号，从 1 开始递增</span>\nGITHUB_JOB          <span># 当前 job 的名称</span>\nGITHUB_SHA          <span># 触发该 workflow 的版本的哈希值</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>不过这些变量只会加入终端的环境变量，不支持在 workflow 中读取。</li>\n</ul>\n</li>\n<li>\n<p>在 GitHub 仓库的 <code>Settings -&gt; Secrets</code> 页面可以添加以密文形式存储的环境变量。然后在 workflow 中按如下格式使用：</p>\n<div><pre><code><span>steps</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> Test\n    <span>env</span><span>:</span>\n      <span>password</span><span>:</span> $<span>{</span><span>{</span> secrets.PASSWORD <span>}</span><span>}</span>\n    <span>run</span><span>:</span> <span>|</span><span>\n      echo $password</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<div><ul>\n<li>workflow 支持通过 <code>${{ expression }}</code> 的格式嵌入一个表达式的值，从而可以获取任意上下文（context）的信息。\n<ul>\n<li><a href=\"https://docs.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions\" target=\"_blank\" rel=\"noopener noreferrer\">上下文和表达式的语法</a></li>\n<li>GitHub 会在读取 workflow 时获取表达式的值，嵌入到 workflow 中，然后才执行 workflow 。</li>\n<li>定义环境变量时，不能在同一个 env 块中读取它。</li>\n</ul>\n</li>\n</ul>\n</div><ul>\n<li><code>$GITHUB_ENV</code> 指向一个存储环境变量的文件，向该文件中添加变量，就可以被后续步骤调用。如下：<div><pre><code><span>steps</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> Test write\n  <span>run</span><span>:</span> <span>|</span><span>\n    echo  tips=Hello  >>  $GITHUB_ENV</span>\n<span>-</span> <span>name</span><span>:</span> Test read\n  <span>run</span><span>:</span> <span>|</span><span>\n    echo  $tips  ${{ env.tips }}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n<h3 id=\"job\"> job</h3>\n<ul>\n<li>定义 job 的示例：<div><pre><code><span>jobs</span><span>:</span>                           <span># job 的列表</span>\n  <span>job1</span><span>:</span>                         <span># 第一个 job ，其 id 为 job1</span>\n    <span># name: Test                # 该 job 的名称。如果省略，则赋值为 job_id</span>\n    <span>runs-on</span><span>:</span> ubuntu<span>-</span><span>18.04</span>       <span># 运行该 workflow 的虚拟机</span>\n    <span># if: ${{ success() }}      # 当 if 条件为 true 时才执行该 job 。这里当之前的 job 执行成功时，success() 的结果才为 true</span>\n    <span># continue-on-error: false  # 该 job 失败时，是否继续执行后续的 job</span>\n    <span># timeout-minutes: 360      # 该 job 的超时时间</span>\n    <span>steps</span><span>:</span>                      <span># 该 job 包含的步骤</span>\n    <span>-</span> <span>name</span><span>:</span> checkout\n      <span>uses</span><span>:</span> actions/checkout@v2\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n<li>执行 job 时会创建一个临时的工作目录，比如 <code>/home/runner/work/repo-name/repo-name</code> 。\n<ul>\n<li>执行每个 job 之前，都会重新创建该目录。因此上一个 job 生成的文件不会保留到下一个 job 。</li>\n<li>执行每个 step 之前，都会重新切换到该目录。因此上一个 step 切换的工作目录，并不会影响下一个 step 。</li>\n</ul>\n</li>\n<li>每个 job 最多执行 6 小时，超时则会放弃执行。</li>\n</ul>\n<h3 id=\"job-needs\"> job.needs</h3>\n<ul>\n<li>定义多个 job 时，默认会并行执行。可以用 needs 参数控制它们的执行顺序：<div><pre><code><span>jobs</span><span>:</span>\n  <span>job1</span><span>:</span>\n  <span>job2</span><span>:</span>\n    <span>needs</span><span>:</span> job1           <span># 当 needs 的 job 执行成功时，才执行该 job</span>\n  <span>job3</span><span>:</span>\n    <span>if</span><span>:</span> always()          <span># 等 needs 的 job 执行结束之后，即使它们执行失败，也执行该 job</span>\n    <span>needs</span><span>:</span> <span>[</span>job1<span>,</span> job2<span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n<h3 id=\"job-runs-on\"> job.runs-on</h3>\n<ul>\n<li><code>job.runs-on</code> 参数用于声明在哪个环境执行该 job 。</li>\n<li>可以直接使用 GitHub 提供的虚拟机：<div><pre><code><span>job1</span><span>:</span>\n  <span>runs-on</span><span>:</span> ubuntu<span>-</span><span>18.04</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>可以使用用户自己的 Runner ：<div><pre><code><span>runs-on</span><span>:</span> self<span>-</span>hosted\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"job-strategy\"> job.strategy</h3>\n<ul>\n<li>\n<p><code>job.strategy</code> 用于将一个 job 以矩阵形式创建多个实例，它们会并行执行。如下：</p>\n<div><pre><code><span>job1</span><span>:</span>\n  <span>runs-on</span><span>:</span> ubuntu<span>-</span><span>18.04</span>\n  <span>strategy</span><span>:</span>\n    <span>matrix</span><span>:</span>\n      <span>python_version</span><span>:</span> <span>[</span><span>3.5</span><span>,</span> <span>3.6</span><span>,</span> <span>3.7</span><span>,</span> <span>3.8</span><span>]</span>    <span># 这会创建 4 个 job 实例，每个实例使用 python_version 变量的一种取值</span>\n    <span># fail-fast: true                         # 默认只要有一个 job 实例执行失败，则会放弃执行其它 job 实例</span>\n    <span># max-parallel: 2                         # 限制并行执行的 job 实例数，默认会尽量最大化</span>\n  <span>steps</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> Set up Python $<span>{</span><span>{</span> matrix.python_version <span>}</span><span>}</span>    <span># 读取矩阵变量，它们不会自动加入终端环境变量</span>\n    <span>uses</span><span>:</span> actions/setup<span>-</span>python@v1\n    <span>with</span><span>:</span>\n      <span>python-version</span><span>:</span> $<span>{</span><span>{</span> matrix.python_version <span>}</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>最多创建 256 个 job 实例。</li>\n</ul>\n</li>\n<li>\n<p>可以在 <code>job.strategy</code> 中定义 <code>runs-on</code> 用到的变量，从而创建多个运行环境：</p>\n<div><pre><code><span>job1</span><span>:</span>\n  <span>strategy</span><span>:</span>\n    <span>matrix</span><span>:</span>                   <span># 这里会创建 3*4=12 个 job 实例</span>\n      <span>os</span><span>:</span> <span>[</span>ubuntu<span>-</span><span>18.04</span><span>,</span> macos<span>-</span><span>10.15</span><span>,</span> windows<span>-</span><span>2019</span><span>]</span>\n      <span>python_version</span><span>:</span> <span>[</span><span>3.5</span><span>,</span> <span>3.6</span><span>,</span> <span>3.7</span><span>,</span> <span>3.8</span><span>]</span>\n  <span>runs-on</span><span>:</span> $<span>{</span><span>{</span> matrix.os <span>}</span><span>}</span>\n  <span>steps</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> Set up Python $<span>{</span><span>{</span> matrix.python_version <span>}</span><span>}</span>\n    <span>uses</span><span>:</span> actions/setup<span>-</span>python@v1\n    <span>with</span><span>:</span>\n      <span>python-version</span><span>:</span> $<span>{</span><span>{</span> matrix.python_version <span>}</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n<h3 id=\"step\"> step</h3>\n<ul>\n<li>定义 step 的示例：<div><pre><code><span>steps</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> Install dependencies  <span># 该 step 的名称。如果省略，则自动命名</span>\n  <span># id: step1                 # 该 step 的唯一标识符</span>\n  <span># if: ${{ success() }}      # 当之前的 step 执行成功时才执行该 step</span>\n  <span># continue-on-error: false  # 该 step 失败时，是否继续执行后续的 step</span>\n  <span># timeout-minutes: 360      # 该 step 的超时时间</span>\n  <span>run</span><span>:</span> <span>|</span>                      <span># 该 step 的主要内容是调用 run 模块，从而在终端执行命令</span>\n    python <span>-</span>m pip install pytest psutil\n    echo Hello\n  <span># shell: bash               # 指定 run 模块采用的 shell 。在 Windows 系统上默认是 pwsh ，在其它系统上默认是 bash</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n</ul>\n<h3 id=\"step-uses\"> step.uses</h3>\n<ul>\n<li>\n<p><code>step.uses</code> 参数用于调用一个 Action 。</p>\n<ul>\n<li>Action 是一个实现某种动作的功能模块，命名格式为 <code>作者名/模块名@版本号</code> 。</li>\n<li><a href=\"https://github.com/marketplace?type=actions\" target=\"_blank\" rel=\"noopener noreferrer\">搜索可用的 Actions</a></li>\n</ul>\n</li>\n<li>\n<p>检出仓库的示例：</p>\n<div><pre><code><span>steps</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> Check out repository\n  <span>uses</span><span>:</span> actions/checkout@v2   <span># 采用一个拉取代码仓库的 action</span>\n  <span># with:                     # 通过 with 为该 action 传入参数</span>\n  <span>#   repository: ${{ github.repository }}  # 拉取哪个仓库</span>\n  <span>#   ref: master             # 切换到哪个 ref 。默认是切换到触发该 workflow 的 commit ，如果不是被 commit 触发则切换到默认分支</span>\n  <span>#   path: ''                # 将拉取的仓库保存到哪个路径，默认为当前目录</span>\n  <span>#   submodules: false       # 是否拉取 submodules ，取值为 true 则拉取，取值为 recursive 则递归拉取</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>\n<p>安装 Python 解释器：</p>\n<div><pre><code><span>-</span> <span>uses</span><span>:</span> actions/setup<span>-</span>python@v2\n  <span>with</span><span>:</span>\n    <span>python-version</span><span>:</span> <span>'3.8'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>缓存文件：</p>\n<div><pre><code><span>-</span> <span>uses</span><span>:</span> actions/cache@v2\n  <span>with</span><span>:</span>\n    <span>path</span><span>:</span> <span>|</span>                 <span># 指定要缓存的文件</span>\n      f1\n      test/                 <span># 可以指定目录</span>\n      tmp<span>*/</span>                 <span># 可以使用通配符</span>\n      <span>!test/*.py</span>            <span># 可以用 ! 排除一些文件</span>\n    <span>key</span><span>:</span> $<span>{</span><span>{</span> runner.os <span>}</span><span>}</span><span>-</span>$<span>{</span><span>{</span> hashFiles('f1') <span>}</span><span>}</span>    <span># 缓存项的唯一 key</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>path 指定的所有文件会先压缩成一个包，再缓存。</li>\n<li>缓存时，如果已存在相同 key 的缓存项，则称为缓存命中。否则称为未命中，并创建新的缓存项。</li>\n</ul>\n</li>\n<li>\n<p>上传、下载文件：</p>\n<div><pre><code><span>-</span> <span>uses</span><span>:</span> actions/upload<span>-</span>artifact@v2\n  <span>with</span><span>:</span>\n    <span>name</span><span>:</span> my<span>-</span>artifact       <span># 上传之后，保存的工件名</span>\n    <span>path</span><span>:</span> <span>|</span>                 <span># 指定要上传的文件。它们会被打包成一个 ZIP 包再上传</span>\n      f1\n      test/\n      tmp<span>*/</span>\n      <span>!test/*.py</span>\n    <span># retention-days: 90    # 保存时长，超时之后会自动删除</span>\n<span>-</span> <span>uses</span><span>:</span> actions/download<span>-</span>artifact@v2\n  <span>with</span><span>:</span>\n    <span>name</span><span>:</span> my<span>-</span>artifact       <span># 指定工件名。如果省略，则下载所有工件，并根据工件名分别创建子目录</span>\n    <span>path</span><span>:</span> .                 <span># 将下载的 artifact 从 ZIP 包解压到 path 目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>在 GitHub 网页上可以查看该 workflow 的执行记录，并点击下载 Artifacts 。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "GitLab",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/GitLab.html",
      "id": "/Hardware/DevOps/CI-CD/GitLab.html",
      "content_html": "<h1 id=\"gitlab\"> GitLab</h1>\n<p>：一个 Web 网站，用于托管 Git 仓库。</p>\n<ul>\n<li><a href=\"https://docs.gitlab.com/ee/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Ruby 开发，基于 Rails 框架。</li>\n<li>可以访问公网上的 GitLab 官方网站，也可以自己部署社区版（CE）或企业版（EE）。</li>\n<li>除了托管 Git 仓库，还提供了 Issue、任务看板、Wiki、CI/CD、WebIDE 等丰富的功能。</li>\n</ul>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>\n<p>GitLab 内置的主要服务：</p>\n<ul>\n<li>puma ：一个 HTTP 服务器。</li>\n<li>workhorse ：反向代理 puma ，用于加速体积较大的 HTTP 请求，比如静态文件、上传文件。</li>\n<li>sidekiq ：负责在后台执行任务。</li>\n<li>gitaly ：负责处理 git 请求。收到用户访问 Git 仓库的请求时，会去访问磁盘中的 Git 仓库。</li>\n</ul>\n</li>\n<li>\n<p>GitLab 依赖的外部服务：</p>\n<ul>\n<li>redis</li>\n<li>postgreSQL</li>\n<li>nginx ：用于反向代理各个内部服务，作为用户访问 GitLab 的入口。</li>\n<li>grafana、prometheus、exporter ：用于监控 Gitlab 自身。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>gitlab</span><span>:</span>\n    <span>container_name</span><span>:</span> gitlab\n    <span>image</span><span>:</span> gitlab/gitlab<span>-</span>ee<span>:</span>14.3.3<span>-</span>ee.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>hostname</span><span>:</span> gitlab.example.com\n    <span>ports</span><span>:</span>\n      <span>-</span> <span>80:80</span>\n      <span>-</span> <span>'1022:22'</span>   <span># YAML 的一个特别语法：如果冒号 : 右侧的数小于 60 ，则视作 60 进制数，此时需要声明为字符串</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config<span>:</span>/etc/gitlab\n      <span>-</span> ./data<span>:</span>/var/opt/gitlab\n      <span>-</span> ./logs<span>:</span>/var/log/gitlab\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>执行 <code>gitlab-rake &quot;gitlab:password:reset&quot;</code> ，根据提示输入用户名 root ，即可设置其密码。</li>\n<li>官方 Docker 镜像中集成了多个进程，因此比较臃肿，启动时需要几分钟。</li>\n</ul>\n</li>\n<li>\n<p>GitLab 企业版增加了少许功能。</p>\n<ul>\n<li>与社区版兼容。部署企业版时，如果未激活，则只能使用社区版的功能。</li>\n<li>激活步骤：\n<ol>\n<li>部署 gitlab-ee 。</li>\n<li>进入 admin 页面，点击 Subscription ，输入激活码，或者上传许可证文件。</li>\n</ol>\n</li>\n<li><a href=\"https://conf.top/post/506/\" target=\"_blank\" rel=\"noopener noreferrer\">破解教程</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>配置文件默认位于 <code>/etc/gitlab/gitlab.rb</code> ，配置示例：<div><pre><code><span># GitLab 地址</span>\nexternal_url <span>\"https://gitlab.example.com\"</span>     <span># GitLab 供用户访问的地址，会影响 git clone 地址</span>\nnginx<span>[</span><span>'listen_port'</span><span>]</span>  <span>=</span> <span>80</span>                    <span># GitLab 实际监听的端口。默认会根据 external_url 选择监听的端口、协议</span>\nnginx<span>[</span><span>'listen_https'</span><span>]</span> <span>=</span> <span>false</span>                 <span># 监听的端口是否采用 HTTPS 协议</span>\ngitlab_rails<span>[</span><span>'gitlab_shell_ssh_port'</span><span>]</span> <span>=</span> <span>1022</span>  <span># SSH 端口，会影响 git clone 地址，不过 GitLab 实际监听的依然是 22 端口</span>\n\n<span># SMTP 配置</span>\ngitlab_rails<span>[</span><span>'smtp_enable'</span><span>]</span>               <span>=</span> <span>true</span>\ngitlab_rails<span>[</span><span>'smtp_domain'</span><span>]</span>               <span>=</span> <span>\"exmail.qq.com\"</span>\ngitlab_rails<span>[</span><span>'smtp_address'</span><span>]</span>              <span>=</span> <span>\"smtp.exmail.qq.com\"</span>\ngitlab_rails<span>[</span><span>'smtp_port'</span><span>]</span>                 <span>=</span> <span>465</span>\ngitlab_rails<span>[</span><span>'smtp_user_name'</span><span>]</span>            <span>=</span> <span>\"test@qq.com\"</span>\ngitlab_rails<span>[</span><span>'smtp_password'</span><span>]</span>             <span>=</span> <span>\"******\"</span>\ngitlab_rails<span>[</span><span>'smtp_authentication'</span><span>]</span>       <span>=</span> <span>\"login\"</span>\ngitlab_rails<span>[</span><span>'smtp_enable_starttls_auto'</span><span>]</span> <span>=</span> <span>true</span>\ngitlab_rails<span>[</span><span>'smtp_tls'</span><span>]</span>                  <span>=</span> <span>true</span>\ngitlab_rails<span>[</span><span>'gitlab_email_from'</span><span>]</span>         <span>=</span> <span>'test@qq.com'</span>\n\n<span># 建议禁用一些很少使用的组件，减少内存占用</span>\ngrafana<span>[</span><span>'enable'</span><span>]</span>                <span>=</span> <span>false</span>\nprometheus<span>[</span><span>'enable'</span><span>]</span>             <span>=</span> <span>false</span>\nprometheus_monitoring<span>[</span><span>'enable'</span><span>]</span>  <span>=</span> <span>false</span>    <span># 与 prometheus 相关的 exporter</span>\n<span># puma['worker_processes']       = 2        # puma 的 worker 进程数，每个 worker 可能占用 1G 内存，但多个 worker 之间会共享内存</span>\ngitlab_rails<span>[</span><span>'packages_enabled'</span><span>]</span> <span>=</span> <span>false</span>    <span># GitLab 提供的 maven、npm、pypi 等仓库</span>\n\n<span># 建议默认禁用项目的一些功能，简化界面</span>\n<span># gitlab_rails['gitlab_default_projects_features_issues']             = true</span>\n<span># gitlab_rails['gitlab_default_projects_features_merge_requests']     = true</span>\n<span># gitlab_rails['gitlab_default_projects_features_wiki']               = true</span>\ngitlab_rails<span>[</span><span>'gitlab_default_projects_features_snippets'</span><span>]</span>             <span>=</span> <span>false</span>  <span># 代码片段</span>\ngitlab_rails<span>[</span><span>'gitlab_default_projects_features_builds'</span><span>]</span>               <span>=</span> <span>false</span>  <span># CI/CD 功能</span>\ngitlab_rails<span>[</span><span>'gitlab_default_projects_features_container_registry'</span><span>]</span>   <span>=</span> <span>false</span>  <span># Docker 镜像仓库</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>修改配置文件之后，需要执行 <code>gitlab-ctl reconfigure</code> 才能生效，而重启不一定生效。</li>\n</ul>\n</li>\n<li>可以执行 <code>gitlab-rails console</code> 进入 Ruby 终端。\n<ul>\n<li>测试发送邮件：<div><pre><code>Notify<span>.</span>test_email<span>(</span><span><span>'test@qq.com'</span></span><span>,</span> <span><span>'Test Email'</span></span><span>,</span> <span><span>'This is for test.'</span></span><span>)</span><span>.</span>deliver_now\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>登录 GitLab 之后，点击网页右上角的头像下拉框 -&gt; Preferences ，可设置语言、每周起始日、时间偏好。</li>\n<li>建议在 admin 页面进行以下配置：\n<ul>\n<li>禁止新用户注册。</li>\n<li>设置仓库的默认分支名为 master 。</li>\n<li>禁止在项目中不存在 CI 配置文件时，默认使用 Auto DevOps 流水线。</li>\n</ul>\n</li>\n<li>建议对 group 进行以下配置：\n<ul>\n<li>配置推送规则，比如限制单个文件的体积。</li>\n<li>将 Default branch protection 策略设置为完全保护：Developer 不能 git push 该分支，Maintainer 才可以。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>Project\n<ul>\n<li>：项目，即一个 Git 仓库。</li>\n</ul>\n</li>\n<li>Group\n<ul>\n<li>：群组，用于批量管理一组项目，类似于文件夹。</li>\n<li>支持创建嵌套的子群组。</li>\n<li>群组级别的配置，会被其下的子群组、项目继承。</li>\n<li>用户名、群组名都属于命名空间，可以在这些命名空间下创建项目，项目的 URL 格式为 <code>&lt;gitlab_url&gt;/&lt;namesapce&gt;/&lt;project&gt;</code> 。\n<ul>\n<li>用户有权创建个人项目、群组，但看不到其他人创建的项目、群组，除非被邀请加入。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>GitLab 不支持创建用户组，而是以 Group 成员的方式批量管理用户。Group 成员分为几种预设的角色，权限从高到低如下：\n<ul>\n<li>Owner ：拥有当前 Group 的所有权限，接近于管理员。</li>\n<li>Maintainer ：维护人员，拥有大部分权限。</li>\n<li>Developer ：开发人员，拥有一般的编辑权限，不能 git push 主分支。</li>\n<li>Reporter ：测试人员，有 Git 仓库的只读权限，可以编辑任务看板。</li>\n<li>Guest ：只能读取 issue、wiki、CI/CD 等信息。不能读取 Git 仓库，除非该项目是公开的。</li>\n</ul>\n</li>\n<li>CI/CD\n<ul>\n<li>GitLab 支持在代码仓库中添加一个 .gitlab-ci.yml 文件，配置要执行的 CI/CD 流水线。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"api\"> API</h2>\n<ul>\n<li>\n<p>GitLab 提供了丰富的 Restful API 。</p>\n</li>\n<li>\n<p>客户端使用 API 时可通过以下几种方式进行身份认证：</p>\n<ul>\n<li>个人 token</li>\n<li>项目 token</li>\n<li>OAuth2 token</li>\n<li>session cookie</li>\n</ul>\n</li>\n<li>\n<p>例：通过 curl 命令下载文件</p>\n<div><pre><code><span>gitlab_url</span><span>=</span><span>10.0</span>.0.1\n<span>project_id</span><span>=</span><span>5</span>\n<span>branch</span><span>=</span>master\n<span>file_path</span><span>=</span>README.md\n<span>token</span><span>=</span>KqKuksUwwcuyvnc8tEw1\n<span>curl</span> <span>\"http://<span>${gitlab_url}</span>/api/v4/projects/<span>${project_id}</span>/repository/files/<span>${file_path}</span>/raw?ref=<span>${branch}</span>&amp;private_token=<span>${token}</span>\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Jenkins",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/Jenkins.html",
      "id": "/Hardware/DevOps/CI-CD/Jenkins.html",
      "content_html": "<h1 id=\"jenkins\"> Jenkins</h1>\n<p>：一个 Web 服务器，用于 CI/CD ，采用 Java 开发。</p>\n<ul>\n<li><a href=\"https://jenkins.io/zh/doc/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>支持托管大量脚本（称为任务、Job ），供用户在浏览器中执行，实现便捷的项目构建、测试、部署等目标。</li>\n</ul>\n<h2 id=\"相关历史\"> 相关历史</h2>\n<ul>\n<li>2005 年，Sun 公司的 Kohsuke Kawaguchi 发布了一个简单的 CI 网站，名为 Hudson 。</li>\n<li>2010 年，Oracle 公司收购了 Sun 公司，拥有了 Hudson 的版权。社区被迫将项目改名为 Jenkins ，进行开发。</li>\n<li>2011 年，Hudson 被交给 Eclipse 基金会管理。但它越来越落后于 Jenkins ，于 2016 年停止开发。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>用 war 包启动：</p>\n<ol>\n<li>安装 JDK 。</li>\n<li>下载 Jenkins 的 war 包。</li>\n<li>启动 Jenkins ：<div><pre><code>java -jar jenkins.war --httpPort<span>=</span><span>8080</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>然后便可用浏览器访问 <code>http://localhost:8080</code> 。</li>\n<li>首次启动时，终端上会显示一个密钥，用于首次登录。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>jenkins</span><span>:</span>\n    <span>container_name</span><span>:</span> jenkins\n    <span>image</span><span>:</span> jenkins/jenkins<span>:</span>2.289.3\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span>JAVA_OPTS</span><span>:</span> <span>-</span>Duser.timezone=GMT+08\n    <span>ports</span><span>:</span>\n      <span>-</span> 8080<span>:</span><span>8080</span>                                   <span># 供用户访问 Jenkins 的 Web 页面</span>\n      <span># - 50000:50000                               # 供 JNLP 类型的 agent 访问 Jenkins</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./jenkins_home<span>:</span>/var/jenkins_home\n      <span>-</span> /var/run/docker.sock<span>:</span>/var/run/docker.sock   <span># 使容器内的 Jenkins 能与 dockerd 通信</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>需要先修改挂载目录的权限：<div><pre><code><span>mkdir</span> jenkins_home\n<span>chown</span> -R <span>1000</span>:1000 <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>\n<p>Jenkins 的主目录称为 JENKINS_HOME ，拷贝该目录就可以备份、迁移 Jenkins 。</p>\n<ul>\n<li>在启动 Jenkins 之前，可以声明环境变量 <code>JENKINS_HOME=/opt/jenkins/</code> ，改变 Jenkins 主目录。</li>\n<li>Jenkins 在每个节点上都会创建 JENKINS_HOME 目录。\n<ul>\n<li>master 节点的 JENKINS_HOME 目录用于保存 Jenkins 的主要数据。</li>\n<li>slave 节点的 JENKINS_HOME 目录主要包含 workspace 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>master 节点的 JENKINS_HOME 目录结构：</p>\n<div><pre><code>jenkins_home\n├── config.xml                <span># Jenkins 的配置文件</span>\n├── jobs/                     <span># 保存各个 Job 的信息</span>\n│   ├── job1/\n│   │   ├── builds/           <span># 保存每次 build 的信息，包括配置文件、日志</span>\n│   │   ├── config.xml        <span># 该 Job 的配置文件</span>\n│   │   └── nextBuildNumber   <span># 记录下一次 build 的编号</span>\n│   ├── job2/\n│   └── job3/\n├── nodes/                    <span># 保存各个节点的信息</span>\n├── plugins/\n└── workspace/                <span># 包含在当前节点执行过的 Job 的工作目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n<li>\n<p>Jenkins 每次执行 Job 时：</p>\n<ul>\n<li>先将该 Job 加入构建队列，等待分配某个 node 上的一个执行器（executor）。\n<ul>\n<li>如果没有可用的 executor ，则在构建队列中阻塞该 Job 。</li>\n<li>如果构建队列中已存在相同的 build 任务（配置、构建参数相同），则不会将当前任务加入构建队列，甚至不会占用 Build ID 。</li>\n<li>通过 API 或上游 job 触发一个 job 时，会在构建队列中等待一段时间才执行，称为静默期。如果在静默期内多次触发该 job ，则会被构建队列自动去重。</li>\n</ul>\n</li>\n<li>默认将当前节点的 <code>$JENKINS_HOME/workspace/$JOB_NAME</code> 目录作为工作目录（称为 workspace ）。\n<ul>\n<li>执行 Job 之前、之后都不会自动清空工作目录，建议用户主动清理。</li>\n<li>如果将一个 Job 并发执行多个实例，则生成的工作目录会自动添加 @1、@2 格式的后缀。</li>\n</ul>\n</li>\n<li>默认在 shell 中加入环境变量 <code>BUILD_ID=xxxxxx</code> ，当执行完 Job 之后就自动杀死所有环境变量 BUILD_ID 值与其相同的进程。\n<ul>\n<li>可以在 shell 中声明环境变量 <code>JENKINS_NODE_COOKIE=dontkillme</code> ，阻止 Jenkins 杀死当前 shell 创建的进程。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>访问 <code>/restart</code> 页面，会显示一个重启按钮。</p>\n</li>\n<li>\n<p>Jenkins 的 Web 页面上，很多地方都显示了 ？ 图标，点击它就会显示此处的帮助文档。</p>\n</li>\n<li>\n<p>新安装的 Jenkins 需要进行一些系统配置，比如添加节点、设置对外的 URL 。</p>\n<ul>\n<li>点击 <code>Manage Jenkins -&gt; Configure System</code> 可进行一些系统配置，比如设置 Jenkins 对外的 URL、邮箱、全局的环境变量。</li>\n<li>用户可以将密码等私密数据保存成 Jenkins 的凭据，然后在执行 Job 时调用，从而避免泄露明文到终端上。</li>\n</ul>\n</li>\n<li>\n<p>Jenkins 的主页默认显示一个视图（view）。</p>\n<ul>\n<li>每个视图以列表形式包含多个任务（Job），便于分组管理。</li>\n</ul>\n</li>\n<li>\n<p>Jenkins 的主页的左侧显示了菜单列，点击新建按钮，即可创建一个 Job ，常见的几种类型如下：</p>\n<ul>\n<li>Freestyle Project\n<ul>\n<li>：自由风格的项目，可以通过 Web 页面上的配置实现大多数构建任务。</li>\n</ul>\n</li>\n<li>Pipeline\n<ul>\n<li>：将项目的处理过程分成多个阶段，依次执行，称为流水线，用 Jenkinsfile 文件描述。</li>\n</ul>\n</li>\n<li>Multibranch Pipeline\n<ul>\n<li>：多分支流水线。用于监听 SCM 仓库的事件，对各个分支分别执行流水线。</li>\n<li>需要先将 pipeline 文件保存到每个分支的 SCM 仓库中。</li>\n</ul>\n</li>\n<li>MultiJob Project\n<ul>\n<li>：用于组合调用多个 Job 。</li>\n<li>可以设置多个阶段（Phase），每个阶段可以串行或并行执行多个 Job 。</li>\n</ul>\n</li>\n<li>Folder\n<ul>\n<li>：用于对 Job 进行分组管理。</li>\n<li>此时 Job 的全名为 <code>&lt;folder&gt;/&lt;job&gt;</code> ，因此不同 Folder 下的 Job 可以重名。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Job 的名称会用于组成 URL ，还会用于创建工作目录，因此应该避免包含特殊字符。</p>\n<ul>\n<li>可以采用 <code>项目名 _ 模块名 _ Job 类型 _ 环境</code> 的命名格式，比如 <code>mysite_front_DEPLOY_in_test</code></li>\n<li>也可以创建多层 Folder ，分组管理 Job ，比如 <code>mysite / front / DEPLOY_in_test</code></li>\n</ul>\n</li>\n<li>\n<p>点击进入一个 Job 的详情页面，如下：</p>\n<p><img src=\"./jenkins_job.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>左上方显示：该 Job 的菜单列，比如启动（Build）、配置、删除、重命名。</li>\n<li>左下方显示：构建历史（Build History），记录每次执行该 Job 的编号、时间、结果。</li>\n<li>中上方显示：Job 名称、描述信息。</li>\n<li>中下方显示：构建历史中，Job 每个阶段的耗时。</li>\n</ul>\n</li>\n<li>\n<p>点击某次构建，可查看其详细信息，比如启动原因、持续时长、控制台输出（Console Output）。</p>\n<ul>\n<li>常见的几种构建结果：\n<ul>\n<li>success ：执行成功，显示为蓝色。</li>\n<li>failure ：执行失败，显示为红色。</li>\n<li>unstable ：不稳定，显示为黄色，比如测试不通过。</li>\n<li>aborted ：放弃执行，显示为灰色。比如达到超时时间、被用户主动取消。</li>\n</ul>\n</li>\n<li>Console Output 中，如果打印一个以 <code>http://</code> 开头的字符串，则会自动显示成超链接。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"管理节点\"> 管理节点</h3>\n<ul>\n<li>用户可以添加一些主机、Docker 容器作为 Jenkins 的运行环境，称为节点（node）、代理（agent）、slave 。\n<ul>\n<li>Jenkins 服务器所在的节点称为 master ，而其它节点称为 slave ，这些节点都可以用于运行 Job 。</li>\n<li>在每个节点上，Jenkins 都需要使用一个目录存储数据。可以指定 <code>/opt/jenkins/</code> 目录，或者创建 jenkins 用户，然后使用 <code>/home/jenkins/</code> 目录。</li>\n<li>增加节点有利于实现 Jenkins 的横向扩容。</li>\n</ul>\n</li>\n<li>添加 slave 节点时，建议通过 SSH 密钥连接。步骤如下：\n<ol>\n<li>安装 <code>SSH Build Agents</code> 插件。</li>\n<li>在 slave 节点上安装 JDK 。</li>\n<li>将 master 节点的 <code>~/.ssh/id_rsa.pub</code> 公钥拷贝到 slave 节点的 <code>~/.ssh/authorized_keys</code> 中。</li>\n<li>在 Jenkins 上创建一个 <code>SSH Username with private key</code> 类型的凭据，填入 master 节点的 <code>~/.ssh/id_rsa</code> 私钥。</li>\n<li>在 Jenkins 上添加该节点，选择以 <code>Launch agents via SSH</code> 方式连接。</li>\n</ol>\n</li>\n<li>当 Jenkins master 通过 SSH 连接到 slave 之后（以 notty 方式连接，不创建终端），会执行 <code>java -jar remoting.jar</code>  命令，保持运行一个客户端。\n<ul>\n<li>master 每次连接 slave 时，不会加载 <code>/etc/profile</code> 和 <code>~/.bash_profile</code> ，只会加载 <code>/etc/bashrc</code> 和 <code>~/.bashrc</code> 。</li>\n<li>建议在 slave 的配置页面添加 Prefix Start Agent Command ：<code>source /etc/profile;source ~/.bash_profile;</code> 。</li>\n<li>客户端执行的所有 shell 命令都会继承它的 shell 环境变量。因此，当用户修改 shell 环境变量时，客户端不会自动更新，必须手动将 slave 断开重连。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"管理权限\"> 管理权限</h3>\n<p>安装 <code>Role-based Authorization Strategy</code> 插件之后便可以实现基于角色的用户权限控制。用法：</p>\n<ol>\n<li>进入 <code>全局安全配置</code> 页面，将授权策略改为 <code>Role-Based Strategy</code> 。</li>\n<li>进入 <code>Manage Jenkins -&gt; Manage Users</code> 页面，创建一个用户账号。</li>\n<li>进入 <code>Manage Jenkins -&gt; Manage and Assign Roles -&gt; Manage Roles</code> 页面，创建角色。\n<ul>\n<li>比如创建一个全局角色 visitor ，给予 Overall 的 Read 权限。即可以查看 Jenkins 主页，但看不到任何 Job 。</li>\n<li>比如创建几个项目角色，分别拥有对不同项目的权限。</li>\n<li>项目角色的 pattern 用于通过正则表达式选中多个项目，供他操作。</li>\n<li>建议将不同类型的 Job 采用不同的前缀命名，便于通过正则表达式分别匹配。</li>\n</ul>\n</li>\n<li>进入 <code>Manage Jenkins -&gt; Assign Roles</code> 页面，给各个用户分配角色。\n<ul>\n<li>默认只能对 Jenkins 内置数据库中存储的用户进行操作，用户较多时配置很麻烦。建议使用 LDAP 服务器中存储的用户、用户组。</li>\n</ul>\n</li>\n</ol>\n<p>推荐做法：</p>\n<ul>\n<li>只有 admin 用户拥有最高权限，比如进行 Jenkins 的系统设置。</li>\n<li>Jenkins 只能以 Job 为单位划分权限，因此应该给一个项目开发、测试、正式环境的构建任务分别创建 Job ，而不是通过构建参数选择它们。\n<ul>\n<li>虽然这样会产生很多 Job ，但 Job 之间可以相互调用。</li>\n</ul>\n</li>\n<li>给每个或每组 Job 创建两种项目角色，按需要分配给各个用户。\n<ul>\n<li><code>*_user</code> ：只是使用该 Job ，拥有 Job 的 Build、Cancel、Read 权限。</li>\n<li><code>*_editor</code> ：允许编辑该 Job ，拥有大部分权限。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"插件\"> 插件</h3>\n<p>在 <code>Manage Jenkins -&gt; Manage Plugins</code> 页面可以管理 Jenkins 的插件。</p>\n<ul>\n<li>安装、卸载插件时都要手动重启 Jenkins 才会生效，甚至修改了插件的配置之后可能也不会立即生效。</li>\n</ul>\n<p>常用插件：</p>\n<ul>\n<li>Localization: Chinese (Simplified)\n<ul>\n<li>用于对 Jenkins 的页面进行汉化。</li>\n</ul>\n</li>\n<li>Blue Ocean\n<ul>\n<li>提供了一个更美观的操作页面，但功能较少。</li>\n</ul>\n</li>\n<li>Extended Choice Parameter\n<ul>\n<li>提供了单选框、复选框、单选按钮、多选按钮类型的输入参数。</li>\n</ul>\n</li>\n<li>Generic Webhook Trigger\n<ul>\n<li>支持以 webhook 的方式触发 Jenkins 的 Job ，需要在 Job 的配置页面定义。通过 token 指定 Job ，可以通过请求字符串或 POST body 输入参数（区分大小写），如下：<div><pre><code><span>curl</span> http://10.0.0.1:8080/generic-webhook-trigger/invoke?token<span>=</span>Sqeuu90VF0TE<span>&amp;</span><span>ACTION</span><span>=</span>start\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>Email Extension Plugin\n<ul>\n<li>支持 Jenkins 发送邮件给用户。</li>\n<li>Jenkins 自带的邮件通知功能比较简陋，不推荐使用。</li>\n</ul>\n</li>\n<li>Job Configuration History\n<ul>\n<li>用于记录各个 Job 以及系统配置的变更历史。</li>\n<li>原理：将每次修改后的 XML 配置文件保存一个副本到 jenkins_home/config-history/ 目录下。</li>\n<li>建议在 Jenkins 系统管理页面，限制该插件保留变更历史的数量。</li>\n</ul>\n</li>\n<li>Folder Properties\n<ul>\n<li>用于在 Folder 中定义一些环境变量，称为属性，供其下的 Job 调用。</li>\n<li>需要在 Pipeline 的 options 中加入 withFolderProperties() ，才会在 stages 阶段载入 Folder 变量。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"♢-jenkinsapi\"> ♢ jenkinsapi</h2>\n<p>：Python 的第三方库，用于通过 HTTP 协议调用 Jenkins 的 API 。</p>\n<ul>\n<li>安装：<code>pip install jenkinsapi</code></li>\n<li><a href=\"https://jenkinsapi.readthedocs.io/en/latest/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n</ul>\n<h3 id=\"例\"> 例</h3>\n<ul>\n<li>\n<p>创建客户端：</p>\n<div><pre><code><span>from</span> jenkinsapi<span>.</span>jenkins <span>import</span> Jenkins\n\njk <span>=</span> Jenkins<span>(</span><span>'http://10.0.0.1:8080'</span><span>,</span> username<span>=</span><span>None</span><span>,</span> password<span>=</span><span>None</span><span>,</span> timeout<span>=</span><span>10</span><span>,</span> useCrumb<span>=</span><span>True</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>Jenkins 要求在 POST 请求中包含 Crumb 参数，避免 CSRF 攻击</li>\n</ul>\n</li>\n<li>\n<p>查询 job ：</p>\n<div><pre><code>job_names <span>=</span> jk<span>.</span>keys<span>(</span><span>)</span>             <span># 返回一个包含所有 job 名字的列表</span>\njk<span>.</span>get_jobs<span>(</span><span>)</span>                     <span># 返回一个可迭代对象，每次迭代返回一个二元组（job 名字，job 对象）</span>\n\njob <span>=</span> jk<span>.</span>get_job<span>(</span><span>'test1'</span><span>)</span>         <span># 根据名字，获取指定的 job 对象，如果不存在则抛出异常</span>\njob<span>.</span>url                           <span># 返回 job 的 URL</span>\njk<span>.</span>delete_job<span>(</span><span>'test1'</span><span>)</span>            <span># 删除一个 job</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>job 的配置：</p>\n<div><pre><code>xml <span>=</span> job<span>.</span>get_config<span>(</span><span>)</span>            <span># 导出 job 的 XML 配置</span>\njob <span>=</span> jk<span>.</span>create_job<span>(</span>jobname<span>,</span> xml<span>)</span> <span># 创建一个 job</span>\njob<span>.</span>update_config<span>(</span>xml<span>)</span>            <span># 修改 job 的 XML 配置</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>job 的构建：</p>\n<div><pre><code>jk<span>.</span>build_job<span>(</span><span>'test_job'</span><span>,</span> params<span>=</span><span>{</span><span>'tag'</span><span>:</span> <span>'v1.0.0'</span><span>}</span><span>)</span>  <span># 构建一个 job（按需要发送参数）</span>\n\nb <span>=</span> job<span>.</span>get_build<span>(</span><span>20</span><span>)</span>             <span># 返回指定编号的 build 对象</span>\nb <span>=</span> job<span>.</span>get_last_build<span>(</span><span>)</span>          <span># 返回最后一次构建的 build 对象</span>\njob<span>.</span>get_next_build_number<span>(</span><span>)</span>       <span># 返回下一次构建的编号（如果为 1 则说明还没有构建）</span>\n\nb<span>.</span>job<span>.</span>name                        <span># 返回这次构建所属 job 的名字</span>\nb<span>.</span>get_number<span>(</span><span>)</span>                    <span># 返回这次构建的编号</span>\nb<span>.</span>get_params<span>(</span><span>)</span>                    <span># 返回一个字典，包含这次构建的所有参数</span>\nb<span>.</span>stop<span>(</span><span>)</span>                          <span># 停止构建，如果成功停止则返回 True</span>\nb<span>.</span>is_running<span>(</span><span>)</span>                    <span># 如果这次构建正在运行，则返回 True</span>\nb<span>.</span>get_status<span>(</span><span>)</span>                    <span># 返回这次构建的结果，可能是 SUCCESS、FAILURE、ABORTED 等状态，如果仍在构建则返回 None</span>\nb<span>.</span>get_console<span>(</span><span>)</span>                   <span># 返回这次构建的控制台 stdout</span>\nb<span>.</span>get_timestamp<span>(</span><span>)</span><span>.</span>strftime<span>(</span><span>'%Y/%m/%d-%H:%M:%S'</span><span>)</span>  <span># 返回开始构建的时间</span>\nb<span>.</span>get_duration<span>(</span><span>)</span><span>.</span>total_seconds<span>(</span><span>)</span>                 <span># 返回这次构建的耗时，如果仍在构建则返回 0</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Jenkinsfile",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/Jenkinsfile.html",
      "id": "/Hardware/DevOps/CI-CD/Jenkinsfile.html",
      "content_html": "<h1 id=\"jenkinsfile\"> Jenkinsfile</h1>\n<p>：一个文本文件，用于描述 Jenkins 的 Pipeline Job ，可以被 Groovy 解释器执行。</p>\n<ul>\n<li>在 Jenkins 上编辑 Job 时，可以通过 Web 表单填写多种配置参数。\n<ul>\n<li>使用 Jenkinsfile 时，可以将大部分 Web 表单的配置参数用代码描述，更灵活，容易迁移。</li>\n<li>每执行一次 Jenkinsfile ，Jenkins 会自动识别其中的配置参数，导入相应的 Web 表单中，实现向下兼容。\n<ul>\n<li>不过，有的配置参数是 Jenkinsfile 独有的，不支持导入。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Jenkinsfile 有两种写法：\n<ul>\n<li>脚本式（Scripted Pipeline）：将流水线定义在 node{} 中，内容为可执行的 Groovy 脚本。</li>\n<li>声明式（Declarative Pipeline）：将流水线定义在 pipeline{} 中，内容为声明式的语句。本文采用这种写法。</li>\n</ul>\n</li>\n<li>所有 Pipeline Job 的 Web 页面中都有一个名为 &quot;流水线语法&quot; 的链接，点击之后可以查看一些关于 Pipeline 的帮助文档。\n<ul>\n<li>比如可以使用 &quot;片段生成器&quot; ，将 Web 表单中的配置参数转换成流水线代码。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"示例\"> 示例</h2>\n<div><pre><code>pipeline <span>{</span>\n    agent <span>{</span>                     <span>// 声明使用的节点</span>\n        label <span>'master'</span>\n    <span>}</span>\n    environment <span>{</span>               <span>// 定义环境变量</span>\n        PORT <span>=</span> <span>'80'</span>\n    <span>}</span>\n    options <span>{</span>\n        <span>timestamps</span><span>(</span><span>)</span>\n        <span>timeout</span><span>(</span>time<span>:</span> <span>5</span><span>,</span> unit<span>:</span> <span>'MINUTES'</span><span>)</span>\n    <span>}</span>\n    stages <span>{</span>\n        <span>stage</span><span>(</span><span>'拉取代码'</span><span>)</span> <span>{</span>      <span>// 开始一个阶段</span>\n            environment <span>{</span>       <span>// 定义该阶段的环境变量</span>\n                GIT_BRANCH <span>=</span> <span>'dev'</span>\n            <span>}</span>\n            steps <span>{</span>             <span>// 执行一些命令</span>\n                sh <span>\"git checkout <span><span>$</span>GIT_BRANCH</span>\"</span>\n                echo <span>'已切换分支'</span>\n            <span>}</span>\n        <span>}</span>\n        <span>stage</span><span>(</span><span>'构建镜像'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                docker build <span>-</span>t <span>$</span><span>{</span>image_hub<span>}</span><span>/<span><span>$</span><span>{</span>image_project<span>}</span></span>/</span><span>$</span><span>{</span>build_image_name<span>}</span><span>:</span><span>$</span><span>{</span>build_image_tag<span>}</span> <span>.</span>\n                docker push <span>$</span><span>{</span>image_hub<span>}</span><span>/<span><span>$</span><span>{</span>image_project<span>}</span></span>/</span><span>$</span><span>{</span>build_image_name<span>}</span><span>:</span><span>$</span><span>{</span>build_image_tag<span>}</span>\n                docker image rm <span>$</span><span>{</span>image_hub<span>}</span><span>/<span><span>$</span><span>{</span>image_project<span>}</span></span>/</span><span>$</span><span>{</span>build_image_name<span>}</span><span>:</span><span>$</span><span>{</span>build_image_tag<span>}</span>\n            <span>}</span>\n        <span>}</span>\n        <span>stage</span><span>(</span><span>'测试'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo <span>'测试中...'</span>\n                echo <span>'测试完成'</span>\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n    post <span>{</span>\n        always <span>{</span>            <span>// 任务结束时总是执行以下操作</span>\n            <span>deleteDir</span><span>(</span><span>)</span>     <span>// 递归地删除当前目录。这里是作用于当前 agent 的 ${env.WORKSPACE} 目录</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br></div></div><ul>\n<li>区分大小写。</li>\n<li>用 // 声明单行注释。</li>\n<li>每个 {} 的内容不能为空。</li>\n</ul>\n<h2 id=\"变量\"> 变量</h2>\n<ul>\n<li>\n<p>例：</p>\n<div><pre><code>script <span>{</span>\n    ID <span>=</span> <span>\"1\"</span>            <span>// 创建变量</span>\n    NAME <span>=</span> <span>\"man\"</span> <span>+</span> ID   <span>// 拼接字符串</span>\n    echo NAME           <span>// 直接打印 Groovy 的变量</span>\n    echo <span>\"<span><span>$</span>ID</span>\"</span>          <span>// 字符串定界符为双引号时，支持用 $ 插入变量或表达式的值</span>\n    echo <span>'$ID'</span>          <span>// 字符串定界符为双引号时，不支持用 $ 取值</span>\n    sh <span>\"echo <span><span>$</span>ID</span>\"</span>       <span>// 执行 sh 语句，字符串定界符为双引号时，会先在 Groovy 解释器中获取 $ 变量的值，再将字符串作为 Shell 命令执行</span>\n    sh <span>'echo $ID'</span>       <span>// 执行 sh 语句，字符串定界符为单引号时，会直接作为 Shell 命令执行，因此 $ 会读取 Shell 变量</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>\n<p>Groovy 语言支持在字符串中用 <code>$</code> 插入变量的值，用 <code>${}</code> 插入表达式的值。</p>\n<ul>\n<li>Jenkins 在执行 Jenkinsfile 之前，会先渲染以双引号作为定界符的字符串，如果其中存在 $ 符号，则尝试对 Groovy 解释器中的变量进行取值。\n<ul>\n<li>如果通过 $ 读取的变量不存在，则会抛出 Groovy 的语法异常：<code>groovy.lang.MissingPropertyException: No such property</code></li>\n<li>如果通过 ${env.A} 方式读取的变量不存在，则会返回 null ，不会报错。</li>\n</ul>\n</li>\n<li>如果想让 Groovy 将字符串中的 $ 当作普通字符处理，则需要使用单引号作为定界符，或者使用转义字符 <code>\\$</code> 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"环境变量\"> 环境变量</h3>\n<ul>\n<li>\n<p>在 environment{} 中可以定义环境变量，它们会保存为 Groovy 变量和 Shell 变量。如下：</p>\n<div><pre><code><span>stage</span><span>(</span><span>'测试'</span><span>)</span> <span>{</span>\n    environment <span>{</span>\n        ID <span>=</span> <span>1</span>\n    <span>}</span>\n    steps <span>{</span>\n        sh <span>\"echo <span><span>$</span>ID</span>\"</span>\n        sh <span>'echo $ID'</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><ul>\n<li>如果给环境变量赋值为空，则会删除该变量。</li>\n<li>定义在 pipeline.environment{} 中的环境变量会作用于该 pipeline 全局，而定义在 stage.environment{} 中的只作用于该阶段。</li>\n<li>还可以在 Jenkins 系统配置页面，定义作用于所有 Job 的环境变量。或者通过 Folder Properties 插件，在文件夹中定义环境变量。</li>\n</ul>\n</li>\n<li>\n<p>在 environment{} 中可以导入 Jenkins 的凭据作为环境变量：</p>\n<div><pre><code>environment <span>{</span>\n    ACCOUNT1 <span>=</span> <span>credentials</span><span>(</span><span>'account1'</span><span>)</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>假设该凭据是 <code>Username With Password</code> 类型，值为 <code>admin:123456</code> ，则 Jenkins 会在 Shell 中加入三个环境变量：</p>\n<div><pre><code><span>ACCOUNT1</span><span>=</span>admin:123456\n<span>ACCOUNT1_USR</span><span>=</span>admin\n<span>ACCOUNT1_PSW</span><span>=</span><span>123456</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>读取其它类型的凭据时，建议打印出 Shell 的所有环境变量，从而发现 Jenkins 加入的环境变量的名字。</li>\n<li>为了保密，如果直接将上述变量打印到 stdout 上，Jenkins 会将它们的值显示成 <code>****</code> 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"构建参数\"> 构建参数</h3>\n<ul>\n<li>\n<p>可以给 Job 声明构建参数，它们会保存为 Groovy 变量和 Shell 变量。</p>\n<ul>\n<li>用户在启动 Job 时，必须传入构建参数，除非它们有默认值。</li>\n</ul>\n</li>\n<li>\n<p>Pipeline Job 可以在 pipeline.parameters{} 中以代码的形式定义构建参数，而其它类型的 Job 只能在 Jenkins Web 页面中定义构建参数。如下：</p>\n<div><pre><code>pipeline <span>{</span>\n    agent any\n    parameters <span>{</span>\n        <span>booleanParam</span><span>(</span>name<span>:</span> <span>'A'</span><span>,</span> defaultValue<span>:</span> <span>true</span><span>,</span> description<span>:</span> <span>''</span><span>)</span>   <span>// 布尔参数</span>\n        <span>choice</span><span>(</span>name<span>:</span> <span>'E'</span><span>,</span> choices<span>:</span> <span>[</span><span>'A'</span><span>,</span> <span>'B'</span><span>,</span> <span>'C'</span><span>]</span><span>,</span> description<span>:</span> <span>''</span><span>)</span>   <span>// 单选参数，输入时会显示成下拉框</span>\n        <span>string</span><span>(</span>name<span>:</span> <span>'B'</span><span>,</span> defaultValue<span>:</span> <span>'Hello'</span><span>,</span> description<span>:</span> <span>''</span><span>)</span>      <span>// 字符串参数，在 Web 页面上输入时不能换行</span>\n        <span>text</span><span>(</span>name<span>:</span> <span>'C'</span><span>,</span> defaultValue<span>:</span> <span>'Hello\\nWorld'</span><span>,</span> description<span>:</span> <span>''</span><span>)</span> <span>// 文本参数，输入时可以换行</span>\n        <span>password</span><span>(</span>name<span>:</span> <span>'D'</span><span>,</span> defaultValue<span>:</span> <span>'123456'</span><span>,</span> description<span>:</span> <span>''</span><span>)</span>   <span>// 密文参数，输入时会显示成密文</span>\n        <span>file</span><span>(</span>name<span>:</span> <span>'f1'</span><span>,</span> description<span>:</span> <span>''</span><span>)</span>                              <span>// 文件参数，输入时会显示文件上传按钮</span>\n    <span>}</span>\n    stages <span>{</span>\n        <span>stage</span><span>(</span><span>'Test'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo <span>\"<span><span>$</span>A</span>\"</span>   <span>// 也可通过 $params.A 的格式读取构建参数，避免与环境变量重名</span>\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>如果定义了 parameters{} ，则会移除在 Jenkins Web 页面中定义的、在上游 Job 中定义的构建参数。</li>\n<li>每次修改了 parameters{} 之后，要执行一次 Job 才会在 Jenkins Web 页面上生效。</li>\n<li>password 类型的参数虽然在输入时显示成密文，但打印到终端上时会显示成明文，不如 Jenkins 的 credentials 安全。</li>\n<li>file 类型的参数上传的文件会存储到 <code>${workspace}/${job_name}/f1</code> 路径处，而用 <code>$f1</code> 可获得上传的文件名。\n<ul>\n<li>pipeline job 的文件参数功能无效，不能上传文件。可采用以下两种替代方案：\n<ul>\n<li>创建一个普通类型的 job ，供用户上传文件，保存到主机的 /tmp 目录下。然后让其它 job 从这里拷贝文件。</li>\n<li>在 Jenkins 之外搭建一个文件服务器，供用户上传文件。然后让其它 job 从这里下载文件。这样上传文件时麻烦些，但方便跨主机拷贝文件。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>在 shell 命令中调用构建参数时，可能被注入攻击。</p>\n<ul>\n<li>比如脚本执行 <code>ls $file</code> ，而用户输入构建参数 <code>file=a;rm -rf *</code> 就会注入攻击。</li>\n<li>如果让用户输入 booleanParam、choice 类型的构建参数，则在 Web 页面上只能选择有限的值。\n<ul>\n<li>即使用户通过 HTTP API 输入构建参数，Jenkins 也会自动检查参数的值是否合法。如果不合法，则采用该参数的默认值。</li>\n</ul>\n</li>\n<li>如果让用户输入 string、text 类型的构建参数，则应该过滤之后再调用。如下：<div><pre><code>parameters <span>{</span>\n    <span>string</span><span>(</span>name<span>:</span> <span>'file'</span><span>)</span>\n<span>}</span>\nenvironment <span>{</span>\n    file <span>=</span> file<span>.</span><span>replaceAll</span><span>(</span><span>'[^\\\\w /:,.*_-]'</span><span>,</span> <span>'_'</span><span>)</span><span>.</span><span>trim</span><span>(</span><span>)</span>    <span>// 将构建参数赋值给一个环境变量，替换特殊字符</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"内置变量\"> 内置变量</h3>\n<ul>\n<li>\n<p>可以通过 params 字典读取 Pipeline 的构建参数。如下：</p>\n<div><pre><code>params.A\nparams.B\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>可以通过 env 字典读取 Pipeline 的环境变量。除了用户添加的环境变量，还有 Jenkins 内置的环境变量，比如：</p>\n<div><pre><code>env.JENKINS_HOME    <span># Jenkins 部署的主目录</span>\nenv.NODE_NAME       <span># 节点名</span>\nenv.WORKSPACE       <span># 在当前节点上的工作目录</span>\n\nenv.JOB_NAME        <span># 任务名</span>\nenv.JOB_URL         <span># 任务链接</span>\nenv.BUILD_NUMBER    <span># 构建编号</span>\nenv.BUILD_URL       <span># 构建链接</span>\n\nenv.BRANCH_NAME     <span># 分支名</span>\nenv.CHANGE_AUTHOR   <span># 版本的提交者</span>\nenv.CHANGE_URL      <span># 版本的链接</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>这些变量的值都是 String 类型。</li>\n<li>这些变量可以按以下格式读取：<div><pre><code>script <span>{</span>\n    echo env<span>.</span>NODE_NAME              <span>// 在 Groovy 代码中，通过 env 字典读取</span>\n    echo <span>\"<span><span>$</span><span>{</span>env<span>.</span>NODE_NAME<span>}</span></span>\"</span>         <span>// 在字符串中，通过 $ 取值</span>\n\n    sh <span>\"echo <span><span>$</span><span>{</span>env<span>.</span>NODE_NAME<span>}</span></span>\"</span>\n    sh <span>'echo $NODE_NAME'</span>            <span>// env 字典的内容会导入 Shell 的环境变量，因此可以在 shell 中直接读取</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>可以通过 currentBuild 字典获取当前的构建信息。如下：</p>\n<div><pre><code>currentBuild.buildCauses       <span># Build 的执行原因，返回一个字典，包括 userId、userName 等</span>\ncurrentBuild.displayName       <span># Build 的名称，格式为 #number</span>\ncurrentBuild.fullDisplayName   <span># Build 的全名，格式为 JOB_NAME #number</span>\ncurrentBuild.description       <span># Build 的描述，默认为 null</span>\ncurrentBuild.duration          <span># Build 的持续时长，单位 ms</span>\ncurrentBuild.result            <span># Build 的结果。如果构建尚未结束，则返回值为 null</span>\ncurrentBuild.currentResult     <span># Build 的当前状态。开始执行时为 SUCCESS ，受每个 stage 影响，不会变为 null</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>只有 displayName、description 变量支持修改。修改其它变量时会报错：<code>RejectedAccessException: No such field</code></li>\n<li>例：修改本次构建的名称<div><pre><code>script <span>{</span>\n    currentBuild<span>.</span>displayName <span>=</span> <span>\"#<span><span>$</span><span>{</span>env<span>.</span>BUILD_NUMBER<span>}</span></span> branch=<span><span>$</span><span>{</span>env<span>.</span>BRANCH<span>}</span></span>\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"agent\"> agent{}</h2>\n<p>：用于控制在哪个 Jenkins 代理上执行流水线。</p>\n<ul>\n<li>可用范围：\n<ul>\n<li>在 pipeline{} 中必须定义 agent{} ，作为所有 stage{} 的默认代理。</li>\n<li>在单个 stage{} 中可选定义 agent{} ，只作用于该阶段。</li>\n</ul>\n</li>\n<li>agent 常见的几种定义格式：<div><pre><code>agent none          <span>// 不设置全局的 agent ，此时要在每个 stage{} 中单独定义 agent{}</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code>agent any           <span>// 让 Jenkins 选择任一代理</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code>agent <span>{</span>\n    label <span>'master'</span>  <span>// 选择指定名字的代理</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><div><pre><code>agent <span>{</span>\n    node <span>{</span>          <span>// 选择指定名字的代理，并指定工作目录</span>\n        label <span>'master'</span>\n        customWorkspace <span>'/opt/jenkins_home/workspace/test1'</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"docker\"> docker</h3>\n<ul>\n<li>\n<p>可以创建临时的 docker 容器作为 agent ：</p>\n<div><pre><code>agent <span>{</span>\n    docker <span>{</span>\n        <span>// label 'master'</span>\n        <span>// customWorkspace \"/opt/jenkins_home/workspace/test1\"</span>\n        image <span>'centos:7'</span>\n        <span>// args  '-v /tmp:/tmp'</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>这会在指定节点上创建一个 docker 容器，执行 pipeline ，然后自动删除该容器。</li>\n<li>该容器默认的启动命令如下：<div><pre><code><span>docker</span> run -t -d <span>\\</span>\n    -u <span>0</span>:0 <span>\\</span>                                    <span># 默认会设置容器内用户为 root</span>\n    -w /opt/jenkins/workspace/test_pipeline <span>\\</span>   <span># 默认会自动挂载 workspace 目录，并将其设置为容器的工作目录</span>\n    -v /opt/jenkins/workspace/test_pipeline:/opt/jenkins/workspace/test_pipeline:rw,z <span>\\</span>\n    -e ******** -e ******** -e ******** <span>\\</span>       <span># 默认会传入 Jenkins 的环境变量</span>\n    centos:7 <span>cat</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>也可以在 script{} 中运行容器：</p>\n<div><pre><code>script<span>{</span>\n    <span>// 运行一个容器，在 Groovy 中保存为 container1 对象</span>\n    docker<span>.</span><span>image</span><span>(</span><span>'mysql:5.7'</span><span>)</span><span>.</span><span>withRun</span><span>(</span><span>'-p 3306:3306'</span><span>)</span> <span>{</span> container1 <span>-></span>\n        <span>// 等待服务启动</span>\n        sh <span>\"\"\"\n            while ! curl 127.0.0.1:3306\n            do\n                echo 'Wait until service is up...'\n                sleep 1\n            done\n        \"\"\"</span>\n\n        <span>// 支持嵌套，从而同时运行多个容器</span>\n        docker<span>.</span><span>image</span><span>(</span><span>'centos:7'</span><span>)</span><span>.</span><span>inside</span><span>(</span><span>\"--link <span><span>$</span><span>{</span>container1<span>.</span>id<span>}</span></span>:db\"</span><span>)</span> <span>{</span>\n            sh <span>\"\"\"\n                sh test.sh\n            \"\"\"</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><ul>\n<li>withRun() 方法执行完之后会自动删除容器。</li>\n<li>inside() 方法启动容器时，会加上像 agent.docker 的默认配置。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"stages\"> stages{}</h2>\n<p>pipeline{} 流水线的主要内容写在 stages{} 中，其中可以定义一个或多个 stage{} ，表示执行的各个阶段。</p>\n<ul>\n<li>Jenkins 会按先后顺序执行各个 stage{} ，并在 Web 页面上显示执行进度。</li>\n<li>每个 stage{} 的名称不能重复。</li>\n<li>每个 stage{} 中有且必须定义一个以下类型的语句块：<div><pre><code>stages<span>{</span><span>}</span>\nsteps<span>{</span><span>}</span>\nmatrix<span>{</span><span>}</span>\nparallel<span>{</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>例：<div><pre><code>stages <span>{</span>\n    <span>stage</span><span>(</span><span>'测试 1'</span><span>)</span> <span>{</span>\n        steps <span>{</span><span>...</span><span>}</span>\n    <span>}</span>\n    <span>stage</span><span>(</span><span>'测试 2'</span><span>)</span> <span>{</span>\n        <span>stages</span><span>(</span><span>'嵌套阶段'</span><span>)</span> <span>{</span>\n            <span>stage</span><span>(</span><span>'单元测试 1'</span><span>)</span> <span>{</span>\n                steps <span>{</span><span>...</span><span>}</span>\n            <span>}</span>\n            <span>stage</span><span>(</span><span>'单元测试 2'</span><span>)</span> <span>{</span>\n                steps <span>{</span><span>...</span><span>}</span>\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n<h2 id=\"steps\"> steps{}</h2>\n<p>在 steps{} 中可以使用多种 DSL 语句。</p>\n<ul>\n<li><a href=\"https://www.jenkins.io/doc/pipeline/steps/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n</ul>\n<h3 id=\"archiveartifacts\"> archiveArtifacts</h3>\n<p>：用于将指定路径的文件归档。</p>\n<ul>\n<li>归档文件会被保存到 master 节点的 <code>$JENKINS_HOME/jobs/$JOB_NAME/builds/$BUILD_ID/archive/</code> 目录下。\n<ul>\n<li>可以在 Jenkins 的 job 页面查看、下载归档文件。</li>\n</ul>\n</li>\n<li>例：<div><pre><code>archiveArtifacts artifacts<span>:</span> <span>'dist.zip'</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>目标文件的路径可以使用通配符：<div><pre><code>target/*.jar\n**/*.log\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"bat\"> bat</h3>\n<p>：用于在 Windows 系统上执行 CMD 命令。</p>\n<h3 id=\"build\"> build</h3>\n<p>：用于执行一个 Job 。</p>\n<ul>\n<li>在流水线上，被执行的 job 位于当前 job 的下游。</li>\n<li>例：<div><pre><code>build <span>(</span>\n    job<span>:</span> <span>'job1'</span><span>,</span>\n    parameters<span>:</span> <span>[</span>\n        <span>string</span><span>(</span>name<span>:</span> <span>'AGENT'</span><span>,</span> value<span>:</span> <span>'master'</span><span>)</span><span>,</span>  <span>// 这里的 string 是指输入值的类型，可输入给大部分类型的 parameters</span>\n    <span>]</span>\n    <span>// wait: true,        // 是否等待下游 job 执行完毕，才继续执行当前 job</span>\n    <span>// propagate: true,   // 是否让下游 job 的构建结果影响当前 job 。需要启用 wait 才生效</span>\n    <span>// quietPeriod: 5,    // 设置静默期，默认为 5 秒</span>\n<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h3 id=\"checkout\"> checkout</h3>\n<p>：用于拉取代码仓库。</p>\n<ul>\n<li>\n<p>例：拉取 Git 仓库</p>\n<div><pre><code><span>checkout</span><span>(</span><span>[</span>\n    <span>$</span><span>class</span><span>:</span> <span>'GitSCM'</span><span>,</span>\n    branches<span>:</span> <span>[</span><span>[</span>name<span>:</span> <span>\"<span><span>$</span>BRANCH</span>\"</span><span>]</span><span>]</span><span>,</span>    <span>// 切换到指定的分支，也可以填 tag 或 commit ID 。不过该插件最终会切换到具体的 commit ID</span>\n    extensions<span>:</span> <span>[</span>\n      <span>[</span><span>$</span><span>class</span><span>:</span> <span>'CleanBeforeCheckout'</span><span>]</span><span>,</span>  <span>// 清理项目文件，默认启用。相当于 git clean -dfx 加 git reset --hard</span>\n      <span>// [$class: 'RelativeTargetDirectory', relativeTargetDir: '.'], // 本地仓库的保存目录，默认为 .</span>\n      <span>// [$class: 'CloneOption', shallow: true, depth: 1],            // 浅克隆，只下载最近 1 个版本的文件</span>\n      <span>// [$class: 'SubmoduleOption', recursiveSubmodules: true, parentCredentials: true, shallow: true, depth: 1], // 递归克隆 submodule ，采用父 Git 项目的凭据，并采用浅克隆</span>\n    <span>]</span><span>,</span>\n    userRemoteConfigs<span>:</span> <span>[</span><span>[</span>\n      credentialsId<span>:</span> <span>'account_for_git'</span><span>,</span> <span>// 登录 git 服务器的凭据，为 Username With Password 类型</span>\n      url<span>:</span> <span>\"<span><span>$</span>repository_url</span>\"</span>            <span>// git 远程仓库的地址</span>\n    <span>]</span><span>]</span>\n<span>]</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><ul>\n<li>也可直接执行 git 命令：<div><pre><code><span>withCredentials</span><span>(</span><span>[</span><span>gitUsernamePassword</span><span>(</span>credentialsId<span>:</span><span>'account_for_git'</span><span>)</span><span>]</span><span>)</span><span>{</span>  <span>// 这会自动绑定 git 账号密码到环境变量 GIT_USERNAME、GIT_PASSWORD</span>\n    sh <span>\"\"\"\n        git clone <span><span>$</span>repository_url</span>\n    \"\"\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>与直接使用 git 命令相比，使用 checkout 语句会将 git commit、diff 等信息收集到 Jenkins 中并显示。</li>\n</ul>\n</li>\n<li>\n<p>例：拉取 SVN 仓库</p>\n<div><pre><code><span>checkout</span><span>(</span><span>[</span>\n    <span>$</span><span>class</span><span>:</span> <span>'SubversionSCM'</span><span>,</span>\n    locations<span>:</span> <span>[</span><span>[</span>\n        remote<span>:</span> <span>\"<span><span>$</span>repository_url</span>\"</span>\n        credentialsId<span>:</span> <span>'account_for_svn'</span><span>,</span>\n        local<span>:</span> <span>'.'</span><span>,</span>                               <span>// 本地仓库的保存目录，默认是创建一个与 SVN 最后一段路径同名的子目录</span>\n        <span>// depthOption: 'infinity',               // 拉取的目录深度，默认是无限深</span>\n    <span>]</span><span>]</span><span>,</span>\n    quietOperation<span>:</span> <span>true</span><span>,</span>                         <span>// 不显示拉取代码的过程</span>\n    workspaceUpdater<span>:</span> <span>[</span><span>$</span><span>class</span><span>:</span> <span>'UpdateUpdater'</span><span>]</span>   <span>// 使本地目录更新到最新版本</span>\n<span>]</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n<h3 id=\"echo\"> echo</h3>\n<p>：用于显示字符串。</p>\n<ul>\n<li>例：<div><pre><code>steps <span>{</span>\n    echo <span>'Hello'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>echo 语句只能显示 String 类型的值，而使用 println 可以显示任意类型的值。</li>\n<li>打印字符串时，要加上双引号 &quot; 或单引号 ' 作为定界符（除非是纯数字组成的字符串），否则会被当作 Groovy 的变量名。\n<ul>\n<li>例如：<code>echo ID</code> 会被当作 <code>echo &quot;$ID&quot;</code> 执行。</li>\n<li>使用三引号 &quot;&quot;&quot; 或 ''' 包住时，可以输入换行的字符串。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"emailext\"> emailext</h3>\n<p>：用于发送邮件。</p>\n<ul>\n<li>需要先在 Jenkins 系统配置中配置 SMTP 服务器。</li>\n<li>例：<div><pre><code>emailext <span>(</span>\n    subject<span>:</span> <span>\"[<span><span>$</span><span>{</span>currentBuild<span>.</span>fullDisplayName<span>}</span></span>]的构建结果为<span><span>$</span><span>{</span>currentBuild<span>.</span>currentResult<span>}</span></span>\"</span><span>,</span>\n    from<span>:</span> <span>\"123456@email.com\"</span><span>,</span>\n    to<span>:</span> <span>'123456@email.com'</span><span>,</span>\n    body<span>:</span> <span>\"\"\"\n        任务名：<span><span>$</span><span>{</span>env<span>.</span>JOB_NAME<span>}</span></span>\n        任务链接：<span><span>$</span><span>{</span>env<span>.</span>JOB_URL<span>}</span></span>\n        构建编号：<span><span>$</span><span>{</span>env<span>.</span>BUILD_NUMBER<span>}</span></span>\n        构建链接：<span><span>$</span><span>{</span>env<span>.</span>BUILD_URL<span>}</span></span>\n        构建耗时：<span><span>$</span><span>{</span>currentBuild<span>.</span>duration<span>}</span></span> ms\n    \"\"\"</span>\n<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ul>\n<h3 id=\"error\"> error</h3>\n<p>：用于让 Job 立即终止，变为 Failure 状态，并显示一行提示文本。</p>\n<ul>\n<li>例：<div><pre><code>error <span>'任务执行出错'</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"lock\"> lock</h3>\n<p>：用于获取一个全局锁，可避免并发任务同时执行时冲突。</p>\n<ul>\n<li>可用范围：steps{}、options{}</li>\n<li>该功能由插件 Lockable Resources 提供。</li>\n<li>例：<div><pre><code><span>lock</span><span>(</span><span>'resource_1'</span><span>)</span> <span>{</span>    <span>// 锁定一个名为 resource-1 的资源。如果该资源不存在则自动创建（任务结束之后会删除）。如果该资源已经被锁定，则一直等待获取</span>\n    sleep <span>10</span>            <span>// 获取锁之后，执行一些语句</span>\n    echo <span>'done'</span>\n<span>}</span>                       <span>// 执行完之后，会自动释放锁定的资源</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>lock 函数的可用参数如下：<div><pre><code><span>lock</span><span>(</span>resource<span>:</span> <span>'resource_1'</span><span>,</span>        <span>// 要锁定的资源名</span>\n      <span>// label: 'my_resource',      // 通过标签筛选锁定多个资源</span>\n      <span>// quantity: 0,               // 至少要锁定的资源数量、默认为 0 ，表示锁定所有</span>\n      <span>// variable: 'LOCK',          // 将资源名赋值给一个变量</span>\n      <span>// inversePrecedence: false,  // 如果有多个任务在等待获取锁，是否插队到第一个</span>\n      <span>// skipIfLocked: false        // 如果需要等待获取锁，是否跳过执行</span>\n      <span>)</span> <span>{</span>\n    <span>...</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h3 id=\"retry\"> retry</h3>\n<p>：用于当任务执行失败时（不包括语法错误），自动重试。</p>\n<ul>\n<li>例：<div><pre><code><span>retry</span><span>(</span><span>3</span><span>)</span> <span>{</span>       <span>// 最多尝试执行 3 次（包括第一次执行）</span>\n    sh <span>'ls /tmp/f1'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n<h3 id=\"script\"> script</h3>\n<p>：用于执行 Groovy 代码。</p>\n<ul>\n<li>\n<p>可以用赋值号 = 直接创建变量。如下：</p>\n<div><pre><code>steps <span>{</span>\n    script <span>{</span>\n        A <span>=</span> <span>1</span>\n    <span>}</span>\n    echo <span>\"<span><span>$</span>A</span>\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>在 script{} 中创建的变量会在 Groovy 解释器中一直存在，因此在该 script{} 甚至该 stage{} 结束之后依然可以读取，但并不会被 Jenkins 加入到 shell 的环境变量中。</li>\n</ul>\n</li>\n<li>\n<p>例：将 shell 命令执行后的 stdout 或返回码赋值给变量</p>\n<div><pre><code>script <span>{</span>\n    STDOUT <span>=</span> <span>sh</span><span>(</span>script<span>:</span> <span>'echo hello'</span><span>,</span> returnStdout<span>:</span> <span>true</span><span>)</span><span>.</span><span>trim</span><span>(</span><span>)</span>\n    EXIT_CODE <span>=</span> <span>sh</span><span>(</span>script<span>:</span> <span>'echo hello'</span><span>,</span> returnStatus<span>:</span> <span>true</span><span>)</span>\n    echo <span>\"<span><span>$</span>STDOUT</span>\"</span>\n    echo <span>\"<span><span>$</span>EXIT_CODE</span>\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>例：从 shell 中获得数组并遍历它</p>\n<div><pre><code>script <span>{</span>\n    FILE_LIST <span>=</span> <span>sh</span><span>(</span>script<span>:</span> <span>\"ls /\"</span><span>,</span> returnStdout<span>:</span> <span>true</span><span>)</span>\n    <span>for</span> <span>(</span>f <span>in</span> FILE_LIST<span>.</span><span>tokenize</span><span>(</span><span>\"\\n\"</span><span>)</span><span>)</span><span>{</span>\n        sh <span>\"echo <span><span>$</span>f</span>\"</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>.tokenize() 方法用于将字符串分割成多个字段的数组，并忽略内容为空的字段。</li>\n</ul>\n</li>\n<li>\n<p>例：捕捉异常</p>\n<div><pre><code>script <span>{</span>\n    <span>try</span> <span>{</span>\n        sh <span>'exit 1'</span>\n    <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>     <span>// 将异常捕捉之后，构建状态就会依然为 SUCCESS</span>\n        echo <span>\"<span><span>$</span><span>{</span>err<span>}</span></span>\"</span>\n    <span>}</span> <span>finally</span> <span>{</span>\n        echo <span>\"finished\"</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><ul>\n<li>也可以用 post{} 语句块实现异常处理。</li>\n</ul>\n</li>\n<li>\n<p>例：修改 Job 的描述</p>\n<div><pre><code>script <span>{</span>\n    currentBuild<span>.</span>rawBuild<span>.</span>project<span>.</span>description <span>=</span> <span>'Hello'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>执行时可能报错：<code>RejectedAccessException: Scripts not permitted to use method xxx</code> <br>\n需要到 Jenkins 管理页面，点击 <code>Script Approval</code> ，批准该方法被脚本调用。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"sh\"> sh</h3>\n<p>：用于执行 shell 命令。</p>\n<ul>\n<li>例：<div><pre><code>steps <span>{</span>\n    sh <span>\"echo Hello\"</span>\n    sh <span>'echo World'</span>\n    sh <span>\"\"\"\n        A=1\n        echo <span><span>$</span>A</span>     // 这会读取 Groovy 解释器中的变量 A\n    \"\"\"</span>\n    sh <span>'''\n        A=1\n        echo $A     // 这会读取 shell 中的变量 A\n    '''</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n<li>每个 sh 语句会被 Jenkins 保存为一个临时的 x.sh 文件，用 <code>/bin/bash -ex x.sh</code> 的方式执行，且切换到该 Job 的工作目录。\n<ul>\n<li>因此各个 sh 语句之间比较独立、解耦。</li>\n<li>因此会记录下执行的每条 shell 命令及其输出。例如执行以下 sh 语句：<div><pre><code>sh <span>\"\"\"\n    echo Hello 你好         # 建议不要在 sh 语句中通过 echo 命令添加注释，因为该注释会打印一次，执行命令时又会记录一次，而且命令中包含中文时还会转码\n    : 测试开始               # 可通过 : 命令加入注释\n    comment=( 测试开始 )     # 可通过数组加入注释，此时数组内的中文不会转码\n\"\"\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div>执行后的 Console Output 为：<div><pre><code>+ <span>echo</span> Hello <span>$'<span title=\"\\344\">\\344</span><span title=\"\\275\">\\275</span><span title=\"\\240\">\\240</span><span title=\"\\345\">\\345</span><span title=\"\\245\">\\245</span><span title=\"\\275\">\\275</span>'</span>\nHello 你好\n+ <span>:</span> 测试开始\n+ <span>comment</span><span>=</span><span>(</span> 测试开始 <span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>每次执行 sh 语句需要耗时 300ms ，因此建议将多个 sh 语句合并。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"timeout\"> timeout</h3>\n<p>：用于设置超时时间。</p>\n<ul>\n<li>超时之后则立即终止 Job ，变为 ABORTED 状态。</li>\n<li>例：<div><pre><code><span>timeout</span><span>(</span>time<span>:</span> <span>3</span><span>,</span> unit<span>:</span> <span>'SECONDS'</span><span>)</span> <span>{</span>     <span>// 时间单位可以是 SECONDS、MINUTES、HOURS</span>\n    sh <span>'ping baidu.com'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n<h3 id=\"waituntil\"> waitUntil</h3>\n<p>：用于暂停执行任务，直到满足特定的条件。</p>\n<ul>\n<li>例：<div><pre><code>waitUntil <span>{</span>\n    fileExists <span>'/tmp/f1'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n<h3 id=\"withcredentials\"> withCredentials</h3>\n<p>：用于调用 Jenkins 的凭据。</p>\n<ul>\n<li>例：<div><pre><code><span>withCredentials</span><span>(</span><span>[</span>\n    <span>usernamePassword</span><span>(</span>\n        credentialsId<span>:</span> <span>'credential_1'</span><span>,</span>\n        usernameVariable<span>:</span> <span>'USERNAME'</span><span>,</span>   <span>// 将凭据的值存到变量中（如果在终端显示该变量的值，Jenkins 会自动隐藏）</span>\n        passwordVariable<span>:</span> <span>'PASSWORD'</span>\n    <span>)</span><span>]</span><span>)</span> <span>{</span>\n    sh <span>'''                              // 此时 sh 语句需要用单引号，避免票据变量被导入 shell 的环境变量\n        docker login -u ${USERNAME} -p ${PASSWORD} ${image_hub}\n    '''</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n</ul>\n<h3 id=\"withenv\"> withEnv</h3>\n<p>：用于给 sh 语句添加环境变量。</p>\n<ul>\n<li>例：<div><pre><code><span>withEnv</span><span>(</span><span>[</span><span>'A=Hello'</span><span>,</span> <span>'B=World'</span><span>]</span><span>)</span> <span>{</span>\n      sh <span>'echo $A $B'</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>执行 pipeline 时，默认会将环境变量、params 字典、env 字典等变量，通过 withEnv 添加到 sh 语句的环境变量中。</li>\n</ul>\n<h2 id=\"matrix\"> matrix{}</h2>\n<p>：包含一个 axes{} 和 stages{} ，用于将一个 stages{} 在不同场景下并行执行一次，相当于执行多个实例。</p>\n<ul>\n<li>可用范围：stage{}</li>\n<li>每个并行任务称为一个 Branch 。\n<ul>\n<li>只要有一个并行执行的任务失败了，最终结果就是 Failure 。</li>\n</ul>\n</li>\n<li>例：<div><pre><code>matrix <span>{</span>\n    axes <span>{</span>\n        axis <span>{</span>\n            name <span>'PLATFORM'</span>\n            values <span>'linux'</span><span>,</span> <span>'darwin'</span><span>,</span> <span>'windows'</span>\n        <span>}</span>\n        axis <span>{</span>\n            name <span>'PYTHON_VERSION'</span>\n            values <span>'3.5'</span><span>,</span> <span>'3.6'</span><span>,</span> <span>'3.7'</span><span>,</span> <span>'3.8'</span>\n        <span>}</span>\n    <span>}</span>\n    stages <span>{</span>\n        <span>stage</span><span>(</span><span>'单元测试'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo PLATFORM\n                echo PYTHON_VERSION\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><ul>\n<li>axes{} 用于定义并发任务的矩阵，可以包含多个 axis{} 。\n<ul>\n<li>每个 axis{} 用于定义一个矩阵变量。</li>\n<li>上例中定义了两个 axis{} ，矩阵变量 PLATFORM、PYTHON_VERSION 分别有 3、4 种取值，因此会执行 3*4=12 个并发任务。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"parallel\"> parallel{}</h2>\n<p>：包含多个 stage{} ，用于并行执行多个任务。</p>\n<ul>\n<li>可用范围：stage{}</li>\n<li>例：<div><pre><code><span>stage</span><span>(</span><span>'单元测试'</span><span>)</span> <span>{</span>\n    parallel <span>{</span>\n        <span>stage</span><span>(</span><span>'单元测试 1'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo <span>'测试完成'</span>\n            <span>}</span>\n        <span>}</span>\n        <span>stage</span><span>(</span><span>'单元测试 2'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo <span>'测试完成'</span>\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<h2 id=\"options\"> options{}</h2>\n<p>：用于给 Pipeline 添加一些可选配置。</p>\n<ul>\n<li>可用范围：pipeline{}、stage{}</li>\n<li>例：<div><pre><code>options <span>{</span>\n    buildDiscarder <span>logRotator</span><span>(</span>daysToKeepStr<span>:</span> <span>'30'</span><span>,</span>          <span>// 限制 build 记录的保留天数</span>\n                              numToKeepStr<span>:</span> <span>'100'</span><span>,</span>          <span>// 限制 build 记录的保留数量</span>\n                              artifactDaysToKeepStr<span>:</span> <span>'10'</span><span>,</span>  <span>// 限制 build 归档文件的保留天数。删除一次 build 记录时，也会删除其包含的 archive</span>\n                              artifactNumToKeepStr<span>:</span> <span>'10'</span><span>)</span>   <span>// 限制 build 归档文件的保留数量</span>\n\n    <span>disableConcurrentBuilds</span><span>(</span><span>)</span>           <span>// 不允许同时执行该 job ，会排队执行</span>\n    <span>lock</span><span>(</span><span>'resource-1'</span><span>)</span>                  <span>// 获取全局锁（此时不支持附加语句块）</span>\n    <span>parallelsAlwaysFailFast</span><span>(</span><span>)</span>           <span>// 用 matrix{}、parallel{} 执行并发任务时，如果有某个任务失败，则立即放弃执行其它任务</span>\n    <span>quietPeriod</span><span>(</span><span>5</span><span>)</span>                      <span>// 设置静默期，默认为 5 秒</span>\n    <span>retry</span><span>(</span><span>3</span><span>)</span>\n    <span>timeout</span><span>(</span>time<span>:</span> <span>60</span><span>,</span> unit<span>:</span> <span>'SECONDS'</span><span>)</span>\n    <span>timestamps</span><span>(</span><span>)</span>                        <span>// 输出内容到终端时，加上时间戳</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<h2 id=\"triggers\"> triggers{}</h2>\n<p>：用于在满足条件时自动触发 Pipeline 。</p>\n<ul>\n<li>可用范围：pipeline{}</li>\n<li>例：<div><pre><code>triggers <span>{</span>\n    <span>cron</span><span>(</span><span>'H */4 * * 1-5'</span><span>)</span>       <span>// 定期触发。其中 H 表示一个随机值，用于分散执行多个同时触发的任务</span>\n    <span>pollSCM</span><span>(</span><span>'H */4 * * 1-5'</span><span>)</span>    <span>// 定期检查 SCM 仓库，如果提交了新版本代码则构建一次</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h2 id=\"when\"> when{}</h2>\n<p>：用于在满足条件时才执行某个 stage 。</p>\n<ul>\n<li>可用范围：stage{}</li>\n<li>不满足 when{} 的条件时，会跳过执行该 stage ，但并不会导致执行状态变为 Failure 。</li>\n<li>例：<div><pre><code>when <span>{</span>\n    environment name<span>:</span> <span>'A'</span><span>,</span> value<span>:</span> <span>'1'</span>  <span>// 当环境变量等于指定值时</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><div><pre><code>when <span>{</span>\n    expression <span>{</span>            <span>// 当 Groovy 表达式为 true 时</span>\n        currentBuild<span>.</span>currentResult <span>==</span> <span>'SUCCESS'</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><div><pre><code>when <span>{</span>\n    not <span>{</span>                   <span>// 当子条件为 false 时</span>\n        environment name<span>:</span> <span>'A'</span><span>,</span> value<span>:</span> <span>'1'</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><div><pre><code>when <span>{</span>\n    allOf <span>{</span>                 <span>// 当子条件都为 true 时</span>\n        environment name<span>:</span> <span>'A'</span><span>,</span> value<span>:</span> <span>'1'</span>\n        environment name<span>:</span> <span>'B'</span><span>,</span> value<span>:</span> <span>'2'</span>\n    <span>}</span>\n    anyOf <span>{</span>                 <span>// 当任一子条件为 true 时</span>\n        environment name<span>:</span> <span>'A'</span><span>,</span> value<span>:</span> <span>'1'</span>\n        environment name<span>:</span> <span>'B'</span><span>,</span> value<span>:</span> <span>'2'</span>\n    <span>}</span>\n    <span>// when{} 子句中的多个条件默认为 allOf{} 的关系</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>environment 表达式只能处理环境变量，而 expression{} 能处理环境变量、普通变量。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"input\"> input{}</h2>\n<p>：用于暂停某个阶段的执行，等待用户输入某些参数。</p>\n<ul>\n<li>可用范围：stage{}</li>\n<li>例：<div><pre><code>input <span>{</span>\n    message <span>'等待输入...'</span>\n    ok <span>'确定'</span>\n    submitter <span>'admin, ops'</span>  <span>// 限制有输入权限的用户</span>\n    parameters <span>{</span>            <span>// 等待用户输入以下参数</span>\n        <span>string</span><span>(</span>name<span>:</span> <span>'NODE'</span><span>,</span> defaultValue<span>:</span> <span>'master'</span><span>,</span> description<span>:</span> <span>'部署到哪个节点？'</span><span>)</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n<h2 id=\"post\"> post{}</h2>\n<p>：用于当构建状态满足某些条件时，才执行操作。</p>\n<ul>\n<li>可用范围：pipeline{}、stage{}</li>\n<li>pipeline 出现语法错误时，Jenkins 会直接报错，而不会执行 post 部分。</li>\n<li>可用条件：<div><pre><code>success       <span># 状态为成功</span>\nfailure       <span># 失败</span>\nunstable      <span># 不稳定</span>\naborted       <span># 放弃执行</span>\n\nunsuccessful  <span># 不成功，包括 failure、unstable、aborted</span>\nalways        <span># 匹配任何状态</span>\ncleanup       <span># 匹配任何状态，且放在其它所有 post 条件之后执行，通常用于清理</span>\nchanged       <span># 与上一次执行的状态不同</span>\nregression    <span># 状态为 failure、unstable 或 aborted ，且上一次执行的状态为 success</span>\nfixed         <span># 状态为 success ，且上一次执行的状态为 failure 或 unstable</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n<li>例：<div><pre><code>pipeline <span>{</span>\n    agent any\n    stages <span>{</span>\n        <span>stage</span><span>(</span><span>'Test'</span><span>)</span> <span>{</span>\n            steps <span>{</span>\n                echo <span>'testing ...'</span>\n            <span>}</span>\n        <span>}</span>\n    <span>}</span>\n    post <span>{</span>\n        success <span>{</span>\n            echo <span>'执行成功'</span>\n        <span>}</span>\n        failure <span>{</span>\n            echo <span>'执行失败'</span>\n        <span>}</span>\n        unstable <span>{</span>\n            echo <span>'执行状态不稳定'</span>\n        <span>}</span>\n        aborted <span>{</span>\n            echo <span>'放弃执行'</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "CI-CD",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/CI-CD/",
      "id": "/Hardware/DevOps/CI-CD/",
      "content_html": "<h1 id=\"ci-cd\"> CI-CD</h1>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Ansible",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/Ansible.html",
      "id": "/Hardware/DevOps/ConfigurationManagement/Ansible.html",
      "content_html": "<h1 id=\"ansible\"> Ansible</h1>\n<p>：一个命令行工具，用于批量管理主机、批量执行脚本。</p>\n<ul>\n<li><a href=\"https://docs.ansible.com/ansible/latest/user_guide/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Python 开发。于 2012 年发布，2015 年被红帽公司收购。</li>\n<li>采用主从架构，比较轻量级。\n<ul>\n<li>选取一个或多个主机安装 Ansible ，作为控制节点（Control node），负责控制其它远程主机。</li>\n<li>远程主机只需要能通过 SSH 登录，即可供 Ansible 执行 shell 命令。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装\"> 安装</h2>\n<ul>\n<li>用 pip 安装 Ansible ：<div><pre><code>yum <span>install</span> python36 sshpass libselinux-python    <span># 安装依赖</span>\npip3 <span>install</span> ansible\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h2 id=\"命令\"> 命令</h2>\n<h3 id=\"ansible-2\"> ansible</h3>\n<div><pre><code>ansible \n        <span>&lt;</span>pattern<span>></span> <span>[</span>-m <span>&lt;</span>name<span>></span><span>]</span> <span>[</span>-a <span>&lt;</span>args<span>></span><span>]</span>  <span># 在远程主机上执行一个模块（默认是采用 command 模块），并给模块传入参数</span>\n        --version                          <span># 显示版本、配置文件的位置</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>pattern 是一个字符串，用于匹配 host 或组名，如果匹配结果为空则不执行任务。\n<ul>\n<li>默认可使用 shell 风格的通配符，以 ~ 开头时则视作正则表达式。</li>\n</ul>\n</li>\n<li>例：<div><pre><code>ansible all -m <span>ping</span>           <span># 测试连接所有 host</span>\nansible all -a <span>ls</span>\nansible <span>10.0</span>.* -m shell -a <span>\"pwd\"</span>\nansible ~10.0.0.<span>(</span><span>1</span><span>|</span><span>2</span><span>)</span> -m shell -a <span>\"pwd\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"ansible-playbook\"> ansible-playbook</h3>\n<div><pre><code>ansible-playbook <span>&lt;</span>name<span>></span>.yml<span>..</span>.       <span># 执行 playbook</span>\n                -i <span>&lt;</span>file<span>></span>            <span># 指定 Inventory 文件</span>\n                -e <span>\"A=Hello B=World\"</span> <span># 传入变量</span>\n                -t tag1,tag2,tag3    <span># 只执行具有某些 tag 的 task</span>\n                --skip-tags tag1     <span># 不执行具有某些 tag 的 task</span>\n                -v                   <span># 显示详细的执行信息</span>\n                -vvv                 <span># 显示更详细的信息</span>\n\n                --syntax-check       <span># 不执行，只是检查 playbook 的语法是否正确</span>\n                --list-hosts         <span># 不执行，只是列出所有 host</span>\n                --list-task          <span># 不执行，只是列出所有 task</span>\n                --list-tags          <span># 不执行，只是列出所有 tag</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><h2 id=\"配置\"> 配置</h2>\n<p>执行 ansible 命令时，会按以下顺序查找配置文件：</p>\n<ul>\n<li><code>$ANSIBLE_CONFIG</code></li>\n<li><code>./ansible.cfg</code></li>\n<li><code>~/.ansible.cfg</code></li>\n<li><code>/etc/ansible/ansible.cfg</code></li>\n</ul>\n<p>配置示例：</p>\n<div><pre><code><span><span>[</span><span>defaults</span><span>]</span></span>\n<span># inventory = /etc/ansible/hosts      # Inventory 文件的路径</span>\n<span>log_path</span> <span>=</span> <span>/var/log/ansible.log       # 记录每次执行 ansible 的 stdout（默认不保存日志）</span>\n<span># forks = 5                           # 同时最多执行多少个任务</span>\n<span>host_key_checking</span> <span>=</span> <span>False             # 进行 SSH 连接时不检查远程主机的密钥是否与 ~/.ssh/known_hosts 中记录的一致</span>\n<span># remote_tmp = $HOME/.ansible/tmp     # 登录远程主机时使用的工作目录</span>\n<span># interpreter_python = auto_legacy    # 远程主机上的 Python 解释器的路径，用于执行 Ansible 模块</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>auto_legacy 表示默认使用 <code>/usr/bin/python</code> ，如果不存在则查找其它 Python 路径。</li>\n</ul>\n<h2 id=\"inventory\"> Inventory</h2>\n<p>Ansible 将待管理主机（称为 host）的配置信息保存在 .ini 文件中，称为 Inventory（资产清单）。</p>\n<p>配置示例：</p>\n<div><pre><code><span>localhost ansible_connection</span><span>=</span><span>local    # 定义一个不分组的 host ，连接方式为本机</span>\n\n<span><span>[</span><span>web_nodes</span><span>]</span></span>                           # 定义一个组，名为 web_nodes\nwww.example.com                       # 添加一个 host 的地址\n10.0.0.1\n<span>node100 ansible_host</span><span>=</span><span>10.0.0.2         # 添加一个 host 的名字、地址</span>\n\n<span><span>[</span><span>web_nodes:vars</span><span>]</span></span>                      # 设置组 web_nodes 的参数\n<span># ansible_connection=ssh              # Ansible 的连接方式</span>\n<span># ansible_ssh_port=22                 # SSH 登录时的端口号</span>\n<span>ansible_ssh_user</span><span>=</span><span>'root'               # SSH 登录时的用户名</span>\n<span>ansible_ssh_pass</span><span>=</span><span>'123456'             # SSH 登录时的密码（使用该项需要安装 sshpass）</span>\n<span># ansible_ssh_private_key_file='~/.ssh/id_rsa'   # 用密钥文件进行 SSH 登录</span>\n<span># ansible_become=false                # SSH 登录之后是否切换用户</span>\n<span># ansible_become_method=sudo          # 切换用户的方式</span>\n<span># ansible_become_user=root            # 切换到哪个用户</span>\n<span># ansible_become_pass='123456'        # 用 sudo 切换用户时的密码</span>\n<span># ansible_python_interpreter=/usr/bin/python</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>host 的地址可以为 IP 、域名或主机名，只要能被 SSH 连接。\n<ul>\n<li>特别地， <code>ansible_connection=local</code> 代表直接连接本机，不会采用 SSH 连接的配置参数。</li>\n</ul>\n</li>\n<li>一个 host 可以同时属于多个组，甚至一个组可以是另一个组的成员。\n<ul>\n<li>默认有两个隐式的分组：\n<ul>\n<li>all ：包含所有 host 。</li>\n<li>ungrouped ：包含所有未分组的 host 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>组名支持通过下标进行索引、切片，如下：<div><pre><code>web_nodes[0]    # 选取第一个 host\nweb_nodes[0:4]  # 选取第 0 ~ 4 个 host （包括第 4 个）\nweb_nodes[-1]\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>Inventory 文件中以明文形式存储 SSH 密钥，需要小心泄露。比如将 Ansible 目录设置为只允许 root 用户访问：<div><pre><code><span>chmod</span> -R <span>go</span><span>=</span>- /etc/ansible\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"playbook\"> Playbook</h2>\n<p>Ansible 将待执行任务（称为 task）的配置信息保存在 .yml 文件中，称为 Playbook 。</p>\n<p>配置示例：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> Test                             <span># 定义一个 playbook</span>\n  <span>hosts</span><span>:</span> 10.0.*                          <span># 是一个 pattern ，用于匹配要管理的 host 或 组</span>\n  <span># gather_facts: true</span>\n  <span>tasks</span><span>:</span>                                 <span># 任务列表</span>\n    <span>-</span> <span>name</span><span>:</span> test echo                    <span># 第一个任务（如果不设置 name ，会默认设置成模块名）</span>\n      <span>shell</span><span>:</span> echo Hello                  <span># 调用 shell 模块</span>\n    <span>-</span> <span>name</span><span>:</span> start httpd                  <span># 第二个任务</span>\n      <span>service</span><span>:</span> name=httpd state=started  <span># 调用 service 模块</span>\n      <span>notify</span><span>:</span>                            <span># 执行一个 handler</span>\n        <span>-</span> stop httpd\n    <span>handlers</span><span>:</span>                            <span># 定义 handlers</span>\n      <span>-</span> <span>name</span><span>:</span> stop httpd\n        <span>service</span><span>:</span> name=httpd state=stop\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>每个 .yml 文件中可以定义一组 playbook ，每个 playbook 中可以定义一组 task 。\n<ul>\n<li>定义 playbook 时，只有 hosts 是必填项。</li>\n</ul>\n</li>\n<li>执行一个 playbook 时，Ansible 会逐个提取其中的 task ，在所有 host 上并行执行。\n<ul>\n<li>等所有 host 都执行完当前 task 之后，才执行下一个 task 。</li>\n<li>如果某个 task 执行之后的返回值不为 0 ，Ansible 就会终止执行并报错。</li>\n</ul>\n</li>\n<li>playbook 中默认执行的第一个任务是 Gathering Facts ，收集 host 的信息。处理大量 host 时，设置 <code>gather_facts: false</code> 可以节省一些时间。</li>\n<li>handler 与 task 类似，由某个 task 通过 notify 激活，在所有 tasks 都执行完之后才会执行，且只会执行一次。</li>\n</ul>\n<h3 id=\"task\"> task</h3>\n<ul>\n<li>\n<p>task 是 Ansible 执行任务的基本单位，而模块是 Ansible 执行任务的基本方式。每个 task 通过调用一个模块来实现某种操作。</p>\n</li>\n<li>\n<p>Ansible 在执行 task 时，会为每个 host 创建一个子进程，然后通过 SSH 连接到 host ，执行任务。进程树如下：</p>\n<div><pre><code>-bash\n<span>\\</span>_ /usr/bin/python3 /usr/local/bin/ansible web_nodes -m shell -a <span>ping</span> localhost\n    <span>\\</span>_ /usr/bin/python3 /usr/local/bin/ansible web_nodes -m shell -a <span>ping</span> localhost\n    <span>|</span>   <span>\\</span>_ sshpass -d11 <span>ssh</span> -C -o <span>ControlMaster</span><span>=</span>auto -o <span>ControlPersist</span><span>=</span>60s -o <span>StrictHostKeyChecking</span><span>=</span>no -o <span>User</span><span>=</span><span>\"root\"</span> -o ConnectTi\n<span>meout</span><span>=</span><span>10</span> -o <span>ControlPath</span><span>=</span>/root/.ansible/cp/5d2a6a8c55 -tt <span>10.0</span>.0.1 /bin/sh -c <span>'/usr/bin/python2.7 /root/.ansible/tmp/ansible-tmp-1619313582.094223-15190-6242900803349/AnsiballZ_command.py &amp;&amp; sleep 0'</span>\n    <span>\\</span>_ /usr/bin/python3 /usr/local/bin/ansible web_nodes -m shell -a <span>ping</span> localhost\n        <span>\\</span>_ sshpass <span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>执行每个 task 时，会生成一个临时的 .py 文件，拷贝到 host 上，用 python 解释器执行。</li>\n</ul>\n</li>\n<li>\n<p>可以给 playbook 或 task 设置 become 选项，用于控制在 SSH 登录之后是否切换用户。如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> Test\n  <span>hosts</span><span>:</span> localhost\n  <span># become: yes               # 默认在 SSH 登录之后会切换用户</span>\n  <span># become_user: root         # 默认切换到 root 用户</span>\n  <span>tasks</span><span>:</span>\n    <span>-</span> <span>shell</span><span>:</span> echo Hello\n      <span># become: yes</span>\n      <span># become_user: root</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>不支持在 shell 模块中执行 su 命令切换用户，否则会阻塞。但可以执行 sudo 命令，或者通过 become 选项切换用户。</li>\n</ul>\n</li>\n<li>\n<p>可以给 task 加上 when 条件选项，当满足条件时才执行该 task ，否则跳过该 task 。如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> test echo\n  <span>shell</span><span>:</span> echo <span>{</span><span>{</span>A<span>}</span><span>}</span>\n  <span>when</span><span>:</span>\n    <span>-</span> A is defined                                 <span># 如果变量 A 已定义</span>\n    <span>-</span> A <span>|</span> int <span>></span>= 1                                 <span># 将变量 A 转换成 int 类型再比较大小</span>\n    <span>-</span> ( A == '1' ) or (A == 'Hello' and B == '2')  <span># 使用逻辑运算符</span>\n    <span>-</span> not (A == '2' and B == \"2\")\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>注意 <code>1</code> 表示数字 1 ，而 <code>'1'</code> 表示字符串 1 。</li>\n<li>判断变量的值时，如果该变量未定义，则会报错。</li>\n</ul>\n</li>\n<li>\n<p>task 可以通过 with_items 选项迭代一组 item 变量，每次迭代就循环执行一次模块。如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> test echo\n  <span>shell</span><span>:</span> echo <span>{</span><span>{</span>item<span>}</span><span>}</span>\n  <span>with_items</span><span>:</span>\n    <span>-</span> Hello\n    <span>-</span> World\n<span>-</span> <span>name</span><span>:</span> test echo\n  <span>shell</span><span>:</span> echo <span>{</span><span>{</span>item.value<span>}</span><span>}</span> <span>{</span><span>{</span>item.length<span>}</span><span>}</span>\n  <span>with_items</span><span>:</span>\n    <span>-</span> <span>{</span><span>src</span><span>:</span> A<span>,</span> <span>dest</span><span>:</span> <span>1</span><span>}</span>\n    <span>-</span> <span>src</span><span>:</span> B\n      <span>dest</span><span>:</span> <span>2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n<h3 id=\"tags\"> tags</h3>\n<ul>\n<li>\n<p>可以给 playbook 或 task 声明 tags 选项，从而允许只执行具有特定标签的任务。如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> Test\n  <span>hosts</span><span>:</span> localhost\n  <span>tags</span><span>:</span> test\n  <span>tasks</span><span>:</span>\n    <span>-</span> <span>shell</span><span>:</span> echo step1\n      <span>tags</span><span>:</span>                     <span># 按 YAML 列表的格式定义标签</span>\n        <span>-</span> debug\n\n    <span>-</span> <span>shell</span><span>:</span> echo step2\n      <span>tags</span><span>:</span> debug<span>,</span> test         <span># 按逗号分隔符的格式定义标签</span>\n\n    <span>-</span> <span>shell</span><span>:</span> echo step3\n      <span>tags</span><span>:</span> <span>[</span><span>\"debug\"</span><span>,</span> <span>\"never\"</span><span>]</span>  <span># 按数组的格式定义标签</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>playbook 的标签会被它的所有 task 继承。</li>\n<li>never 标签默认不会被执行，除非被指定执行。</li>\n<li>always 标签总是会被执行，除非被 --skip-tags 指定跳过。</li>\n</ul>\n</li>\n<li>\n<p>例如：<code>ansible-playbook test.yml -t debug</code> 表示只执行具有 debug 标签的内容。</p>\n<ul>\n<li>如果不输入 -t 选项，则默认会输入 <code>-t all</code> ，选中所有标签。</li>\n<li>如果输入 -t 选项，且指定的标签在 playbook 中并不存在，则不会执行任何 task 。（除非具有 always 标签）</li>\n<li>输入 <code>-t tagged</code> 会执行所有打了标签的，输入 <code>-t untagged</code> 会执行所有没打标签的。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"vars\"> vars</h3>\n<ul>\n<li>Ansible 支持在 playbook 中定义变量并调用。如下：<div><pre><code><span>-</span> <span>name</span><span>:</span> Test\n  <span>hosts</span><span>:</span> 10.0.*\n  <span>vars</span><span>:</span>                   <span># 定义变量</span>\n    <span>-</span> <span>tips</span><span>:</span> Hello         <span># 定义键值对类型的变量</span>\n    <span>-</span> <span>service</span><span>:</span>            <span># 定义字典类型的变量</span>\n        <span>name</span><span>:</span> httpd\n        <span>port</span><span>:</span> <span>80</span>\n  <span># vars_files:           # 从文件中导入变量</span>\n  <span>#   - external_vars.yml</span>\n  <span>tasks</span><span>:</span>\n    <span>-</span> <span>name</span><span>:</span> test echo\n      <span>shell</span><span>:</span> echo <span>{</span><span>{</span>tips<span>}</span><span>}</span>\n    <span>-</span> <span>name</span><span>:</span> start httpd\n      <span>service</span><span>:</span> name=<span>{</span><span>{</span>service.name<span>}</span><span>}</span> state=started\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<div><ul>\n<li>Ansible 采用 Jinja2 模板语言渲染 playbook ，因此其中的变量要使用 <code>{{var}}</code> 的格式取值。\n<ul>\n<li>不过在 YAML 文件中，如果该变量独占一个字段，则需要用 <code>&quot;{{var}}&quot;</code> 的格式取值，否则不会被 YAML 视作字符串，导致语法错误。</li>\n<li>如果读取的变量不存在，则会报错，而不会默认取值为空。</li>\n</ul>\n</li>\n</ul>\n</div><ul>\n<li>\n<p>启动 playbook 时，可以用 <code>ansible-playbook test.yml -e &quot;tips=Hello&quot;</code> 的格式传入外部变量，这会覆盖同名的内部变量。</p>\n</li>\n<li>\n<p>变量名只能包含字母、数字、下划线，且只能以字母开头。</p>\n</li>\n<li>\n<p>字典类型的变量可以用以下两种格式取值：</p>\n<div><pre><code>echo <span>{</span><span>{</span>service.name<span>}</span><span>}</span>       <span># 这种格式的缺点是：key 的名字不能与 Python 中字典对象的成员名冲突</span>\necho <span>{</span><span>{</span>service<span>[</span><span>'name'</span><span>]</span><span>}</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>变量的值允许换行输入，如下：</p>\n<div><pre><code><span>vars</span><span>:</span>\n  <span>-</span> <span>text</span><span>:</span> <span>|</span><span>\n      Hello\n        World\n      # 注意缩进到这个位置</span>\n<span>tasks</span><span>:</span>\n  <span>-</span> <span>shell</span><span>:</span> echo \"<span>{</span><span>{</span>text<span>}</span><span>}</span>\" <span>></span><span>></span> f1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>Ansible 提供了一些内置变量。如下：</p>\n<div><pre><code><span>debug</span><span>:</span>\n  <span>var</span><span>:</span> inventory_hostname         <span># 获取当前 host 的名称</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>获取指定 host 的配置变量：</p>\n<div><pre><code>hostvars<span>[</span><span>'localhost'</span><span>]</span>             <span># 一个字典</span>\nhostvars<span>[</span><span>'localhost'</span><span>]</span><span>[</span><span>'inventory_hostname'</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>获取从当前 host 收集的信息：</p>\n<div><pre><code>ansible_facts                     <span># 一个字典</span>\nansible_facts<span>[</span><span>'distribution'</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>Ansible 会将每个模块的执行结果记录成一段 JSON 信息，可以用 register 选项赋值给变量。如下：</p>\n<div><pre><code><span>tasks</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> step1\n    <span>shell</span><span>:</span> ls f1\n    <span>register</span><span>:</span> step1_result              <span># 将模块的执行结果赋值给变量 step1_result</span>\n    <span>ignore_errors</span><span>:</span> <span>True</span>                 <span># 即使该模块执行失败，也继续执行下一个模块</span>\n\n  <span>-</span> <span>shell</span><span>:</span> echo <span>{</span><span>{</span>step1_result<span>}</span><span>}</span>\n    <span># 直接打印，则是一个 JSON 对象，如下：</span>\n    <span># {changed: True, end: 2020-06-08 13:50:28.332773, stdout: f1, cmd: ls f1, rc: 0, start: 2020-06-08 13:50:28.329216, stderr: , delta: 0:00:00.003557, stdout_lines: [f1], stderr_lines: [], failed: False}</span>\n  \n  <span>-</span> <span>shell</span><span>:</span> echo <span>{</span><span>{</span>step1_result.stdout<span>}</span><span>}</span>\n\n  <span>-</span> <span>shell</span><span>:</span> echo \"step1 failed<span>!</span>\"\n    <span>when</span><span>:</span> step1_result.failed\n    <span># when: step1_result.rc != 0</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><p>不同模块的执行结果的格式可能不同，返回码代表的含义也可能不同。</p>\n</li>\n</ul>\n<h3 id=\"environment\"> environment</h3>\n<ul>\n<li>可以给 playbook 或 task 声明 environment ，从而设置终端的环境变量。如下：<div><pre><code><span>-</span> <span>name</span><span>:</span> Test\n  <span>hosts</span><span>:</span> localhost\n  <span>vars</span><span>:</span>\n    <span>PATH</span><span>:</span> /usr/local/sbin<span>:</span>/usr/local/bin<span>:</span>/usr/bin/\n  <span>environment</span><span>:</span>\n    <span>A</span><span>:</span> Hello\n    <span>PATH</span><span>:</span> <span>'{{ PATH }}'</span>    <span># 可以在环境变量中引用 Ansible 变量</span>\n  <span>tasks</span><span>:</span>\n    <span>-</span> <span>shell</span><span>:</span> env          <span># 打印环境变量</span>\n      <span>environment</span><span>:</span>\n        <span>B</span><span>:</span> World\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n<h2 id=\"module\"> Module</h2>\n<ul>\n<li>Anisble 内置了很多种用途的模块，参考 <a href=\"https://docs.ansible.com/ansible/latest/collections/index_module.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方的模块列表</a></li>\n<li>如果 host 上启用了 SELinux ，则需要先在它上面安装 <code>yum install libselinux-python</code> ，否则一些模块不能执行。</li>\n<li>Ansible 内置的模块大多具有幂等性。\n<ul>\n<li>幂等性可以保证对同一个 host 重复执行一个 playbook 时，只会产生一次效果，不会因为重复执行而出错。比如使用 yum 模块安装软件时，它会检查是否已经安装，如果已经安装就不执行。</li>\n<li>重复执行幂等性模块时，只有第一次的执行结果中的 &quot;changed&quot; 参数为 true ，表示成功将 host 改变成了目标状态。之后重复执行时，&quot;changed&quot; 参数应该总是为 false 。</li>\n</ul>\n</li>\n<li>例如：\n<ul>\n<li>使用 command、shell、raw 模块时可以自由地执行命令，通用性强，但不保证幂等性。</li>\n<li>使用 copy 等具体的模块可以保证幂等性，但通用性差，需要分别学习它们的用法，而且可能出现 Python 版本兼容问题。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"关于执行命令\"> 关于执行命令</h3>\n<ul>\n<li>\n<p>测试连接 host ：</p>\n<div><pre><code><span>ping</span><span>:</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>ping 模块会测试能否通过 ssh 登录 host ，并检查是否有可用的 Python 解释器，如果操作成功则返回 pong 。</li>\n</ul>\n</li>\n<li>\n<p>用 command、shell、raw 模块可以在 host 上执行 shell 命令：</p>\n<ul>\n<li>\n<div><pre><code><span>command</span><span>:</span> /tmp/test.sh chdir=/tmp/\n</code></pre>\n<div><span>1</span><br></div></div><p>调用模块时也可以写作以下格式：</p>\n<div><pre><code><span>command</span><span>:</span>\n  <span>cmd</span><span>:</span> /tmp/test.sh\n  <span># chdir: /tmp/      # 执行该命令之前，先切换到指定目录（可以是绝对路径或相对路径）</span>\n  <span># creates: /tmp/f1  # 如果该文件存在，则跳过该任务（这样有利于实现幂等性）</span>\n  <span># removes: /tmp/f1  # 如果该文件不存在，则跳过该任务</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<div><pre><code><span>shell</span><span>:</span>\n  <span>cmd</span><span>:</span> ls <span>|</span> grep ssh\n  <span># executable: /bin/sh   # 指定要执行 shell 命令的可执行文件</span>\n  <span># chdir: /tmp/</span>\n  <span># creates: /tmp/f1</span>\n  <span># removes: /tmp/f1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>shell 模块时会在 Python 中调用 subprocess.Popen(cmd, shell=True) ，新建一个 shell 终端来执行 cmd 命令。<br>\n而 command 模块是调用 subprocess.Popen(cmd, shell=False) ，不在 shell 终端中执行 cmd 命令。因此可以防止 shell 注入攻击，但是不支持管道符等 shell 语法。如下：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># ansible localhost -a 'echo $PWD | wc -l >> f1 &amp;&amp; echo $PWD'</span>\nlocalhost <span>|</span> CHANGED <span>|</span> <span>rc</span><span>=</span><span>0</span> <span>>></span>\n/etc/ansible <span>|</span> <span>wc</span> -l <span>>></span> f1 <span>&amp;&amp;</span> <span>echo</span> /etc/ansible\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>如果 command 模块中调用了 shell 环境变量，则会在执行命令之前就完成替换。</p>\n</li>\n<li>\n<div><pre><code><span>raw</span><span>:</span> echo hello\n<span># args:</span>\n<span>#   executable: /bin/bash   # 指定解释器</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>raw 模块是通过 ssh 直接向 host 发送 shell 命令。适用于 host 上没有安装 Python 解释器，而无法使用 command、shell 模块的情况。</p>\n</li>\n<li>\n<p>按以下格式可以给模块输入多行字符串：</p>\n<div><pre><code><span>shell</span><span>:</span> <span>|</span><span>\n  cd /tmp\n  pwd\n  touch f1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>注意输入的内容要缩进一层。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>在 host 上执行脚本：</p>\n<div><pre><code><span>script</span><span>:</span>\n  <span>cmd</span><span>:</span> /tmp/test.sh\n  <span># executable: /bin/bash  # 设置执行该脚本的程序</span>\n  <span># chdir: /tmp/</span>\n  <span># creates: /tmp/f1</span>\n  <span># removes: /tmp/f1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>cmd 是本机上的一个脚本的路径，它会被拷贝到 host 上执行，执行完之后会自动删除。</li>\n<li>executable 不一定是 shell 解释器，因此执行的不一定是 shell 脚本，比如：<code>script: &quot;executable=/usr/bin/python /tmp/1.py&quot;</code></li>\n</ul>\n</li>\n<li>\n<p>打印调试信息：</p>\n<div><pre><code><span>debug</span><span>:</span>\n  <span>var</span><span>:</span> hostvars<span>[</span>inventory_hostname<span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><div><pre><code><span>debug</span><span>:</span>\n  <span>msg</span><span>:</span> System <span>{</span><span>{</span>inventory_hostname<span>}</span><span>}</span> has gateway <span>{</span><span>{</span>ansible_default_ipv4.gateway<span>}</span><span>}</span>\n<span>when</span><span>:</span> ansible_default_ipv4.gateway is defined\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>debug 模块的 var 、msg 选项不能同时使用。</li>\n<li>when 选项、debug 模块的 var 选项已经隐式地用花括号包装，因此不需要再给变量加花括号取值。</li>\n</ul>\n</li>\n<li>\n<p>加入断言：</p>\n<div><pre><code><span>assert</span><span>:</span>\n  <span>that</span><span>:</span>                                                     <span># 相当于 when 选项</span>\n    <span>-</span> ansible_facts<span>[</span><span>'distribution'</span><span>]</span> == \"CentOS\"\n    <span>-</span> ansible_facts<span>[</span><span>'distribution_major_version'</span><span>]</span> == \"7\"\n  <span># quiet: no                                               # 是否显示执行的结果信息</span>\n  <span># fail_msg: \"This system is not CentOS7.\"                 # 失败时显示该消息（需要 quiet 为 no ）</span>\n  <span># success_msg: \"This system is CentOS7.\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>主动结束脚本的执行：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> End the playbook\n  <span>when</span><span>:</span>\n    <span>-</span> ansible_facts<span>[</span><span>'distribution'</span><span>]</span> == \"CentOS\"\n  <span>meta</span><span>:</span> end_host            <span># 结束脚本在当前主机上的执行</span>\n  <span># meta: end_play          # 结束脚本在所有主机上的执行</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>主动结束脚本时，该 task 不会记录在终端。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"关于管理文件\"> 关于管理文件</h3>\n<ul>\n<li>\n<p>管理 host 上的文件或目录：</p>\n<div><pre><code><span>file</span><span>:</span>\n  <span>path</span><span>:</span> /tmp/f1\n  <span># state: touch    # 可以取值为 touch（创建文件）、directory（创建目录）、link（创建软链接）、hard（创建硬链接）、absent（删除文件）</span>\n  <span># mode: 0774      # 设置文件的权限（加上前缀 0 ，声明这是八进制）</span>\n  <span># owner: root     # 设置文件的所有者</span>\n  <span># group: root     # 设置文件的所有者组</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>在 path 字符串中不能使用 * 通配符。</li>\n</ul>\n</li>\n<li>\n<p>将本机的文件拷贝到 host 上：</p>\n<div><pre><code><span>copy</span><span>:</span>\n  <span>src</span><span>:</span> f1\n  <span>dest</span><span>:</span> /tmp/\n  <span># mode: 0774</span>\n  <span># owner: root</span>\n  <span># group: root</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>src 可以是绝对路径或相对路径。</li>\n<li>当 src 是目录时，如果以 / 结尾，则会拷贝其中的所有文件到 dest 目录下，否则直接拷贝 src 目录。</li>\n<li>如果 dest 目录并不存在，则会自动创建。</li>\n<li>如果 dest 目录下存在同名文件，且 md5 值相同，则不拷贝，否则会拷贝并覆盖。</li>\n<li>Ansible 默认通过 SFTP 传输文件。</li>\n</ul>\n</li>\n<li>\n<p>将 host 上的文件拷贝到本机：</p>\n<div><pre><code><span>fetch</span><span>:</span>\n  <span>src</span><span>:</span> /tmp/f1\n  <span>dest</span><span>:</span> /tmp/     <span># 以 / 结尾，表示这是一个已存在的目录</span>\n  <span># flat: no      # 默认为 no ，表示保存路径为 dest_path/hostname/src_path ，设置成 yes 则是 dest_path/filename</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>src 必须是一个文件的路径，不能是一个目录。</li>\n</ul>\n</li>\n<li>\n<p>对 host 上的文本文件插入多行字符串：</p>\n<div><pre><code><span>blockinfile</span><span>:</span>\n  <span>path</span><span>:</span> /var/spool/cron/root\n  <span>block</span><span>:</span> <span>|</span><span>\n    */1 * * * * echo Hello\n    */1 * * * * echo World</span>\n  <span># create: no                  # 如果不存在该文件，是否自动创建它</span>\n  <span># state: present              # 取值为 absent 则会删除该 block</span>\n  <span># insertafter: EOF            # 将 block 插入到该正则表达式的最后一个匹配项之后（默认取值为 EOF ，即插入到文件末尾）</span>\n  <span># insertbefore: BOF           # 将 block 插入到该正则表达式的最后一个匹配项之前（取值为 BOF 则插入到文件开头）</span>\n  <span># marker: # {mark} ANSIBLE MANAGED BLOCK    # 设置该 block 的标记语，其中 {mark} 会被 marker_begin 或 marker_end 替换</span>\n  <span># marker_begin: BEGIN </span>\n  <span># marker_end: END</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>上例中最终插入的 block 如下：<div><pre><code><span># BEGIN ANSIBLE MANAGED BLOCK</span>\n*/1 * * * * <span>echo</span> Hello\n*/1 * * * * <span>echo</span> World\n<span># END ANSIBLE MANAGED BLOCK</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>Ansible 在插入 block 时，会自动在开始、结束处加上一行 marker 字符串作为标记。重复插入该 block 时，如果检查到该标记，且标记中的内容相同，则不会修改该文件。</li>\n</ul>\n</li>\n<li>\n<p>对 host 上的文本文件进行正则替换：</p>\n<div><pre><code><span>replace</span><span>:</span>\n  <span>path</span><span>:</span> /tmp/f1\n  <span>regexp</span><span>:</span> <span>'Hello(\\w*)'</span>    <span># 将匹配 regexp 的部分替换为 replace</span>\n  <span>replace</span><span>:</span> <span>'Hi\\1'</span>         <span># 这里用 \\1 引用匹配的第一个元素组</span>\n  <span># after: 'line_1'       # 在某位置之后开始匹配</span>\n  <span># before: 'line_10.*'   # 在某位置之前开始匹配</span>\n  <span># encoding: 'utf-8'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>采用 Python 的正则引擎，默认的编码格式是 utf-8 。</li>\n</ul>\n</li>\n<li>\n<p>渲染 Jinja2 模块文件，生成新文件：</p>\n<div><pre><code><span>template</span><span>:</span>\n  <span>src</span><span>:</span> templates/test.conf.j2\n  <span>dest</span><span>:</span> /tmp/test.conf\n  <span># mode: 0774    # 拷贝后文件的权限</span>\n  <span># owner: root   # 拷贝后文件的所有者</span>\n  <span># group: root   # 拷贝后文件的所有者组</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"关于配置系统\"> 关于配置系统</h3>\n<ul>\n<li>\n<p>创建用户：</p>\n<div><pre><code><span>user</span><span>:</span>\n  <span>name</span><span>:</span> leo\n  <span># password: \"{{'123456' | password_hash('sha512')}}\"    # 设置密码</span>\n  <span># update_password: always # 可以取值为 always（默认，总是设置密码）、on_create（仅在创建用户时才设置密码）</span>\n  <span># generate_ssh_key: no    # 是否生成 ssh 密钥（已存在密钥的话不会覆盖）</span>\n  <span># home: /home/leo</span>\n  <span># shell: /bin/bash</span>\n  <span># group: root             # 设置基本用户组（该 group 必须已存在）</span>\n  <span># groups: root,docker     # 设置扩展用户组</span>\n  <span># append: no              # 默认取值为 no ，会将用户从其它组删除</span>\n  <span># comment: testing        # 添加备注信息</span>\n  <span># expires: 1591343903     # 设置过期时间</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><div><pre><code><span>user</span><span>:</span>\n  <span>name</span><span>:</span> leo\n  <span>state</span><span>:</span> absent         <span># 删除用户</span>\n  <span># remove: yes         # 删除家目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>用 yum 安装软件：</p>\n<div><pre><code><span>yum</span><span>:</span>\n  <span>name</span><span>:</span>\n    <span>-</span> vim\n    <span>-</span> git\n    <span>-</span> httpd<span>-</span>2.2.29\n  <span># state: installed    # 可以取值为 installed（安装了即可，默认这种）、latest（安装最新版本）、removed（卸载）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>管理 systemd 服务：</p>\n<div><pre><code><span>systemd</span><span>:</span>\n  <span>name</span><span>:</span> httpd\n  <span>state</span><span>:</span> started        <span># 可以取值为 started、stopped、restarted、reloaded</span>\n  <span>enabled</span><span>:</span> yes\n  <span># daemon-reload: no   # 是否重新加载 unit 的配置文件</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<p>配置 firewalld 防火墙：</p>\n<div><pre><code><span>firewalld</span><span>:</span>              <span># 设置启用的 zone</span>\n  <span>zone</span><span>:</span> public\n  <span>state</span><span>:</span> present        <span># zone 的 state 可以取值为 present 或 absent</span>\n  <span>permanent</span><span>:</span> yes\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><div><pre><code><span>firewalld</span><span>:</span>\n  <span>service</span><span>:</span> http         <span># 同时只能指定一个 service</span>\n  <span># port: 80/tcp        # 同时只能指定一个端口</span>\n  <span># rich_rule: rule family='ipv4' port port=22 protocol=tcp accept</span>\n  <span>state</span><span>:</span> enabled        <span># 可以取值为 enabled 或 disabled</span>\n  <span>permanent</span><span>:</span> yes\n  <span>immediate</span><span>:</span> yes        <span># 是否立即生效（当 permanent 为 yes 时，默认 immediate 为 no ）</span>\n  <span># zone: public</span>\n  <span># interface: eth2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><ul>\n<li>如果 firewalld 没有启动，则该模块会无法执行而报错。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"include\"> include</h2>\n<p>Ansible 原本采用 include 选项导入其它 playbook 文件的内容到当前文件中，不过从 2.4 版本开始拆分成多个具体的选项，如下：</p>\n<ul>\n<li>import_tasks</li>\n<li>include_tasks ：用于导入 tasks 列表文件。</li>\n<li>import_playbook ：用于导入 playbook 文件。</li>\n<li>import_role ：用于导入 role ，与 role 选项的原理相同。</li>\n<li>include_role</li>\n</ul>\n<p>特点：</p>\n<ul>\n<li>import_* 导入的内容会在所有 playbook 启动之前就被预处理，比如确定变量的值，属于静态导入。</li>\n<li>include_* 导入的内容会在被执行时才开始解析，比如可以每次循环使用不同的变量值，属于动态导入。</li>\n</ul>\n<p>例：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> test1\n  <span>hosts</span><span>:</span> <span>\"{{host}}\"</span>\n  <span>vars</span><span>:</span>\n    <span>-</span> <span>tips</span><span>:</span> Hello\n  <span>tasks</span><span>:</span>\n    <span>-</span> <span>include_tasks</span><span>:</span> tasks/test2.yml  <span># 导入一个 playbook ，不指定路径则默认是在当前目录下</span>\n      <span>vars</span><span>:</span>                           <span># 传入变量</span>\n        <span>tips</span><span>:</span> Hi\n\n<span>-</span> <span>name</span><span>:</span> test3\n  <span>import_playbook</span><span>:</span> test4.yml\n  <span># hosts: localhost                  # 不能设置 hosts 选项，它会沿用前一个 playbook 的 host</span>\n  <span>vars</span><span>:</span>\n    <span>tips</span><span>:</span> Hello\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><ul>\n<li>\n<p>include_tasks 必须作为一个 playbook 的 task 使用，且导入的目标文件必须是一个纯 tasks 列表，如下：</p>\n<div><pre><code><span>-</span> <span>command</span><span>:</span> echo <span>{</span><span>{</span>tips<span>}</span><span>}</span>\n<span>-</span> <span>command</span><span>:</span> ls\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>上例中，被导入的 test2.yml 会继承 test1 的 vars ，且接受从外部传入的变量、标签。</p>\n</li>\n<li>\n<p>import_playbook 必须在已定义的 playbook 之后使用，导入一个独立的 playbook 文件。\n上例中，被导入的 test4.yml 不会继承 test1 的 vars ，只会接受从外部传入的变量、标签。</p>\n</li>\n<li>\n<p>使用 include 这类选项时，不能选择只导入具有某些标签的内容，如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> test3\n  <span>import_playbook</span><span>:</span> test4.yml\n  <span>tags</span><span>:</span>             <span># 这里声明的 tags 会作用于 test3</span>\n    <span>-</span> debug\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>因此，只能将要导入的内容拆分成不同文件，或者通过变量判断是否执行某些内容，如下：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> test3\n  <span>import_playbook</span><span>:</span> test4.yml\n  <span>vars</span><span>:</span>\n    <span>debug</span><span>:</span>\n    <span>tips</span><span>:</span> Hello\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><div><pre><code><span>-</span> <span>name</span><span>:</span> test4\n  <span>host</span><span>:</span> <span>\"{{host}}\"</span>\n  <span>tasks</span><span>:</span>\n  <span>-</span> <span>shell</span><span>:</span> echo <span>{</span><span>{</span>tips<span>}</span><span>}</span>\n    <span>when</span><span>:</span> debug is defined\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n<h2 id=\"role\"> role</h2>\n<ul>\n<li>\n<p>处理大型任务时，可以将一些 playbook、配置文件整合在一个目录下，称为 role 。</p>\n</li>\n<li>\n<p>可以到官方的 roles 分享平台 &lt;galaxy.ansible.com&gt; 上寻找可用的 roles ，然后用 ansible-galaxy 命令下载 roles 。命令如下：</p>\n<div><pre><code>ansible-galaxy\n              <span>install</span> <span>&lt;</span>name<span>></span>\n              search <span>&lt;</span>name<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>项目的目录结构示例：</p>\n<div><pre><code>├── hosts\n├── README.md\n├── roles/\n│   └── common/                   # 一个 role\n│       ├── defaults/             # 保存该 role 的默认变量\n│       │   └── main.yml\n│       ├── files/                # 存放一些文件，比如要拷贝到 host 上的文件\n│       │   ├── settings.py\n│       │   └── supervisor.conf\n│       ├── handlers/\n│       │   └── main.yml\n│       ├── meta/\n│       │   └── main.yml\n│       ├── tasks/\n│       │   └── main.yml\n│       ├── templates/            # 存放一些 Jinja2 模板文件\n│       │   ├── Dockerfile.j2\n│       │   └── nginx.conf.j2\n│       └── vars/                 # 存放一些变量\n│           └── main.yml\n└── site.yml\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></li>\n<li>\n<p>以上的目录结构是一种规范。</p>\n<ul>\n<li>导入一个 role 时，会自动导入它的 defaults/、handlers/、meta/、tasks/、vars/ 子目录下的 main.yml 文件的内容。如果这些文件不存在则忽略。</li>\n<li>使用 copy 、script 模块时会自动到 files/ 目录下寻找相应的文件，不需要指明相对路径；使用 template 模块时会自动引用 templates/ 目录；使用 include 选项时会自动引用 tasks/ 目录。</li>\n</ul>\n</li>\n<li>\n<p>在 playbook 中导入 role 的示例：</p>\n<div><pre><code><span>-</span> <span>name</span><span>:</span> Build Docker Image\n  <span>hosts</span><span>:</span> all\n  <span>roles</span><span>:</span>\n    <span>-</span> <span>role</span><span>:</span> common                <span># 导入一个 role ，写作 YAML 格式</span>\n      <span>vars</span><span>:</span>\n        <span>tips</span><span>:</span> Hello\n    <span>-</span> <span>role</span><span>:</span> <span>'roles/build_image'</span>   <span># 根据路径导入 role</span>\n    <span>-</span> <span>{</span> <span>role</span><span>:</span> push_image<span>,</span> <span>when</span><span>:</span> <span>\"docker_registry is defined\"</span> <span>}</span>  <span># 导入一个 role ，写作字典格式</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n<h2 id=\"ansible-awx\"> Ansible AWX</h2>\n<p>Ansible Tower 提供了 Ansible 的 Web UI ，采用 Django 开发，其开源版本是 Ansible AWX 。</p>\n<ul>\n<li>\n<p><a href=\"https://docs.ansible.com/ansible-tower/latest/html/userguide/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></p>\n</li>\n<li>\n<p>用 docker-compose 部署 Ansible AWX ：</p>\n<div><pre><code>pip3 <span>install</span> <span>docker-compose</span>\n<span>wget</span> https://github.com/ansible/awx/archive/11.2.0.tar.gz    <span># 下载 Ansible AWX</span>\n<span>tar</span> -zxvf <span>11.2</span>.0.tar.gz\n<span>cd</span> awx-11.2.0/installer\nansible-playbook -i inventory install.yml                    <span># 用 Ansible 启动 Ansible AWX ，这会花一段时间拉取 docker 镜像</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>默认将 docker-compose 的配置文件保存在 ~/.awx/awxcompose/docker-compose.yml 。\n默认访问地址为 <a href=\"http://localhost:80\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:80</a> ，用户名、密码为 admin 、 password 。</p>\n</li>\n<li>\n<p>用法：</p>\n<ul>\n<li>可以在 Web 页面上方便地调用大量 playbook ，不过不能直接在 Web 页面上编辑 playbook 。因此只适合管理已稳定可用的 playbook 。</li>\n<li>以 Project 为单位执行任务，可以从 Git、SVN 仓库或本地目录导入 playbook 文件。</li>\n<li>删除一个机构时，会自动删除其下的 Inventory 等配置。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Consul",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/Consul.html",
      "id": "/Hardware/DevOps/ConfigurationManagement/Consul.html",
      "content_html": "<h1 id=\"consul\"> Consul</h1>\n<p>：一个 Web 服务器，提供了配置管理、服务发现、DNS 等功能。</p>\n<ul>\n<li><a href=\"https://www.consul.io/docs\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>发音为 <code>/ˈkɒnsl/</code> 。</li>\n<li>由 HashiCorp 公司采用 Golang 开发。</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>\n<p>架构：</p>\n<ul>\n<li>部署多个 Consul agent 进程，组成分布式集群。</li>\n<li>业务程序向一个 agent 发出请求，使用 Consul 的功能。</li>\n</ul>\n</li>\n<li>\n<p>agent 又称为 node ，有两种运行模式：</p>\n<ul>\n<li>client\n<ul>\n<li>：普通的 agent 。</li>\n<li>业务程序访问任一 agent ，都能使用 Consul 的功能。</li>\n</ul>\n</li>\n<li>server\n<ul>\n<li>：比 client 多了维护集群的责任。</li>\n<li>一个 Consul 集群至少要有 1 个 server 节点，负责存储集群数据。</li>\n<li>集群采用 Raft 算法实现分布式一致性。\n<ul>\n<li>server 之间会自行选出一个 server 担任 leader ，负责引导集群。其它 server 则担任 follower 。</li>\n<li>每次修改集群数据时需要 quorum 个 server 同意。</li>\n</ul>\n</li>\n<li>建议部署 3 或 5 个 server ，此时允许 1 或 2 个 server 故障，实现高可用。\n<ul>\n<li>client 数量不影响集群的可用性，可以部署上万节点。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>agent 的状态：</p>\n<ul>\n<li>agent 进程启动，通过 join 命令加入集群，标记为 alive 状态。</li>\n<li>如果一个 agent 不能被其它 agent 访问到，则标记为 failed 状态。\n<ul>\n<li>这可能是因为网络不通，或 agent 崩溃。</li>\n</ul>\n</li>\n<li>如果一个 agent 通过 leave 命令退出集群，则标记为 left 状态。\n<ul>\n<li>比如 agent 进程正常终止时，会主动退出集群。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>agent 采用多种通信协议，监听不同的端口：</p>\n<ul>\n<li>agent 之间通过 RPC 协议进行通信，传输层协议为 TCP 。</li>\n<li>agent 之间通过 Gossip 协议进行节点发现、服务发现，传输层协议同时采用 TCP、UDP 。\n<ul>\n<li>Gossip 协议：基于 Serf 库开发，用于在集群广播消息，比如节点状态。</li>\n<li>agent 分别为 LAN、WAN 监听一个端口，提供 Gossip 服务。</li>\n</ul>\n</li>\n<li>agent 可以提供 HTTP、HTTPS、gRPC 端口供业务程序访问，传输层协议为 TCP 。</li>\n<li>agent 可以提供 DNS 端口供业务程序访问，传输层协议同时采用 TCP、UDP 。</li>\n</ul>\n</li>\n<li>\n<p>Consul 支持在集群中划分多个数据中心（Data Center）。</p>\n<ul>\n<li>每个数据中心相当于一个子集群，各有一个 leader server 。</li>\n<li>每个数据中心代表一个局域网，包含一组 agent ，可以通过 LAN 通信。\n<ul>\n<li>不同数据中心之间的 agent 通过 WAN 通信。</li>\n<li>每个数据中心拥有一个 Gossip LAN 节点池，记录该局域网的所有节点。</li>\n<li>整个集群拥有一个 Gossip WAN 节点池，记录集群的所有节点。</li>\n</ul>\n</li>\n<li>用户可以向集群的任一 agent 发出请求，会被自动转发到正确的节点，基于 RPC 通信。\n<ul>\n<li>如果 agent 收到指向数据中心的写请求，则会自动转发到 leader 节点。</li>\n<li>如果 agent 收到指向其它数据中心的请求，则会转发到该数据中心的任一节点。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Consul 的 Enterprise 版本支持划分多个 namespace ，用于隔离 service、KV、ACL 数据。</p>\n</li>\n<li>\n<p>Consul 启用 Connect 功能时，会在服务之间启用 TLS 加密通信。</p>\n<ul>\n<li>支持透明代理服务的流量，实现 Service Mesh 。</li>\n<li>支持用 Intention 功能允许、禁止服务之间的网络连通。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"服务发现\"> 服务发现</h3>\n<ul>\n<li>\n<p>服务发现的工作流程：</p>\n<ol>\n<li>访问 agent ，注册服务。</li>\n<li>访问 agent ，通过 HTTP 或 DNS 端口查询已注册的服务。</li>\n</ol>\n</li>\n<li>\n<p>Consul 集群将已注册的所有节点、服务的信息保存在一个称为 catalog 的命名空间中，可以通过 API 访问。</p>\n<ul>\n<li>注销一个对象，就会从 catalog 删除其存在。</li>\n<li>Consul 的设计是在每个主机上部署一个 agent ，让每个主机上的业务程序访问本机的 agent 进行服务注册。\n<ul>\n<li>一个 agent 变为 left 状态时，会自动注销该 agent 上注册的所有服务。</li>\n</ul>\n</li>\n<li>agent 会将自己注册为名为 consul 的服务，但不存在健康检查。</li>\n</ul>\n</li>\n<li>\n<p>一个 service 的信息示例：</p>\n<div><pre><code><span>{</span>\n    <span>\"ID\"</span><span>:</span> <span>\"django\"</span><span>,</span>                 <span>// 该服务在当前 agent 上的唯一 ID 。如果未指定，则采用服务名</span>\n    <span>\"Service\"</span><span>:</span> <span>\"django\"</span><span>,</span>            <span>// 服务名。注册服务时只有该字段是必填的</span>\n    <span>\"Address\"</span><span>:</span> <span>\"10.0.0.1\"</span><span>,</span>          <span>// 服务的 IP 地址或主机名。如果未指定，则采用当前 agent 的 IP 地址</span>\n    <span>\"Port\"</span><span>:</span> <span>80</span><span>,</span>\n    <span>\"Datacenter\"</span><span>:</span> <span>\"dc1\"</span><span>,</span>            <span>// 该服务所属的数据中心</span>\n    <span>\"TaggedAddresses\"</span><span>:</span> <span>{</span>            <span>// 可以给服务附加多个地址</span>\n        <span>\"lan\"</span><span>:</span> <span>{</span>                    <span>// LAN 地址，供同一数据中心的其它服务访问。默认为 IPv4 类型</span>\n            <span>\"Address\"</span><span>:</span> <span>\"10.0.0.1\"</span><span>,</span>\n            <span>\"Port\"</span><span>:</span> <span>80</span>\n        <span>}</span><span>,</span>\n        <span>\"wan\"</span><span>:</span> <span>{</span>                    <span>// WAN 地址，供其它数据中心的服务访问。默认为 IPv4 类型</span>\n            <span>\"Address\"</span><span>:</span> <span>\"10.0.0.1\"</span><span>,</span>\n            <span>\"Port\"</span><span>:</span> <span>80</span>\n        <span>}</span>\n    <span>}</span><span>,</span>\n    <span>\"Tags\"</span><span>:</span> <span>[</span>                       <span>// 可以给服务加上一些字符串类型的标签</span>\n        <span>\"test\"</span>\n    <span>]</span><span>,</span>\n    <span>\"enable_tag_override\"</span><span>:</span> <span>false</span><span>,</span>   <span>// 是否允许其它 agent 修改该服务的 tag</span>\n    <span>\"Meta\"</span><span>:</span> <span>{</span>                       <span>// 可以给服务加上一些键值对类型的元数据，默认为 false</span>\n        <span>\"description\"</span><span>:</span> <span>\"This is for test.\"</span>\n    <span>}</span><span>,</span>\n    <span>\"checks\"</span><span>:</span> <span>[</span><span>]</span><span>,</span>                   <span>// 健康检查的任务，默认为空</span>\n    <span>\"Weights\"</span><span>:</span> <span>{</span>                    <span>// 该服务存在其它实例时，指定其在 DNS SRV 响应中的权重，默认为 1</span>\n        <span>\"Passing\"</span><span>:</span> <span>1</span><span>,</span>\n        <span>\"Warning\"</span><span>:</span> <span>1</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br></div></div></li>\n</ul>\n<h4 id=\"健康检查\"> 健康检查</h4>\n<ul>\n<li>\n<p>每个 agent 会定期进行健康检查，并更新 catalog 中的信息。</p>\n</li>\n<li>\n<p>健康检查的对象分为两种：</p>\n<ul>\n<li>节点：该 agent 本身，是否运行、可连接。</li>\n<li>服务：该 agent 上注册的各个服务。</li>\n</ul>\n</li>\n<li>\n<p>健康检查的结果分为多种：</p>\n<ul>\n<li>passing ：健康。</li>\n<li>warning ：存在异常，但依然工作。</li>\n<li>failing、critical ：不健康。</li>\n</ul>\n</li>\n<li>\n<p>每个节点默认启用 Serf 类型的监控检查，而每个服务可启用以下类型的健康检查：</p>\n<ul>\n<li>Script ：指定一个 shell 命令，定期执行一次。\n<ul>\n<li>如果退出码为 0 则视作 passing ，为 1 则视作 warning ，为其它值则视作 failing 。</li>\n<li>执行时的 stdout、stderr 会被记录到检查结果的 output 字段，可在 Web UI 查看。</li>\n</ul>\n<div><pre><code><span>{</span>\n    <span>\"args\"</span><span>:</span> <span>[</span><span>\"/usr/bin/curl\"</span><span>,</span> <span>\"127.0.0.1\"</span><span>]</span><span>,</span>\n    <span>// \"id\": \"xx\",</span>\n    <span>// \"name\": \"xx\",</span>\n    <span>// \"interval\": \"5s\",                    // 每隔 interval 时间执行一次</span>\n    <span>// \"timeout\": \"10s\",                    // 每次检查的超时时间</span>\n    <span>// \"status\": \"critical\",                 // 在第一次健康检查之前，服务的默认状态</span>\n    <span>// \"deregister_critical_service_after\": \"30s\"  // 如果服务实例变为 critical 状态超过一定时间，则注销。默认禁用该功能</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>HTTP ：指定一个 URL ，定期发出一个 HTTP 请求。\n<ul>\n<li>如果状态码为 200 则视作 passing ，为 429 则视作 warning ，为其它值则视作 failing 。</li>\n</ul>\n<div><pre><code><span>{</span>\n    <span>\"http\"</span><span>:</span> <span>\"http://localhost/health\"</span><span>,</span>\n    <span>\"method\"</span><span>:</span> <span>\"POST\"</span><span>,</span>                       <span>// 请求方法，默认为 GET</span>\n    <span>\"header\"</span><span>:</span> <span>{</span><span>\"Content-Type\"</span><span>:</span> <span>[</span><span>\"application/json\"</span><span>]</span><span>}</span><span>,</span>\n    <span>\"body\"</span><span>:</span> <span>\"{\\\"check\\\": \\\"is_running\\\"}\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>TCP ：指定主机名和端口，定期尝试建立一次 TCP 连接。\n<ul>\n<li>如果连接成功则视作 success ，否则视作 critical 。</li>\n</ul>\n<div><pre><code><span>{</span>\n    <span>\"tcp\"</span><span>:</span> <span>\"localhost:80\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>Alias ：指定另一个节点或服务，跟随其状态。<div><pre><code><span>{</span>\n    <span>\"alias_node\"</span><span>:</span> <span>\"node1\"</span><span>,</span>    <span>// 目标节点。默认为当前节点</span>\n    <span>\"alias_service\"</span><span>:</span> <span>\"web\"</span>    <span>// 目标服务。如果不指定则跟随节点的状态</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>Docker ：通过 docker exec 执行 shell 脚本。</li>\n<li>TTL ：要求服务在一定时间内向 agent 的特定 URL 发送 HTTP 请求，超时则视作异常。</li>\n<li>gRPC</li>\n</ul>\n</li>\n<li>\n<p>一个服务要通过自身的健康检查（如果要求检查），并且所在 agent 也通过健康检查，才标记为健康状态。</p>\n<ul>\n<li>非健康状态的服务不会被自动删除。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"dns\"> DNS</h4>\n<ul>\n<li>Consul 支持通过 DNS 请求查询节点、服务的地址。</li>\n<li>域名格式如下：<div><pre><code><span>&lt;</span>node<span>></span>.node<span>[</span>.datacenter<span>]</span>.<span>&lt;</span>domain<span>></span>               <span># 节点的域名</span>\n<span>[</span>tag.<span>]</span><span>&lt;</span>service<span>></span>.service<span>[</span>.datacenter<span>]</span>.<span>&lt;</span>domain<span>></span>   <span># 服务的域名</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>如果不指定数据中心，则默认采用当前 agent 的数据中心。</li>\n<li>查询服务时，可以加上 tag 进行筛选。\n<ul>\n<li>如果有多个健康的服务实例，则根据权重随机选择一个，返回其地址。</li>\n<li>如果不存在健康的服务实例，则查询结果为空。</li>\n</ul>\n</li>\n<li>DNS 记录为 A 类型，查询服务时还支持 SRV 类型。</li>\n<li>DNS 记录的 TTL 默认为 0 。</li>\n</ul>\n</li>\n<li>例：<div><pre><code><span>dig</span> @10.0.0.1 -p <span>8600</span> +short node1.node.consul          <span># 查询节点</span>\n<span>dig</span> @10.0.0.1 -p <span>8600</span> +short node1.node.dc2.consul      <span># 查询其它数据中心的节点</span>\n<span>dig</span> @10.0.0.1 -p <span>8600</span> +short django.service.consul      <span># 查询服务</span>\n<span>dig</span> @10.0.0.1 -p <span>8600</span> +short django.service.consul  SRV <span># 查询 DNS SRV 记录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"配置管理\"> 配置管理</h3>\n<ul>\n<li>\n<p>Consul 提供了 Key/Value 形式的数据存储功能，常用于存储配置信息。</p>\n<ul>\n<li>如果 key 以 / 结尾，则会创建一个文件夹</li>\n<li>value 的长度不能超过 512KB 。</li>\n</ul>\n</li>\n<li>\n<p>Consul 集群的所有节点都拥有一份 KV 数据的副本，供用户访问。</p>\n<ul>\n<li>server 节点才有权修改 KV 数据。如果用户向 client 节点发出写请求，则会被转发到 server 节点。</li>\n</ul>\n</li>\n<li>\n<p>提供了 acquire、release 功能，用于锁定、解锁与 session 关联的 key 。</p>\n</li>\n</ul>\n<h3 id=\"watch\"> watch</h3>\n<ul>\n<li>Consul 提供了 watch 功能，用于监视某些事件，当事件发生时执行 handler 任务。\n<ul>\n<li>可以监视节点、服务、KV 的变化，或者用户自定义的事件。</li>\n<li>handler 有两种类型：\n<ul>\n<li>执行 shell 脚本</li>\n<li>发送 HTTP 请求</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>例：在 Consul 配置文件中添加 watch 的配置<div><pre><code><span>{</span>\n  <span>\"watches\"</span><span>:</span> <span>[</span>                  <span>// 定义一组 watch</span>\n    <span>{</span>\n      <span>\"type\"</span><span>:</span> <span>\"key\"</span><span>,</span>            <span>// watch 类型为 key</span>\n      <span>\"key\"</span><span>:</span> <span>\"redis/config\"</span><span>,</span>    <span>// 指定要监视的 key</span>\n      <span>\"handler_type\"</span><span>:</span> <span>\"script\"</span><span>,</span>\n      <span>\"args\"</span><span>:</span> <span>[</span><span>\"/usr/bin/my_handler.sh\"</span><span>,</span> <span>\"-redis\"</span><span>]</span>\n    <span>}</span><span>,</span>\n    <span>{</span>\n      <span>\"type\"</span><span>:</span> <span>\"service\"</span><span>,</span>        <span>// watch 类型为 service</span>\n      <span>\"service\"</span><span>:</span> <span>\"redis\"</span><span>,</span>       <span>// 指定要监视的服务名</span>\n      <span>\"passingonly\"</span><span>:</span> <span>true</span><span>,</span>      <span>// 添加筛选条件，只监视健康的服务</span>\n      <span>\"handler_type\"</span><span>:</span> <span>\"http\"</span><span>,</span>\n      <span>\"http_handler_config\"</span><span>:</span> <span>{</span>\n        <span>\"path\"</span><span>:</span> <span>\"http://10.0.0.1/watch/handler\"</span><span>,</span>\n        <span>\"method\"</span><span>:</span> <span>\"POST\"</span>\n      <span>}</span>\n    <span>}</span>\n  <span>]</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></li>\n</ul>\n<h3 id=\"cli\"> CLI</h3>\n<ul>\n<li>使用 consul 命令行工具可以启动 agent 服务器，也可以作为客户端与 agent 交互。用法：<div><pre><code>consul\n      agent                           <span># 启动 agent 进程，在前台运行</span>\n          -server                     <span># 采用 server 运行模式</span>\n          -config-file <span>&lt;</span>file<span>></span>         <span># 指定配置文件</span>\n          -config-dir /consul/config  <span># 指定配置目录，加载该目录下的配置文件</span>\n\n      members                         <span># 列出所有节点</span>\n      force-leave <span>&lt;</span>node<span>></span>              <span># 强制让一个节点 leave ，进入 left 状态。但如果它依然运行，则可能重新加入集群</span>\n          --prune                     <span># 删除节点。默认会等待 reconnect_timeout 长时间无响应才删除</span>\n      operator\n          raft                        <span># 操作 raft 协议</span>\n              list-peers              <span># 列出所有 raft 节点</span>\n              remove-peer -address<span>=</span><span>\"10.0.0.1:8300\"</span> <span># 删除一个 raft 节点</span>\n\n      catalog                   <span># 访问 catalog</span>\n          datacenters           <span># 列出所有数据中心</span>\n          nodes                 <span># 列出所有节点</span>\n            -service <span>&lt;</span>service<span>></span>  <span># 只显示指定服务所在的节点</span>\n            -detailed\n          services              <span># 列出所有服务</span>\n            -node <span>&lt;</span>node<span>></span>        <span># 只显示指定节点上的服务</span>\n            -tags               <span># 增加显示 tags</span>\n\n      kv                        <span># 访问 KV 数据</span>\n          get <span>&lt;</span>key<span>></span>             <span># 读取一个 key ，返回其 value</span>\n            -keys               <span># 访问前缀匹配的所有 key ，不包括子 key</span>\n            -recurse            <span># 递归访问文件夹中的子 key</span>\n          put <span>&lt;</span>key<span>></span> <span>[</span>value<span>]</span>\n          delete <span>&lt;</span>key<span>></span>\n          <span>export</span> <span>[</span>prefix<span>]</span>       <span># 导出前缀匹配的所有 key ，包括子 key 。返回值为 JSON 格式</span>\n          <span>import</span> <span>[</span>data<span>]</span>         <span># 导入 key 。输入必须为 JSON 格式</span>\n            -prefix <span>[</span>prefix<span>]</span>    <span># 只导入前缀匹配的 key</span>\n\n      snapshot                  <span># 访问 snapshot 功能</span>\n          save    <span>&lt;</span>file<span>></span>        <span># 保存一个快照文件，包含集群当前的 catalog、kv、acl 等数据</span>\n          restore <span>&lt;</span>file<span>></span>        <span># 导入一个快照文件</span>\n          inspect <span>&lt;</span>file<span>></span>        <span># 查看快照的信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br></div></div></li>\n</ul>\n<h3 id=\"api\"> API</h3>\n<ul>\n<li>agent 提供了一些 Restful API ：<div><pre><code><span># 关于 agent</span>\nGET   /v1/agent/members           <span># 获取所有 agent 的信息</span>\nPUT   /v1/agent/reload            <span># 让当前 agent 重新加载其配置文件</span>\nPUT   /v1/agent/leave             <span># 让当前 agent 正常退出集群</span>\nGET   /v1/agent/checks            <span># 获取当前 agent 上所有健康检查的结果信息</span>\nGET   /v1/agent/services                        <span># 获取当前 agent 上注册的所有服务的信息</span>\nGET   /v1/agent/service/<span>&lt;</span>serivce.id<span>></span>            <span># 获取当前 agent 上注册的指定服务的信息</span>\nPUT   /v1/agent/service/register                <span># 注册服务，这会调用 /v1/catalog/register</span>\nPUT   /v1/agent/service/deregister/<span>&lt;</span>serivce.id<span>></span> <span># 注销服务，这会调用 /v1/catalog/deregister</span>\n\n<span># 关于 catalog</span>\nPUT   /v1/catalog/register        <span># 在 catalog 中注册对象</span>\nPUT   /v1/catalog/deregister      <span># 在 catalog 中注销对象</span>\nGET   /v1/catalog/nodes           <span># 列出所有节点</span>\nGET   /v1/catalog/services        <span># 列出所有服务</span>\n\n<span># 关于 Key/Value</span>\nGET     /v1/kv/<span>&lt;</span>key<span>></span>              <span># 获取指定的 key 的信息，包括 key、value</span>\nPUT     /v1/kv/<span>&lt;</span>key<span>></span>              <span># 创建 key ，如果该 key 已存在则更新它</span>\nDELETE  /v1/kv/<span>&lt;</span>key<span>></span>              <span># 删除 key</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>consul</span><span>:</span>\n    <span>container_name</span><span>:</span> consul\n    <span>image</span><span>:</span> consul<span>:</span>1.9.8\n    <span>command</span><span>:</span> agent\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 8300<span>:</span><span>8300</span>\n      <span>-</span> 8301<span>-</span>8302<span>:</span>8301<span>-</span><span>8302</span>\n      <span>-</span> 8301<span>-</span>8302<span>:</span>8301<span>-</span>8302/udp\n      <span>-</span> 8500<span>:</span><span>8500</span>\n      <span>-</span> 8600<span>:</span><span>8600</span>\n      <span>-</span> 8600<span>:</span>8600/udp\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n      <span>-</span> ./config<span>:</span>/consul/config\n      <span>-</span> ./data<span>:</span>/consul/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div><ul>\n<li>容器内以非 root 用户运行服务，需要调整挂载目录的权限：<div><pre><code><span>mkdir</span> -p  config data\n<span>chown</span> -R  <span>100</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>agent 启动时的日志示例：</p>\n<div><pre><code><span>==</span><span>></span> Found address <span>'10.0.0.1'</span> <span>for</span> interface <span>'eth0'</span>, setting <span>bind</span> option<span>..</span>.   <span># 发现网卡的 IP 地址，绑定它</span>\n<span>==</span><span>></span> Starting Consul agent<span>..</span>.\n          Version: <span>'v1.6.1'</span>\n          Node ID: <span>'2e5r747a-806a-a337-8a0f-7ac5o98d0cc4'</span>\n        Node name: <span>'node1'</span>\n        Datacenter: <span>'dc1'</span> <span>(</span>Segment: <span>'&lt;all>'</span><span>)</span>\n            Server: <span>true</span> <span>(</span>Bootstrap: <span>false</span><span>)</span>                                 <span># 是否采用 server 运行模式</span>\n      Client Addr: <span>[</span><span>0.0</span>.0.0<span>]</span> <span>(</span>HTTP: <span>8500</span>, HTTPS: -1, gRPC: -1, DNS: <span>8600</span><span>)</span>   <span># client_addr</span>\n      Cluster Addr: <span>10.0</span>.0.1 <span>(</span>LAN: <span>8301</span>, WAN: <span>8302</span><span>)</span>                         <span># bind_addr</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>Consul 支持多种配置方式，优先级从高到低如下：</p>\n<ul>\n<li>命令行参数</li>\n<li>配置文件：可以是 JSON 或 HCL 格式，文件扩展名为 .json 或 .hcl 。</li>\n<li>默认配置</li>\n</ul>\n</li>\n<li>\n<p>配置文件示例：</p>\n<div><pre><code><span>{</span>\n    <span>// 关于磁盘</span>\n    <span>// \"data_dir\": \"/consul/data\" ,</span>\n    <span>// \"log_file\": \"/var/log/consul\" ,</span>\n    <span>// \"log_level\": \"INFO\",</span>\n    <span>// \"log_json\": true,        // 是否让日志采用 JSON 格式，默认禁用</span>\n\n    <span>// 关于节点</span>\n    <span>// \"datacenter\": \"dc1\",     // 指定该 agent 所属的数据中心名称，默认为 dc1</span>\n    <span>\"node_name\"</span><span>:</span> <span>\"node1\"</span><span>,</span>       <span>// 指定该节点的名称，在集群中唯一。默认采用主机名</span>\n    <span>// \"node_id\": \"xxxx\",       // 指定该节点的 UUID 。 node 名称可以修改，但 node_id 不会变</span>\n    <span>\"server\"</span><span>:</span> <span>true</span><span>,</span>             <span>// agent 是否采用 server 运行模式。默认为 false ，采用 client 运行模式</span>\n    <span>\"ui_config\"</span><span>:</span> <span>{</span>\n        <span>\"enabled\"</span><span>:</span> <span>true</span>         <span>// 是否让 HTTP 端口提供 Web UI 。默认不提供，只提供 Restful API</span>\n    <span>}</span><span>,</span>\n\n    <span>// 关于 IP 地址</span>\n    <span>// \"bind_addr\": \"0.0.0.0\",            // RPC 通信时绑定的地址，供其它 gent 访问，默认绑定 0.0.0.0</span>\n    <span>// \"serf_lan\": \"0.0.0.0\",             // Gossip LAN 通信时绑定的地址，默认等于 bind_addr</span>\n    <span>// \"serf_wan\": \"0.0.0.0\",             // Gossip WAN 通信时绑定的地址，默认等于 bind_addr</span>\n    <span>\"advertise_addr\"</span><span>:</span> <span>\"10.0.0.1\"</span><span>,</span>         <span>// 公布一个地址，供其它 agent 访问。默认公布本机的 IPv4 地址，如果本机有多个地址则启动失败</span>\n    <span>// \"advertise_addr_wan\": \"10.0.0.1\",  // 公布一个地址，供其它 agent 通过 WAN 访问。默认等于 advertise_addr</span>\n    <span>\"client_addr\"</span><span>:</span> <span>\"0.0.0.0\"</span><span>,</span>             <span>// 该 agent 的 HTTP、HTTPS、DNS、gRPC 服务绑定的地址，供业务程序访问。默认绑定 localhost</span>\n\n    <span>// 关于各服务监听的端口，-1 表示禁用</span>\n    <span>// \"ports\": {</span>\n    <span>//     \"server\":   8300,</span>\n    <span>//     \"serf-lan\": 8301,</span>\n    <span>//     \"serf-wan\": 8302,</span>\n    <span>//     \"http\":     8500,</span>\n    <span>//     \"https\":    -1  ,        // 默认为 -1 ，启用时建议为 8501</span>\n    <span>//     \"grpc\":     -1  ,        // 默认为 -1 ，启用时建议为 8502</span>\n    <span>//     \"dns\":      8600,</span>\n    <span>// },</span>\n\n    <span>// 关于加入集群</span>\n    <span>// \"bootstrap\": false,          // 该 agent 启动之后是否直接担任 leader 。默认为 false ，避免与集群已有的 leader 冲突。集群只包含一个节点时，需要启用该参数</span>\n    <span>\"bootstrap_expect\"</span><span>:</span> <span>3</span><span>,</span>          <span>// 当发现指定数量的 server 时，才开始引导集群，选出 leader 。应该设置成与实际 server 总数相同，以避免脑裂</span>\n    <span>// \"start_join\": [\"&lt;IP>\"],      // agent 启动时，连接到其它 agent 的 LAN 端口，加入其所属的集群。如果加入失败，则启动失败</span>\n    <span>// \"start_join_wan\": [\"&lt;IP>\"],  // 通过 WAN 端口加入集群</span>\n    <span>\"retry_join\"</span><span>:</span> <span>[</span><span>\"&lt;IP>\"</span><span>]</span><span>,</span>         <span>// 代替 start_join 方式，如果加入失败，则自动重试</span>\n    <span>// \"retry_interval\": \"30s\",     // 重试的间隔时间</span>\n    <span>// \"retry_max\": \"0\",            // 重试次数。默认为 0 ，即不限制</span>\n    <span>// \"retry_join_wan\": [\"&lt;IP>\"],  // 代理 start_join_wan 方式</span>\n    <span>// \"retry_interval_wan\": \"30s\",</span>\n    <span>// \"retry_max_wan\": \"0\",</span>\n    <span>\"rejoin_after_leave\"</span><span>:</span> <span>true</span><span>,</span>         <span>// agent 每次启动是否重新 join 。默认为 false ，只要成功 join 一次之后，重启时并不会重新 join ，导致该 agent 可能故障过久而被被集群删除</span>\n    <span>// \"reconnect_timeout\": \"72h\",      // 删除集群中长时间无响应的 LAN 节点，包括 failed、left 状态</span>\n    <span>// \"reconnect_timeout_wan\": \"72h\",  // 删除集群中长时间无响应的 WAN 节点</span>\n    <span>// \"limits\": {</span>\n    <span>//     \"http_max_conns_per_client\": 200  // 限制每个客户端 IP 的并发连接数</span>\n    <span>// }</span>\n\n    <span>// 关于 DNS</span>\n    <span>// \"domain\": \"consul\",          // 让 agent 解析指向该域名的 DNS 查询请求，其它请求则转发给上游 DNS 服务器</span>\n    <span>// \"recursors\": \"&lt;IP>\",         // 添加上游 DNS 服务器</span>\n    <span>// \"dns_config\": {</span>\n    <span>//     \"node_ttl\": \"0s\",        // ttl ，默认为 0 ，即禁用缓存</span>\n    <span>//     \"service_ttl\": \"0s\",</span>\n    <span>//     \"only_passing\": false,   // DNS 结果中是否排除是否健康检查为 warning 或 critical 的节点。默认为 false ，只排除 failing 的节点</span>\n    <span>// }</span>\n    <span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br></div></div></li>\n</ul>\n<h3 id=\"acl\"> ACL</h3>\n<p>Consul 支持为 HTTP、RPC 通信设置 ACL 规则，主要概念如下：</p>\n<ul>\n<li>\n<p>Token</p>\n<ul>\n<li>：一个格式像 UUID 的十六进制字符串，由 Consul 随机生成，代表一个用户。</li>\n<li>token 的属性：\n<ul>\n<li>AccessorID ：token 的标识符，不需要保密。</li>\n<li>SecretID ：用户实际使用的 token 。</li>\n</ul>\n</li>\n<li>访问 Consul 时，可使用 token 进行身份认证，有以下几种方法：\n<ul>\n<li>访问 Web 页面，点击右上角的 Log in 按钮，输入 token 进行登录。</li>\n<li>客户端发送 HTTP 请求，在 URL 请求参数中包含 <code>?token=******</code> ，或者在 Header 中包含 <code>Authorization: Bearer ******</code> 。</li>\n<li>执行 consul 命令，加上参数 <code>-token=******</code> ，或者声明环境变量 <code>export CONSUL_HTTP_TOKEN=******</code> 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Policy</p>\n<ul>\n<li>\n<p>：访问策略，用于控制某个 token 的访问权限。</p>\n</li>\n<li>\n<p>格式如下：</p>\n<div><pre><code>&lt;resource> <span>\"&lt;name>\"</span> <span>{</span>\n  <span>policy</span> <span>=</span> <span>\"&lt;policy>\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>语义：对 name 名称的 resource 资源，策略为 policy 。</li>\n<li>resource 有多种取值，代表对不同类型资源的操作：<div><pre><code>agent     <span># Consul agent ，可执行 join、leave 等操作</span>\n<span>node</span>      <span># 数据节点</span>\n<span>service</span>\nkey       <span># KV 资源</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>上述 resource 还可扩展成 <code>&lt;resource&gt;_prefix</code> ，用于进行前缀匹配。如果指定的前缀为空，则匹配所有名称的该类资源。</li>\n</ul>\n</li>\n<li>policy 有多种取值，从高到低如下：<div><pre><code>deny      <span># 不允许读、写</span>\n<span>write</span>     <span># 允许读、写、list</span>\nlist      <span># 只对 key 资源有效，允许递归读取当前 key 的子 key</span>\n<span>read</span>      <span># 只允许读</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>在 Web 界面，node、service 资源总是只读的，不支持修改。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>例：</p>\n<div><pre><code>service_prefix <span>\"\"</span> <span>{</span>     <span># 允许读取所有服务</span>\n  <span>policy</span> <span>=</span> <span>\"read\"</span>\n<span>}</span>\nservice <span>\"service1\"</span> <span>{</span>    <span># 允许读写指定服务</span>\n  <span>policy</span> <span>=</span> <span>\"write\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><div><pre><code>key <span>\"\"</span> <span>{</span>                          <span># 允许读取名为空的 key ，从而在 Web 端显示 Key/Value 页面</span>\n  <span>policy</span> <span>=</span> <span>\"read\"</span>\n<span>}</span>\nkey_prefix <span>\"test_env/project1\"</span> <span>{</span>  <span># 允许读写某个路径开头的 key</span>\n  <span>policy</span> <span>=</span> <span>\"read\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>内置了一个名为 Global Management 的策略，赋予对所有资源的访问权限。</p>\n</li>\n<li>\n<p>内置了 Service Identities 和 Node Identities ，作为服务、node 的策略模板。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>Role</p>\n<ul>\n<li>：角色。可以给某个角色分配一组 Policy ，然后让一组 token 采用该角色。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"示例\"> 示例</h4>\n<p>启用 ACL 的步骤：</p>\n<ol>\n<li>\n<p>修改配置文件：</p>\n<div><pre><code><span>{</span>\n  <span>\"acl\"</span> <span>:</span> <span>{</span>\n    <span>\"enabled\"</span> <span>:</span> <span>true</span><span>,</span>           <span>// 是否启用 ACL ，默认禁用</span>\n    <span>\"default_policy\"</span> <span>:</span> <span>\"deny\"</span><span>,</span>  <span>// 当用户的操作不匹配已有的 ACL 规则时，默认采用的策略。默认为 allow</span>\n    <span>\"tokens\"</span><span>:</span> <span>{</span>\n      <span>// \"default\": \"******\",   // 如果设置了 default token ，则会取代 Anonymous token</span>\n      <span>\"agent\"</span><span>:</span> <span>\"******\"</span>         <span>// 指定 agent 之间通信时采用的 token 。如果未指定，则采用 Anonymous token</span>\n    <span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n<li>\n<p>执行以下命令，初始化 ACL ：</p>\n<div><pre><code>consul acl bootstrap\n</code></pre>\n<div><span>1</span><br></div></div><p>这会创建两个 token ：</p>\n<ul>\n<li>管理员 token ：分配 Global Management 策略。</li>\n<li>Anonymous token ：不分配策略。当 agent 收到的请求不包含 token 时，会当作该 token 处理。</li>\n</ul>\n</li>\n<li>\n<p>访问 Web 页面，用管理员 token 登录，创建一个供 agent 使用的 token ，分配的 policy 如下：</p>\n<div><pre><code>node_prefix <span>\"\"</span> <span>{</span>\n  <span>policy</span> <span>=</span> <span>\"write\"</span>\n<span>}</span>\nservice_prefix <span>\"\"</span> <span>{</span>\n  <span>policy</span> <span>=</span> <span>\"read\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>将该 token 保存到配置文件的 acl.tokens.agent 中，重启 agent 即可生效。</p>\n</li>\n<li>\n<p>创建一个允许读取所有 node 的策略：</p>\n<div><pre><code>node_prefix <span>\"\"</span> <span>{</span>\n  <span>policy</span> <span>=</span> <span>\"read\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>DNS 请求不支持传递 token ，因此建议将该策略分配给 Anonymous token 。</p>\n</li>\n</ol>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Jumpserver",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/Jumpserver.html",
      "id": "/Hardware/DevOps/ConfigurationManagement/Jumpserver.html",
      "content_html": "<h1 id=\"jumpserver\"> Jumpserver</h1>\n<p>：一个 Web 服务器，提供了跳板机、堡垒机的功能，简称为 JMS 。</p>\n<ul>\n<li><a href=\"https://docs.jumpserver.org/zh/master/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>由飞致云公司开源，基于 Python 的 Django 框架开发，于 2018 年发布 1.0 版本。</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<h3 id=\"功能\"> 功能</h3>\n<ul>\n<li>支持基于 SSH、Telnet、RDP、VNC 协议托管 Linux 或 Windows 主机，还可管理 Mysql 等应用。</li>\n<li>连接 Linux 主机时会打开一个 WebSSH 窗口，连接 Windows 主机时会打开一个 GUI 窗口。\n<ul>\n<li>支持 Ctrl+C 复制、Ctrl+V 粘贴等快捷键。</li>\n<li>支持基于 SFTP 协议上传、下载文件。</li>\n<li>基于 Ansible 批量管理主机，支持批量执行命令。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优点\"> 优点</h3>\n<ul>\n<li>便于批量管理主机的登录权限。</li>\n<li>避免将主机的登录密码直接告诉用户。</li>\n<li>用户可以通过跳板机连接到网络不能直达的主机。</li>\n<li>提供了命令过滤、操作记录等功能，安全程度高。</li>\n</ul>\n<h3 id=\"缺点\"> 缺点</h3>\n<ul>\n<li>存在单点故障的风险。JMS 挂掉时用户就不可以访问所有托管主机，JMS 被入侵时所有托管主机都有安全风险。\n<ul>\n<li>不过可以分布式部署多实例，进行负载均衡，实现高可用。</li>\n</ul>\n</li>\n<li>与 SecureCRT 等专用的 SSH 客户端相比，功能较少。</li>\n</ul>\n<h3 id=\"主要模块\"> 主要模块</h3>\n<ul>\n<li>Core ：核心组件，通过 Restful API 与其它模块交互。</li>\n<li>Coco ：一个 SSH 客户端，采用 Python 开发。目前已被 Koko 替换。</li>\n<li>Koko ：一个 SSH 客户端，采用 Golang 开发。</li>\n<li>Guacamole ：一个无客户端的远程桌面网关，由 Apache 开源。JMS 调用它来实现 RDP 功能。</li>\n<li>Luna ：用于渲染、输出前端文件。</li>\n<li>Nginx ：用于反向代理 Luna 。</li>\n<li>MySQL</li>\n<li>Redis</li>\n<li>Celery</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<p>下载<a href=\"https://github.com/jumpserver/installer\" target=\"_blank\" rel=\"noopener noreferrer\">官方脚本</a>：</p>\n<div><pre><code><span>wget</span> https://github.com/jumpserver/installer/releases/download/v2.9.1/jumpserver-installer-v2.9.1.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div><p>解压后执行：</p>\n<div><pre><code><span>sh</span> jmsctl.sh\n              <span>install</span>     <span># 安装，下载 Docker 镜像，并提示用户进行一些配置</span>\n              uninstall   <span># 卸载</span>\n              upgrade     <span># 升级</span>\n\n              start\n              stop\n              status\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>部署时至少需要 4G 内存。</li>\n<li>基于 docker-compose 启动。</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<p>配置文件位于 <code>jumpserver/config/config.txt</code> 。部分内容示例：</p>\n<div><pre><code><span>HTTP_PORT</span><span>=</span><span>8080</span>      <span># HTTP 端口，供用户通过浏览器访问 JMS</span>\n<span>HTTPS_PORT</span><span>=</span><span>8443</span>     <span># HTTPS 端口</span>\n<span>SSH_PORT</span><span>=</span><span>2222</span>       <span># SSH 端口，供用户通过 SSH 客户端访问 JMS</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>默认账号、密码为 admin、admin 。</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<p>管理页面示例：</p>\n<p><img src=\"./Jumpserver01.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>用户管理：用于管理 JMS 网站本身的用户。用户登录 JMS 之后，才可以跳转登录一些服务器。</li>\n<li>资产管理\n<ul>\n<li>资产列表：用于添加一些服务器作为资产，可以按树形结构分组。</li>\n<li>网域列表：用于添加 SSH 代理，使得 JMS 可以连接到某个网络的服务器。</li>\n<li>管理用户：指 JMS 通过 Ansible 批量登录服务器时采用的用户，获取硬件信息，还可以推送创建系统用户。</li>\n<li>系统用户：指通过 Web 终端登录服务器时采用的用户。</li>\n</ul>\n</li>\n<li>权限管理：用于控制 JMS 用户对哪些资产拥有访问权限。\n<ul>\n<li>例如：\n<ol>\n<li>先添加一些服务器资产，分组节点为 “测试环境” 。并创建相应的管理用户、系统用户，都名为 “测试环境-管理员” 。</li>\n<li>再创建一个名为 “测试环境-管理员” 的授权规则，将上述服务器的系统用户分配给某些 JMS 用户。</li>\n<li>当 JMS 用户登录某个服务器时，如果有多个系统用户可用，则默认采用优先级最高的那个。如果优先级相同，则会弹出一个对话框供选择。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>会话管理：\n<ul>\n<li>会话管理：用于管理用户打开的 Web 终端，支持终断、实时监控、回放。\n<ul>\n<li>会实时监控用户输入的每个字符，包括 Enter、Backspace、Ctrl+C 。</li>\n<li>连命令的终端输出也会监控。</li>\n</ul>\n</li>\n<li>命令记录：用于记录用户在 Web 终端执行过的命令。\n<ul>\n<li>不适合实时监控，存在一条命令的滞后。</li>\n<li>只会记录用户执行过的命令，不会记录用户输入的 Enter、Backspace、Ctrl+C 。</li>\n<li>记录命令的终端输出时，最多记录十几行。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Web 终端示例：</p>\n<p><img src=\"./Jumpserver02.png\" alt=\"\" loading=\"lazy\"></p>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Nacos",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/Nacos.html",
      "id": "/Hardware/DevOps/ConfigurationManagement/Nacos.html",
      "content_html": "<h1 id=\"nacos\"> Nacos</h1>\n<p>：一个 Web 服务器，提供了配置管理、服务发现的功能。</p>\n<ul>\n<li><a href=\"https://nacos.io/zh-cn/docs/quick-start.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>发音为 <code>/nɑ:kəʊs/</code> 。</li>\n<li>由阿里巴巴公司开源，采用 Java 开发。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制包，解压后以单机模式启动：</p>\n<div><pre><code><span>sh</span> startup.sh -m standalone\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>访问 <code>http://127.0.0.1:8848/nacos/</code> 即可登录 Nacos 的 Web 页面，默认账号、密码为 nacos、nacos 。</li>\n</ul>\n</li>\n<li>\n<p>或者用 Docker 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>nacos</span><span>:</span>\n    <span>container_name</span><span>:</span> nacos\n    <span>image</span><span>:</span> nacos/nacos<span>-</span>server<span>:</span>v2.0.4\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span>MODE</span><span>:</span> standalone\n      <span># JVM_XMS: 1g</span>\n      <span># JVM_XMX: 1g</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 8848<span>:</span><span>8848</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>Nacos 默认将数据存储在自己目录中，可配置以下环境变量，将数据存储到 MySQL 中：<div><pre><code><span>SPRING_DATASOURCE_PLATFORM</span><span>:</span> mysql\n<span>MYSQL_SERVICE_HOST</span><span>:</span> 10.0.0.1\n<span>MYSQL_SERVICE_PORT</span><span>:</span> <span>3306</span>\n<span>MYSQL_SERVICE_USER</span><span>:</span> nacos\n<span>MYSQL_SERVICE_PASSWORD</span><span>:</span> <span>******</span>\n<span>MYSQL_SERVICE_DB_NAME</span><span>:</span> nacos\n<span>MYSQL_SERVICE_DB_PARAM</span><span>:</span> characterEncoding=utf8<span>&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=false</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div>需要执行数据库的初始化脚本 <a href=\"https://github.com/alibaba/nacos/blob/master/distribution/conf/nacos-mysql.sql\" target=\"_blank\" rel=\"noopener noreferrer\">nacos-mysql.sql</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"配置管理\"> 配置管理</h3>\n<ul>\n<li>Configuration Set ：配置集，即一个配置文件，包含一些配置参数。</li>\n<li>DataID ：每个配置集的 ID ，命名格式为 <code>${prefix}-${spring.profile.active}.${file-extension}</code> 。</li>\n<li>Namespace ：Nacos 支持创建多个命名空间，比如 default、test、prod ，用于隔离 service、DataID、Group 等资源。</li>\n<li>Group ：每个 Namespace 中可以创建多个分组，用于隔离配置集。</li>\n</ul>\n<h3 id=\"服务发现\"> 服务发现</h3>\n<ul>\n<li>\n<p>Nacos 将注册的服务分为两类，采用不同的健康检查方式：</p>\n<ul>\n<li>临时实例\n<ul>\n<li>：不健康一段时间之后会被自动注销。</li>\n<li>临时实例会定期向 Nacos 发送一个 HTTP 请求，进行心跳检查。如果该实例尚未注册，则自动注册。</li>\n</ul>\n</li>\n<li>持久实例\n<ul>\n<li>：不健康时不会注销，只是不加入负载均衡。</li>\n<li>Nacos 定期（默认间隔为 20 秒）向持久实例发送一个 TCP 或 HTTP 请求，如果响应失败则将它标记为不健康。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Spring Boot 服务使用 Nacos 的配置示例：</p>\n<div><pre><code><span>server</span><span>:</span>\n  <span>port</span><span>:</span> <span>80</span>\n<span>spring</span><span>:</span>\n  <span>application</span><span>:</span>\n    <span>name</span><span>:</span> demo\n  <span>profiles</span><span>:</span>\n    <span>active</span><span>:</span> test\n  <span>cloud</span><span>:</span>\n    <span>nacos</span><span>:</span>\n      <span>config</span><span>:</span>                                     <span># 关于配置管理功能</span>\n        <span>server-addr</span><span>:</span> 10.0.0.1<span>:</span><span>8848</span>                <span># Nacos 服务器的地址</span>\n        <span># namespace: public                       # 该服务所属的命名空间</span>\n        <span># group: DEFAULT_GROUP                    # 该服务所属的 group</span>\n        <span># prefix: ${spring.application.name}      # 根据 prefix 等参数确定 DataID ，找到对应的配置集，给该服务采用</span>\n        <span># file-extension: properties              # 配置文件的扩展名，比如 yaml</span>\n        <span># refresh:</span>\n        <span>#   enabled: true                         # 是否自动从 Nacos 获取最新的配置，这样不必重启服务</span>\n      <span>discovery</span><span>:</span>                                  <span># 关于服务发现功能</span>\n        <span>server-addr</span><span>:</span> 10.0.0.1<span>:</span><span>8848</span>\n        <span># namespace: public</span>\n        <span># group: DEFAULT_GROUP</span>\n        <span># service: ${spring.application.name}     # 注册的服务名</span>\n        <span># spring.cloud.nacos.discovery.ip: xxx    # 注册的 IP ，供其它服务调用。默认采用第一个网卡的 IP</span>\n        <span># spring.cloud.nacos.discovery.port: ${server.port}</span>\n        <span># ephemeral: true                         # 是否为临时实例</span>\n        <span># weight: 1                               # 该服务实例在负载均衡时的权重，取值范围为 1~100</span>\n        <span># metadata:                               # 添加一些该服务实例的元数据</span>\n        <span>#   preserved.heart.beat.interval: 5000   # 发送心跳的间隔时长，单位为 ms</span>\n        <span>#   preserved.heart.beat.timeout: 15000   # 如果该时长内无心跳，则 Nacos 将该服务实例标记为不健康</span>\n        <span>#   preserved.ip.delete.timeout: 30000    # 如果该时长内无心跳，则 Nacos 将该服务实例注销</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br></div></div></li>\n<li>\n<p>健康保护阈值：一个浮点数，取值范围为 0~1 。当一个服务的健康实例数占总数的比值小于阈值时，Nacos 会将不健康的实例加入负载均衡。这样会损失部分流量，但避免剩下的健康实例负载过大、服务雪崩。</p>\n</li>\n</ul>\n<h3 id=\"http-api\"> HTTP API</h3>\n<div><pre><code><span># 发布配置</span>\n<span>curl</span> -X POST <span>\"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=d1&amp;group=test&amp;content=HelloWorld\"</span>\n\n<span># 获取配置</span>\n<span>curl</span> -X GET <span>\"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=d1&amp;group=test\"</span>\n\n<span># 注册服务</span>\n<span>curl</span> -X POST <span>'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nginx&amp;ip=10.0.0.1&amp;port=80'</span>\n\n<span># 发现服务</span>\n<span>curl</span> -X GET <span>'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nginx'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Supervisor",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/Supervisor.html",
      "id": "/Hardware/DevOps/ConfigurationManagement/Supervisor.html",
      "content_html": "<h1 id=\"supervisor\"> Supervisor</h1>\n<p>：一个命令行工具，用于管理进程，类似于 systemd 。，</p>\n<ul>\n<li><a href=\"http://supervisord.org/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Python 开发。</li>\n<li>功能：\n<ul>\n<li>支持运行在 Linux、MacOS 等系统上，不支持 Windows 系统。</li>\n<li>可以通过简单的命令来启动、停止进程，并且当进程异常退出时会自动重启它。</li>\n<li>可以记录进程的 stdout、stderr 。</li>\n<li>提供了 Web 管理页面。</li>\n</ul>\n</li>\n<li>采用 C/S 架构：\n<ul>\n<li>首先运行一个守护进程 supervisord ，然后由它以子进程的方式启动各个托管的进程。</li>\n<li>用户可以执行 supervisorctl 命令，通过与 supervisord 通信，来控制托管的进程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装\"> 安装</h2>\n<ul>\n<li>\n<p>用 yum 安装：</p>\n<div><pre><code>yum <span>install</span> supervisor\n</code></pre>\n<div><span>1</span><br></div></div><p>然后启动：</p>\n<div><pre><code>supervisord                           <span># 启动服务器</span>\n            -c /etc/supervisord.conf  <span># 使用指定的配置文件</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>或者下载 Python 库然后安装：</p>\n<div><pre><code><span>wget</span> https://github.com/Supervisor/supervisor/archive/4.1.0.tar.gz\n<span>tar</span> -zxvf supervisor-4.1.0.tar.gz\n<span>cd</span> supervisor-4.1.0\npython setup.py <span>install</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"开机自启\"> 开机自启</h3>\n<p>虽然 Supervisor 能自动重启它托管的进程，但 supervisord 本身还不能自动重启。因此建议用 systemd 启动 supervisord ，从而保证 supervisord 能够开机自启、自动重启。步骤如下：</p>\n<ol>\n<li>添加配置文件 /usr/lib/systemd/system/supervisord.service ：<div><pre><code><span><span>[</span><span>Unit</span><span>]</span></span>\n<span>Description</span><span>=</span><span>Supervisor Daemon</span>\n\n<span><span>[</span><span>Service</span><span>]</span></span>\n<span>User</span><span>=</span><span>leo</span>\n<span>Group</span><span>=</span><span>leo</span>\n<span>Type</span><span>=</span><span>forking</span>\n<span>ExecStart</span><span>=</span><span>/usr/bin/supervisord -c /etc/supervisord.conf</span>\n<span>ExecStop</span><span>=</span><span>/usr/bin/supervisorctl shutdown</span>\n<span>ExecReload</span><span>=</span><span>/usr/bin/supervisorctl reload</span>\n<span>KillMode</span><span>=</span><span>process</span>\n<span>Restart</span><span>=</span><span>on-failure</span>\n<span>RestartSec</span><span>=</span><span>1s</span>\n\n<span><span>[</span><span>Install</span><span>]</span></span>\n<span>WantedBy</span><span>=</span><span>multi-user.target</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n<li>然后启动 supervisord ：<div><pre><code>systemctl start supervisord\nsystemctl <span>enable</span> supervisord\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ol>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>用户需要先在配置文件中定义要控制的进程，然后才能用 Supervisor 管理。</li>\n<li>Supervisor 默认使用 /etc/supervisord.conf 作为主配置文件（常用于保存 supervisord 的配置）。\n<ul>\n<li>还会导入 /etc/supervisord.d/ 目录下的其它配置文件（常用于保存各个进程的配置），这些配置文件的扩展名为 .ini ，采用 INI 的语法。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"主配置\"> 主配置</h3>\n<div><pre><code><span><span>[</span><span>unix_http_server</span><span>]</span></span>\n<span>file</span><span>=</span><span>/var/run/supervisor/supervisor.sock   ; supervisord 的 sock 文件的路径</span>\n<span>;chmod=0700                 ; sock 文件的权限(默认为 0700)</span>\n<span>;chown=nobody:nogroup       ; sock 文件的 uid:gid</span>\n\n<span>;[inet_http_server]         ; Web 管理页面（默认不启用）</span>\n<span>;port=127.0.0.1:9001</span>\n<span>;username=user</span>\n<span>;password=123</span>\n\n<span><span>[</span><span>supervisord</span><span>]</span></span>\n<span>logfile</span><span>=</span><span>/var/log/supervisor/supervisord.log</span>\n<span>;logfile_maxbytes=50MB</span>\n<span>;logfile_backups=10</span>\n<span>;loglevel=info</span>\n<span>pidfile</span><span>=</span><span>/var/run/supervisord.pid</span>\n<span>nodaemon</span><span>=</span><span>false</span>\n\n<span><span>[</span><span>rpcinterface:supervisor</span><span>]</span></span>\n<span>supervisor.rpcinterface_factory</span><span>=</span><span>supervisor.rpcinterface:make_main_rpcinterface</span>\n\n<span><span>[</span><span>supervisorctl</span><span>]</span></span>\n<span>serverurl</span><span>=</span><span>unix:///var/run/supervisor/supervisor.sock</span>\n\n<span><span>[</span><span>include</span><span>]</span></span>   ; 导入其它配置文件\n<span>files</span> <span>=</span> <span>supervisord.d/*.ini</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br></div></div><ul>\n<li>使用非 root 用户启动 supervisord 时，它会因为无法创建某些目录而无法启动。因此建议采用以下措施：\n<ul>\n<li>将配置文件中的 <code>/var/run/supervisor/</code> 目录改为 <code>/var/log/supervisor/</code> 。</li>\n<li>手动创建以下目录，并分配权限：<div><pre><code><span>sudo</span> <span>mkdir</span> /etc/supervisord.d/\n<span>sudo</span> <span>mkdir</span> /var/log/supervisor/\n\n<span>sudo</span> <span>chown</span> -R leo:leo /etc/supervisord.d/\n<span>sudo</span> <span>chown</span> -R leo:leo /etc/supervisord.conf\n<span>sudo</span> <span>chown</span> -R leo:leo /var/log/supervisor/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n<li>当 supervisord 开启了 inet_http_server 时，可以通过发出 HTTP 请求来管理该主机上的进程，如下：<div><pre><code><span>curl</span> -L <span>\"http://10.0.0.1:9001/index.html?processname=ping&amp;action=start\"</span> -u <span>\"admin:WJnhZdpFvtml\"</span>   <span># 启动</span>\n<span>curl</span> -L <span>\"http://10.0.0.1:9001/index.html?processname=ping&amp;action=stop\"</span> -u <span>\"admin:WJnhZdpFvtml\"</span>    <span># 停止</span>\n<span>curl</span> -L <span>\"http://10.0.0.1:9001/index.html?processname=ping&amp;action=restart\"</span> -u <span>\"admin:WJnhZdpFvtml\"</span> <span># 重启</span>\n<span>curl</span> -L <span>\"http://10.0.0.1:9001/logtail/ping\"</span> -u <span>\"admin:WJnhZdpFvtml\"</span>                               <span># 查看日志</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"进程配置\"> 进程配置</h3>\n<div><pre><code><span><span>[</span><span>program:ping</span><span>]</span></span>              ; 被管理的进程名\n<span>command</span><span>=</span><span>/bin/ping 127.0.0.1 ; 该进程的启动命令</span>\n<span>directory</span><span>=</span><span>/root             ; 工作目录（执行 command 之前会切换到该目录）</span>\n<span>user</span><span>=</span><span>root                   ; 用哪个用户启动该进程</span>\n<span>;environment=A=\"1\",B=\"2\"    ; 设置环境变量</span>\n<span>;numprocs=1                 ; 该进程要启动多少个副本</span>\n<span>;priority=999               ; 进程启动的优先级，值越小则越优先启动</span>\n\n<span>autostart</span><span>=</span><span>true              ; 当 supervisord 启动时是否自动启动该进程</span>\n<span>autorestart</span><span>=</span><span>unexpected      ; 当进程启动成功之后退出时是否重启它</span>\n<span>startsecs</span><span>=</span><span>1                 ; 进程启动之后保持运行多少秒，才视作进程启动成功了</span>\n<span>startretries</span><span>=</span><span>3              ; 启动失败之后最多尝试重启多少次</span>\n<span>;exitcodes=0,2              ; 如果进程以这些退出码退出，则视作正常退出，否则视作异常退出</span>\n<span>;stopsignal=TERM            ; 当 supervisord 主动终止该进程时，发送哪种信号（可以是 TERM、HUP、INT、QUIT、KILL、USR1、USR2）</span>\n<span>;stopwaitsecs=10            ; 发送 stopsignal 信号之后，如果超过 stopwaitsecs 秒进程仍然没退出，则发送 SIGKILL 信号强制终止</span>\n<span>;stopasgroup=false          ; 发送 stopsignal 信号时，是否发送给子进程</span>\n<span>;killasgroup=false          ; 发送 SIGKILL 信号时，是否发送给子进程</span>\n\n<span>stdout_logfile</span><span>=</span><span>/var/log/supervisor/%(program_name)s_stdout.log   ; stdout 日志文件的保存路径（不配置的话就不会记录日志）</span>\n<span>stdout_logfile_maxbytes</span><span>=</span><span>100MB                                    ; stdout 日志文件的最大大小，超出则会循环写入，设置成 0 则不限制大小</span>\n<span>stdout_logfile_backups</span><span>=</span><span>0                                         ; 最多保存多少份以前的日志文件（按 *.1、*.2、*.3 格式编号），设置成 0 则不保存</span>\n<span>;redirect_stderr=false                                           ; 是否把 stderr 重定向到 stdout</span>\n<span>stderr_logfile</span><span>=</span><span>/var/log/supervisor/%(program_name)s_stderr.log   ; stderr 日志文件的保存路径</span>\n<span>stderr_logfile_maxbytes</span><span>=</span><span>100MB</span>\n<span>stderr_logfile_backups</span><span>=</span><span>0</span>\n\n<span>;[group:test]                       ; 创建一个 group ，便于同时管理多个 program</span>\n<span>;programs=ping,program2,program3</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br></div></div><ul>\n<li>\n<p>如果 command 是执行一个可执行文件，则必须使用绝对路径，如下：</p>\n<div><pre><code><span>command</span><span>=</span><span>./test.sh         # 错误</span>\n<span>command</span><span>=</span><span>/root/test.sh     # 正确</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>command 不支持动态取值，如下：</p>\n<div><pre><code><span>command</span><span>=</span><span>echo $PWD     # 执行结果相当于 echo '$PWD'</span>\n<span>command</span><span>=</span><span>echo `date`   # 执行结果相当于 echo '`date`'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>如果需要动态取值，建议将 command 保存到一个 sh 脚本中，然后执行该 sh 脚本。</p>\n</li>\n<li>\n<p>用 supervisord 管理的进程必须保持在前台运行，否则会脱离 supervisord 的控制，不能捕捉它的 stdout、stderr ，也不能终止它。</p>\n</li>\n<li>\n<p>用 supervisord 启动 Python 进程时， Python 解释器默认不会自动刷新输出缓冲区，导致不能记录该进程的 stdout、stderr 。因此需要用 python -u 的方式启动，禁用输出缓冲区。如下：</p>\n<div><pre><code><span>command</span><span>=</span><span>python -u test.py</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>当 supervisord 启动一个进程时（状态为 STARTING ）：</p>\n<ul>\n<li>如果进程在 startsecs 秒之内退出了（包括正常退出、异常退出），则视作启动失败（状态为 BACKOFF ），最多尝试重启 startretries 次（如果依然失败则状态为 FATAL ）。</li>\n<li>如果进程在 startsecs 秒之内没有退出，则视作进程启动成功了（状态为 RUNNING ）。</li>\n<li>如果进程在 startsecs 秒之后退出了（包括正常退出、异常退出，状态为 EXITED ），则根据 autorestart 策略决定是否重启它（不受 startretries 限制）。</li>\n<li>如果进程在 startsecs 秒之后被用户通过 supervisorctl stop 命令主动停止了，则状态为 STOPPED 。</li>\n</ul>\n</li>\n<li>\n<p>使用 supervisorctl start 启动进程时，至少会阻塞前端 startsecs 秒。</p>\n</li>\n<li>\n<p>autorestart 有三种取值，决定了进程（启动成功之后）退出时是否重启它：</p>\n<ul>\n<li>true ：总是重启。</li>\n<li>flase ：总是不重启。</li>\n<li>unexpected ：异常退出时才重启，即退出码与 exitcodes 不同。</li>\n</ul>\n</li>\n<li>\n<p>建议为进程只保留一份日志，另外用 logrotate 来按日期切割日志。配置如下：</p>\n<div><pre><code><span>stdout_logfile</span><span>=</span><span>/var/log/supervisor/%(program_name)s.out</span>\n<span>stdout_logfile_maxbytes</span><span>=</span><span>0</span>\n<span>stdout_logfile_backups</span><span>=</span><span>0</span>\n<span>redirect_stderr</span><span>=</span><span>true</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h2 id=\"命令\"> 命令</h2>\n<div><pre><code>supervisorctl\n              start <span>&lt;</span>name<span>></span>    <span># 启动进程</span>\n              stop <span>&lt;</span>name<span>></span>     <span># 停止进程</span>\n              restart <span>&lt;</span>name<span>></span>  <span># 重启进程</span>\n\n              status          <span># 查看所有进程的状态</span>\n              update          <span># 重新加载发生改变的 /etc/supervisord.d/*.ini 配置文件（这会自动重启受影响的进程）</span>\n\n              <span>shutdown</span>        <span># 停止 supervisord</span>\n              reload          <span># 重启 supervisord（这会重新加载所有配置文件、重启所有进程）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>直接执行 supervisorctl 命令会进入其交互式终端。</li>\n<li><code>&lt;name&gt;</code> 有以下几种取值：\n<ul>\n<li><code>all</code> ：选中当前主机上所有被 supervisord 管理的进程。</li>\n<li><code>program_name</code> ：只选中指定名字的进程。</li>\n<li><code>group_name</code> ：选中一个组内的所有进程。</li>\n<li><code>group_name:program_name</code> ：选中一个组内的指定进程。</li>\n</ul>\n</li>\n<li>supervisord 启动的进程都是它的子进程，因此：\n<ul>\n<li>如果修改了 shell 的环境变量，要重启 supervisord 才会生效。</li>\n<li>如果 supervisord 进程退出了，通常会自动终止它管理的各个进程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"日志\"> 日志</h2>\n<p>Supervisor 的日志文件默认保存在 <code>/var/log/supervisor/</code> 目录下，主要包括：</p>\n<ul>\n<li>supervisord.log ：记录了 supervisord 的日志，例如：<div><pre><code>2020-01-12 06:42:25,426 INFO exited: kafka-consumer (exit status 1; not expected)     # 进程退出了，且没有使用预期的退出码\n2020-01-12 06:42:25,496 INFO spawned: &#39;kafka-consumer&#39; with pid 20535                 # 已重新启动进程\n2020-01-12 06:42:26,487 INFO success: kafka-consumer entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)  # 进程启动成功\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>%(program_name)s_stdout.log ：记录了进程的 stdout 。</li>\n<li>%(program_name)s_stderr.log ：记录了进程的 stderr 。</li>\n</ul>\n<h2 id=\"cesi\"> Cesi</h2>\n<p>：一个 Web 服务器，基于 Python3 的 Flask 开发，用于管理多台主机上的 Supervisor （需要它们开启 inet_http_server ）。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/gamegos/cesi\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>安装：</p>\n<div><pre><code><span>wget</span> https://github.com/gamegos/cesi/releases/download/v2.6.8/cesi-extended.tar.gz\n<span>mkdir</span> cesi/\n<span>tar</span> -zxvf cesi-extended.tar.gz -C cesi/\n<span>cd</span> cesi/\npip3 <span>install</span> -r requirements.txt\npython3 cesi/run.py --config-file defaults/cesi.conf.toml\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>启动之后，访问 <a href=\"http://127.0.0.1:5000\" target=\"_blank\" rel=\"noopener noreferrer\">http://127.0.0.1:5000</a> 即可查看 Web 页面。默认的账号、密码为 admin、admin 。</li>\n</ul>\n</li>\n<li>\n<p>Cesi 的主配置文件是 defaults/cesi.conf.toml ，内容示例如下：</p>\n<div><pre><code><span><span>[</span><span>cesi</span><span>]</span></span>                            # 对 cesi 本身的配置\n<span>database</span> <span>=</span> <span>\"sqlite:///users.db\"   # SQLite 数据库的位置</span>\n<span>activity_log</span> <span>=</span> <span>\"activity.log\"     # 日志文件的保存路径</span>\n<span>admin_username</span> <span>=</span> <span>\"<span>admin</span>\"</span>\n<span>admin_password</span> <span>=</span> <span>\"<span>admin</span>\"</span>\n\n<span><span>[</span><span>[nodes</span><span>]</span></span>]                         # 对一个 Supervisor 节点的配置\n<span>name</span> <span>=</span> <span>\"<span>node1</span>\"</span>\n<span>environment</span> <span>=</span> <span>\"内网\"              # 用于对 Supervisor 进行逻辑上的分组</span>\n<span>host</span> <span>=</span> <span>\"<span>10.0.0.1</span>\"</span>\n<span>port</span> <span>=</span> <span>\"<span>9001</span>\"</span>\n<span>username</span> <span>=</span> <span>\"\"                     # 用于登录 Supervisor 的账号</span>\n<span>password</span> <span>=</span> <span>\"\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>Cesi 将用户信息存储在 SQLite 数据库中，因此不能通过配置文件创建账号、修改密码，要在 Web 页面上操作。</li>\n<li>Cesi 只划分了两种用户权限：\n<ul>\n<li>Admin ：有权使用 Cesi ，并管理用户。</li>\n<li>Normal User ：有权使用 Cesi 。</li>\n</ul>\n</li>\n<li>可以通过 Environment 对各个 Supervisor 进行分组。</li>\n<li>可以通过 Group 对全部 Supervisor 中的进程进行分组（该 Group 参数在 Supervisor 中配置）。</li>\n<li>只要有一个 node 无法连接， Cesi 就会抛出异常，导致所有 node 都不会显示。</li>\n</ul>\n</li>\n<li>\n<p>Cesi 提供了一些 Restful API ：</p>\n<div><pre><code>GET /api/v2/nodes/                                         <span># 获取全部 Supervisor 节点的信息</span>\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/                             <span># 获取指定节点的信息（包括节点信息、进程信息）</span>\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/                   <span># 获取指定节点上全部进程的信息</span>\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/<span>&lt;</span>process_name<span>></span>/    <span># 获取指定节点上的指定进程的信息</span>\n\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/<span>&lt;</span>process_name<span>></span>/start/\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/<span>&lt;</span>process_name<span>></span>/stop/\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/<span>&lt;</span>process_name<span>></span>/restart/\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/processes/<span>&lt;</span>process_name<span>></span>/log/\n\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/all-processes/start/         <span># 启动指定节点上的全部进程</span>\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/all-processes/stop/\nGET /api/v2/nodes/<span>&lt;</span>node_name<span>></span>/all-processes/restart/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "配置信息",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/ConfigurationManagement/",
      "id": "/Hardware/DevOps/ConfigurationManagement/",
      "content_html": "<h1 id=\"配置信息\"> 配置信息</h1>\n<p>项目的配置信息分为多种，管理措施也不同：</p>\n<ul>\n<li>源代码\n<ul>\n<li>用 Git 或 SVN 服务器管理。</li>\n</ul>\n</li>\n<li>运行环境\n<ul>\n<li>比如运行项目需要的操作系统、依赖软件。</li>\n<li>如果项目部署在虚拟机上，可用 Ansible 批量管理主机。</li>\n<li>如果项目部署在容器中，可用 Dockerfile 配置运行环境。</li>\n</ul>\n</li>\n<li>配置文件\n<ul>\n<li>有的项目没有准备配置文件，而是将配置信息直接写在代码中。这样不方便管理配置信息，仅适用于开发阶段。</li>\n<li>配置文件可能包含服务器密码等敏感信息，因此不应该保存在项目的代码仓库中，否则会被所有人可见。</li>\n<li>常见需求：\n<ul>\n<li>静态配置\n<ul>\n<li>：程序一般只需在启动时读取一次，不需要经常更新。</li>\n<li>如果存在大量非私密的静态配置信息，可以保存到一个独立的 Git 仓库中，并进行版本控制。</li>\n</ul>\n</li>\n<li>动态配置\n<ul>\n<li>：程序在运行时可能多次读取，需要经常更新，甚至实时更新。</li>\n<li>用传统的 Ansible 等脚本工具不方便管理，建议使用 Consul 等配置管理工具。</li>\n</ul>\n</li>\n<li>服务发现\n<ul>\n<li>：指程序需要获取某些服务的数量、地址。</li>\n<li>可能属于静态配置，也可能属于动态配置。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>构建产物\n<ul>\n<li>称为构件、工件，或者 artifact、component 。</li>\n<li>应该根据文件格式，用各种仓库存储。例如 jar 包存储到 Nexus 服务器，Docker 镜像存储到 Harbor 服务器。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置管理工具\"> 配置管理工具</h2>\n<p>适合批量管理主机的工具：</p>\n<ul>\n<li>Ansible\n<ul>\n<li>一个命令行工具。</li>\n<li>采用 Python 开发，于 2012 年发布。</li>\n<li>采用主从架构。以 SSH 方式控制远程主机，可以执行任意命令、传输文件。</li>\n</ul>\n</li>\n<li>Saltstack\n<ul>\n<li>一个命令行工具。</li>\n<li>采用 Python 开发，于 2011 年发布。</li>\n<li>采用 C/S 架构。需要在主控主机上运行 master 进程，在受控主机上运行 minion 进程。它们之间通过消息队列 ZeroMQ 进行通信。</li>\n</ul>\n</li>\n<li>Puppet\n<ul>\n<li>一个 Web 服务器。</li>\n<li>采用 Ruby 开发，于 2005 年发布。</li>\n<li>采用 C/S 架构、HTTP 通信。需要在主控主机上运行 master 进程，在受控主机上运行 agent 进程。</li>\n</ul>\n</li>\n<li>Chef\n<ul>\n<li>一个 Web 服务器。</li>\n<li>采用 Ruby 开发，于 2009 年发布。</li>\n<li>采用 C/S 架构、HTTP 通信。</li>\n</ul>\n</li>\n</ul>\n<p>适合动态配置的工具：</p>\n<ul>\n<li>confd\n<ul>\n<li>一个命令行工具，采用 Golang 开发，用于自动生成配置文件。</li>\n<li>原理：从 zk、etcd、consul、redis 等后端轮询配置参数，根据 Golang 模板文件，渲染出配置文件。</li>\n</ul>\n</li>\n<li>Apollo\n<ul>\n<li>一个 Web 服务器。提供了丰富的配置管理功能，支持划分环境、版本回滚、安全审计。</li>\n<li>由携程公司开源，采用 Java 开发。</li>\n</ul>\n</li>\n</ul>\n<p>适合服务发现的工具：</p>\n<ul>\n<li>Zookeeper</li>\n<li>etcd</li>\n<li>Consul</li>\n<li>Nacos\n<ul>\n<li>一个 Web 服务器。支持配置管理、服务发现。</li>\n<li>由阿里巴巴公司开源，采用 Java 开发。</li>\n</ul>\n</li>\n<li>Eureka ：由 Netflix 公司开源。</li>\n</ul>\n<h2 id=\"gitops\"> GitOps</h2>\n<p>：一种配置文件的管理方案，于 2017 年提出。</p>\n<ul>\n<li>特点：\n<ul>\n<li>将配置文件全部存储在 Git 仓库中，能够据此重新部署项目。</li>\n<li>当用户修改 Git 仓库中的配置文件时，会自动触发 CI/CD 部署脚本。</li>\n</ul>\n</li>\n<li>优点：\n<ul>\n<li>记录每次修改的版本，并可以回滚。</li>\n<li>多个用户操作时，可以通过发出合并请求的方式，修改配置文件，实现流程审批。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"microservices\"> Microservices</h2>\n<p>：微服务，一种服务器架构，将业务系统从传统的大型服务器，划分成多个小型服务器，有利于模块化。</p>\n<ul>\n<li>特点：\n<ul>\n<li>每个微服务独立部署，低耦合。</li>\n<li>微服务之间通过 API 交互，可以采用不同的编程语言。</li>\n<li>需要一个服务发现机制，让微服务之间能够连通。</li>\n<li>Docker 技术流行之后，微服务变得容易实现。通常将每个微服务部署到一个 Docker 容器中。</li>\n</ul>\n</li>\n<li>常见的几种微服务框架：\n<ul>\n<li>Dubbo ：由阿里巴巴公司发布。微服务之间通过 RPC 协议进行通信，仅支持 Java 。</li>\n<li>Spring Cloud ：微服务之间通过 RESTful API 进行通信，性能比 RPC 低。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"service-mesh\"> Service Mesh</h3>\n<p>：服务网格，是新一代的微服务技术，于 2016 年提出。</p>\n<ul>\n<li>特点：\n<ul>\n<li>引入一个网络代理层，自动转发服务的流量，并进行服务发现、负载均衡。</li>\n<li>属于透明代理，不需要服务编写代码来使用代理。</li>\n</ul>\n</li>\n<li>常见的几种框架：\n<ul>\n<li>Envoy</li>\n<li>Linkerd</li>\n<li>Istio\n<ul>\n<li>比 Linkerd 的功能更多。</li>\n<li>在 k8s Pod 中加入一个 init 类型的容器，名为 istio-init 。负责设置 iptables 规则，将服务的出入流量转发到 Envoy 。</li>\n<li>在 k8s Pod 中加入一个 sidecar 类型的容器，名为 istio-proxy 。负责运行 Envoy ，代理服务的流量。</li>\n</ul>\n</li>\n<li>Consul Connect</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Docker Compose",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/Docker-Compose.html",
      "id": "/Hardware/DevOps/Container/Docker/Docker-Compose.html",
      "content_html": "<h1 id=\"docker-compose\"> Docker Compose</h1>\n<p>：一个 Docker 容器的编排工具。</p>\n<ul>\n<li><a href=\"https://docs.docker.com/compose/compose-file/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>由 Docker 公司发布，采用 Python 开发。</li>\n<li>用于管理当前主机上的多个容器，但不能管理其它主机上的容器。</li>\n</ul>\n<h2 id=\"安装\"> 安装</h2>\n<ul>\n<li>\n<p>用 pip 安装：</p>\n<div><pre><code>pip3 <span>install</span> <span>docker-compose</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>用 yum 安装：</p>\n<div><pre><code>yum <span>install</span> <span>docker-compose</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"命令\"> 命令</h2>\n<div><pre><code><span>docker-compose</span>\n            -f <span>&lt;</span>file<span>></span>                 <span># 指定 compose 文件。默认会在当前目录及祖父目录中寻找 docker-compose.yml 文件</span>\n            -p <span>&lt;</span>name<span>></span>                 <span># --project-name ，指定项目名，默认采用 compose 文件所在的目录名</span>\n\n            <span># 启动</span>\n            up <span>[</span>service<span>]</span><span>..</span>.           <span># 启动服务，这会创建并启动容器</span>\n                -d                    <span># 以 daemon 方式运行。默认会在当前终端的前台运行</span>\n                --build               <span># 总是构建镜像。默认如果镜像已存在，则不会构建</span>\n                --force-recreate      <span># 总是重新创建容器。默认会检查 compose 文件，如果配置变化则删除容器再重新创建</span>\n                --scale <span>web</span><span>=</span><span>2</span> <span>redis</span><span>=</span><span>1</span> <span># 设置各服务运行的实例数量</span>\n            <span>ps</span>      <span>[</span>service<span>]</span><span>..</span>.      <span># 显示正在运行的服务（的容器）</span>\n            start   <span>[</span>service<span>]</span><span>..</span>.      <span># 启动已停止的服务</span>\n            restart <span>[</span>service<span>]</span><span>..</span>.      <span># 重启服务</span>\n\n            <span># 停止</span>\n            stop    <span>[</span>service<span>]</span><span>..</span>.      <span># 停止服务</span>\n                -t <span>&lt;</span>n<span>></span>                <span># 超时时间，默认为 10 秒</span>\n            <span>kill</span>    <span>[</span>service<span>]</span><span>..</span>.      <span># 杀死服务</span>\n                -s <span>&lt;</span>signal<span>></span>           <span># 发送的信号，默认为 SIGKILL</span>\n            down                      <span># 停止并删除所有容器，默认会删除用到的网络</span>\n                -v                    <span># --volumes ，同时删除 compose 文件中定义的 volumes 以及用到的匿名 volumes</span>\n                --rmi all             <span># 同时删除该服务用到的所有镜像</span>\n\n            <span>exec</span> <span>&lt;</span>service<span>></span> <span>&lt;</span>command<span>></span>  <span># 在服务的容器中执行一条命令</span>\n                -d                    <span># 在后台执行命令</span>\n                -T                    <span># 不分配终端（默认会分配一个 tty）</span>\n                --index<span>=</span>n             <span># 指定该服务的第 n 个容器实例</span>\n\n            logs <span>&lt;</span>service<span>></span><span>..</span>.         <span># 查看服务的日志</span>\n                -f                    <span># 保持显示</span>\n                -t                    <span># 显示时间戳</span>\n                --tail <span>10</span>             <span># 显示最后几行</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>编写好 compose 文件之后，通常执行以下命令来启动容器：<div><pre><code><span>docker-compose</span> up         <span># 先尝试在前台运行，看日志是否正常</span>\nCtrl + C                  <span># 终止运行</span>\n<span>docker-compose</span> up -d      <span># 以 daemon 方式运行</span>\n<span>docker-compose</span> down       <span># 销毁服务</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>用 docker-compose 命令启动容器之后，也可以用 docker 命令查看、管理。</li>\n</ul>\n<h2 id=\"compose-文件\"> compose 文件</h2>\n<ul>\n<li>docker-compose 命令根据 compose 配置文件来创建、管理 docker 容器。\n<ul>\n<li>compose 文件保存为 yaml 格式，扩展名为 .yaml 或 .yml 。</li>\n</ul>\n</li>\n<li>compose 文件的主要版本：\n<ul>\n<li>v2</li>\n<li>v3\n<ul>\n<li>移除了 cpu_shares、mem_limit 等限制容器资源使用率的配置，改为通过 deploy 参数配置，但只支持部署到 docker swarm 集群。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"语法\"> 语法</h3>\n<p>例：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>                  <span># 声明 compose 文件的语法版本</span>\n\n<span>services</span><span>:</span>                     <span># 开始定义服务</span>\n\n  <span>redis</span><span>:</span>                      <span># 定义第一个服务</span>\n    <span>image</span><span>:</span> redis<span>:</span>5.0.5        <span># 指定使用的镜像</span>\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n\n  <span>web</span><span>:</span>                        <span># 定义第二个服务</span>\n    <span>container_name</span><span>:</span> web       <span># 指定生成的容器名</span>\n\n    <span># 关于镜像</span>\n    <span># image: centos:7</span>\n    <span>build</span><span>:</span>                    <span># 使用构建出的镜像</span>\n      <span>context</span><span>:</span> ./etc\n      <span>dockerfile</span><span>:</span> Dockerfile\n      <span>network</span><span>:</span> host\n      <span>args</span><span>:</span>\n        <span>arg1</span><span>:</span> Hello\n\n    <span># 关于启动</span>\n    <span>depends_on</span><span>:</span>               <span># 声明对其它服务的依赖关系</span>\n      <span>-</span> redis                 <span># 这表示 docker-compose start 时会先启动 redis 服务，再启动 web 服务。docker-compose stop 时顺序相反，而 docker-compose restart 时不控制顺序</span>\n    <span>init</span><span>:</span> <span>true</span>                <span># 使用 init 作为 1 号进程</span>\n    <span>hostname</span><span>:</span> CentOS          <span># 主机名</span>\n    <span>user</span><span>:</span> root                <span># 覆盖 Dockerfile 中的 USER</span>\n    <span>working_dir</span><span>:</span> /opt         <span># 覆盖 Dockerfile 中的 WORKDIR</span>\n    <span>privileged</span><span>:</span> <span>false</span>         <span># 是否开启特权模式</span>\n    <span>entrypoint</span><span>:</span>               <span># 覆盖 Dockerfile 中的 ENTRYPOINT ，取值可以为字符串类型或列表类型</span>\n      <span>-</span> /bin/sh\n      <span>-</span> <span>-</span>c\n      <span>-</span> echo Hello            <span># 此处容器的启动命令为 /bin/sh -c 'echo Hello' World ，实际上只会执行 echo Hello</span>\n      <span>-</span> World\n    <span>command</span><span>:</span> echo Hello       <span># 覆盖 Dockerfile 中的 CMD</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped   <span># 容器的重启策略</span>\n\n    <span># 关于环境变量</span>\n    <span>environment</span><span>:</span>              <span># 环境变量，采用数组的格式声明</span>\n      <span>-</span> var1=1\n      <span>-</span> var2=hello\n    <span># environment:            # 也可以采用键值对的格式声明</span>\n    <span>#   var1: 1</span>\n    <span>#   var2: hello</span>\n    <span>env_file</span><span>:</span>                 <span># 从文件中导入环境变量。这些文件中每行为 VAR=VALUE 的格式，用 # 声明单行注释</span>\n      <span>-</span> ./test.env\n\n    <span># 关于标签</span>\n    <span>labels</span><span>:</span>                   <span># 给容器添加标签。注意 key 不加引号，而 value 必须加引号</span>\n      <span>project</span><span>:</span> <span>\"test_1\"</span>\n      <span>branch</span><span>:</span> <span>\"dev\"</span>\n      <span>-</span> /etc/test.env\n\n    <span># 关于网络</span>\n    <span>dns</span><span>:</span>                      <span># 指定 DNS 服务器</span>\n      <span>-</span> 8.8.8.8\n    <span>networks</span><span>:</span>                 <span># 使当前容器连接到一些 docker 网络</span>\n      <span>-</span> net\n    <span># network_mode: host      # 网络模式，不能与 networks 同时配置</span>\n    <span># links:                  # 使当前容器连接到其它容器。不建议使用 links 配置，而应该使用 networks 配置</span>\n    <span>#  - redis</span>\n    <span>ports</span><span>:</span>                    <span># 映射端口</span>\n      <span>-</span> 8080<span>:</span><span>80</span>               <span># 注意这里的每行配置是一个字符串，因此冒号 : 之后不能加空格</span>\n      <span>-</span> 9090<span>-</span>9091<span>:</span>8080<span>-</span><span>8081</span>\n\n    <span># 关于挂载</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /root/data<span>:</span>/root/data <span># 挂载文件或目录</span>\n      <span>-</span> ./log<span>:</span>/root/log       <span># 支持挂载相对路径（必须以 ./ 或 ../ 开头，省略的话则会视作数据卷的名称）</span>\n      <span>-</span> conf<span>:</span>/root/conf       <span># 挂载数据卷（不允许省略数据卷名，因此不支持挂载匿名卷）</span>\n\n    <span># 设置 ulimit 参数</span>\n    <span>ulimits</span><span>:</span>\n      <span>nproc</span><span>:</span> <span>65535</span>\n      <span>nofile</span><span>:</span>\n        <span>soft</span><span>:</span> <span>20000</span>\n        <span>hard</span><span>:</span> <span>40000</span>\n\n    <span># 健康检查</span>\n    <span>healthcheck</span><span>:</span>\n      <span>test</span><span>:</span> curl http<span>:</span>//localhost <span>|</span><span>|</span> exit 1\n      <span>interval</span><span>:</span> 1m30s\n      <span>timeout</span><span>:</span> 10s\n      <span>retries</span><span>:</span> <span>3</span>\n      <span>start_period</span><span>:</span> 40s\n\n<span>networks</span><span>:</span>                     <span># 定义网络。每个网络按 &lt;project>_&lt;network> 的格式命名</span>\n  <span># default:                  # 如果没有自定义网络，则默认会创建一个 default 网络，让所有服务的容器连接到它</span>\n  <span>net</span><span>:</span>\n    <span># driver: bridge</span>\n\n<span>volumes</span><span>:</span>                      <span># 所有挂载的数据卷都必须在此定义。每个数据卷按 &lt;project>_&lt;volume> 的格式命名</span>\n  <span>conf</span><span>:</span>\n  <span>db</span><span>:</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br><span>65</span><br><span>66</span><br><span>67</span><br><span>68</span><br><span>69</span><br><span>70</span><br><span>71</span><br><span>72</span><br><span>73</span><br><span>74</span><br><span>75</span><br><span>76</span><br><span>77</span><br><span>78</span><br><span>79</span><br><span>80</span><br><span>81</span><br><span>82</span><br><span>83</span><br><span>84</span><br><span>85</span><br><span>86</span><br><span>87</span><br><span>88</span><br><span>89</span><br><span>90</span><br><span>91</span><br><span>92</span><br><span>93</span><br><span>94</span><br></div></div><ul>\n<li>\n<p>每个 compose 文件可以定义一个或多个服务，每个服务可以运行一个或多个容器实例。</p>\n<ul>\n<li>如果用户不指定生成的容器名，则会自动按照 <code>项目名_服务名_实例编号</code> 的格式命名，比如：web_web_1 。</li>\n<li>一个服务运行多个容器实例时，可能因为使用相同的资源而冲突，比如：\n<ul>\n<li>指定的容器名相同，此时应该让它自动生成容器名</li>\n<li>挂载的宿主机路径或数据卷相同</li>\n<li>映射的端口相同</li>\n</ul>\n</li>\n<li>使用多个 compose 文件时，需要避免它们所在的目录名相同，导致生成的容器、网络、数据卷同名而冲突。</li>\n</ul>\n</li>\n<li>\n<p>上例中，web 容器向宿主机映射了两个端口，而 redis 容器没有映射端口，因此不能被宿主机访问。</p>\n<ul>\n<li>两个容器都连接到了 net_1 网络，因此可以相互访问。比如 web 容器可以通过 <code>127.0.0.1:6379</code> 或 <code>redis:6379</code> 访问到 redis 容器。</li>\n</ul>\n</li>\n<li>\n<p>使用 depends_on 并不能判断服务是否就绪，不如自定义启动脚本，等上一个服务启动就绪了，才启动当前服务。如下：</p>\n<div><pre><code><span>command</span><span>:</span>\n  <span>-</span> /bin/bash\n  <span>-</span> <span>-</span>c\n  <span>-</span> <span>|</span><span>\n    while ! curl 127.0.0.1:80;\n    do\n      sleep 1;\n    done\n    python3 run.py</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>\n<p>compose 文件中支持引用环境变量，例如：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>redis</span><span>:</span>\n    <span>image</span><span>:</span> redis<span>:</span>$<span>{</span>IMAGE_TAG<span>}</span>\n    <span>environment</span><span>:</span>\n      <span>var1</span><span>:</span> $var1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>执行 docker-compose 命令时，会尝试在当前 shell 或 ./.env 文件中读取同名的环境变量，如果不存在则取值为空。</li>\n</ul>\n</li>\n<li>\n<p>docker-compose 会自动给容器添加一些 labels ，例如：</p>\n<div><pre><code>com.docker.compose.config-hash         <span>:</span> <span>\"fcd1bc82cbd8c940c0f6b5bc9c053914332bc3a8a2f4d51b46924feb0e7c05b7\"</span>\ncom.docker.compose.container-number    <span>:</span> <span>\"1\"</span>\ncom.docker.compose.oneoff              <span>:</span> <span>\"False\"</span>\ncom.docker.compose.project             <span>:</span> <span>\"redis\"</span>\ncom.docker.compose.project.config_files: <span>\"docker-compose.yml\"</span>\ncom.docker.compose.project.working_dir <span>:</span> <span>\"/opt/redis\"</span>\ncom.docker.compose.service             <span>:</span> <span>\"redis\"</span>\ncom.docker.compose.version             <span>:</span> <span>\"1.29.1\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Dockerfile",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/Dockerfile.html",
      "id": "/Hardware/DevOps/Container/Docker/Dockerfile.html",
      "content_html": "<h1 id=\"dockerfile\"> Dockerfile</h1>\n<p>：一个文本文件，用于描述构建 Docker 镜像时需要执行的指令。</p>\n<ul>\n<li><a href=\"https://docs.docker.com/engine/reference/builder/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n</ul>\n<h2 id=\"语法\"> 语法</h2>\n<ul>\n<li>\n<p>Dockerfile 中可以包含多行指令（instruction）。</p>\n<ul>\n<li>指令名不区分大小写，但一般大写。</li>\n<li>一般在每行以指令名开头，允许添加前置空格。</li>\n<li>第一个非注释的指令应该是 FROM ，否则报错：<code>no build stage in current context</code>\n<ul>\n<li>Dockerfile 至少需要包含一个 FROM 指令，其它指令都可以省略。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Dockerfile 中的大部分指令可使用多次。</p>\n<ul>\n<li>ENTRYPOINT、CMD 指令如果存在多个，则只有最后一个会生效。</li>\n</ul>\n</li>\n<li>\n<p>用 # 声明单行注释，且必须在行首声明。</p>\n<ul>\n<li>执行 Dockerfile 之前，注释行会被删除。因此：<div><pre><code>RUN <span>echo</span> hello <span>\\</span>\n    <span># comment</span>\n    world\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div>会变成：<div><pre><code>RUN <span>echo</span> hello <span>\\</span>\n    world\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"构建阶段\"> 构建阶段</h2>\n<ul>\n<li>dockerd 构建镜像时，会依次执行 Dockerfile 中的指令。\n<ul>\n<li>每个指令划分为一个构建步骤（build step）</li>\n<li>从 FROM 指令开始的一组指令划分为一个构建阶段（build stage）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"from\"> FROM</h3>\n<p>：表示以某个镜像为基础镜像，开始一个构建阶段。</p>\n<ul>\n<li>\n<p>会沿用基础镜像的 layer ，继承其大部分指令的配置。</p>\n</li>\n<li>\n<p>语法：</p>\n<div><pre><code>FROM <span>[</span>--platform<span>=</span><span>&lt;</span>platform<span>></span><span>]</span> <span>&lt;</span>image<span>></span><span>[</span>:<span>&lt;</span>tag<span>></span><span>]</span> <span>[</span>AS <span>&lt;</span>name<span>></span><span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>FROM 指令表示一个构建阶段的开始，可用 AS 给该阶段命名。</li>\n<li>有的程序不支持跨平台运行，因此需要指定不同的 --platform ，对不同平台分别构建镜像。常见的几种平台（OS/Architecture）：<div><pre><code>windows/amd64     <span># 常用于 Windows 主机</span>\nlinux/amd64       <span># 常用于 Linux 主机</span>\nlinux/arm64\nlinux/arm64/v8    <span># 常用于 Apple M1 CPU</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>默认根据本机的操作系统、CPU 架构，指定 --platform 的值。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>例：</p>\n<div><pre><code>FROM nginx\nFROM nginx AS stage1\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>基础镜像举例：</p>\n<ul>\n<li>scratch ：一个空镜像。以它作为基础镜像，将可执行文件拷贝进去，就可以构建出体积最小的镜像。</li>\n<li>*-slim ：一种后缀，表示某种镜像的精简版，体积较小。通常是去掉了一些文件，只保留运行时环境。</li>\n<li>busybox ：集成了许多常用的 Unix 命令，体积只有 2MB ，相当于一个小巧的工具箱。</li>\n<li>debian</li>\n<li>alpine ：一个专为容器设计的轻量级 Linux 系统，体积只有 5MB 。\n<ul>\n<li>包含了 busybox ，用 musl libc 库代替了 glibc 库，可能遇到兼容性问题。</li>\n<li>可用 apk add 命令安装软件包。</li>\n<li>busybox 不包含 curl 命令，可用以下命令启动一个包含 curl 的容器：<div><pre><code><span>docker</span> run -it --rm --entrypoint <span>sh</span> alpine/curl\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>Container Linux ：一个专为容器设计的轻量级 Linux 系统，由 CoreOS 团队发布。2020 年停止开发，被 Fedora CoreOS 替代。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"多阶段\"> 多阶段</h3>\n<ul>\n<li>\n<p>一个 Dockerfile 可以包含多个 FROM 指令，即多个构建阶段。</p>\n</li>\n<li>\n<p>使用多阶段构建的好处：</p>\n<ul>\n<li>将复杂的 Dockerfile 划分成多个独立的部分。</li>\n<li>减小镜像体积。\n<ul>\n<li>一个构建步骤 step ，会使用之前 step 的中间镜像，不得不继承 layer 中的全部文件，因此镜像容易包含无用文件。</li>\n<li>而一个构建阶段 stage ，会使用一个独立的基础镜像，但可以选择性地 COPY 之前 stage 的文件。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>例：</p>\n<div><pre><code>FROM nginx AS stage1                             <span># 开始一个阶段，并用 AS 命名</span>\nRUN <span>touch</span> /root/f1\n\nFROM nginx AS stage2\nCOPY --from<span>=</span>stage1  /root/f1  /tmp/              <span># 从指定阶段的最终镜像中拷贝文件</span>\nCOPY --from<span>=</span>nginx   /etc/nginx/nginx.conf /tmp/  <span># 从其它镜像中拷贝文件</span>\nRUN  <span>ls</span> /tmp\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>存在多个 FROM 阶段时，传入的构建参数会被第一个声明该 ARG 的阶段获取，之后的阶段不能再获取。</p>\n<div><pre><code>FROM    nginx\nARG     <span>A</span><span>=</span><span>10</span>\n\nFROM    nginx\nARG     A\n<span># 这里 $A 的值为空</span>\nRUN <span>echo</span> <span>$A</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>支持在第一个 FROM 指令之前声明 ARG 指令，此时该 ARG 变量会存在于所有 FROM 阶段。如下：</p>\n<div><pre><code><span><span>ARG</span> A=10</span>\n\n<span><span>FROM</span> nginx</span>\n<span># 此时 $A 属于当前作用域，值为空</span>\n<span><span>ENV</span>     B=<span>$A</span></span>\n<span># 如果声明一个同名的 ARG 变量并赋值为空，则可以获得全局作用域的值，因此这里 $A 的值为 10</span>\n<span><span>ARG</span> A</span>\n<span><span>RUN</span> echo <span>$A</span></span>\n\n<span><span>FROM</span> nginx</span>\n<span># 这里 $A 的值为 10</span>\n<span><span>ARG</span> A</span>\n<span><span>RUN</span> echo <span>$A</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n<h2 id=\"变量\"> 变量</h2>\n<ul>\n<li>Dockerfile 中可通过 ARG、ENV 指令定义变量，可在大部分指令中引用。\n<ul>\n<li>例：<div><pre><code>ARG     <span>A</span><span>=</span><span>10</span>\nENV     <span>B</span><span>=</span><span>$A</span>\n\nEXPOSE  <span>${A<span>:-</span>80}</span>\nWORKDIR <span>${A<span>:+</span>'<span>/</span>tmp'}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>支持多种读取变量的语法：<div><pre><code><span>$var</span>\n<span>${var}</span>\n<span>${var<span>:-</span>default}</span>      <span># 如果变量存在且不为空，则返回其值，否则返回默认值</span>\n<span>${var<span>:+</span>default}</span>      <span># 如果变量存在且不为空，则返回默认值，否则返回空</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"arg\"> ARG</h3>\n<p>：声明一个或多个键值对格式的构建参数。</p>\n<ul>\n<li>例：<div><pre><code>ARG var1  <span>\\</span>\n    <span>var2</span><span>=</span>value2\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>可以不赋值，此时值为空。</li>\n</ul>\n</li>\n<li>构建镜像时，可通过 <code>docker build --build-arg</code> 传入构建参数。</li>\n<li>ARG 变量只影响构建过程，不会保留。\n<ul>\n<li>可以通过 <code>docker history</code> 命令查看 ARG 变量的值，因此不应该通过 ARG 传递密码等敏感信息。可改为读取 secret 文件，或者让最终镜像不继承当前构建阶段。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"env\"> ENV</h3>\n<p>：给容器内 shell 添加一个或多个键值对格式的环境变量。</p>\n<ul>\n<li>语法与 ARG 指令相同。</li>\n<li>ENV 变量会保存到镜像中，并添加到容器内 shell 中。</li>\n</ul>\n<h3 id=\"label\"> LABEL</h3>\n<p>：给镜像添加一个或多个键值对格式的标签。</p>\n<ul>\n<li>语法与 ARG 指令相同，但必须赋值。</li>\n<li>标签属于 docker 对象的元数据，不会影响容器内进程。</li>\n</ul>\n<h2 id=\"文件\"> 文件</h2>\n<h3 id=\"copy\"> COPY</h3>\n<p>：从构建上下文拷贝文件到镜像中。</p>\n<ul>\n<li>语法：<div><pre><code>COPY <span>&lt;</span>src_path<span>></span><span>..</span>.  <span>&lt;</span>dst_path<span>></span>\n    --chown<span>=</span><span>&lt;</span>user<span>></span>:<span>&lt;</span>group<span>></span>    <span># 拷贝之后的文件权限</span>\n    --from<span>=</span><span>&lt;</span>name<span>></span>             <span># 表示拷贝的源对象，默认是 build context ，可以指定其它构建阶段或镜像</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>src_path 只能是相对路径，且不能使用 .. 指向超出构建上下文的路径。\n<ul>\n<li>src_path 可以包含通配符 ? 和 * 。</li>\n<li>src_path 为目录时，不会拷贝该目录，而是拷贝该目录下的所有文件。</li>\n</ul>\n</li>\n<li>dst_path 可以是相对路径或绝对路径。\n<ul>\n<li>为相对路径时，起点为 WORKDIR 。不会受到 RUN 指令中的 cd 命令的影响，因为每个构建步骤都是创建一个新的中间容器，工作目录复位为 WORKDIR 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>例：<div><pre><code>COPY *.py /tmp/\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"add\"> ADD</h3>\n<p>：用法与 COPY 相似，但支持 src_path 为 URL 。</p>\n<h2 id=\"执行命令\"> 执行命令</h2>\n<h3 id=\"run\"> RUN</h3>\n<p>：用于在构建镜像时，在中间容器内执行一些 shell 命令。</p>\n<ul>\n<li>有两种写法：<div><pre><code>RUN <span>&lt;</span>command<span>></span> <span>&lt;</span>param<span><span>1</span>></span> <span>&lt;</span>param<span><span>2</span>></span><span>..</span>.        <span># shell 格式</span>\nRUN <span>[</span><span>\"command\"</span>, <span>\"param1\"</span>, <span>\"param2\"</span><span>..</span>.<span>]</span>    <span># exec 格式，即 JSON array 。注意使用双引号，否则使用单引号会被视作 shell 格式</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>shell 格式是在 shell 解释器中执行命令。而 exec 格式是直接执行命令，因此不支持 shell 语法，比如管道符、用 $ 读取变量。</li>\n<li>制作镜像时，dockerd 会将所有命令都从 shell 格式转换成 exec 格式 <code>[&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;&lt;command&gt; &lt;param1&gt; &lt;param2&gt;...&quot;]</code> ，然后保存 。\n<ul>\n<li>在 Windows 平台上，前缀为 <code>[&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]</code> 。</li>\n</ul>\n</li>\n<li>在容器中，dockerd 会将所有命令都从 exec 格式转换成 shell 格式，然后执行。</li>\n</ul>\n</li>\n<li>例：<div><pre><code>RUN <span>set</span> -eu   <span>;</span><span>\\</span>\n    <span>echo</span> <span>\"Hello World!\"</span> <span>;</span><span>\\</span>\n    <span>touch</span> f1\nRUN <span>[</span><span>\"/bin/echo\"</span>, <span>\"hello\"</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"entrypoint、cmd\"> ENTRYPOINT、CMD</h3>\n<ul>\n<li>\n<p>ENTRYPOINT、CMD 指令都用于设置容器的启动命令，前者的优先级更高。</p>\n<ul>\n<li>都支持 shell 格式、exec 格式两种写法。CMD 指令还支持第三种写法：<div><pre><code>CMD <span>[</span><span>\"param1\"</span>, <span>\"param2\"</span><span>..</span>.<span>]</span>   <span># 只有参数的 exec 格式</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>创建容器时，dockerd 会将 ENTRYPOINT、CMD 命令都从 exec 格式转换成 shell 格式，再将 CMD 命令附加到 ENTRYPOINT 命令之后，然后执行。\n<ul>\n<li>如果执行 <code>docker run &lt;image&gt; [command]</code> 时声明了启动命令，则会覆盖镜像中的 CMD 指令。</li>\n<li>还可通过 <code>docker run --entrypoint</code> 覆盖镜像中的 ENTRYPOINT 指令。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>下表统计不同写法时， ENTRYPOINT 指令与 CMD 指令组合的结果，即容器的启动命令是什么：</p>\n<table>\n<thead>\n<tr>\n<th>-</th>\n<th><code>ENTRYPOINT echo 1</code></th>\n<th><code>ENTRYPOINT [&quot;echo&quot;, &quot;1&quot;]</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>CMD echo 2</code></td>\n<td>/bin/sh -c 'echo 1' /bin/sh -c 'echo 2'</td>\n<td>echo 1 /bin/sh -c 'echo 2'</td>\n</tr>\n<tr>\n<td><code>CMD [&quot;echo&quot;, &quot;2&quot;]</code></td>\n<td>/bin/sh -c 'echo 1' echo 2</td>\n<td>echo 1 echo 2</td>\n</tr>\n<tr>\n<td><code>CMD [&quot;2&quot;]</code></td>\n<td>/bin/sh -c 'echo 1' 2</td>\n<td>echo 1 2</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>ENTRYPOINT 指令应该采用 exec 格式，因为采用 shell 格式时，CMD 指令不会被执行，而且容器内由 shell 解释器担任 1 号进程。</li>\n<li>一般 ENTRYPOINT 指令填程序的启动命令，CMD 指令填程序的启动参数。例如：<div><pre><code><span><span>ENTRYPOINT</span> [<span>\"java\"</span>]</span>\n<span><span>CMD</span> [<span>\"-jar\"</span>, <span>\"test.jar\"</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"shell\"> SHELL</h3>\n<p>：声明执行 shell 格式的命令时，采用的 shell 解释器。</p>\n<ul>\n<li>默认值：<div><pre><code><span>SHELL</span> <span>[</span><span>\"/bin/sh\"</span>, <span>\"-c\"</span><span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"onbuild\"> ONBUILD</h3>\n<p>：用于声明触发器（build trigger），托管一个普通的 Dockerfile 命令。当其它镜像通过 FROM 继承当前镜像时，就会执行所有触发器。</p>\n<ul>\n<li>不支持嵌套 ONBUILD 。</li>\n<li>例：在构建 nginx:v1 的 Dockerfile 中加入 ONBUILD ：<div><pre><code>ONBUILD RUN <span>mkdir</span> -p /data\nONBUILD COPY <span>.</span> /data\nONBUILD RUN <span>ls</span> /data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div>使用 nginx:v1 作为基础镜像，构建另一个镜像：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker build . -t nginx:v2</span>\nSending build context to Docker daemon  <span>2</span>.048kB\nStep <span>1</span>/2 <span>:</span> FROM  nginx:v1\n<span># Executing 3 build triggers      # 在 FROM 步骤，依次执行所有触发器，每个触发器都会创建一个中间容器</span>\n---<span>></span> Running <span>in</span> ba646d1c9824\nRemoving intermediate container ba646d1c9824\n---<span>></span> Running <span>in</span> 09ba6f8a6933\nDockerfile\nRemoving intermediate container 09ba6f8a6933\n---<span>></span> 8f66dce6bb3c\nStep <span>2</span>/2 <span>:</span> EXPOSE <span>80</span>\n---<span>></span> Running <span>in</span> 1f6182a06031\nRemoving intermediate container 1f6182a06031\n---<span>></span> 2b4beb4d379a\nSuccessfully built 2b4beb4d379a\nSuccessfully tagged nginx:v2\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h2 id=\"其它\"> 其它</h2>\n<h3 id=\"user\"> USER</h3>\n<p>：切换容器内的 shell 用户。</p>\n<ul>\n<li>镜像构建时、构建之后都会使用该配置。</li>\n<li>语法：<div><pre><code><span>USER</span> <span>&lt;</span>user<span>></span><span>[</span>:<span>&lt;</span>group<span>></span><span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"workdir\"> WORKDIR</h3>\n<p>：切换容器内的 shell 工作目录。</p>\n<ul>\n<li>镜像构建时、构建之后都会使用该配置。</li>\n<li>语法：<div><pre><code>WORKDIR <span>&lt;</span>dir<span>></span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"expose\"> EXPOSE</h3>\n<p>：声明容器内进程监听的端口。</p>\n<ul>\n<li>如果用户创建容器时，没有主动映射该端口，则并不会自动映射，除非使用 <code>docker run -P</code> 。</li>\n<li>例：<div><pre><code>EXPOSE <span>80</span>\nEXPOSE <span>80</span>/tcp <span>80</span>/udp\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>默认为 TCP 协议。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"volume\"> VOLUME</h3>\n<p>：将容器内的目录声明为挂载点。</p>\n<ul>\n<li>如果用户创建容器时，没有主动覆盖该挂载点，则默认会自动创建匿名的数据卷来挂载。</li>\n<li>例：<div><pre><code>VOLUME /data\nVOLUME /root  /var/log\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h3 id=\"stopsignal\"> STOPSIGNAL</h3>\n<p>：声明 <code>docker stop</code> 停止容器时，应该给 1 号进程发送的信号。</p>\n<ul>\n<li>默认值：<div><pre><code>STOPSIGNAL  SIGTERM\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"例\"> 例</h2>\n<ul>\n<li>\n<p>例：通过多阶段构建一个 Java 镜像</p>\n<div><pre><code><span># 多阶段共享的 ARG 变量</span>\n<span><span>ARG</span> GIT_REPO=https://github.com/xx/xx.git <span>\\</span>\n    GIT_REFS=master</span>\n\n<span># 基础阶段。这些配置很少变动，重复构建时应该命中缓存，还可以做成一个基础镜像</span>\n<span><span>FROM</span> openjdk:8u312-jre-buster <span>AS</span> base_image</span>\n\n<span># 定义环境变量</span>\n<span><span>ENV</span> USER=test <span>\\</span>\n    USER_ID=1000  <span>\\</span>\n    WORK_DIR=/opt</span>\n\n<span># 创建用户及目录</span>\n<span><span>RUN</span> set -eu ;<span>\\</span>\n    useradd <span>$USER</span> -u <span>$USER_ID</span> -m -s /bin/bash ;<span>\\</span>\n    mkdir -p <span>$WORK_DIR</span> ;<span>\\</span>\n    chown -R <span>$USER</span>:<span>$USER</span> <span>$WORK_DIR</span></span>\n\n<span># 其它配置</span>\n<span><span>USER</span> <span>$USER</span></span>\n<span><span>WORKDIR</span> <span>$WORK_DIR</span></span>\n<span># EXPOSE 80</span>\n<span># VOLUME $WORK_DIR/data</span>\n\n<span># 构建阶段</span>\n<span><span>FROM</span> maven:3.8.4-jdk-8 <span>AS</span> builder</span>\n<span><span>WORKDIR</span> <span>$WORK_DIR</span></span>\n<span><span>RUN</span> git clone <span>$GIT_REPO</span> .   ;<span>\\</span>\n    git checkout <span>$GIT_REFS</span>  ;<span>\\</span>\n    mvn clean package</span>\n\n<span># 最终阶段</span>\n<span><span>FROM</span> base_image</span>\n<span><span>LABEL</span> GIT_REPO=<span>$GIT_REPO</span> <span>\\</span>\n      GIT_REFS=<span>$GIT_REFS</span></span>\n<span><span>COPY</span> <span><span>--from</span><span>=</span><span>builder</span></span> /root/*/target/*.jar .</span>\n<span><span>ENTRYPOINT</span> [<span>\"java\"</span>]</span>\n<span><span>CMD</span> [<span>\"-jar\"</span>, <span>\"test.jar\"</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br></div></div></li>\n<li>\n<p>例：给容器编写一个 entrypoint.sh 脚本，可实现复杂的启动过程</p>\n<div><pre><code>...\n<span><span>COPY</span> ./entrypoint.sh /</span>\n<span><span>ENTRYPOINT</span> [<span>\"/entrypoint.sh\"</span>]</span>\n<span><span>CMD</span> [<span>\"-jar\"</span>, <span>\"test.jar\"</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>entrypoint.sh 的内容示例：</p>\n<div><pre><code><span>#!/bin/bash</span>\n<span>set</span> -eu\n\n<span># 如果传入的 CMD 命令即 $@ 中，第一个参数为 -jar ，则采用正常的启动命令</span>\n<span>if</span> <span>[</span> <span>\"<span>$1</span>\"</span> <span>=</span> <span>'-jar'</span> <span>]</span><span>;</span> <span>then</span>\n    <span># 调整工作目录的权限。该目录可能是挂载目录，因此在容器启动时才能确定权限</span>\n    <span>chown</span> -R <span>$USER</span> <span>\"<span>$WORK_DIR</span>\"</span>\n\n    <span># 如果工作目录为空，则进行初始化</span>\n    <span># if [ -z \"$(ls -A \"$WORK_DIR\")\" ]; then</span>\n    <span>#     gosu $USER init.sh</span>\n    <span># fi</span>\n\n    <span># 以非 root 用户运行进程，用 $@ 作为进程的启动命令</span>\n    <span>exec</span> gosu <span>$USER</span> <span>\"<span>$@</span>\"</span>\n<span>fi</span>\n\n<span># 如果 $@ 不匹配以上条件，则直接执行</span>\n<span>exec</span> <span>\"<span>$@</span>\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div><ul>\n<li>这里没有通过 USER 指令切换用户，而是先以 root 用户运行 entrypoint.sh 脚本，方便调整目录权限。然后脚本通过 gosu 切换到普通用户，提高安全性。</li>\n<li>gosu 命令与 sudo 类似，用于以指定用户的身份执行一个命令。\n<ul>\n<li>sudo 命令会创建一个子进程去执行，而 gosu 会通过 exec 方式执行。</li>\n</ul>\n</li>\n<li>通过 exec 方式执行命令，会让该命令进程替换当前 shell 进程，作为 1 号进程，且该命令结束时当前 shell 也会退出。</li>\n<li>entrypoint.sh 调用的环境变量在 Dockerfile 中声明了默认值，也可以在启动容器时修改，例如：docker run -e USER=xx</li>\n</ul>\n</li>\n<li>\n<p>例：使用 tini</p>\n<div><pre><code>...\n<span><span>RUN</span> wget https://github.com/krallin/tini/releases/download/v0.19.0/tini -O /usr/bin/tini ;<span>\\</span>\n    chmod +x /usr/bin/tini</span>\n<span><span>ENTRYPOINT</span> [<span>\"tini\"</span>, <span>\"--\"</span>, <span>\"/entrypoint.sh\"</span>]</span>\n<span><span>CMD</span> [<span>\"-jar\"</span>, <span>\"test.jar\"</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n<h2 id=\"构建镜像\"> 构建镜像</h2>\n<h3 id=\"build-命令\"> build 命令</h3>\n<div><pre><code><span>docker</span> build <span>&lt;</span><span>PATH</span><span>>|</span><span>&lt;</span>URL<span>></span>\n            -f <span>&lt;</span>file<span>></span>                   <span># Dockerfile 的路径，默认为 &lt;dir>/Dockerfile</span>\n            -t <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span>            <span># --tag ，给构建出的镜像加上名称和标签（可多次使用该选项）</span>\n            --build-arg <span>VERSION</span><span>=</span><span>\"1.0\"</span>   <span># 传入 ARG 构建参数。可多次使用该选项，每次只能传入一个键值对</span>\n            --target <span>&lt;</span>stage<span>></span>            <span># 执行完某个阶段就停止构建</span>\n            --network <span>&lt;</span>name<span>></span>            <span># 设置中间容器使用的网络</span>\n            --no-cache                  <span># 构建时不使用缓存</span>\n            --force-rm                  <span># 即使构建失败，也强制删除中间容器</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>执行 <code>docker build &lt;PATH&gt;</code> 时，会将目标目录及其子目录的所有文件（包括隐藏文件）作为构建上下文（build context），拷贝发送给 dockerd ，从而允许用 COPY 或 ADD 指令拷贝文件到容器中。\n<ul>\n<li>执行 <code>docker build - &lt; Dockerfile</code> ，则只会发送 Dockerfile 作为构建上下文。</li>\n</ul>\n</li>\n<li>可以在 .dockerignore 文件中声明不想被发送的文件或目录。如下：<div><pre><code>*.log     <span># 匹配当前目录下的文件</span>\n<span>!</span>*.md     <span># ! 表示反向匹配</span>\n*/tmp*    <span># 匹配子目录下的文件</span>\n**/tmp*   <span># ** 匹配任意数量的目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>Dockerfile 和 .dockerignore 文件总是会被发送给 dockerd ，即使在这声明了也没用。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"buildkit\"> BuildKit</h3>\n<ul>\n<li>\n<p>Docker 的 18.09 版本增加了一个构建工具 BuildKit 。</p>\n</li>\n<li>\n<p>特点：</p>\n<ul>\n<li>采用一种更低级的格式来定义构建过程，称为（Low Level Builder，LLB）。\n<ul>\n<li>兼容 Dockerfile ，通过前端组件自动将其转换成 LLB 。</li>\n</ul>\n</li>\n<li>优化了构建过程，减少耗时。\n<ul>\n<li>会显示每个 step 的耗时。</li>\n<li>会并行构建所有 stage ，除非存在 FROM 依赖关系。因此适合同时构建多个平台的镜像。</li>\n</ul>\n</li>\n<li>构建时，由 dockerd 进程创建基于 runc 的中间容器，不是由 containerd-shim 管理，因此不能通过 docker 命令查看容器。</li>\n</ul>\n</li>\n<li>\n<p>可通过 buildx 插件启用 BuildKit ：</p>\n<div><pre><code><span>docker</span> buildx\n          build <span>&lt;</span>dir<span>></span>             <span># 构建，兼容 docker build 的命令选项</span>\n              --cache-from <span>&lt;</span>image<span>></span>                  <span># 采用某个镜像作为缓存源</span>\n              --platform linux/arm64,<span>..</span>.            <span># 指定构建的目标平台，默认采用本机平台，可指定多个平台</span>\n              --progress plain                      <span># 构建过程的输出类型。默认为 auto ，设置为 plain 则会显示终端输出</span>\n              --secret <span>id</span><span>=</span>mysecret,src<span>=</span>/root/secret <span># 将宿主机上的文件声明为一个私密文件，指定 id ，可供 RUN 命令挂载</span>\n          <span>ls</span>                      <span># 列出所有 builder 实例</span>\n          <span>du</span>                      <span># 显示 buildx 占用的磁盘</span>\n          prune                   <span># 清空 buildx cache</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><ul>\n<li>可以修改 daemon.json 的配置，使得 docker build 也启用 BuildKit 。</li>\n</ul>\n</li>\n</ul>\n<p>启用 Buildkit 时的新语法：</p>\n<ul>\n<li>支持在 Dockerfile 中声明语法版本：<div><pre><code><span># syntax=docker/dockerfile:1.2</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>RUN 命令支持使用 <code>--mount</code> 选项，可多次使用，有多种挂载类型：\n<ul>\n<li>bind ：默认挂载类型。<div><pre><code>RUN --mount<span>=</span>type<span>=</span>bind,src<span>=</span>./dist,dst<span>=</span>/dist <span>\\</span>\n    --mount<span>=</span>type<span>=</span>bind,from<span>=</span>stage1,src<span>=</span>/root,dst<span>=</span>/root <span>\\</span>\n    <span>ls</span> /root\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>from 表示挂载的源对象，用法与 COPY --from 相同。</li>\n<li>src 表示源路径，默认为 from 的顶级目录。</li>\n<li>dst 表示目标路径，如果不存在则会自动创建。</li>\n<li>挂载时默认的访问模式为 rw ，可以改为 ro 。</li>\n<li>使用 RUN --mount 方式获取文件，可以避免像 COPY 命令那样将文件保存到镜像中。</li>\n</ul>\n</li>\n<li>cache ：用于挂载缓存目录，类似于数据卷。<div><pre><code>RUN --mount<span>=</span>type<span>=</span>cache,target<span>=</span>/app/node_modules,id<span>=</span>/app/node_modules <span>\\</span>\n    <span>cd</span> /app   <span>;</span><span>\\</span>\n    <span>npm</span> <span>install</span>\n\nRUN --mount<span>=</span>type<span>=</span>cache,target<span>=</span>/app/node_modules,sharing<span>=</span>locked <span>\\</span>\n    <span>cd</span> /app   <span>;</span><span>\\</span>\n    <span>npm</span> run build\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>cache 会在第一次挂载时自动创建。当构建结束，且不存在引用它的镜像时，自动删除。\n<ul>\n<li>挂载 cache 的好处：可以让多个构建步骤共享文件。</li>\n</ul>\n</li>\n<li>cache 的 id 默认等于 target 。</li>\n<li>sharing 表示并行构建时，对 cache 的访问模式。可取值如下：\n<ul>\n<li>shared ：默认值，允许并行读写。</li>\n<li>locked ：同时只能有一方绑定该 cache 。</li>\n<li>private ：如果 cache 已被绑定，则创建新的 cache 实例。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>secret ：用于挂载一个私密文件。该文件不是来自 build context ，而是由用户指定的任意宿主机文件。<div><pre><code>RUN --mount<span>=</span>type<span>=</span>secret,id<span>=</span>mysecret,dst<span>=</span>/secret <span>\\</span>\n    <span>cat</span> /secret\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"例-2\"> 例</h3>\n<ol>\n<li>\n<p>编写一个 Dockerfile ：</p>\n<div><pre><code><span><span>FROM</span> nginx</span>\n\n<span><span>LABEL</span> maintainer=test</span>\n<span><span>RUN</span> set -eu   ;<span>\\</span>\n    echo Hello</span>\n\n<span><span>CMD</span> [<span>\"nginx\"</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>首次构建镜像：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker build . -t nginx:v1</span>\nSending build context to Docker daemon  <span>2</span>.048kB <span># 发送构建上下文</span>\nStep <span>1</span>/4 <span>:</span> FROM nginx                           <span># 第一个步骤</span>\n---<span>></span> ea335eea17ab                               <span># 步骤结束，生成一个中间镜像（这里是 FROM 的源镜像）</span>\nStep <span>2</span>/4 <span>:</span> LABEL <span>maintainer</span><span>=</span>test                <span># 第二个步骤</span>\n---<span>></span> Running <span>in</span> 144c44cb0874                    <span># 在一个中间容器内运行</span>\nRemoving intermediate container 144c44cb0874    <span># 删除中间容器</span>\n---<span>></span> 94cb9642d8d7                               <span># 步骤结束，生成一个中间镜像（这里是将中间容器提交为中间镜像）</span>\nStep <span>3</span>/4 <span>:</span> RUN <span>set</span> -eu<span>;</span>     <span>touch</span> f1\n---<span>></span> Running <span>in</span> a1150f37fb12\nRemoving intermediate container a1150f37fb12\n---<span>></span> 4da89ebe5fe6\nStep <span>4</span>/4 <span>:</span> CMD <span>[</span><span>\"nginx\"</span><span>]</span>\n---<span>></span> Running <span>in</span> d239ef15d1eb\nRemoving intermediate container d239ef15d1eb\n---<span>></span> d4c94f7870ad\nSuccessfully built d4c94f7870ad                 <span># 构建完成</span>\nSuccessfully tagged nginx:v1                    <span># 加上镜像名和标签</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>构建镜像时，每个步骤的主要内容为：\n<ol>\n<li>使用上一步骤的镜像，创建一个临时的中间容器（intermediate container），用于执行 Dockerfile 中的一个指令。</li>\n<li>将中间容器提交为一个中间镜像，用于创建下一步骤的中间容器。</li>\n<li>删除当前的中间容器，开始下一步骤。\n<ul>\n<li>如果构建步骤出错，则不会删除中间容器。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>中间镜像会作为悬空镜像一直保留在本机，用于缓存，默认隐藏显示。\n<ul>\n<li>如果删除构建的最终镜像，则会自动删除它调用的所有中间镜像。</li>\n<li>用 docker push 推送最终镜像时，不会推送中间镜像。</li>\n</ul>\n</li>\n<li>大部分 Dockerfile 指令不会生成新的 layer ，只是修改了配置而生成新的中间镜像。\n<ul>\n<li>执行 ADD、RUN 指令时，不会创建中间容器，而是直接修改 layer 。</li>\n<li>执行 RUN 指令时，可能修改文件，添加一层新的非空 layer ，保存到镜像配置的 rootfs.diff_ids 列表。\n<ul>\n<li>因此建议尽量减少 RUN 指令的数量，避免增加大量 layer 。比如将多条 RUN 指令合并成一条，但合并了经常不命中缓存的命令时，又会增加构建耗时。</li>\n<li>安装软件时，记得删除缓存。例如：<div><pre><code><span><span>RUN</span> yum update &amp;&amp; <span>\\</span>\n    yum install -y vim &amp;&amp; <span>\\</span>\n    yum clean all &amp;&amp; <span>\\</span>\n    rm -rf /var/cache/yum</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><div><pre><code><span><span>RUN</span> apt update &amp;&amp; <span>\\</span>\n    apt install -y vim &amp;&amp; <span>\\</span>\n    apt clean &amp;&amp; <span>\\</span>\n    rm -rf /var/lib/apt/lists/*</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>在构建时，使用 shell 的 rm 命令只能删除当前 layer 的文件。不能删除之前 layer 的文件，只是添加一层新的 layer ，覆盖原 layer 中的文件。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>再次构建镜像：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker build . -t nginx:v2</span>\nSending build context to Docker daemon  <span>2</span>.048kB\nStep <span>1</span>/4 <span>:</span> FROM nginx\n---<span>></span> ea335eea17ab\nStep <span>2</span>/4 <span>:</span> LABEL <span>maintainer</span><span>=</span>test\n---<span>></span> Using cache                            <span># 使用缓存</span>\n---<span>></span> 94cb9642d8d7\nStep <span>3</span>/4 <span>:</span> RUN <span>set</span> -eu<span>;</span>     <span>touch</span> f1\n---<span>></span> Using cache\n---<span>></span> 4da89ebe5fe6\nStep <span>4</span>/4 <span>:</span> CMD <span>[</span><span>\"nginx\"</span><span>]</span>\n---<span>></span> Using cache\n---<span>></span> d4c94f7870ad\nSuccessfully built d4c94f7870ad\nSuccessfully tagged nginx:v1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>执行一个构建步骤时，如果 dockerd 发现已有的某个镜像执行过相同的构建步骤，则跳过执行当前步骤，直接采用该镜像作为中间镜像，实现缓存，减少构建耗时。\n<ul>\n<li>如果某个构建步骤未命中缓存，则之后的所有步骤都会禁用缓存。建议尽量将这样的构建步骤写在 Dockerfile 后面。</li>\n<li>重复执行 RUN 指令时，如果指令的内容相同，则会使用缓存。</li>\n<li>重复执行 ADD、COPY 指令时，如果指令的内容相同，拷贝的文件的哈希值也相同，才会使用缓存。</li>\n<li>使用缓存不一定合适，例如重复执行 <code>RUN date &gt; build_time</code> 时，得到的时间不会变，此时可通过 <code>docker build --no-cache</code> 禁用缓存。</li>\n</ul>\n</li>\n<li>例如构建 npm 前端项目时，可以分别 install 和 build ，尽量让 install 命中缓存：<div><pre><code><span><span>WORKDIR</span> /app</span>\n<span><span>COPY</span> package.json /app/package.json</span>\n<span><span>RUN</span> npm install</span>\n<span><span>COPY</span> . .</span>\n<span><span>RUN</span> npm run build</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n</ol>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "原理",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/Principle.html",
      "id": "/Hardware/DevOps/Container/Docker/Principle.html",
      "content_html": "<h1 id=\"原理\"> 原理</h1>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>容器（Container）是一个像虚拟机的沙盒，内部可以运行一组进程。</li>\n<li>镜像（Image）是用于创建容器的模板，包含了应用程序的可执行文件文件、依赖文件、配置信息等。</li>\n<li>Docker 采用 C/S 架构工作：\n<ul>\n<li>在宿主机上运行一个守护进程 dockerd ，作为服务器，负责管理本机的容器、镜像、数据卷、网络等对象。\n<ul>\n<li>早期版本的 dockerd 进程以子进程的形式运行各个容器的 1 号进程，存在单点故障的风险。</li>\n<li>后来，改为给每个容器创建一个守护进程 containerd-shim （新版本为 containerd-shim-runc-v2 ），作为容器的父进程。</li>\n</ul>\n</li>\n<li>用户可以在宿主机上执行 docker 命令，作为客户端，与 dockerd 交互，比如请求启动容器。\n<ul>\n<li>客户端默认通过本机的 <code>/var/run/docker.sock</code> 文件与 dockerd 通信，也可通过 tcp 端口访问本机或其它主机的 dockerd 。</li>\n<li>非 root 用户无权访问 docker.sock 文件，导致无权执行 docker ps 等命令。此时可以将该用户加入 docker 用户组：<code>sudo usermod leo -aG docker</code> ，从而开通权限。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"namespace\"> namespace</h2>\n<ul>\n<li>\n<p>Docker 基于 Linux namespace 技术隔离了各个容器的运行环境。</p>\n<ul>\n<li>隔离了进程、网络、文件系统等系统资源，接近于独享一个虚拟机的运行环境。</li>\n<li>没有隔离硬件资源。例如：一个容器可能占用全部的 CPU 和内存；在容器内执行 top 命令会看到整个宿主机的硬件资源。</li>\n<li>没有隔离 Linux 内核，容器内的进程可能通过内核漏洞逃逸到宿主机上。</li>\n</ul>\n</li>\n<li>\n<p>namespace 分为多种类型，分别用于隔离不同的系统资源。如下：</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>Flag</th>\n<th>隔离资源</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ipc</td>\n<td>CLONE_NEWIPC</td>\n<td>System V 系统的 IPC 对象、POSIX 系统的消息队列</td>\n</tr>\n<tr>\n<td>network</td>\n<td>CLONE_NEWNET</td>\n<td>网络设备、IP、Socket</td>\n</tr>\n<tr>\n<td>mnt</td>\n<td>CLONE_NEWNS</td>\n<td>文件系统的挂载点</td>\n</tr>\n<tr>\n<td>pid</td>\n<td>CLONE_NEWPID</td>\n<td>进程的 PID</td>\n</tr>\n<tr>\n<td>user</td>\n<td>CLONE_NEWUSER</td>\n<td>用户、用户组</td>\n</tr>\n<tr>\n<td>uts</td>\n<td>CLONE_NEWUTS</td>\n<td>主机名、域名</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>每种类型的 namespace 可以创建多个实例。\n<ul>\n<li>每个进程可以同时使用多种类型的 namespace 实例。</li>\n<li>如果一个 namespace 内的所有进程都退出，则内核会自动销毁该 namespace 。除非 <code>/proc/&lt;pid&gt;/ns/&lt;namespace&gt;</code> 文件被一直打开或挂载。</li>\n</ul>\n</li>\n<li>例：\n<ul>\n<li>不同 pid namespace 中的进程可以分配相同的 PID 。</li>\n<li>docker 容器内，第一个启动的进程被分配的 PID 为 1 ，而 PPID 为 0 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>关于 pid namespace ：</p>\n<ul>\n<li>pid namespace 支持嵌套，当前 pid namespace 中创建的所有 pid namespace 都属于子实例。\n<ul>\n<li>父实例可以看到子孙实例的进程信息，但反之不行。<br>\n比如在父实例中执行 ps -ef 命令，会将子孙实例中的进程也显示出来，并将它们的 PID 转换成父实例中的 PID 。</li>\n<li>子孙实例不可用看到父实例的进程信息。</li>\n<li>主机启动之后，第一个创建的 pid namespace 就是最上层的实例。</li>\n</ul>\n</li>\n<li>每个 pid namespace 中，第一个创建的进程的 PID 为 1 ，通常为 init 进程。\n<ul>\n<li>如果其它进程产生了孤儿进程，则内核会将它们改为当前 pid namespace 的 init 进程的子进程。</li>\n<li>如果 init 进程退出，则内核会向当前及子孙 pid namespace 中的所有进程发送 SIGKILL 信号，杀死它们。</li>\n<li>内核只支持将已注册 handler 的信号发送给 init 进程，会忽略 SIGKILL、SIGSTOP 等信号。但是可以发送给子孙 pid namespace 中的 init 进程，因为它们在当前 pid namespace 中的 PID 不为 1 。这样会导致子孙 pid namespace 被销毁。</li>\n</ul>\n</li>\n<li>调用 setns() 或 unshare() 时，不会改变当前进程的 pid namespace ，而是影响之后创建的子进程。\n<ul>\n<li>因此，一个进程在创建之后，其 PID 总是不变。成为孤儿进程时， PPID 会变为 1 。</li>\n</ul>\n</li>\n<li>相关 API ：<div><pre><code><span><span>#</span><span>include</span> <span>&lt;unistd.h></span></span>\n\n<span>pid_t</span> <span>getpid</span><span>(</span><span>void</span><span>)</span><span>;</span>   <span>// 返回当前进程的 PID ，属于当前的 pid namespace</span>\n<span>pid_t</span> <span>getppid</span><span>(</span><span>void</span><span>)</span><span>;</span>  <span>// 返回父进程的 PID 。如果父进程属于不同的 pid namespace ，则返回 0</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p><code>/proc/&lt;pid&gt;/ns/</code> 目录下，通过一些软链接，记录了进程所属的 namespace ID 。如下：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># ll /proc/1/ns</span>\ntotal <span>0</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 ipc -<span>></span> ipc:<span>[</span><span>4026531839</span><span>]</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 mnt -<span>></span> mnt:<span>[</span><span>4026531840</span><span>]</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 net -<span>></span> net:<span>[</span><span>4026531956</span><span>]</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 pid -<span>></span> pid:<span>[</span><span>4026531836</span><span>]</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 user -<span>></span> user:<span>[</span><span>4026531837</span><span>]</span>\nlrwxrwxrwx. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>13</span>:25 uts -<span>></span> uts:<span>[</span><span>4026531838</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>如果两个进程的某种 namespace ID 相同，则说明属于这种类型的同一个 namespace 实例。</li>\n<li>创建子进程时，默认继承父进程的 namespace 实例。</li>\n</ul>\n</li>\n<li>\n<p>相关 API ：</p>\n<div><pre><code><span><span>#</span><span>include</span> <span>&lt;sched.h></span></span>\n\n<span>int</span> <span>clone</span><span>(</span><span>int</span> <span>(</span><span>*</span>child_func<span>)</span><span>(</span><span>void</span> <span>*</span><span>)</span><span>,</span> <span>void</span> <span>*</span>child_stack<span>,</span> <span>int</span> flags<span>,</span> <span>void</span> <span>*</span>arg<span>)</span><span>;</span>\n    <span>// 创建一个子进程，并创建指定类型的 namespace ，让子进程加入其中</span>\n    <span>// child_func   ：子进程要运行的函数</span>\n    <span>// child_stack  ：子进程使用的栈空间</span>\n    <span>// flags        ：一种或多种 namespace 的 flag ，比如 flags = CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER</span>\n    <span>// args         ：传给子进程的参数</span>\n\n<span>int</span> <span>setns</span><span>(</span><span>int</span> fd<span>,</span> <span>int</span> nstype<span>)</span><span>;</span>\n    <span>// 让当前进程加入已存在的 namespace</span>\n    <span>// fd     ：一个 namespace 的文件描述符</span>\n    <span>// nstype ：用于检查 fd 指向的 namespace 类型，填 0 则不检查</span>\n\n<span>int</span> <span>unshare</span><span>(</span><span>int</span> flags<span>)</span><span>;</span>\n    <span>// 根据 flags 创建新的 namespace ，然后让当前进程加入其中。这会先离开已加入的同类型 namespace</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h2 id=\"cgroup\"> Cgroup</h2>\n<ul>\n<li>\n<p>Docker 基于 Linux Cgroup 技术限制各个容器占用的 CPU、内存等系统资源。</p>\n<ul>\n<li>在 Cgroup 技术之前，通常通过 ulimit 命令限制 shell 终端占用的系统资源，但功能较少。</li>\n</ul>\n</li>\n<li>\n<p>Cgroup 的版本：</p>\n<ul>\n<li>v1\n<ul>\n<li><a href=\"https://www.kernel.org/doc/Documentation/cgroup-v1/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>本文采用该版本。</li>\n</ul>\n</li>\n<li>v2\n<ul>\n<li>将所有 subsystem 都关联到一个 unified hierarchy 中。</li>\n<li>同一个 subsystem 不能同时关联 v1 和 v2 版本的 hierarchy 。</li>\n<li>只允许在根节点、叶子节点创建 cgroup 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"主要概念\"> 主要概念</h3>\n<ul>\n<li>task\n<ul>\n<li>：代表一个进程。</li>\n</ul>\n</li>\n<li>cgroup\n<ul>\n<li>：控制组，包含一组进程。</li>\n<li>cgroup 的最小管理单位是进程，不能管理进程中的某个线程。</li>\n<li>创建子进程时，默认继承父进程的 cgroup 。但是创建之后，修改父进程或子进程的 cgroup ，不再相互影响。</li>\n</ul>\n</li>\n<li>hierarchy\n<ul>\n<li>：层级，是由多个 cgroup 实例以目录树的形式组成，又称为 cgroup 树。</li>\n<li>通过挂载文件系统的方式，创建 hierarchy 。\n<ul>\n<li>一般将 hierarchy 挂载在 <code>/sys/fs/cgroup/</code> 目录下。</li>\n<li>通过在 hierarchy 目录下创建、删除子目录的方式，创建、删除 cgroup 节点。</li>\n<li>cgroup 子节点默认继承父节点的属性。</li>\n<li>如果一个 cgroup 节点不包含任何进程，也没有子节点，则称为空节点，允许被删除。</li>\n<li>创建 hierarchy 时，根路径下的 cgroup 节点是第一个创建的节点，称为 root cgroup 。</li>\n</ul>\n</li>\n<li>每个进程同时可以存在于多个 hierarchy 中。\n<ul>\n<li>在同一个 hierarchy 中，每个进程同时只能属于一个 cgroup ，但可以切换到其它 cgroup 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>subsystem\n<ul>\n<li>：资源控制器（Resource Controller）。</li>\n<li>通过将 subsystem 关联到 hierarchy 的方式，控制 cgroup 内进程占用的系统资源。\n<ul>\n<li>每个 subsystem 同时只能关联一个 hierarchy 。</li>\n<li>每个 hierarchy 同时可以关联多个 subsystem 。</li>\n</ul>\n</li>\n<li>subsystem 分为多种类型：<div><pre><code>pids        <span># 限制、统计进程总数，包括 Cgroup 当前节点及其子节点</span>\n\ncpu         <span># 限制 CPU 使用量</span>\ncpuacct     <span># 统计 CPU 使用量</span>\ncpuset      <span># 只允许使用 CPU 的指定核</span>\n\nmemory      <span># 限制、统计内存的使用量</span>\n\nblkio       <span># 限制对块设备的 IO 速度</span>\ndevices     <span># 控制能否访问某些设备</span>\nfreezer     <span># 暂停进程。这不是通过发送 SIGSTOP 信号，而是在进程被 CPU 执行时突然阻塞。此时进程依然存在，不能继续执行，不能响应信号</span>\nhugetlb     <span># 限制 huge page 的使用量</span>\nperf_event  <span># 允许进程被 perf 命令监控</span>\n\nnet_prio    <span># 设置对网络接口的访问优先级</span>\nnet_cls     <span># 通过等级识别符 (classid) 标记进程发出的网络数据包，便于被 iptables 等工具统计</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n<li>每种 subsystem 通过读写一组文件来实现配置，例如：<div><pre><code>pids.max              <span># 限制进程总数，取值为 max 则不限制</span>\npids.current          <span># 记录当前的进程总数</span>\n\ncpu.shares\ncpu.cfs_period_us     <span># 对应 --cpu-period</span>\ncpu.cfs_quota_us      <span># 对应 --cpu-quota</span>\n\nmemory.limit_in_bytes <span># 限制进程最大的内存使用量，取值为 -1 则不限制</span>\nmemory.usage_in_bytes <span># 记录进程当前的内存使用量，包括 RSS 和 Page Cache 。因此，如果 Docker 容器进行大量磁盘 IO ，则监控到的内存开销会比 RSS 偏大</span>\nmemory.oom_control    <span># 取值为 0 时，启用 OOM-killer ，当进程占用的内存超过限制时杀死它。取值为 1 时，禁用 OOM-killer ，只是暂停进程</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"查看\"> 查看</h3>\n<ul>\n<li>\n<p>例：查看指定进程的 cgroup 信息</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># cat /proc/$$/cgroup</span>\n<span>11</span>:memory:/user.slice\n<span>10</span>:cpuset:/\n<span>9</span>:cpuacct,cpu:/user.slice\n<span>8</span>:hugetlb:/\n<span>7</span>:net_prio,net_cls:/\n<span>6</span>:devices:/user.slice\n<span>5</span>:freezer:/\n<span>4</span>:blkio:/user.slice\n<span>3</span>:pids:/user.slice\n<span>2</span>:perf_event:/\n<span>1</span>:name<span>=</span>systemd:/user.slice/user-1000.slice/session-3785.scope\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>每行的三个字段分别表示：\n<ul>\n<li>cgroup ID 。</li>\n<li>cgroup 绑定的所有 subsystem 的名称，用逗号分隔。\n<ul>\n<li><code>name=systemd</code> 表示没有绑定 subsystem ，只是定义了名称。</li>\n</ul>\n</li>\n<li>进程在 cgroup 树中的路径。\n<ul>\n<li>这是对于挂载点的相对路径，以 / 开头。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>对于 Cgroup v2 ，每行总是显示成 <code>0::&lt;PATH&gt;</code> 的格式。</li>\n</ul>\n</li>\n<li>\n<p>例：查看系统的所有 subsystem</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># cat /proc/cgroups</span>\n<span>#subsys_name    hierarchy       num_cgroups     enabled</span>\ncpuset          <span>10</span>              <span>5</span>               <span>1</span>\ncpu             <span>9</span>               <span>71</span>              <span>1</span>\ncpuacct         <span>9</span>               <span>71</span>              <span>1</span>\nmemory          <span>11</span>              <span>71</span>              <span>1</span>\ndevices         <span>6</span>               <span>71</span>              <span>1</span>\nfreezer         <span>5</span>               <span>5</span>               <span>1</span>\nnet_cls         <span>7</span>               <span>5</span>               <span>1</span>\nblkio           <span>4</span>               <span>71</span>              <span>1</span>\nperf_event      <span>2</span>               <span>5</span>               <span>1</span>\nhugetlb         <span>8</span>               <span>5</span>               <span>1</span>\npids            <span>3</span>               <span>71</span>              <span>1</span>\nnet_prio        <span>7</span>               <span>5</span>               <span>1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><ul>\n<li>四列分别表示 subsystem 的：\n<ul>\n<li>名称</li>\n<li>关联的 hierarchy ID</li>\n<li>关联的 cgroup 中的进程数</li>\n<li>是否启用</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"创建\"> 创建</h3>\n<p>创建 Cgroup 的示例：</p>\n<ol>\n<li>\n<p>通过挂载文件系统的方式，创建 hierarchy ：</p>\n<div><pre><code><span>mkdir</span> -p /cgroup/hierarchy_1\n\n<span># 挂载一个 cgroup 类型的虚拟文件系统，作为 hierarchy ，命名为 hierarchy_1 。默认关联所有 subsystem</span>\n<span># mount -t cgroup hierarchy_1 /cgroup/hierarchy_1</span>\n\n<span># 可以通过 -o 选项传入一些参数，这里是只关联指定的 subsystem</span>\n<span># mount -t cgroup -o cpuset,cpuacct hierarchy_1 /cgroup/hierarchy_1</span>\n\n<span># 挂载 hierarchy ，关联的 subsystem 为空</span>\n<span>mount</span> -t cgroup -o none,name<span>=</span>subsystem_1  hierarchy_1  /cgroup/hierarchy_1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>如果使用的 subsystem 已经被关联，则挂载 hierarchy 时会报错：<div><pre><code>mount: hierarchy_1 is already mounted or /cgroup/hierarchy_1 busy\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>删除 hierarchy 的命令：<div><pre><code><span>umount</span>      /cgroup/hierarchy_1\n/bin/rm -r  /cgroup/hierarchy_1\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>hierarchy 在挂载之后会自动创建 root cgroup 节点，生成一些默认文件。如下：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># cd /cgroup/hierarchy_1</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1<span>]</span><span># ll</span>\ntotal <span>0</span>\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 cgroup.clone_children  <span># 文件内容默认为 0 。如果为 1 ，则创建子节点时会拷贝当前节点的 cpuset subsystem 配置</span>\n--w--w--w-. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 cgroup.event_control\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 cgroup.procs           <span># 记录该 cgroup 关联的所有进程，每行一个 PID</span>\n-r--r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 cgroup.sane_behavior\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 notify_on_release      <span># 文件内容默认为 0 。如果为 1 ，则 cgroup 退出时会执行 release_agent</span>\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 release_agent          <span># 该文件只存在于 root cgroup 中，包含一些 cgroup 退出时需要执行的命令</span>\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:17 tasks                  <span># 与 cgroup.procs 类似，记录进程中主线程的 TID ，即与 PID 一致</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1<span>]</span><span># head cgroup.procs          # root cgroup 默认包含系统的所有进程</span>\n<span>1</span>\n<span>2</span>\n<span>4</span>\n<span>6</span>\n<span>7</span>\n<span>8</span>\n<span>9</span>\n<span>10</span>\n<span>11</span>\n<span>12</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></li>\n<li>\n<p>在 hierarchy 目录下添加 cgroup 节点：</p>\n<div><pre><code><span>[</span>root@CentOS /cgroup/hierarchy_1<span>]</span><span># mkdir cgroup_1             # 创建一个 cgroup 子节点，这会自动生成一些默认文件</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1<span>]</span><span># cd cgroup_1/</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># ll</span>\ntotal <span>0</span>\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:35 cgroup.clone_children\n--w--w--w-. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:35 cgroup.event_control\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:35 cgroup.procs\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:35 notify_on_release\n-rw-r--r--. <span>1</span> root root <span>0</span> Mar <span>26</span> <span>17</span>:35 tasks\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat cgroup.procs  # 非 root cgroup 的节点，默认不包含任何进程</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n<li>\n<p>在 cgroup 节点中增加进程：</p>\n<div><pre><code><span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># echo 1 >> cgroup.procs   # 向该 cgroup 分组加入一个进程，这会自动将该进程移出之前的 cgroup</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat cgroup.procs</span>\n<span>1</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># head ../cgroup.procs</span>\n<span>2</span>\n<span>4</span>\n<span>6</span>\n<span>7</span>\n<span>8</span>\n<span>9</span>\n<span>10</span>\n<span>11</span>\n<span>12</span>\n<span>13</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat ../cgroup.procs >> cgroup.procs # 每次只能加入一个 PID</span>\ncat: <span>write</span> error: Argument list too long\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># echo 3 >> cgroup.procs              # 不能加入不存在的进程的 PID</span>\n-bash: echo: <span>write</span> error: No such process\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># echo > cgroup.procs                 # 只能在 cgroup 中加入进程，不支持删除进程</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat cgroup.procs</span>\n<span>1</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># echo $$ > cgroup.procs  # 加入当前终端的 PID</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat cgroup.procs</span>\n<span>1</span>\n<span>4593</span>\n<span>6121</span>                                                                <span># 终端执行命令时创建了子进程，因此也加入了其 PID</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># echo $$ > cgroup.procs  # 加入 PID 时，会自动排序、去重、去掉不存在的 PID</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cat cgroup.procs</span>\n<span>1</span>\n<span>4593</span>\n<span>6160</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br></div></div><ul>\n<li>非 root 用户只能修改自己进程所属的 cgroup 。</li>\n<li>非空节点的 cgroup 不允许被删除：<div><pre><code><span>[</span>root@CentOS /cgroup/hierarchy_1/cgroup_1<span>]</span><span># cd ..</span>\n<span>[</span>root@CentOS /cgroup/hierarchy_1<span>]</span><span># /bin/rm -r cgroup_1/</span>\n/bin/rm: cannot remove ‘cgroup_1/cgroup.clone_children’: Operation not permitted\n/bin/rm: cannot remove ‘cgroup_1/cgroup.event_control’: Operation not permitted\n/bin/rm: cannot remove ‘cgroup_1/notify_on_release’: Operation not permitted\n/bin/rm: cannot remove ‘cgroup_1/cgroup.procs’: Operation not permitted\n/bin/rm: cannot remove ‘cgroup_1/tasks’: Operation not permitted\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n</li>\n</ol>\n<h3 id=\"libcgroup-tools\"> libcgroup-tools</h3>\n<p>：一个用于查看、配置 Cgroup 的工具包。</p>\n<ul>\n<li>安装：<code>yum install -y libcgroup-tools</code></li>\n<li>命令：<div><pre><code>lscgroup        <span># 显示本机的所有 cgroup</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code>lssubsys        <span># 显示已挂载的 subsystem</span>\n        -a      <span># 显示所有 subsystem</span>\n        -m      <span># 增加显示每个 subsystem 的挂载点</span>\n        -i      <span># 增加显示每个 subsystem 关联的 hierarchy ID</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><div><pre><code>cgdelete <span>[</span><span>&lt;</span>controllers<span>></span>:<span>&lt;</span>path<span>></span><span>]</span><span>..</span>.  <span># 删除 cgroup</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>例：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># lscgroup</span>\n<span>..</span>.\ncpu,cpuacct:/               <span># 每行的格式为 &lt;controllers>:&lt;path> ，即 subsystem 的类型、cgroup 在 hierarchy 下的相对路径</span>\ncpu,cpuacct:/docker\ncpu,cpuacct:/docker/baf31e1d1a0b055b7f7d9947ec035d716a2d7788ee47473f85f9f4061633fabe\ncpu,cpuacct:/docker/ba919a1393fbd560291ec8dd28eedf12b1e6ce4f0c1ab4df04d929074a436661\ncpu,cpuacct:/user.slice\ncpu,cpuacct:/system.slice\ncpu,cpuacct:/system.slice/iptables.service\ncpu,cpuacct:/system.slice/run-user-1000.mount\ncpu,cpuacct:/system.slice/crond.service\ncpuset:/\ncpuset:/docker\ncpuset:/docker/baf31e1d1a0b055b7f7d9947ec035d716a2d7788ee47473f85f9f4061633fabe\ncpuset:/docker/ba919a1393fbd560291ec8dd28eedf12b1e6ce4f0c1ab4df04d929074a436661\n<span>name</span><span>=</span>subsystem_1:/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h2 id=\"layer\"> layer</h2>\n<ul>\n<li>Docker 容器内采用联合挂载（Union mount）技术挂载多层文件系统（file system layer）。\n<ul>\n<li>mount 命令会让挂载的 layer 覆盖挂载点，而 Union mount 会让挂载的 layer 与挂载点合并：路径不同的文件会混合，路径相同的文件会覆盖。</li>\n<li>支持 Union mount 的 layer 称为 Union Filesystem ，比如 UnionFS、AUFS、OverlayFS 等。</li>\n<li>使用 Union mount 合并多层 layer 时，只有最上层的那个 layer 为读写模式（称为 top layer），其它 layer 都为 read-only 模式。</li>\n</ul>\n</li>\n<li>一个 Docker 镜像由一层或多层 layer 组成，每层 layer 采用 SHA256 哈希值作为 ID 。</li>\n<li>创建 Docker 容器时的挂载过程：\n<ol>\n<li>先根据 Docker 镜像创建一个只读模式的 RootFS 文件系统，包含 /bin、/dev、/home 等 FHS 标准目录。</li>\n<li>然后挂载一层读写模式的 top layer ，内容为空，不包含任何文件。\n<ul>\n<li>容器内进程创建、修改的所有文件，都保存在 top layer 中。</li>\n<li>采用写时复制（Copy On Write，COW）：当容器要修改 read-only layer 中的文件时，内核会自动将该文件拷贝到 top layer 中，供容器修改，并覆盖原 layer 中的文件。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "容器",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/container.html",
      "id": "/Hardware/DevOps/Container/Docker/container.html",
      "content_html": "<h1 id=\"容器\"> 容器</h1>\n<h2 id=\"启动\"> 启动</h2>\n<div><pre><code><span>docker</span> run <span>&lt;</span>image<span>></span> <span>[</span>command<span>]</span>  <span># 根据一个镜像创建并启动一个容器，可选指定容器的启动命令</span>\n          -i                  <span># --interactive ，保持打开容器的 stdin ，允许输入</span>\n          -t                  <span># --tty ，创建一个伪终端，绑定到容器的 stdin ，供用户操作</span>\n          -d                  <span># --detach ，以 daemon 方式运行，默认在当前终端的前台运行</span>\n          --init              <span># 使用 docker-init 进程作为容器的 1 号进程</span>\n          --rm                <span># 当容器停止时，自动删除它</span>\n\n          -u <span>&lt;</span>uid<span>></span><span>[</span>:gid<span>]</span>      <span># 在容器内使用指定的用户（默认为 root）</span>\n          -w <span>&lt;</span>path<span>></span>           <span># --workdir ，指定容器的工作目录，如果该目录不存在则会自动创建</span>\n          -e <span>&lt;</span>name<span>></span><span>[</span><span>=</span>value<span>]</span>   <span># --env ，设置容器内的环境变量（可重复使用该命令选项）如果省略 value ，则读取宿主机上的同名环境变量</span>\n          -l <span>&lt;</span>key<span>></span><span>[</span><span>=</span><span>&lt;</span>value<span>></span><span>]</span>  <span># --label ，给容器添加键值对格式的标签，比如 branch=dev 。如果不指定 value ，则默认赋值为 \"\" 。可以多次使用该选项</span>\n\n          --name <span>&lt;</span>name<span>></span>       <span># 设置容器的名称</span>\n          --hostname <span>&lt;</span>name<span>></span>   <span># 设置容器内的主机名，默认为容器 ID</span>\n          --privileged        <span># 特权模式，默认不启用。允许在容器内访问所有设备文件，比如挂载磁盘，甚至可以在容器内运行嵌套的容器</span>\n          --entrypoint <span>'xx'</span>   <span># 覆盖 Dockerfile 中的 ENTRYPOINT</span>\n          --pid <span>&lt;</span>namespace<span>></span>   <span># 容器采用的 PID namespace 。比如 --pid=host 是采用宿主机的 namespace ，--pid=container:redis 是采用指定容器的 namespace ，共享进程列表</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div><ul>\n<li>创建容器时，如果本机不存在指定名称的镜像，则会自动从镜像仓库拉取。</li>\n<li>例：<div><pre><code><span>docker</span> run busybox                        <span># 运行一个镜像</span>\n<span>docker</span> run -it busybox <span>sh</span>                 <span># 创建容器，并进入该容器的终端</span>\n<span>docker</span> run -d  busybox <span>tail</span> -f /dev/null  <span># 创建一个容器，让它执行一个不会停止的启动命令</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>运行嵌套容器的示例：<div><pre><code><span>docker</span> run -d --name dind --privileged docker:dind  <span># dind 镜像代表 docker in docker ，内置了 dockerd</span>\n<span>docker</span> <span>exec</span> -it dind <span>sh</span>                             <span># 进入 dind 容器</span>\n<span>docker</span> run -d nginx                                 <span># 在 dind 容器内运行嵌套的容器</span>\n<span>ps</span> auxf                                             <span># 查看此时的进程树</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"启动命令\"> 启动命令</h3>\n<ul>\n<li>用户创建一个容器时，需要指定一条启动命令，否则采用镜像默认的启动命令。\n<ul>\n<li>容器启动之后，用户可以进入容器内终端，执行任意命令，启动其它进程。</li>\n<li>启动命令默认为容器内 PID 为 1 的进程，即 1 号进程。\n<ul>\n<li>一旦容器内 1 号进程退出，或者不在前台运行，则 dockerd 会自动停止容器。</li>\n<li>因此，为了让容器保持运行，容器的启动命令应该一直保持运行，并且在前台运行，比如 <code>tail -f /dev/null</code> 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>建议在容器内使用非 root 用户运行应用程序。\n<ul>\n<li>因为容器内的 root 用户虽然受到限制，没有宿主机的 root 用户那么多特权。但它也是作为 root 用户与内核交互，可能通过内核漏洞逃出容器，成为宿主机的 root 用户。</li>\n</ul>\n</li>\n<li>建议每个容器内只运行一个应用程序，使得启动、停止该容器相当于启动、停止该应用，这样方便管理。\n<ul>\n<li>例如一个容器内只运行一个 Nginx 服务器，它包含多个子进程。</li>\n</ul>\n</li>\n<li>如果容器内包含多个进程，建议用 tini、supervisord 等工具管理。\n<ul>\n<li>执行 docker stop 时，dockerd 只会发送 SIGTERM 信号给容器内的 1 号进程，然后等待 1 号进程清理容器内的其它进程。如果等待超时，则发送 SIGKILL 信号。\n<ul>\n<li>如果 1 号进程是 shell 解释器，则不会捕捉 SIGTERM 信号，也不会传递信号给子进程，因此 dockerd 只能等超时之后才杀死容器。</li>\n<li>如果 1 号进程是用户自定义的程序，则可能不会捕捉 SIGTERM 信号、清理僵尸进程。</li>\n<li>如果 1 号进程为 docker-init 进程（来自 tini 项目），则会以子进程的形式执行容器的启动命令。它会捕捉 SIGTERM 信号并转发给直接子进程，还会清理僵尸进程（不包括子孙进程）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>无状态容器（Stateless）\n<ul>\n<li>：指不需要保持连续运行的容器。其它容器称为有状态容器（Stateful）。</li>\n<li>这种容器比较方便管理。可以随时重启，甚至随时销毁并从镜像重新创建，不会中断服务、不会丢失数据。</li>\n<li>以运行 Web 服务器的容器为例：\n<ul>\n<li>如果 Web 服务器没有进行中的 HTTP 通信，则可以重启容器。</li>\n<li>如果 Web 服务器把产生的数据保存在容器内，则只能重启容器，但不能销毁容器。如果保存在容器外的数据库中，则可以销毁容器。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"重启策略\"> 重启策略</h3>\n<ul>\n<li>容器的重启策略（restart policy）：当容器停止时，是否通过 docker start 重启。\n<ul>\n<li>如果在 10 秒内连续重启，则重启间隔从 100ms 开始，每次增加一倍，最多增加到 1min。</li>\n</ul>\n</li>\n<li>设置重启策略：<div><pre><code><span>docker</span> run\n          --restart no              <span># 禁止自动重启（默认采用）</span>\n          --restart on-failure      <span># 当容器异常停止时（不包括 dockerd 重启的情况），才会自动重启。该策略还可限制连续重启次数，比如 on-failure:3</span>\n          --restart unless-stopped  <span># 当容器停止时，就自动重启（除非容器是被 docker stop 了）</span>\n          --restart always          <span># 当容器停止时，总是会自动重启（即使被 docker stop 了，当 dockerd 重启时又会自动重启该容器）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n<h3 id=\"资源限制\"> 资源限制</h3>\n<ul>\n<li>可以限制容器占用的系统资源：<div><pre><code><span>docker</span> run\n          -c <span>1024</span>                   <span># --cpu-shares ，与其它容器抢占 CPU 时的权重，取值范围为 1~1024</span>\n          --cpus <span>1.5</span>                <span># 限制同时占用 CPU 的核数（每秒的平均值）。默认为 0 即不限制</span>\n          --cpuset-cpus <span>0</span>-2,3       <span># 限制可用的 CPU 核的编号</span>\n          --cpu-period <span>100000</span>       <span># 设置 CPU 调度的 CFS 周期。单位为 us ，取值范围为 1ms~1s ，默认为 100ms</span>\n          --cpu-quota <span>0</span>             <span># 容器在每个 CFS 周期内占用的 CPU 最大时长。取值范围为 >1ms ，默认为 0 即不限制</span>\n\n          -m 256m                   <span># --memory ，限制占用的 RAM 内存大小，单位可以是 b、k、m、g 。默认不限制</span>\n          --memory-swap <span>0</span>           <span># 限制占用的 RAM + swap 大小。默认取值为 0 ，相当于为 -m 的两倍。为 -1 时，不限制。与 -m 相等时，会禁用 swap</span>\n          --memory-swappiness       <span># 用 swap 内存的推荐度，取值范围为 0~100 ，0 表示禁用</span>\n          --oom-kill-disable <span>false</span>  <span># 是否禁止 OOM 杀死进程</span>\n          --kernel-memory 4m        <span># 限制占用的内核态内存，比如 stack、slab、socket 。默认不限制。如果取值小于 --memory ，则属于后者的子集</span>\n          --shm-size 64m            <span># 限制挂载到 /dev/shm 的 tmpfs 文件系统的体积，默认为 64m</span>\n\n          --device-read-bps 1kb     <span># 限制每秒读磁盘的数据量，默认不限制</span>\n          --device-write-bps 1kb    <span># 限制每秒写磁盘的数据量</span>\n          --device-read-iops <span>10</span>     <span># 限制每秒读磁盘的次数</span>\n          --device-write-iops <span>10</span>    <span># 限制每秒读磁盘的次数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div></li>\n</ul>\n<h2 id=\"查看\"> 查看</h2>\n<div><pre><code><span>docker</span>\n      <span>ps</span>                          <span># 显示所有 running 状态的容器</span>\n          -a                      <span># 显示所有状态的容器</span>\n          -n <span>&lt;</span>int<span>></span>                <span># --last ，显示最后创建的几个容器（包括所有状态的）</span>\n          --no-trunc              <span># 不截断显示过长的内容</span>\n          -q                      <span># --quiet ，只显示 ID</span>\n          -s                      <span># --size ，增加显示容器占用的磁盘空间</span>\n          -f <span>status</span><span>=</span>running       <span># --filter ，添加过滤条件，只显示部分容器</span>\n          -f <span>\"label=branch\"</span>       <span># 过滤具有 branch 标签的容器</span>\n          -f <span>\"label=branch=dev\"</span>   <span># 过滤具有 branch 标签且取值为 dev 的容器</span>\n          --format <span>'{{.Names}} {{.Status}}'</span> <span># 自定义每个容器显示的字段信息，基于 Go 模板语法</span>\n\n      <span>diff</span>  <span>&lt;</span>container<span>></span>           <span># 显示容器内 top layer 的变化，用 A、C、D 分别表示增加、更改、删除了文件</span>\n      port  <span>&lt;</span>container<span>></span>           <span># 显示指定容器映射的所有端口</span>\n      <span>top</span>   <span>&lt;</span>container<span>></span> <span>[</span>options<span>]</span> <span># 显示指定容器内的进程列表，可加上 ps 命令的参数</span>\n      stats <span>[</span>container<span>]</span><span>..</span>.        <span># 显示容器的资源占用情况，包括单核 CPU 使用率、分配的内存使用率、网络 IO 量、磁盘 IO 量、创建的线程数</span>\n      inspect <span>&lt;</span>object<span>></span>                      <span># 显示一个 docker 对象的详细信息</span>\n          -f <span>\"{{json .HostConfig.Binds }}\"</span>  <span># --format ，只按照 JSON 格式显示指定信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>docker 的容器、镜像、数据卷、网络等对象可采用 ID 或 Name 作为标识符。\n<ul>\n<li>ID   ：取自对象十六进制哈希值的开头 n 位。用户可自由指定 n 位 ID ，只需与其它对象不同即可。</li>\n<li>Name ：与 <code>[A-Za-z0-9][A-Za-z0-9_.-]*</code> 正则匹配的名称。如果用户未指定，则由 dockerd 自动分配。</li>\n<li>每个对象在创建之后，不支持修改其 ID 或 Name 。</li>\n</ul>\n</li>\n<li><code>docker ps --format</code> 可显示以下字段，区分大小写：<div><pre><code>.ID\n.Image\n.Command      <span># 容器的启动命令</span>\n.CreatedAt    <span># 容器的创建时间</span>\n.RunningFor\t  <span># 容器从创建以来，存在的时长</span>\n.Ports\t      <span># 镜像 EXPOSE 的端口、容器实际映射的端口</span>\n\n.Names\n.Labels       <span># 容器的所有标签</span>\n.Label        <span># 容器的指定标签的值，比如 '{{.Label \"maintainer\"}}'</span>\n\n.State        <span># 容器的运行状态，比如 created、running、exited</span>\n.Status       <span># 容器的运行状态，以及该状态的持续时间，例如： Up 2 minutes</span>\n.Size         <span># 容器占用的磁盘空间。例如：0B (virtual 206MB) 分别表示 top layer 所占磁盘空间、全部层 layer 所占虚拟磁盘空间，不包括日志驱动器、挂载卷、swap 占用的磁盘空间</span>\n.Mounts       <span># 容器挂载的所有卷，例如：/etc/localtime, /data/mysql</span>\n.Networks     <span># 容器关联的网络名</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h2 id=\"管理\"> 管理</h2>\n<div><pre><code><span>docker</span>\n      <span># 运行容器</span>\n      run                       <span># 运行容器，相当于先 create 再 start</span>\n      create                    <span># 创建容器，命令行参数与 docker run 差不多。此时容器处于 created 状态，没有运行</span>\n      start   <span>&lt;</span>container<span>></span><span>..</span>.    <span># 启动容器，容器会从 exited 状态变为 running 状态</span>\n      restart <span>&lt;</span>container<span>></span><span>..</span>.    <span># 重启容器，相当于先 stop 再 start</span>\n\n      <span># 暂停容器</span>\n      pause   <span>&lt;</span>container<span>></span><span>..</span>.    <span># 暂停容器内所有进程，基于 Cgroup 的 freezer</span>\n      unpause <span>&lt;</span>container<span>></span><span>..</span>.    <span># 解除暂停的容器</span>\n\n      <span># 停止容器</span>\n      stop    <span>&lt;</span>container<span>></span><span>..</span>.    <span># 停止容器。这会向容器内 1 号进程发送 SIGTERM 信号，然后等待容器内所有进程退出</span>\n          -t <span>&lt;</span>n<span>></span>                <span># 超时时间，默认为 10 秒。如果超时之后，容器内依然有进程未退出，则自动发送 SIGKILL 信号</span>\n      <span>kill</span>    <span>&lt;</span>container<span>></span><span>..</span>.    <span># 杀死容器。这会向容器内 1 号进程发送 SIGKILL 信号</span>\n          -s <span>&lt;</span>signal<span>></span>           <span># 发送的信号，默认为 SIGKILL</span>\n      <span>wait</span>    <span>&lt;</span>container<span>></span><span>..</span>.    <span># 阻塞等待容器停止，然后打印其退出码</span>\n      <span>rm</span>      <span>&lt;</span>container<span>></span><span>..</span>.    <span># 删除容器（只能删除已停止的）</span>\n          -f                    <span># 强制删除（可以删除正在运行的）</span>\n      container prune           <span># 删除所有已停止的容器</span>\n\n      <span># 修改容器</span>\n      <span>rename</span>  <span>&lt;</span>container<span>></span> <span>&lt;</span>new_name<span>></span>  <span># 重命名容器</span>\n      update  <span>&lt;</span>container<span>></span><span>..</span>.          <span># 更改容器的配置</span>\n          --cpus <span>2</span>\n          -m 256m\n          --restart no\n\n      <span># 管理 docker 引擎</span>\n      system\n          info                  <span># 显示宿主机、docker 的配置信息</span>\n          <span>df</span>                    <span># 显示各种 docker 对象占用的磁盘空间</span>\n          prune                 <span># 删除所有未被使用的 docker 对象</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br></div></div><ul>\n<li>例：<div><pre><code><span>docker</span> restart <span><span>`</span><span>docker</span> <span>ps</span> -aq<span>`</span></span>  <span># 重启所有容器</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>容器的生命周期：<div><pre><code>created           <span># 已创建。此时容器被 dockerd 分配了 CPU 、内存等资源，创建了根目录文件系统</span>\nrunning、up       <span># 运行中</span>\npaused            <span># 暂停运行。此时容器内所有进程依然存在，只是不再被 CPU 执行</span>\nexited、stopped   <span># 停止运行。此时容器内所有进程都退出，占用的 CPU、内存、文件描述符等资源被释放</span>\nrestart           <span># 重启。此时容器重新被分配资源，但依然使用之前的文件系统，重新执行启动命令</span>\ndelete            <span># 被删除。此时容器占用的资源被释放，文件系统也被删除。最终消失不见，在 dockerd 中不能查询到该容器</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"执行命令\"> 执行命令</h3>\n<div><pre><code><span>docker</span> <span>exec</span> <span>[</span>options<span>]</span> <span>&lt;</span>container<span>></span> <span>&lt;</span>command<span>></span>  <span># 在容器内执行一条命令</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>这样可以在宿主机上让容器执行命令，不必进入容器的终端。\n<ul>\n<li>该容器必须正在运行。</li>\n</ul>\n</li>\n<li>例：<div><pre><code><span>docker</span> <span>exec</span> -it centos1 <span>bash</span>    <span># 在容器内创建终端并进入</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"拷贝文件\"> 拷贝文件</h3>\n<div><pre><code><span>docker</span> <span>cp</span>   /root/f1                <span>&lt;</span>container<span>></span>:/root/    <span># 从宿主机拷贝文件到容器内</span>\n<span>docker</span> <span>cp</span>   <span>&lt;</span>container<span>></span>:/root/f1    /root/                <span># 从容器内拷贝文件到宿主机</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>拷贝当前目录时不能使用 <code>docker cp *</code> ，要使用 <code>docker cp .</code> ，默认会递归拷贝、拷贝文件权限。</li>\n</ul>\n<h2 id=\"日志\"> 日志</h2>\n<div><pre><code><span>docker</span> logs <span>&lt;</span>container<span>></span>   <span># 显示一个容器的日志</span>\n          -f              <span># 保持显示</span>\n          --tail <span>10</span>       <span># 只显示最后几行。默认从头开始显示</span>\n          -t              <span># 增加显示时间戳</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>dockerd 会记录容器内 1 号进程的 stdout、stderr ，作为该容器的日志。\n<ul>\n<li>将其它进程的输出重定向到 1 号进程的终端，就会一起记录到容器的日志中。如下：<div><pre><code><span>echo</span> Hello  <span><span>1</span>></span> /proc/1/fd/1  <span><span>2</span>></span> /proc/1/fd/2\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code><span>ln</span> -s  /proc/1/fd/1  stdout.log\n<span>echo</span> Hello       <span>&amp;></span>  stdout.log\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"日志驱动器\"> 日志驱动器</h3>\n<ul>\n<li>\n<p>日志驱动器（logging driver）：用于保存容器的日志。</p>\n<ul>\n<li>属于每个容器的独立配置。</li>\n</ul>\n</li>\n<li>\n<p>docker 支持多种日志驱动器：</p>\n<ul>\n<li>nong ：不保存日志。</li>\n<li>local\n<ul>\n<li>将日志按文本格式保存在宿主机的 <code>/var/lib/docker/containers/{ContainerId}/local-logs/container.log</code> 文件中。</li>\n<li>默认会自动进行日志切割， max-size 为 10m ，max-file 为 5 。</li>\n</ul>\n</li>\n<li>json-file\n<ul>\n<li>默认启用这种。</li>\n<li>将日志按 JSON 格式保存在宿主机的 <code>/var/lib/docker/containers/{ContainerId}/{ContainerId}-json.log</code> 文件中。如下：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># tail -n 1 /var/lib/docker/containers/3256c21887f9b110e84f0f4a620a2bf01a8a7b9e3a5c857e5cae53b22c5436d4/3256c21887f9b110e84f0f4a620a2bf01a8a7b9e3a5c857e5cae53b22c5436d4-json.log</span>\n<span>{</span><span>\"log\"</span><span>:</span><span>\"2021-02-22T03:16:15.807469Z 0 [Note] mysqld: ready for connections.<span title=\"\\n\">\\n</span>\"</span>,<span>\"stream\"</span><span>:</span><span>\"stderr\"</span>,<span>\"time\"</span><span>:</span><span>\"2021-02-22T03:16:15.80758596Z\"</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>使用 docker logs 命令查看日志时，只会显示其 log 字段的值。</li>\n</ul>\n</li>\n<li>默认不会进行日志切割， max-size 为 -1 即不限制大小，max-file 为 1 。</li>\n</ul>\n</li>\n<li>syslog  ：将日志保存到宿主机的 syslog 中。</li>\n<li>journald ：将日志保存到宿主机的 journald 中。</li>\n<li>fluentd ：将日志保存到 fluentd 服务中。</li>\n</ul>\n</li>\n<li>\n<p>每个容器只能选用一种日志驱动器。</p>\n<ul>\n<li>可以在 daemon.json 中配置日志驱动器。也可以在创建一个容器时，单独配置：<div><pre><code><span>docker</span> run -d <span>\\</span>\n      --log-driver json-file  <span>\\</span>\n      --log-opt max-size<span>=</span>100m <span>\\</span>\n      --log-opt max-file<span>=</span><span>3</span>    <span>\\</span>\n      nginx\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"网络\"> 网络</h2>\n<h3 id=\"网络驱动器\"> 网络驱动器</h3>\n<ul>\n<li>\n<p>网络驱动器（Network driver）：用于控制容器的网络连接。</p>\n<ul>\n<li>属于每个容器的独立配置。</li>\n<li>基于操作系统的底层网络工具来工作，比如 iptables 。</li>\n</ul>\n</li>\n<li>\n<p>docker 支持多种网络驱动器：</p>\n<ul>\n<li>none\n<ul>\n<li>：无网络，容器内只有一个环回网卡 lo ，因此不能访问到宿主机 ip 或其它容器 ip 。</li>\n</ul>\n</li>\n<li>host\n<ul>\n<li>：主机网络，让容器使用宿主机的网卡 eth 。</li>\n<li>此时容器内进程相当于直接部署在宿主机上，监听端口时是监听宿主机网卡 eth 上的 Socket 。</li>\n</ul>\n</li>\n<li>bridge\n<ul>\n<li>：桥接网络，默认采用。</li>\n<li>它表示一个虚拟子网，拥有一个子网 IP 池，由 dockerd 提供 DHCP 服务。</li>\n<li>它会在宿主机上创建一个虚拟网卡，命名格式为 <code>br-&lt;哈希值&gt;</code> 。</li>\n</ul>\n</li>\n<li>overlay\n<ul>\n<li>：用于 docker swarm ，连通多个主机的网络。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>每个容器可以同时加入多个 bridge 网络。</p>\n<ul>\n<li>当容器加入一个 bridge 网络时，会增加一个该子网的虚拟网卡，分配一个子网 IP 。</li>\n<li>当多个容器加入同一个 bridge 网络时，可通过子网 IP 相互通信。\n<ul>\n<li>此时每个容器拥有独立的虚拟网卡，相当于隔离的主机。dockerd 会自动配置 iptables 规则，实现路由转发。</li>\n<li>dockerd 还支持自动将容器名 DNS 解析为 ip ，但默认的 bridge 网络未开启该功能。</li>\n</ul>\n</li>\n<li>如果容器没有加入 bridge 网络，则不能访问到其它容器的 IP ，会报错：<code>No route to host</code></li>\n</ul>\n</li>\n<li>\n<p>在 bridge 网络中，容器与宿主机之间的网络连通性：</p>\n<ul>\n<li>从容器内可以访问到宿主机，比如 ping 宿主机的 IP 、其它主机的 IP 。</li>\n<li>从宿主机不能访问到容器内，比如 ping 容器的虚拟 IP 。\n<ul>\n<li>容器内进程监听端口时，是监听其虚拟网卡上的 Socket ，因此默认不能从容器外访问到该端口，除非映射端口。</li>\n</ul>\n</li>\n<li>允许容器内端口被宿主机访问的几种方案：\n<ul>\n<li>创建容器时，映射端口。</li>\n<li>让容器采用 host 网络。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"网络对象\"> 网络对象</h3>\n<div><pre><code><span>docker</span> network\n              <span>ls</span>                  <span># 显示所有的 docker 网络对象</span>\n              inspect <span>&lt;</span>network<span>></span>   <span># 查看一个网络的详细信息</span>\n              create  <span>&lt;</span>network<span>></span>   <span># 创建一个网络</span>\n                  -d bridge       <span># --dirver ，选择驱动器，默认为 bridge</span>\n                  --subnet  <span>172.17</span>.0.0/16   <span># 子网的范围。默认会给每个 network 创建一个独立子网</span>\n                  --gateway <span>172.17</span>.0.1      <span># 子网中的网关，这会添加到本机的路由表，可用 route 命令查看</span>\n              <span>rm</span>      <span>&lt;</span>network<span>></span>   <span># 删除一个网络</span>\n              prune               <span># 删除所有未被使用的网络</span>\n\n              connect     <span>&lt;</span>network<span>></span> <span>&lt;</span>container<span>></span>   <span># 将一个网络连接到指定容器</span>\n                  --ip    <span>&lt;</span>ip<span>></span>                    <span># 指定容器在该网络中的 IP 地址，默认会随机分配</span>\n                  --alias <span>&lt;</span>name<span>></span>                  <span># 给容器添加 DNS 名称，默认采用容器名</span>\n              disconnect  <span>&lt;</span>network<span>></span> <span>&lt;</span>container<span>></span>   <span># 取消连接</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><ul>\n<li>dockerd 安装之后会创建三个初始的 docker 网络：\n<ul>\n<li>bridge ：采用 bridge 驱动，会在宿主机上创建一个名为 docker0 的虚拟网卡。</li>\n<li>host ：采用 host 驱动。</li>\n<li>none ：采用 none 驱动。</li>\n</ul>\n</li>\n<li>新建一个容器时，默认的网络配置是 <code>docker run --network bridge</code> ，因此会加入初始的 bridge 网络，与 host 主机网络隔离。\n<ul>\n<li>用户可以创建其它 bridge 类型的网络，使多个容器的网络连通。</li>\n</ul>\n</li>\n</ul>\n<p>例：</p>\n<ol>\n<li>创建一个容器：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker run -it --rm --name test1 nginx bash</span>\nroot@16948ee51a84:/<span># ip addr            # 查看网卡，可见有一个环回网卡 lo 和虚拟网卡 eth0</span>\n<span>1</span>: lo: <span>&lt;</span>LOOPBACK,UP,LOWER_UP<span>></span> mtu <span>65536</span> qdisc noqueue state UNKNOWN group default qlen <span>1000</span>\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet <span>127.0</span>.0.1/8 scope <span>host</span> lo\n      valid_lft forever preferred_lft forever\n<span>3609</span>: eth0@if3610: <span>&lt;</span>BROADCAST,MULTICAST,UP,LOWER_UP<span>></span> mtu <span>1500</span> qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid <span>0</span>\n    inet <span>172.17</span>.0.2/16 brd <span>172.17</span>.255.255 scope global eth0\n      valid_lft forever preferred_lft forever\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n<li>按同样方法创建第二个容器：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker run -it --rm --name test1 nginx bash</span>\nroot@818dcf340ce3:/<span># ping 172.17.0.2    # 与容器 test1 的网络连通</span>\nPING <span>172.17</span>.0.2 <span>(</span><span>172.17</span>.0.2<span>)</span> <span>56</span><span>(</span><span>84</span><span>)</span> bytes of data.\n<span>64</span> bytes from <span>172.17</span>.0.2: <span>icmp_seq</span><span>=</span><span>1</span> <span>ttl</span><span>=</span><span>64</span> <span>time</span><span>=</span><span>0.088</span> ms\n<span>64</span> bytes from <span>172.17</span>.0.2: <span>icmp_seq</span><span>=</span><span>2</span> <span>ttl</span><span>=</span><span>64</span> <span>time</span><span>=</span><span>0.067</span> ms\nroot@818dcf340ce3:/<span># ping test1         # 容器只加入初始的 bridge 网络时，未开启 DNS 解析</span>\nping: test1: Name or <span>service</span> not known\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>创建一个网络，连接两个容器：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker network create bridge1</span>\n950323e01c9f2c862a712c4fda12e55dd5a9b4afd8d59993fe1adaf581e008b0\n<span>[</span>root@CentOS ~<span>]</span><span># docker network connect bridge1 test1</span>\n<span>[</span>root@CentOS ~<span>]</span><span># docker network connect bridge1 test2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>在第二个容器中测试：<div><pre><code>root@818dcf340ce3:/<span># ip addr      # 可见此时增加了一个虚拟网卡 eth1</span>\n<span>1</span>: lo: <span>&lt;</span>LOOPBACK,UP,LOWER_UP<span>></span> mtu <span>65536</span> qdisc noqueue state UNKNOWN group default qlen <span>1000</span>\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet <span>127.0</span>.0.1/8 scope <span>host</span> lo\n      valid_lft forever preferred_lft forever\n<span>3611</span>: eth0@if3612: <span>&lt;</span>BROADCAST,MULTICAST,UP,LOWER_UP<span>></span> mtu <span>1500</span> qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid <span>0</span>\n    inet <span>172.17</span>.0.3/16 brd <span>172.17</span>.255.255 scope global eth0\n      valid_lft forever preferred_lft forever\n<span>3616</span>: eth1@if3617: <span>&lt;</span>BROADCAST,MULTICAST,UP,LOWER_UP<span>></span> mtu <span>1500</span> qdisc noqueue state UP group default\n    link/ether 02:42:c0:a8:70:03 brd ff:ff:ff:ff:ff:ff link-netnsid <span>0</span>\n    inet <span>192.168</span>.112.3/20 brd <span>192.168</span>.127.255 scope global eth1\n      valid_lft forever preferred_lft forever\nroot@818dcf340ce3:/<span># ping test1   # 此时支持将容器名 DNS 解析到对应虚拟网卡的 IP</span>\nPING test1 <span>(</span><span>192.168</span>.112.2<span>)</span> <span>56</span><span>(</span><span>84</span><span>)</span> bytes of data.\n<span>64</span> bytes from test1.bridge1 <span>(</span><span>192.168</span>.112.2<span>)</span>: <span>icmp_seq</span><span>=</span><span>1</span> <span>ttl</span><span>=</span><span>64</span> <span>time</span><span>=</span><span>0.054</span> ms\n<span>64</span> bytes from test1.bridge1 <span>(</span><span>192.168</span>.112.2<span>)</span>: <span>icmp_seq</span><span>=</span><span>2</span> <span>ttl</span><span>=</span><span>64</span> <span>time</span><span>=</span><span>0.048</span> ms\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div></li>\n</ol>\n<h3 id=\"网络配置\"> 网络配置</h3>\n<div><pre><code><span>docker</span> run\n          -p <span>80</span>:8080                  <span># 将宿主机的 80 端口映射到容器的 8000 端口（可重复使用该命令选项），默认是指 TCP 端口</span>\n          -p <span>80</span>:8080/udp              <span># 映射 UDP 端口</span>\n          -p <span>127.0</span>.0.1:80:8080        <span># 映射宿主机指定网卡的端口</span>\n          -P                          <span># 从宿主机上随机选取端口，映射到容器 EXPOSE 声明的所有端口</span>\n\n          --network <span>&lt;</span>network<span>></span>         <span># 让容器加入指定的 docker 网络（启用该命令选项时，-p 选项会失效）</span>\n          --network container:<span>&lt;</span>name<span>></span>  <span># 让容器共用指定容器的网卡</span>\n          --link <span>&lt;</span>container<span>></span><span>[</span>:alias<span>]</span>  <span># 将当前容器通过网络连接到另一个容器，需要两个容器都加入初始的 bridge 网络。可选添加目标容器的别名，支持 DNS 解析</span>\n\n          --dns <span>&lt;</span>ip<span>></span>                  <span># 设置容器的 DNS 服务器</span>\n          --mac-address <span>&lt;</span>string<span>></span>      <span># 设置容器的 MAC 地址。默认会根据容器 IP 自动生成</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>创建容器时，默认会继承宿主机的 DNS 配置，比如 /etc/resolv.conf ，但不包括 /etc/hosts 。\n<ul>\n<li>会自动将容器内主机名添加到容器内 /etc/hosts 中。</li>\n</ul>\n</li>\n<li>映射端口时，dockerd 会自动添加 iptables 规则，将宿主机的 src_port 收到的网络包转发到容器的 dst_port 。\n<ul>\n<li>此时宿主机的防火墙会暴露 src_port 端口，允许被任意外部 IP 访问。</li>\n<li>这样自动添加的 iptables 规则很复杂，建议不要手动修改，容易出错。\n<ul>\n<li>比如启动、停止 firewalld.service 时，会导致 dockerd 的 iptables 规则出错。</li>\n<li>如果出错，可以尝试重启 dockerd ，让它重新配置 iptables 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>例：</p>\n<ol>\n<li>创建两个容器<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker run -d --name test1 --network host nginx</span>\n9c1c537e8a304ad9e4244e3c7ae1743b88d45924b7b48cbb0a9f63606c82d76d\n<span>[</span>root@CentOS ~<span>]</span><span># docker run -d --name test2 -p 2080:80 nginx</span>\n4601a81b438e31e5cb371291e1299e4c5333e853a956baeb629443774a066e9c\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>在宿主机上可以访问容器的端口：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># curl -I 10.0.0.1:80      # test1 容器使用宿主机的网卡，因此能访问到</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># curl -I 10.0.0.1:2080    # test2 容器的端口已经映射到宿主机的网卡，因此能访问到</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div>还可以通过环回地址访问容器的端口：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># curl -I 127.0.0.1:80</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># curl -I 127.0.0.1:2080</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>在容器内可以访问宿主机上的任意端口：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test1 curl -I 10.0.0.1:80</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test1 curl -I 10.0.0.1:2080</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test2 curl -I 10.0.0.1:80</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test2 curl -I 10.0.0.1:2080</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n<li>在容器内访问环回地址的端口：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test1 curl -I 127.0.0.1:80</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test1 curl -I 127.0.0.1:2080</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test2 curl -I 127.0.0.1:80</span>\nHTTP/1.1 <span>200</span> OK\n<span>..</span>.\n<span>[</span>root@CentOS ~<span>]</span><span># docker exec -it test2 curl -I 127.0.0.1:2080   # test2 容器的网卡上没有监听 2080 端口，因此不能访问</span>\ncurl: <span>(</span><span>7</span><span>)</span> Failed to connect to <span>127.0</span>.0.1 port <span>2080</span>: Connection refused\n<span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ol>\n<h2 id=\"存储\"> 存储</h2>\n<ul>\n<li>删除容器时，其 top layer 也会被删除，因此容器内产生的数据都会丢失。</li>\n<li>持久化存储容器内数据的几种方案：\n<ul>\n<li>让容器内进程，主动将数据发送到容器外，比如数据库中。</li>\n<li>bind mount ：在创建容器时，将宿主机的文件、目录挂载到容器中某个路径。\n<ul>\n<li>挂载的文件、目录实际存储在宿主机上，而不是容器的 top layer 中，因此删除容器也不会影响。</li>\n</ul>\n</li>\n<li>volume mount ：挂载数据卷到容器中某个路径。\n<ul>\n<li>与 bind mounts 类似，但更容易迁移到其它主机。</li>\n<li>同一个文件、目录或数据卷可以被多个容器同时挂载。</li>\n</ul>\n</li>\n<li>tmpfs mount ：将数据临时保存在内存中。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"存储驱动器\"> 存储驱动器</h3>\n<ul>\n<li>存储驱动器（storage driver）：用于控制容器对 layer 的读写。\n<ul>\n<li>属于每个容器的独立配置。</li>\n</ul>\n</li>\n<li>docker 支持多种存储驱动器：\n<ul>\n<li>aufs</li>\n<li>fuse-overlayfs</li>\n<li>overlay2 ：默认采用，取代旧版的 overlay 。</li>\n<li>zfs</li>\n</ul>\n</li>\n<li>与容器的存储驱动器不同，数据卷的驱动器默认为 local ，表示存储在本机。</li>\n</ul>\n<h3 id=\"挂载\"> 挂载</h3>\n<div><pre><code><span>docker</span> run\n          -v <span>&lt;</span>src_path<span>></span>:<span>&lt;</span>dst_path<span>></span><span>[</span>:mode<span>]</span>       <span># --volume ，将宿主机的文件、目录或数据卷挂载到容器的 dst_path 路径（可重复使用该命令选项）</span>\n\n          --mount <span>type</span><span>=</span>bind,src<span>=</span>/tmp,dst<span>=</span>/tmp   <span># --mount 的配置比 --volume 更详细，支持传入多个键值对形式的配置参数，用逗号分隔</span>\n          --mount <span>type</span><span>=</span>volume,src<span>=</span>volume_1,dst<span>=</span>/tmp,volume-driver<span>=</span>local,ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>\n<p>挂载时，src_path 有多种形式：</p>\n<ul>\n<li>如果为绝对路径，则视作一个宿主机路径。例如 <code>/tmp:/tmp</code> 。\n<ul>\n<li>如果该绝对路径不存在，则会自动在宿主机上创建一个该路径的目录，所有权为 root 用户，然后挂载。</li>\n</ul>\n</li>\n<li>如果为相对路径，则报错不支持。例如 <code>./tmp:/tmp</code> 。</li>\n<li>如果无路径，则视作一个数据卷的名称。 。\n<ul>\n<li>如果该数据卷不存在，则 dockerd 会自动在宿主机的 <code>/var/lib/docker/volumes/&lt;volumeID&gt;/</code> 目录下创建一个 _data 目录，作为数据卷，挂载到容器中。\n<ul>\n<li>还会自动给 _data 目录分配合适的文件权限，供容器内进程访问。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>如果为空，则会自动创建一个匿名的数据卷。例如 <code>:/tmp</code> 。\n<ul>\n<li>用 docker inspect 命令可查看匿名卷的实际路径。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>挂载宿主机的文件时，注意 docker 基于 inode 来挂载文件。在宿主机上用 vi/vim 修改被挂载文件时，会生成一个新 inode 的文件，而容器内依然挂载原 inode 的文件。</p>\n<ul>\n<li>可通过以下方式更新挂载文件：\n<ul>\n<li>通过 <code>cat f1.tmp &gt; f1</code> 的方式修改文件。</li>\n<li>重启容器，使其自动重新挂载文件。</li>\n<li>改为挂载目录，在目录中修改文件。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>挂载的文件、目录的所有权依然采用宿主机上的 uid、gid ，容器内使用非 root 用户时，可能对挂载路径没有访问权限。</p>\n<ul>\n<li>此时需要先在宿主机上调整挂载路径的权限，比如 <code>chown -R &lt;UID&gt; &lt;PATH&gt;</code> 。</li>\n<li>可以在挂载时限制访问权限 mode ：<div><pre><code>-v /etc/localtime:/etc/localtime:rw  <span># 允许读写（默认采用）</span>\n:ro     <span># 只允许读取</span>\n:z      <span># 添加 selinux 标签，将数据卷标记为会被多个容器共享</span>\n:Z      <span># 添加 selinux 标签，将数据卷标记为不会被其它容器共享</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>一些经常挂载的宿主机文件：</p>\n<div><pre><code>/etc/hosts\n/etc/passwd             <span># 让容器采用宿主机的用户名、uid</span>\n/etc/localtime          <span># 让容器内采用与宿主机相同的时区，不过有的容器不会读取该文件</span>\n/var/run/docker.sock    <span># 允许在容器内与 dockerd 通信，可以执行 docker ps 等命令</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"数据卷\"> 数据卷</h3>\n<div><pre><code><span>docker</span> volume\n            <span>ls</span>                <span># 显示所有的数据卷</span>\n            inspect <span>&lt;</span>volume<span>></span>  <span># 查看数据卷的详细信息</span>\n            create  <span>&lt;</span>volume<span>></span>  <span># 创建一个数据卷</span>\n                -d <span>local</span>      <span># --dirver ，选择驱动器，默认为 local</span>\n            <span>rm</span>      <span>&lt;</span>volume<span>></span>  <span># 删除一个数据卷</span>\n            prune             <span># 删除所有未使用的数据卷</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Docker",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/",
      "id": "/Hardware/DevOps/Container/Docker/",
      "content_html": "<h1 id=\"docker\"> Docker</h1>\n<p>：一个管理镜像、容器的软件。</p>\n<ul>\n<li><a href=\"https://docs.docker.com/reference/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Golang 开发，在 Moby 项目中开源。</li>\n<li>提供了用于 Linux、MacOS、Windows 系统的软件安装包。</li>\n</ul>\n<h2 id=\"安装\"> 安装</h2>\n<ul>\n<li>\n<p>在 CentOS 上安装：</p>\n<div><pre><code>yum <span>install</span> -y yum-utils       <span># 安装 yum-config-manager</span>\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo   <span># 添加 docker 的官方镜像源</span>\nyum <span>install</span> -y docker-ce      <span># 下载 docker 社区版</span>\nsystemctl start <span>docker</span>        <span># 启动 dockerd</span>\nsystemctl <span>enable</span> <span>docker</span>       <span># 使 dockerd 开机自启</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<p>在 ubuntu 上，可以用官方脚本自动安装：</p>\n<div><pre><code><span>curl</span> -fsSL https://get.docker.com <span>|</span> <span>bash</span> -s <span>docker</span> --mirror Aliyun\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"版本\"> 版本</h3>\n<ul>\n<li>2017 年 3 月，Docker 的软件版本号从 v1.13 升级到 17.03 ，从数字编号改为日期格式。并且分为两种发行版：\n<ul>\n<li>Docker CE ：社区版（Community Edition），免费提供。</li>\n<li>Docker EE ：企业版（Enterprise Edition），增加了一些收费的功能。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>dockerd 的配置文件默认位于 <code>/etc/docker/daemon.json</code> ，且默认未创建。内容示例：</p>\n<div><pre><code><span>{</span>\n  <span>// dockerd 配置</span>\n  <span>// \"containerd\": \"/run/containerd/containerd.sock\",</span>\n  <span>// \"containerd-namespace\": \"docker\",</span>\n  <span>// \"data-root\": \"/var/lib/docker\",        // dockerd 的数据目录</span>\n  <span>// \"debug\": false,                        // 是否开启调试模式</span>\n  <span>// \"exec-root\": \"/var/run/docker\",        // dockerd 的工作目录</span>\n  <span>\"insecure-registries\"</span> <span>:</span> <span>[</span><span>\"10.0.0.1:80\"</span><span>]</span><span>,</span>  <span>// dockerd 默认以 HTTPS 方式访问镜像仓库服务器。如果服务器不支持 SSL 认证，则需要将其地址加入白名单</span>\n  <span>\"live-restore\"</span><span>:</span> <span>true</span><span>,</span>                     <span>// 当 dockerd 终止时，是否保持容器运行。默认为 false ，建议启用，方便重启 dockerd</span>\n  <span>// \"oom-score-adjust\": -500,              // dockerd 的 oom_score_adj</span>\n  <span>// \"selinux-enabled\": false,</span>\n  <span>\"registry-mirrors\"</span><span>:</span> <span>[</span>           <span>// docker 默认采用官方镜像仓库 docker.io ，这里可添加对该仓库的镜像代理，需要部署官方 registry 服务器。只能 pull 不能 push ，不支持代理第三方仓库</span>\n      <span>\"https://harbor.test.com\"</span>\n  <span>]</span><span>,</span>\n\n  <span>// 网络配置</span>\n  <span>// \"bridge\": \"bridge\",          // 新建容器时采用的 docker network 。默认为 bridge ，改为 none 则无网络</span>\n  <span>\"default-address-pools\"</span><span>:</span> <span>[</span>      <span>// docker network 的子网范围，默认为 172.[17-31].0.0/16 和 192.168.[0-240].0/20</span>\n    <span>{</span>\n      <span>\"base\"</span><span>:</span> <span>\"172.20.0.0/16\"</span><span>,</span>    <span>// 可在该范围创建子网，比如 172.20.0.0/24、172.20.1.0/24</span>\n      <span>\"size\"</span><span>:</span> <span>24</span>                  <span>// 子网掩码的长度，增加其值有利于创建更多子网</span>\n    <span>}</span>\n  <span>]</span><span>,</span>\n  <span>// \"ip-forward\": true,          // 是否开启 net.ipv4.ip_forward</span>\n  <span>// \"ip-masq\": true,             // 是否自动配置 iptables 规则来实现 masquerade ，使得只有私有 IP 的容器能够与其它主机通信</span>\n  <span>// \"iptables\": true,            // 是否允许 dockerd 自动配置 iptables 规则来维护容器网络</span>\n\n  <span>// 创建容器时的默认配置。修改这些配置不会影响已创建的容器，只会影响到新创建的容器</span>\n  <span>// \"default-runtime\": \"runc\",</span>\n  <span>// \"default-shm-size\": \"64M\",</span>\n  <span>// \"default-ulimits\": {</span>\n  <span>//   \"nofile\": {</span>\n  <span>//     \"Name\": \"nofile\",</span>\n  <span>//     \"Hard\": 64000,</span>\n  <span>//     \"Soft\": 64000</span>\n  <span>//   }</span>\n  <span>// },</span>\n  <span>// \"dns\": [\"8.8.8.8\"],          // 容器默认的 DNS 服务器</span>\n  <span>\"log-driver\"</span><span>:</span> <span>\"json-file\"</span><span>,</span>      <span>// 设置日志驱动器的类型，默认为 json-file</span>\n  <span>\"log-opts\"</span><span>:</span> <span>{</span>\n    <span>\"max-size\"</span><span>:</span> <span>\"100m\"</span>            <span>// 日志文件的最大大小。超过该大小则滚动一次，创建一个新日志文件继续写入</span>\n    <span>\"max-file\"</span><span>:</span> <span>\"1\"</span>               <span>// 最多保留多少份日志文件。即使只保留 1 份，每次滚动时也会创建一个新日志文件</span>\n  <span>}</span><span>,</span>\n  <span>// \"shutdown-timeout\": 15,      // 停止容器时的超时时间</span>\n\n  <span>// 是否启用可选功能</span>\n  <span>// \"features\": {</span>\n  <span>//     \"buildkit\": false</span>\n  <span>// }</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br></div></div><ul>\n<li>修改配置之后，需要重启 dockerd 。</li>\n</ul>\n</li>\n<li>\n<p>docker 命令的配置文件存放在 <code>$HOME/.docker/</code> 目录下。</p>\n</li>\n<li>\n<p>如果想让 dockerd 使用代理，需要在 <code>/usr/lib/systemd/system/docker.service</code> 中加入环境变量：</p>\n<div><pre><code><span>[</span>Service<span>]</span>\n<span>Environment</span><span>=</span><span>\"HTTP_PROXY=socks5://10.0.0.1:1080\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>然后重启 dockerd ：</p>\n<div><pre><code>systemctl daemon-reload\nsystemctl restart <span>docker</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>同理，也可以在容器内添加环境变量 HTTP_PROXY ，一些容器内应用支持通过这种方式配置代理。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "镜像",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/Docker/mirror.html",
      "id": "/Hardware/DevOps/Container/Docker/mirror.html",
      "content_html": "<h1 id=\"镜像\"> 镜像</h1>\n<h2 id=\"标识符\"> 标识符</h2>\n<ul>\n<li>\n<p>每个 Docker 镜像有三种标识符：</p>\n<ul>\n<li><code>&lt;image_id&gt;</code> ：取自其十六进制哈希值的开头 n 位。\n<ul>\n<li>因为未指定完整的哈希值，只能用于在本机标识镜像，不能在 pull、push 时标识镜像。</li>\n</ul>\n</li>\n<li><code>&lt;image&gt;@&lt;digest&gt;</code> ：镜像名加完整的哈希值。\n<ul>\n<li>默认采用 SHA256 哈希算法，因此 <code>&lt;digest&gt;</code> 格式为 <code>sha256:&lt;hash&gt;</code> 。</li>\n</ul>\n</li>\n<li><code>&lt;image&gt;[:tag]</code> ：镜像名加标签，由用户自定义。\n<ul>\n<li>tag 通常用于表示镜像的版本号。</li>\n<li>省略 tag 时，默认取值为 latest 。\n<ul>\n<li>制作镜像时，通常将 latest 标签指向最新一个版本，便于用户拉取。</li>\n<li>正式使用时，建议不要拉取镜像的 latest 版本，否则在不同时间拉取的 latest 版本可能不同。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>悬空镜像（dangling images）：一些只有 ID 的镜像，没有镜像名和标签，而是名为 <code>&lt;none&gt;:&lt;none&gt;</code> 。</p>\n</li>\n</ul>\n<h2 id=\"查看\"> 查看</h2>\n<div><pre><code><span>docker</span>\n      image\n            <span>ls</span>                <span># 显示本机的镜像（默认不显示悬空镜像）。可简写为 docker images 命令</span>\n                -a            <span># 显示所有的镜像</span>\n            <span>history</span> <span>&lt;</span>image<span>></span>   <span># 显示镜像的构建步骤（按时间倒序排列），包含每个步骤增加的 layer 大小</span>\n                --no-trunc\n\n            <span>rm</span> <span>&lt;</span>image<span>></span><span>..</span>.     <span># 删除本机的镜像（只能删除未被容器使用的），可简写为 docker rmi 命令</span>\n            prune             <span># 删除所有悬空镜像</span>\n                -a            <span># 删除所有未被容器使用的镜像</span>\n\n      tag <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span> <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span> <span># 给镜像添加另一个镜像名和标签。如果已有镜像占用目标标签，则将其标签改为 &lt;none></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><h2 id=\"拉取\"> 拉取</h2>\n<div><pre><code><span>docker</span>\n      pull    <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span>         <span># 从镜像仓库拉取镜像，即下载镜像</span>\n          --platform <span>&lt;</span>os/arch<span>></span>      <span># 拉取指定平台的镜像。默认只拉取匹配本机操作系统的镜像</span>\n      push    <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span>         <span># 推送镜像到镜像仓库</span>\n      search  <span>&lt;</span>image<span>></span>               <span># 在远程镜像仓库中搜索某个镜像</span>\n      login  <span>&lt;</span>domain<span>></span>               <span># 登录一个镜像仓库。登录凭证会保存在 $HOME/.docker/config.json 中</span>\n          -u <span>&lt;</span>username<span>></span>\n          -p <span>&lt;</span>password<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>\n<p>例：</p>\n<div><pre><code><span>docker</span> pull nginx:1.20              <span># 拉取镜像</span>\n<span>docker</span> pull nginx                   <span># 相当于 docker pull nginx:latest</span>\n<span>docker</span> tag  nginx:1.20 nginx:test   <span># 添加标签</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>例：拉取镜像的过程</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker pull nginx:1.20</span>\n<span>1.20</span>: Pulling from library/nginx            <span># 开始从镜像仓库拉取镜像</span>\ne5ae68f74026: Pull complete                 <span># 拉取镜像中的一个 layer ，如果本机已存在则不会拉取</span>\n2dc3587e7d0c: Pull complete\nb8258363a4a3: Pull complete\n963807cfb489: Pull complete\n5faf54adf667: Pull complete\n07bd53fd2d21: Pull complete\nDigest: sha256:71a1217d769cbfb5640732263f81d74e853f101b7f2b20fcce991a22e68adbc7   <span># 检验整个镜像的哈希值</span>\nStatus: Downloaded newer image <span>for</span> nginx:1.20\ndocker.io/library/nginx:1.20\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>拉取每个 layer 时，分为多个步骤：<div><pre><code>Downloading           <span># 下载 layer 的压缩包</span>\nDownload complete     <span># 下载完毕</span>\nExtracting            <span># 解压 layer 并导入，存储在宿主机上</span>\nPull complete         <span># 拉取完毕</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>可以将宿主机上存储的 docker 镜像，推送到镜像仓库服务器进行存储。</p>\n<ul>\n<li>默认采用官方镜像仓库 docker.io ，允许未登录用户 pull 公开镜像。\n<ul>\n<li>官方还提供了 Web 页面 hub.docker.com ，用于搜索镜像。</li>\n<li>用户也可以自己部署仓库服务器，比如 harbor 。</li>\n</ul>\n</li>\n<li>为了区分不同的镜像仓库，需要在镜像名的前面加上仓库地址：<div><pre><code><span>docker</span> pull harbor.test.com/project1/nginx   <span># 使用指定的镜像仓库，格式为 &lt;仓库域名>/&lt;命名空间>/&lt;镜像名></span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>默认采用官方镜像仓库 docker.io 的 library 命名空间中的镜像，因此以下三种写法的指向相同：<div><pre><code><span>docker</span> pull nginx\n<span>docker</span> pull docker.io/nginx\n<span>docker</span> pull docker.io/library/nginx\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"导出\"> 导出</h2>\n<ul>\n<li>Docker 镜像由一组 layer 和配置文件组成，在宿主机上存储为一些零散文件，可以用以下命令导出：<div><pre><code><span>docker</span> save -o image.tar <span>&lt;</span>image<span>></span><span>..</span>.         <span># 将镜像打包成 tar 格式</span>\n<span>docker</span> save <span>&lt;</span>image<span>></span><span>..</span>. <span>|</span> <span>gzip</span> <span>></span> image.tgz   <span># 打包并压缩，大概压缩到 40% 大小</span>\n\n<span>docker</span> load -i image.tar                    <span># 导入镜像</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>例：<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># docker save -o nginx.tar nginx:latest</span>\n<span>[</span>root@CentOS ~<span>]</span><span># ls -lh</span>\ntotal 131M\n-rw-------. <span>1</span> root root 131M Mar <span>28</span> <span>16</span>:04 nginx.tar\n<span>[</span>root@CentOS ~<span>]</span><span># tar -tf nginx.tar</span>\n28d499c51144128e64b6ffefa6c714bbfaf3e55772b080d1b0636f1971cb3203/           <span># 每个目录对应一层 layer 。目录名是此时导出文件的哈希值，并不等于 layer.tar 的哈希值</span>\n28d499c51144128e64b6ffefa6c714bbfaf3e55772b080d1b0636f1971cb3203/VERSION    <span># 该 layer 的格式规范，目前为 1.0</span>\n28d499c51144128e64b6ffefa6c714bbfaf3e55772b080d1b0636f1971cb3203/json       <span># 该 layer 的配置文件，记录了其 id、父级 layer 的 id、构建时的 container_config</span>\n28d499c51144128e64b6ffefa6c714bbfaf3e55772b080d1b0636f1971cb3203/layer.tar  <span># 该 layer 包含的所有文件</span>\n40aef34ac16b8c7eee6da1869452f5c9b9963ab583415d4999565738c719ded9/\n40aef34ac16b8c7eee6da1869452f5c9b9963ab583415d4999565738c719ded9/VERSION\n40aef34ac16b8c7eee6da1869452f5c9b9963ab583415d4999565738c719ded9/json\n40aef34ac16b8c7eee6da1869452f5c9b9963ab583415d4999565738c719ded9/layer.tar\n456351a127e9a9ce4cc79f7f6ad9f401d1714e514780f1603fa0b263119e329b/\n456351a127e9a9ce4cc79f7f6ad9f401d1714e514780f1603fa0b263119e329b/VERSION\n456351a127e9a9ce4cc79f7f6ad9f401d1714e514780f1603fa0b263119e329b/json\n456351a127e9a9ce4cc79f7f6ad9f401d1714e514780f1603fa0b263119e329b/layer.tar\n9000127bc2e7878a10491bb7a16a4b5874e4bdf6a01952d14211fad55defdd0a/\n9000127bc2e7878a10491bb7a16a4b5874e4bdf6a01952d14211fad55defdd0a/VERSION\n9000127bc2e7878a10491bb7a16a4b5874e4bdf6a01952d14211fad55defdd0a/json\n9000127bc2e7878a10491bb7a16a4b5874e4bdf6a01952d14211fad55defdd0a/layer.tar\nb526b761d738d1fba0774ea5af56ae1e664c812c6ce75743d74773cb3867bf7b/\nb526b761d738d1fba0774ea5af56ae1e664c812c6ce75743d74773cb3867bf7b/VERSION\nb526b761d738d1fba0774ea5af56ae1e664c812c6ce75743d74773cb3867bf7b/json\nb526b761d738d1fba0774ea5af56ae1e664c812c6ce75743d74773cb3867bf7b/layer.tar\nb8cf2cbeabb915843204ceb7ef0055fecadd55c2b0c58ac030e01fe75235885a.json       <span># 一个以镜像哈希值为名的 JSON 文件，记录该镜像的详细配置</span>\nc0b073121bb2a6106dae6af85ade7274253f26626661e6e3cb20b0fa7fb59475/\nc0b073121bb2a6106dae6af85ade7274253f26626661e6e3cb20b0fa7fb59475/VERSION\nc0b073121bb2a6106dae6af85ade7274253f26626661e6e3cb20b0fa7fb59475/json\nc0b073121bb2a6106dae6af85ade7274253f26626661e6e3cb20b0fa7fb59475/layer.tar\nmanifest.json                                                               <span># 镜像的内容清单，记录了镜像名、tag、JSON 配置文件的路径、各个 layer 的路径</span>\nrepositories\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>docker pull 命令会根据 manifest.json 文件拉取镜像的各个 layer 。如果本机已存在，则不必下载。</li>\n<li>JSON 配置文件的内容示例：<div><pre><code><span>{</span>\n  <span>\"architecture\"</span><span>:</span> <span>\"amd64\"</span><span>,</span>\n  <span>\"config\"</span><span>:</span> <span>{</span>                   <span>// 记录该镜像的配置，主要由 Dockerfile 决定</span>\n    <span>\"Hostname\"</span><span>:</span> <span>\"\"</span><span>,</span>\n    <span>\"Domainname\"</span><span>:</span> <span>\"\"</span><span>,</span>\n    <span>\"User\"</span><span>:</span> <span>\"\"</span><span>,</span>\n    <span>\"AttachStdin\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"AttachStdout\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"AttachStderr\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"ExposedPorts\"</span><span>:</span> <span>{</span>\n      <span>\"80/tcp\"</span><span>:</span> <span>{</span><span>}</span>\n    <span>}</span><span>,</span>\n    <span>\"Tty\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"OpenStdin\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"StdinOnce\"</span><span>:</span> <span>false</span><span>,</span>\n    <span>\"Env\"</span><span>:</span> <span>[</span><span>\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"</span><span>,</span> <span>\"NGINX_VERSION=1.20.2\"</span><span>,</span> <span>\"NJS_VERSION=0.7.0\"</span><span>,</span> <span>\"PKG_RELEASE=1~bullseye\"</span><span>]</span><span>,</span>\n    <span>\"Cmd\"</span><span>:</span> <span>[</span><span>\"nginx\"</span><span>,</span> <span>\"-g\"</span><span>,</span> <span>\"daemon off;\"</span><span>]</span><span>,</span>\n    <span>\"Image\"</span><span>:</span> <span>\"sha256:8e9a1b312fca0584850ce522438997f952010118d95f408add7eed34b8a2462d\"</span><span>,</span>\n    <span>\"Volumes\"</span><span>:</span> <span>null</span><span>,</span>\n    <span>\"WorkingDir\"</span><span>:</span> <span>\"\"</span><span>,</span>\n    <span>\"Entrypoint\"</span><span>:</span> <span>[</span><span>\"/docker-entrypoint.sh\"</span><span>]</span><span>,</span>\n    <span>\"OnBuild\"</span><span>:</span> <span>null</span><span>,</span>\n    <span>\"Labels\"</span><span>:</span> <span>{</span>\n      <span>\"maintainer\"</span><span>:</span> <span>\"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\"</span>\n    <span>}</span><span>,</span>\n    <span>\"StopSignal\"</span><span>:</span> <span>\"SIGQUIT\"</span>\n  <span>}</span><span>,</span>\n  <span>\"container\"</span><span>:</span> <span>\"d9a5e6a8c2e78750b6e1cf3e1c62542d0d9bac5e5d714744a652974b20b3f987\"</span><span>,</span>    <span>// 记录构建镜像时的最后一个中间容器</span>\n  <span>\"container_config\"</span><span>:</span> <span>{</span>\n    <span>\"Hostname\"</span><span>:</span> <span>\"d9a5e6a8c2e7\"</span><span>,</span>\n    ...\n  <span>}</span><span>,</span>\n  <span>\"history\"</span><span>:</span> <span>[</span><span>{</span>       <span>// 记录该镜像的构建步骤，按时间顺序排列</span>\n    <span>\"created\"</span><span>:</span> <span>\"2021-11-17T02:20:41.91188934Z\"</span><span>,</span>\n    <span>\"created_by\"</span><span>:</span> <span>\"/bin/sh -c #(nop) ADD file:a2405ebb9892d98be2eb585f6121864d12b3fd983ebf15e5f0b7486e106a79c6 in / \"</span>\n  <span>}</span><span>,</span> ...\n  <span>{</span>\n    <span>\"created\"</span><span>:</span> <span>\"2021-11-17T10:39:44.423437008Z\"</span><span>,</span>\n    <span>\"created_by\"</span><span>:</span> <span>\"/bin/sh -c #(nop)  CMD [\\\"nginx\\\" \\\"-g\\\" \\\"daemon off;\\\"]\"</span><span>,</span>\n    <span>\"empty_layer\"</span><span>:</span> <span>true</span>\n  <span>}</span><span>]</span><span>,</span>\n  <span>\"os\"</span><span>:</span> <span>\"linux\"</span><span>,</span>\n  <span>\"rootfs\"</span><span>:</span> <span>{</span>         <span>// 记录组成该镜像的各个 layer 的哈希值。创建容器时需要按先后顺序载入这些 layer ，生成 RootFS 文件系统</span>\n    <span>\"type\"</span><span>:</span> <span>\"layers\"</span><span>,</span>\n    <span>\"diff_ids\"</span><span>:</span> <span>[</span><span>\"sha256:e1bbcf243d0e7387fbfe5116a485426f90d3ddeb0b1738dca4e3502b6743b325\"</span><span>,</span> <span>\"sha256:72e7342f59d8d99e69f1a39796e9023fee99f2b9c72bfe75cd7cc8c86b43c918\"</span><span>,</span> ...<span>]</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"制作\"> 制作</h2>\n<p>Docker 镜像主要有两种制作方式：</p>\n<ul>\n<li>\n<p>将一个容器提交为镜像：</p>\n<div><pre><code><span>docker</span> commit <span>&lt;</span>container<span>></span> <span>&lt;</span>image<span>></span><span>[</span>:tag<span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>每次 commit 时，会在原镜像外部加上一层新的 layer 。因此 commit 次数越多，镜像的体积越大。</li>\n</ul>\n</li>\n<li>\n<p>编写 Dockerfile 文件，然后根据它构建镜像。</p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "容器",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/",
      "id": "/Hardware/DevOps/Container/",
      "content_html": "<h1 id=\"容器\"> 容器</h1>\n<p>运行多个进程时，隔离它们的运行环境有利于管理。常见的几种隔离方式：</p>\n<ul>\n<li>运行多个物理主机\n<ul>\n<li>缺点：冗余大，不方便通过软件管理</li>\n</ul>\n</li>\n<li>在物理机上运行多个虚拟机</li>\n<li>在主机上运行多个容器，每个容器内包含一组进程</li>\n</ul>\n<h2 id=\"虚拟机\"> 虚拟机</h2>\n<p>：Hypervisor ，又称为 VMM（Virtual Machine Monitor ，虚拟机监视器）</p>\n<ul>\n<li>原理：\n<ul>\n<li>在计算机硬件与操作系统之间隔离出一个中间层，用于运行虚拟化的操作系统。</li>\n</ul>\n</li>\n<li>优点：\n<ul>\n<li>实现了对整个操作系统的隔离。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>重量级\n<ul>\n<li>运行虚拟机软件，大概消耗 10% 的系统资源。</li>\n<li>每个虚拟机要运行一个完整的操作系统，但应用程序一般只需要用到其中少量的功能服务、系统资源，因此冗余较多。</li>\n<li>部署一个应用程序时，需要先创建一个虚拟机、安装操作系统，再配置运行环境、拷贝应用程序，耗时为几小时。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>创建虚拟机的软件举例：\n<ul>\n<li>Xen\n<ul>\n<li>2003 年发布。</li>\n</ul>\n</li>\n<li>OpenVZ\n<ul>\n<li>2005 年发布。</li>\n<li>在底层操作系统上运行多个虚拟操作系统，共用一个内核。</li>\n<li>只支持 Linux 系统。</li>\n</ul>\n</li>\n<li>KVM（Kernel-based Virtual Machine）\n<ul>\n<li>2006 年发布。</li>\n<li>每个虚拟操作系统使用一个独立的内核，因此可采用不同的操作系统。</li>\n<li>OpenVZ 属于半虚拟化，而 KVM 属于全虚拟化，开销更大。</li>\n</ul>\n</li>\n<li>VirtualBox</li>\n<li>VMwareWorkstation</li>\n<li>Windows Hyper-V</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"容器-2\"> 容器</h2>\n<p>：Container ，新一代的虚拟化技术。</p>\n<ul>\n<li>原理：\n<ul>\n<li>在应用程序与操作系统之间隔离出一个中间层，用于运行容器。</li>\n<li>以镜像作为模板，在主机上创建容器并保持运行。\n<ul>\n<li>运行容器的主机称为宿主机，可以是物理机或虚拟机。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>优点：\n<ul>\n<li>能隔离进程的运行环境\n<ul>\n<li>隔离程度比虚拟机低，比如容器会共享宿主机内核，但足够满足一般项目的需求。</li>\n</ul>\n</li>\n<li>便于管理进程\n<ul>\n<li>包含了进程管理工具的功能，比如启动、停止、自动重启。</li>\n<li>进程及其子进程都运行在容器中，不会游离到容器外。</li>\n</ul>\n</li>\n<li>轻量级\n<ul>\n<li>运行容器引擎，大概只消耗 5% 的系统资源。</li>\n<li>部署一个应用时，直接启动一个容器即可，耗时为几秒。</li>\n</ul>\n</li>\n<li>兼容性好\n<ul>\n<li>同一个镜像可以拷贝到不同平台上，创建容器，只需系统内核相同。</li>\n<li>便于将应用迁移部署到其它主机。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>总之，容器能在一般场景下模拟虚拟机，更轻量级，但不能完全替代虚拟机。</li>\n</ul>\n<h3 id=\"相关历史\"> 相关历史</h3>\n<ul>\n<li>1979 年，Unix 系统加入了 chroot 技术（change root directory），用于更改正在运行的进程的根目录。\n<ul>\n<li>这里是指文件系统的根目录，不是指当前的工作目录。</li>\n<li>更改根目录时，需要先拷贝 /lib 等库文件到新的根目录下，供进程调用。</li>\n</ul>\n</li>\n<li>2002 年，Linux 系统加入了 namespace 技术，用于隔离进程可见、可用的系统资源。</li>\n<li>2008 年，Linux 系统加入了 Control group 技术，简称为 Cgroup ，用于限制进程占用的 CPU、内存等系统资源。</li>\n<li>2008 年，Linux 系统加入了 LXC 工具，用于控制 namespace 和 Cgroup 。</li>\n<li>2013 年，dotCloud 公司于发布 Docker 软件，使得容器技术流行、普及，公司也改名为 Docker 公司。</li>\n</ul>\n<h3 id=\"容器引擎\"> 容器引擎</h3>\n<ul>\n<li>容器引擎（Container Engine）：通常是一个复杂的软件，负责与用户交互、管理镜像、管理容器。</li>\n<li>容器引擎举例：\n<ul>\n<li>LXC（Linux Container）</li>\n<li>Docker</li>\n<li>Podman ：兼容 Docker CLI 的大部分命令。</li>\n<li>Windows Hyper-V Containers</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"容器运行时\"> 容器运行时</h3>\n<ul>\n<li>\n<p>容器运行时（Container Runtime）：通常是一个 CLI 程序，用于创建、运行、管理容器。</p>\n<ul>\n<li>有的容器引擎会直接管理容器，而有的容器引擎会调用容器运行时来管理容器。</li>\n<li>早期版本的 Docker 引擎是通过 LXC 来控制 namespace、Cgroup ，实现容器化。从 0.9 版本开始，弃用 LXC ，改用 libcontainer 等 Golang 库，后来演变为 runC 组件。\n<ul>\n<li>2016 年，Docker 引擎将其底层组件 runC、containerd 抽离出来，成为独立的容器运行时项目。</li>\n<li>此后，Docker 引擎会调用 containerd 来管理容器，而 containerd 会调用 runC ，runC 才会直接管理容器。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>OCI（Open Container Initiative ，开放容器倡议）</p>\n<ul>\n<li>该组织于 2015 年创立，负责制定容器行业的镜像规范、容器运行时规范。</li>\n<li>如果一个镜像符合 OCI 规范，则可以被符合 OCI 标准的容器运行时用于创建容器。</li>\n</ul>\n</li>\n<li>\n<p>底层的容器运行时：</p>\n<ul>\n<li>runC\n<ul>\n<li>只支持 Linux 系统。</li>\n</ul>\n</li>\n<li>crun</li>\n<li>rkt（CoreOS Rocket）\n<ul>\n<li>由 CoreOS 团队发布，以 Pod 为单位管理容器。但不符合 OCI 规范，已被弃用。</li>\n</ul>\n</li>\n<li>kata-containers\n<ul>\n<li>在一个轻量级虚拟机中运行容器，不共享宿主机的内核，隔离程度更高。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>高层的容器运行时：基于 runC 等底层的容器运行时来管理容器。例如：</p>\n<ul>\n<li>containerd\n<ul>\n<li>支持 Linux、Windows 系统。</li>\n<li>支持 k8s 的 CRI 接口。</li>\n</ul>\n</li>\n<li>CRI-O\n<ul>\n<li>主要用于将底层的容器运行时对接到 k8s CRI 接口。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"容器编排工具\"> 容器编排工具</h3>\n<p>当容器数量较多时，手动管理很麻烦，需要使用容器编排工具，例如：</p>\n<ul>\n<li>Docker Compose ：由 Docker 公司发布，只能管理当前宿主机上的容器，不能管理服务器集群。</li>\n<li>Docker Swarm ：由 Docker 公司发布，在 docker 软件包中自带，可以管理多台宿主机上的容器。</li>\n<li>Mesos ：由 ASF 管理。</li>\n<li>k8s ：由 Google 公司发布，功能多但也复杂，通过命令行操作。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Network",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/Network.html",
      "id": "/Hardware/DevOps/Container/k8s/Network.html",
      "content_html": "<h1 id=\"network\"> Network</h1>\n<h2 id=\"原理\"> 原理</h2>\n<p>k8s 常见的几种 IP 地址：</p>\n<ul>\n<li>Node IP\n<ul>\n<li>：集群中一个主机节点的 IP 地址。</li>\n<li>Node IP 一般绑定在物理机或虚拟机的 eth 网卡上，固定不变。</li>\n</ul>\n</li>\n<li>Pod IP\n<ul>\n<li>：一个 Pod 的 IP 地址。</li>\n<li>k8s 创建每个 Pod 时，会给它分配一个独立的虚拟 IP 。</li>\n<li>一个应用可以部署多个 Pod 实例，拥有不同的 Pod IP ，而且重新部署时 Pod IP 还会变化。因此使用 Pod IP 不方便访问，建议用 Service IP 或 Ingress IP 。</li>\n</ul>\n</li>\n<li>Service IP\n<ul>\n<li>用户可以创建一个 Service ，反向代理某些 Pod 。向 Service IP 发送的网络流量，会被自动转发到对应的 Pod IP 。\n<ul>\n<li>此时，外部访问应用时，目的地址是 Service IP 。而应用访问外部时，源地址是 Pod IP 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Ingress IP</li>\n</ul>\n<p>k8s 常见的几种网络通信：</p>\n<ul>\n<li>同一个 Pod 内，容器之间的通信</li>\n<li>同一个服务内，Pod 之间的通信</li>\n<li>同一个集群内，Pod 到服务的通信</li>\n<li>集群内与集群外的通信</li>\n</ul>\n<h2 id=\"service\"> Service</h2>\n<p>：一种管理逻辑网络的对象，用于对某些 Pod 进行 TCP、UDP 反向代理，常用于实现服务发现、负载均衡。</p>\n<ul>\n<li>Service 分为 ClusterIP、NodePort、LoadBalancer 等多种类型。</li>\n</ul>\n\n<h3 id=\"clusterip\"> ClusterIP</h3>\n<p>：默认的 Service 类型，是给 Service 分配一个集群内的虚拟 IP 。</p>\n<ul>\n<li>访问 ClusterIP:Port 的流量会被转发到 EndPoint 。\n<ul>\n<li>在集群内节点上，才能访问 ClusterIP 。从集群外则访问不到，需要使用 LoadBalancer 等类型的 Service 。</li>\n</ul>\n</li>\n<li>Service 的配置文件通常命名为 service.yml ，内容示例如下：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Service\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n<span>spec</span><span>:</span>\n  <span>type</span><span>:</span> ClusterIP\n  <span>clusterIP</span><span>:</span> 10.124.0.1\n  <span>selector</span><span>:</span>               <span># 通过 selector 选中一些 Pod ，进行反向代理</span>\n    <span>app</span><span>:</span> redis\n  <span>ports</span><span>:</span>                  <span># 定义一组反向代理规则</span>\n  <span>-</span> <span>name</span><span>:</span> redis\n    <span>port</span><span>:</span> <span>6379</span>            <span># Service 监听的端口，供外部访问</span>\n    <span>protocol</span><span>:</span> TCP         <span># 反向代理的协议，默认为 TCP ，还可以填 UDP</span>\n    <span>targetPort</span><span>:</span> <span>6379</span>      <span># 将访问 clusterIP:port 的流量，转发到 Pod_IP:targetPort</span>\n    <span># targetPort: port1   # 可以指定 Pod 的端口名，而不是具体的端口号</span>\n  <span>-</span> <span>name</span><span>:</span> sentinel\n    <span>port</span><span>:</span> <span>26379</span>\n    <span>protocol</span><span>:</span> TCP\n    <span>targetPort</span><span>:</span> <span>26379</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><ul>\n<li>该 Service 分配了一个 clusterIP ，映射了两个 port ，供用户访问。</li>\n<li>此时可以通过 3 种地址访问 Pod 端口：<div><pre><code>service_name:port   <span># 访问者与 service 在同一命名空间时，service_name 会被自动 DNS 解析到 service_ip 。在不同命名空间时，则不支持</span>\nservice_ip:port     <span># 在不同命名空间时，也可以通过 service_ip 访问 service</span>\npod_ip:targetPort   <span># 也可以直接访问 Pod</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"nodeport\"> NodePort</h3>\n<p>：在所有 Node 上监听一个 Port ，将访问 <code>NodeIP:Port</code> 的流量转发到 EndPoint 。</p>\n<ul>\n<li>NodePort 默认的取值范围为 30000~32767 ，以免与系统端口冲突。</li>\n<li>例：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Service\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n<span>spec</span><span>:</span>\n  <span>clusterIP</span><span>:</span> 10.124.0.1   <span># NodePort 类型的 service 也会绑定一个 clusterIP</span>\n  <span>ports</span><span>:</span>\n  <span>-</span> <span>nodePort</span><span>:</span> <span>31017</span>       <span># 如果不指定 nodePort ，则随机选取一个端口</span>\n    <span>port</span><span>:</span> <span>80</span>\n    <span>protocol</span><span>:</span> TCP\n    <span>targetPort</span><span>:</span> <span>80</span>\n  <span>selector</span><span>:</span>\n    <span>k8s-app</span><span>:</span> redis\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<h3 id=\"hostport\"> HostPort</h3>\n<p>：与 NodePort 相似，但只使用 Pod 所在节点的端口。</p>\n<ul>\n<li>HostPort 不属于 Service 对象，没有监听端口，只是添加 iptables 规则实现端口转发。\n<ul>\n<li>HostPort 的取值范围不限。</li>\n<li>如果 HostPort 与 NodePort 端口号相同，则依然可以创建，但优先级更高。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>当 Pod 迁移部署到其它节点时，节点 IP 会变化，因此通常将 Pod 固定调度在某个节点上。</li>\n<li>同一节点上不允许重复使用同一个 HostPort ，因此 Pod 不支持 rollingUpdate 。</li>\n</ul>\n</li>\n<li>HostPort 需要在 Pod 的 spec.containers 里配置，如下：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Pod\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n<span>spec</span><span>:</span>\n  <span>containers</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> redis\n    <span>image</span><span>:</span> redis<span>:</span>5.0.6\n    <span>command</span><span>:</span> <span>[</span><span>\"redis-server /opt/redis/redis.conf\"</span><span>]</span>\n    <span>ports</span><span>:</span>\n    <span>-</span> <span>containerPort</span><span>:</span> <span>6379</span>\n      <span>hostPort</span><span>:</span> <span>6379</span>      <span># 将访问 hostPort 的流量转发到 containerPort</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ul>\n<h3 id=\"loadbalancer\"> LoadBalancer</h3>\n<p>：给 Service 分配一个负载均衡 IP 。</p>\n<ul>\n<li>访问 <code>loadBalancerIP:Port</code> 的流量会被转发到 EndPoint 。</li>\n<li>一般需要购买公有云平台的负载均衡器，将其接收的流量代理到 Service。\n<ul>\n<li>LB 位于集群之外，不受防火墙限制。</li>\n<li>LB 可以使用内网 IP 或公网 IP 。</li>\n</ul>\n</li>\n<li>例：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Service\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n<span>spec</span><span>:</span>\n  <span>type</span><span>:</span> LoadBalancer\n  <span>clusterIP</span><span>:</span> 10.124.0.1\n  <span>loadBalancerIP</span><span>:</span> 123.0.0.1\n  <span>selector</span><span>:</span>\n    <span>app</span><span>:</span> redis\n  <span>ports</span><span>:</span>\n    <span>-</span> <span>name</span><span>:</span> redis\n      <span>port</span><span>:</span> <span>6379</span>\n      <span>protocol</span><span>:</span> TCP\n      <span>targetPort</span><span>:</span> <span>6379</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h3 id=\"externalname\"> ExternalName</h3>\n<p>：添加一条neiw集群内的 DNS 规则，将 ServiceName 解析到指定的域名。</p>\n<ul>\n<li>例：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Service\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n<span>spec</span><span>:</span>\n  <span>type</span><span>:</span> ExternalName\n  <span>externalName</span><span>:</span> redis.test.com\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n<h3 id=\"externalips\"> ExternalIPs</h3>\n<p>：给 Service 分配集群外的 IP ，此时 Service 可以是任意 type 。</p>\n<ul>\n<li>例：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Service\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n<span>spec</span><span>:</span>\n  <span>selector</span><span>:</span>\n    <span>app</span><span>:</span> redis\n  <span>ports</span><span>:</span>\n  <span>-</span> <span>name</span><span>:</span> redis\n    <span>port</span><span>:</span> <span>6379</span>\n    <span>protocol</span><span>:</span> TCP\n    <span>targetPort</span><span>:</span> <span>6379</span>\n  <span>externalIPs</span><span>:</span>\n  <span>-</span> 123.0.0.1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n<h3 id=\"headless-service\"> Headless Service</h3>\n<p>：配置 <code>clusterIP: None</code> 。此时 Service 没有自己的 IP ，必须通过 selector 选中一个 Pod ，Service 名会被解析到 Pod IP 。</p>\n<h2 id=\"ingress\"> Ingress</h2>\n<p>：一种管理逻辑网络的对象，用于对某些 Service 进行 HTTP、HTTPS 反向代理，常用于实现路由转发。</p>\n<ul>\n<li>实现 Ingress 功能的 Controller 有多种，常见的是 Nginx Ingress Controller ，它基于 Nginx 实现 Ingress 功能。</li>\n<li>配置示例：<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Ingress\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> test<span>-</span>ingress\n<span>spec</span><span>:</span>\n  <span>rules</span><span>:</span>                        <span># Ingress 的入站规则列表</span>\n  <span>-</span> <span>http</span><span>:</span>                       <span># 定义 http 协议的规则</span>\n      <span>paths</span><span>:</span>\n      <span>-</span> <span>path</span><span>:</span> /login            <span># 将发往该 URL 的请求转发到后端（backend）的 Service</span>\n        <span>backend</span><span>:</span>\n          <span>serviceName</span><span>:</span> nginx\n          <span>servicePort</span><span>:</span> <span>80</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ul>\n<h2 id=\"访问控制\"> 访问控制</h2>\n<ul>\n<li>Service Account</li>\n<li>RBAC</li>\n<li>NetWorkPolicy ：管控 Pod 之间的网络流量，相当于第四层的 ACL 。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "权限",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/Permissions.html",
      "id": "/Hardware/DevOps/Container/k8s/Permissions.html",
      "content_html": "<h1 id=\"权限\"> 权限</h1>\n<ul>\n<li>k8s 组件提供了 Restful API ，但对于组件之间、用户对组件的请求，启用了以下安全措施：\n<ul>\n<li>SSL 证书和公钥基础设施（Certificates and public key infrastructure，PKI)）\n<ul>\n<li>默认给 apiserver、kubelet、etcd 等组件分别创建了自签名的 CA 证书。</li>\n</ul>\n</li>\n<li>身份认证策略</li>\n<li>鉴权策略</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"身份认证\"> 身份认证</h2>\n<ul>\n<li>\n<p>客户端发送 HTTP 请求到 k8s 时，需要进行身份认证。</p>\n<ul>\n<li>如果一个 HTTP 请求未通过身份认证，则会被 k8s 视作 system:anonymous 用户，属于 system:unauthenticated 用户组。\n<ul>\n<li>默认禁止匿名用户的请求，会返回响应 403: Forbidden</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>k8s 支持多种身份认证方式：</p>\n<ul>\n<li>SSL 客户端证书：用于验证客户端的身份，证书中的 CN 字段记录了用户名。</li>\n<li>ServiceAccount Token ：需要客户端在 HTTP 请求头中加入 <code>Authorization: Bearer &lt;token&gt;</code> 。</li>\n<li>Bootstrap Token ：用于部署 k8s 集群、新增节点。</li>\n<li>支持集群外的身份认证服务，比如 LDAP、Kerberos、OIDC 。</li>\n</ul>\n</li>\n<li>\n<p>k8s 将账户分为两类：</p>\n<ul>\n<li>UserAccount ：供自然人使用，比如 kubectl 。\n<ul>\n<li>不能通过 k8s API 创建。</li>\n</ul>\n</li>\n<li>ServiceAccount ：供应用程序使用。\n<ul>\n<li>UserAccount 作用于集群全局，而 ServiceAccount 会被 namespace 隔离，可以划分更细的权限。</li>\n<li>创建一个 ServiceAccount 时，会自动创建并关联一个 secret ，包含了身份凭证，命名格式为 <code>&lt;ServiceAccount&gt;-token-&lt;random_id&gt;</code> 。\n<ul>\n<li>如果删除该 secret ，则会自动创建一个新 id 的 secret 。</li>\n<li>如果删除该 ServiceAccount ，则会自动删除相应的 secret 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"示例\"> 示例</h3>\n<ul>\n<li>\n<p>创建 Pod 时可以配置 ServiceAccount ：</p>\n<div><pre><code><span>spec</span><span>:</span>\n  <span>serviceAccountName</span><span>:</span> default         <span># 该 Pod 采用的 ServiceAccount ，如果不存在则不能创建 Pod 。默认名为 default</span>\n  <span>automountServiceAccountToken</span><span>:</span> <span>true</span>  <span># 是否自动将 ServiceAccount 关联的 secret 挂载到 Pod 的 /var/run/secrets/kubernetes.io/serviceaccount/ 目录下。默认为 true</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>ServiceAccount 的配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> ServiceAccount\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> promethues\n  <span>namespace</span><span>:</span> default\n<span># secrets:            # 创建 ServiceAccount 之后会自动关联 secret</span>\n<span># - name: promethues-token-zqltx</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>ServiceAccount 的 secret 示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>data</span><span>:</span>\n  <span>ca.crt</span><span>:</span> <span>******</span>      <span># CA 证书，用于验证服务器的身份</span>\n  <span>namespace</span><span>:</span> <span>******</span>\n  <span>token</span><span>:</span> <span>******</span>       <span># 用于验证 ServiceAccount 的身份</span>\n<span>kind</span><span>:</span> Secret\n<span>metadata</span><span>:</span>\n  <span>annotations</span><span>:</span>\n    <span>kubernetes.io/service-account.name</span><span>:</span> default\n    <span>kubernetes.io/service-account.uid</span><span>:</span> <span>******</span>\n  <span>name</span><span>:</span> promethues<span>-</span>token<span>-</span>zqltx\n  <span>namespace</span><span>:</span> default\n<span>type</span><span>:</span> kubernetes.io/service<span>-</span>account<span>-</span>token\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n<h2 id=\"鉴权\"> 鉴权</h2>\n<ul>\n<li>\n<p>客户端通过身份认证之后，k8s 会根据鉴权模块分配权限。</p>\n</li>\n<li>\n<p>k8s 支持多种鉴权模块：</p>\n<ul>\n<li>Node ：用于控制 kubelet 对已调度的 Pod 的权限，比如读取 ConfigMap、修改 Pod 状态。</li>\n<li>ABAC ：基于属性的访问控制，根据用户的属性，决定其权限。</li>\n<li>RBAC ：基于角色的访问控制，根据用户所属的角色，决定其权限。</li>\n<li>Webhook ：发送 HTTP 请求给第三方，根据响应报文决定权限。</li>\n</ul>\n</li>\n<li>\n<p>k8s 支持同时启用多个鉴权模块。</p>\n<ul>\n<li>启动 apiserver 时，可通过命令行配置要启用的鉴权模块：<div><pre><code>--authorization-mode<span>=</span>Node,RBAC\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>k8s 处理一个客户端请求时，会依次调用各个鉴权模块。\n<ul>\n<li>如果某个鉴权模块批准或拒绝该请求，则立即结束鉴权。</li>\n<li>如果所有鉴权模块都未决策，则默认拒绝该请求。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>可用以下命令，测试客户端是否有权执行某个操作：</p>\n<div><pre><code>kubectl auth can-i <span>\\</span>\n    create deployments\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>输出为 yes 或 no 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"rbac\"> RBAC</h3>\n<ul>\n<li>\n<p>RBAC 鉴权模块定义了四种对象：</p>\n<ul>\n<li>Role ：角色，作用于某个 namespace 。</li>\n<li>RoleBinding ：在某个 namespace 中，将一个 Role 或 ClusterRole 角色，绑定到一些用户。</li>\n<li>ClusterRole ：集群角色，作用于集群全局。</li>\n<li>ClusterRoleBinding ：将角色绑定到用户，作用于集群全局。</li>\n</ul>\n</li>\n<li>\n<p>Role 的配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> rbac.authorization.k8s.io/v1\n<span>kind</span><span>:</span> Role\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> pod<span>-</span>reader\n  <span>namespace</span><span>:</span> default\n<span>rules</span><span>:</span>                  <span># 角色的权限，可声明多条规则</span>\n<span>-</span> <span>apiGroups</span><span>:</span> <span>[</span><span>\"\"</span><span>]</span>       <span># 第一条规则，允许通过 API 组对哪些 resources 执行哪些 verbs 操作</span>\n  <span>resources</span><span>:</span>\n    <span>-</span> pods\n    <span>-</span> pods/log          <span># 允许访问 pods 的子资源 log</span>\n  <span># resourceNames:      # 只允许访问指定名称的资源。默认不限制名称</span>\n  <span>#   - nginx</span>\n  <span>verbs</span><span>:</span>\n    <span>-</span> get\n    <span>-</span> list\n    <span>-</span> watch\n<span># aggregationRule: ...  # 定义 ClusterRole 时，可通过聚合功能，继承其它多个 ClusterRole</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div></li>\n<li>\n<p>RoleBinding 的配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> rbac.authorization.k8s.io/v1\n<span>kind</span><span>:</span> RoleBinding\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> pod<span>-</span>reader\n  <span>namespace</span><span>:</span> default\n<span>roleRef</span><span>:</span>                <span># 要绑定的角色。创建 Binding 之后不允许修改该配置</span>\n  <span>apiGroup</span><span>:</span> rbac.authorization.k8s.io\n  <span>kind</span><span>:</span> Role            <span># 可以为 Role 或 ClusterRole</span>\n  <span>name</span><span>:</span> pod<span>-</span>reader\n<span>subjects</span><span>:</span>               <span># 主体内容，声明要绑定的用户</span>\n<span>-</span> <span>kind</span><span>:</span> User\n  <span>name</span><span>:</span> leo\n  <span>apiGroup</span><span>:</span> rbac.authorization.k8s.io\n<span>-</span> <span>kind</span><span>:</span> Group\n  <span>name</span><span>:</span> system<span>:</span>authenticated    <span># 一个内置的用户组，表示所有通过身份认证的用户</span>\n  <span>apiGroup</span><span>:</span> rbac.authorization.k8s.io\n<span>-</span> <span>kind</span><span>:</span> ServiceAccount\n  <span>name</span><span>:</span> default\n  <span>namespace</span><span>:</span> kube<span>-</span>system\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div></li>\n</ul>\n<h2 id=\"客户端示例\"> 客户端示例</h2>\n<ul>\n<li>\n<p>使用 kubecbtl 作为客户端时，会从 kubeconfig 配置文件中获取 CA 证书、token ，从而连接 apiserver 。</p>\n</li>\n<li>\n<p>可以用 kubectl 反向代理 apiserver ，此时发向 proxy 的 HTTP 请求不必采用 SSL、不需要 token 。</p>\n<div><pre><code>kubectl proxy <span>&amp;</span>\n<span>curl</span> <span>127.0</span>.0.1:8001/\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>可以直接用 curl 命令访问 k8s ：</p>\n<div><pre><code><span>TOKEN</span><span>=</span><span><span>`</span>kubectl config view --raw <span>|</span> yq <span>'.users[0].user.token'</span><span>`</span></span>         <span># 获取 token</span>\n<span>curl</span> https://apiserver -H <span>\"Authorization: Bearer <span>$TOKEN</span>\"</span> -k   <span># 用 -k 选项跳过 SSL 认证</span>\n\nkubectl config view --raw <span>|</span> <span>grep</span> certificate-authority-data <span>|</span> <span>awk</span> <span>'{print $2}'</span> <span>|</span> base64 -d <span>></span> ca.crt       <span># 获取 k8s 的 ca 证书</span>\nkubectl config view --raw <span>|</span> <span>grep</span> client-certificate-data    <span>|</span> <span>awk</span> <span>'{print $2}'</span> <span>|</span> base64 -d <span>></span> client.pem   <span># 获取客户端的证书</span>\nkubectl config view --raw <span>|</span> <span>grep</span> client-key-data            <span>|</span> <span>awk</span> <span>'{print $2}'</span> <span>|</span> base64 -d <span>></span> client-key.pem\n<span>curl</span> https://apiserver -H <span>\"Authorization: Bearer <span>$TOKEN</span>\"</span> --cacert ca.crt --cert client.pem --key client-key.pem\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "插件",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/Plugin.html",
      "id": "/Hardware/DevOps/Container/k8s/Plugin.html",
      "content_html": "<h1 id=\"插件\"> 插件</h1>\n<h2 id=\"api\"> API</h2>\n<p>k8s 为一些底层组件定义了 API 规范，如果一个插件实现了这些 API ，则可以替换默认组件。比如：</p>\n<ul>\n<li>容器运行时接口（Container Runtime Interface，CRI）：供 k8s 调用容器运行时，从而管理容器、镜像。\n<ul>\n<li>大部分容器运行时并不兼容 CRI ，因此 k8s 还开发了一些 shim 模块，用于将各种容器运行时对接到 CRI 。\n<ul>\n<li>后来改为通过 containerd 或 CRI-O 来调用底层的容器运行时。</li>\n</ul>\n</li>\n<li>CRI 使得 k8s 与容器运行时解耦，允许 k8s 同时使用多种容器运行时。</li>\n</ul>\n</li>\n<li>容器网络接口（Container Network Interface，CNI）：供 k8s 管理容器的网络。</li>\n<li>容器存储接口（Container Storage Interface，CSI）：供 k8s 管理容器的存储层。</li>\n</ul>\n<p>常见插件：</p>\n<ul>\n<li>kube-dns ：为 k8s 集群提供 DNS 服务。</li>\n<li>Kube-router</li>\n<li>Flannel ：一个 CNI 插件，比较简单。</li>\n<li>Calico ：一个 CNI 插件，比较复杂，功能更多。</li>\n<li>Dashboard ：提供 Web UI 。</li>\n<li>Federation ：提供跨可用区的集群。\n<ul>\n<li>k8s 原本是部署在同一局域网内的主机上，如果部署在跨地域（Region）的不同主机上，则网络延迟会比较大。</li>\n</ul>\n</li>\n<li>Fluentd-elasticsearch ：采集、管理 k8s 集群的日志。</li>\n</ul>\n\n<h2 id=\"helm\"> Helm</h2>\n<p>：一个命令行工具，用于管理 k8s 中的应用，相当于高层的包管理工具。</p>\n<ul>\n<li>将 k8s 中一个应用的相关配置文件打包成一个 .tgz 文件，称为 Chart 。\n<ul>\n<li>charts 可以存储在本机，或者存储到远端仓库。</li>\n</ul>\n</li>\n<li>Helm 2.0 采用 C/S 架构。\n<ul>\n<li>客户端名为 Helm ，负责管理 charts 。</li>\n<li>服务器名为 Tiller ，会将客户端发来的 chart 渲染成 release 文件，然后传给 k8s 的 apiserver 。</li>\n</ul>\n</li>\n<li>Helm 3.0 于 2019 年 11 月发布，与 Helm2 不兼容，移除了 Tiller ，成为了一个纯客户端工具。</li>\n</ul>\n<p>命令：</p>\n<div><pre><code>helm\n    init            <span># 初始化 Helm（这会创建 Helm 的配置文件、安装 Tiller）</span>\n    reset           <span># 卸载 Tiller</span>\n\n    create <span>&lt;</span>dir<span>></span>    <span># 创建一个 Chart 目录（会包含一些模板文件）</span>\n    inspect <span>&lt;</span>dir<span>></span>   <span># 查看一个 Chart 的详细信息</span>\n    lint <span>&lt;</span>dir<span>></span>      <span># 检查 Chart 的语法</span>\n    package <span>&lt;</span>dir<span>></span>   <span># 将一个 Chart 目录打包，这会生成一个 .tgz 文件</span>\n    template <span>&lt;</span>dir<span>></span>                       <span># 渲染 Chart 目录中的所有模板</span>\n            <span>></span> release.yml                <span># 将渲染结果保存到一个文件中</span>\n            -x templates/configmap.yaml  <span># 只渲染指定模板文件</span>\n\n    <span>install</span> <span>&lt;</span>name<span>></span>  <span># 将一个 Chart 部署到 k8s</span>\n    delete <span>&lt;</span>name<span>></span>   <span># 删除 k8s 中的一个 release</span>\n    status <span>&lt;</span>name<span>></span>   <span># 显示 k8s 中的一个 release 的状态</span>\n    list            <span># 显示 k8s 中的所有 release</span>\n\n    search <span>&lt;</span>name<span>></span>   <span># 在 Helm Hub 中查找 Chart</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><h3 id=\"制作-chart\"> 制作 Chart</h3>\n<p>Chart 的目录结构：</p>\n<div><pre><code>app/\n├── Chart.yaml          <span># 描述该 Chart 的信息</span>\n├── templates/          <span># 存放该应用的配置文件</span>\n│   ├── deployment.yaml\n│   └── service.yaml\n├── values.yaml         <span># 用于给 templates 中的变量赋值</span>\n├── requirements.yaml   <span># 描述当前 Chart 依赖的其它 Chart</span>\n├── charts/             <span># 存放当前 Chart 依赖的其它 Chart</span>\n├── .helmignore         <span># 描述打包 Chart 时要忽略的文件</span>\n├── LICENSE\n└── README.md\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><p>Chart.yaml 的示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>appVersion</span><span>:</span> <span>\"1.0\"</span>\n<span>description</span><span>:</span> A Helm chart for Kubernetes\n<span>name</span><span>:</span> redis\n<span>version</span><span>:</span> 0.1.0\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>values.yaml 的示例：</p>\n<div><pre><code><span>image</span><span>:</span>\n  <span>repository</span><span>:</span> myharbor.com/test/redis\n  <span>tag</span><span>:</span> 5.0.6\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>在 deployment.yaml 中使用 values 的示例：</p>\n<div><pre><code><span>template</span><span>:</span>\n  <span>spec</span><span>:</span>\n      <span>containers</span><span>:</span>\n      <span>-</span> <span>image</span><span>:</span> <span>\"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"</span>\n      <span>...</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Pod",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/Pod.html",
      "id": "/Hardware/DevOps/Container/k8s/Pod.html",
      "content_html": "<h1 id=\"pod\"> Pod</h1>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>Docker 以容器为单位部署应用，而 k8s 以 Pod 为单位部署应用。</li>\n<li>一个 Pod 由一个或多个容器组成，它们会被部署到同一个 Node 上。特点：\n<ul>\n<li>共享一个网络空间，可以相互通信。对外映射的访问 IP 都是 Pod IP ，因此不能暴露同样的端口号。</li>\n<li>共享所有存储卷。</li>\n</ul>\n</li>\n<li>用 kubectl 命令手动管理 Pod 比较麻烦，因此一般用 Controller 管理 Pod 。\n<ul>\n<li>用户需要编写 Controller 配置文件，描述如何部署一个应用的 Pod 。然后创建该 Controller ，k8s 就会自动部署其 Pod 。</li>\n</ul>\n</li>\n</ul>\n\n<h3 id=\"状态\"> 状态</h3>\n<p>--&gt;</p>\n<h2 id=\"controller\"> Controller</h2>\n<p>：控制器，用于管理 Pod 。</p>\n<ul>\n<li>Controller 分为 Deployment、StatefulSet 等多种类型。</li>\n</ul>\n<h3 id=\"deployment\"> Deployment</h3>\n<p>：默认的 Controller 类型，用于部署无状态的 Pod 。</p>\n<h4 id=\"配置\"> 配置</h4>\n<p>配置文件示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Deployment            <span># 该 Controller 的类型</span>\n<span>metadata</span><span>:</span>                   <span># 该 Controller 的元数据</span>\n  <span>annotations</span><span>:</span>\n    <span>deployment.kubernetes.io/revision</span><span>:</span> <span>\"1\"</span>  <span># k8s 自动添加该字段，表示当前配置是第几次修改版本，从 1 开始递增</span>\n  <span>labels</span><span>:</span>\n    <span>creator</span><span>:</span> Leo\n  <span>name</span><span>:</span> redis\n  <span>namespace</span><span>:</span> default\n  <span># generation: 1           # k8s 自动添加该字段，表示配置文件的版本序号，从 1 开始递增</span>\n<span>spec</span><span>:</span>                       <span># Controller 的规格</span>\n  <span>replicas</span><span>:</span> <span>3</span>               <span># Pod 运行的副本数</span>\n  <span>selector</span><span>:</span>                 <span># 选择 Pod</span>\n    <span>matchLabels</span><span>:</span>\n      <span>app</span><span>:</span> redis\n  <span># strategy:               # 更新部署的策略，默认为滚动更新</span>\n  <span>#   type: RollingUpdate</span>\n  <span>#   rollingUpdate:              # 滚动更新过程中的配置</span>\n  <span>#     maxUnavailable: 25%       # 允许同时不可用的 Pod 数量。可以为整数，或者百分数，默认为 25%</span>\n  <span>#     maxSurge: 25%             # 为了同时运行新、旧 Pod ，允许 Pod 总数超过 replicas 一定数量。可以为整数，或者百分数，默认为 25%</span>\n  <span># progressDeadlineSeconds: 600  # 如果 Deployment 停留在 Progressing 状态超过一定时长，则变为 Failed 状态</span>\n  <span># revisionHistoryLimit: 10      # 保留 Deployment 的多少个旧版本，可用于回滚（rollback）。设置为 0 则不保留</span>\n  <span>template</span><span>:</span>                       <span># 开始定义 Pod 的模板</span>\n    <span>metadata</span><span>:</span>                     <span># Pod 的元数据</span>\n      <span>labels</span><span>:</span>\n        <span>app</span><span>:</span> redis\n    <span>spec</span><span>:</span>                         <span># Pod 的规格</span>\n      <span>containers</span><span>:</span>                 <span># 定义该 Pod 中的容器</span>\n      <span>-</span> <span>name</span><span>:</span> redis               <span># 该 Pod 中的第一个容器名</span>\n        <span>image</span><span>:</span> redis<span>:</span>5.0.6\n        <span>command</span><span>:</span> <span>[</span><span>\"redis-server /opt/redis/redis.conf\"</span><span>]</span>\n        <span>ports</span><span>:</span>\n        <span>-</span> <span>containerPort</span><span>:</span> <span>6379</span>   <span># 声明容器监听的端口，相当于 Dockerfile 中的 expose 指令</span>\n      <span># dnsPolicy: ClusterFirst</span>\n      <span># imagePullSecrets:</span>\n      <span># - name: qcloudregistrykey</span>\n      <span># restartPolicy: Always</span>\n      <span># schedulerName: default-scheduler</span>\n      <span># securityContext: {}</span>\n      <span># terminationGracePeriodSeconds: 30</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br></div></div><ul>\n<li>\n<p>部署一个 Deployment 时，可以创建多个 Pod 实例。</p>\n<ul>\n<li>Pod 的命名格式为 <code>&lt;Controller_name&gt;-&lt;ReplicaSet_id&gt;-&lt;Pod_id&gt;</code> ，例如：<div><pre><code>redis-65d9c7f6fc-szgbk\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>用 kubectl 命令管理 Pod 时，不能事先知道 Pod 的具体名称，应该通过 label 来筛选 Pod 。</li>\n</ul>\n</li>\n<li>每个 Pod 中，容器的命名格式为 <code>k8s_&lt;container_name&gt;_&lt;pod_name&gt;_&lt;k8s_namespace&gt;_&lt;pod_uid&gt;_&lt;restart_id&gt;</code> ，例如：<div><pre><code>k8s_POD_redis-65d9c7f6fc-szgbk_default_c7e3e169-08c9-428f-9a62-0fb5d14336f8_0   <span># Pod 中内置的 pause 容器，其容器名为 POD</span>\nk8s_redis_redis-65d9c7f6fc-szgbk_default_c7e3e169-08c9-428f-9a62-0fb5d14336f8_0\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>当 Pod 配置不变时，如果触发重启事件，创建新 Pod ，则会将容器末尾的 restart_id 加 1（从 0 开始递增）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Deployment 的 spec.selector 是必填字段，称为选择器，用于与 spec.template.metadata.labels 进行匹配，从而筛选 Pod 进行控制，匹配结果可能有任意个（包括 0 个）。</p>\n<ul>\n<li>当 selector 中设置了多个筛选条件时，只会选中满足所有条件的对象。</li>\n<li>当 selector 中没有设置筛选条件时，会选中所有对象。</li>\n<li>例：<div><pre><code><span>selector</span><span>:</span>\n  <span>matchLabels</span><span>:</span>\n    <span>app</span><span>:</span> redis      <span># 要求 labels 中存在该键值对</span>\n  <span>matchExpressions</span><span>:</span>\n    <span>-</span> <span>{</span><span>key</span><span>:</span> app<span>,</span> <span>operator</span><span>:</span> In<span>,</span> <span>values</span><span>:</span> <span>[</span>redis<span>,</span> redis2<span>]</span><span>}</span>   <span># 要求 labels 中存在 app 键，且值为 redis 或 redis2</span>\n    <span>-</span> <span>{</span><span>key</span><span>:</span> app<span>,</span> <span>operator</span><span>:</span> Exists<span>}</span>                        <span># 运算符可以是 In、NotIn、Exists、DidNotExist</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>spec.template 是必填字段，用于描述 Pod 的配置。</p>\n<ul>\n<li>当用户修改了 template 之后（改变 ReplicaSet 不算），k8s 就会创建一个新版本的 Deployment ，据此重新部署 Pod 。</li>\n<li>删除 Deployment 时，k8s 会自动销毁对应的 Pod 。</li>\n<li>修改 Deployment 时，k8s 会自动部署新 Pod ，销毁旧 Pod 。该过程称为更新部署，有两种策略：\n<ul>\n<li>Recreate ：先销毁旧 Pod ，再部署新 Pod 。</li>\n<li>RollingUpdate ：先部署新 Pod ，等它们可用了，再销毁旧 Pod 。\n<ul>\n<li>这可以保证在更新过程中不中断服务。但新旧 Pod 短期内会同时运行，可能引发冲突，比如同时访问挂载的数据卷。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"状态-2\"> 状态</h3>\n<ul>\n<li>\n<p>Deployment 的生命周期分为多种条件（condition）：</p>\n<div><pre><code>Progressing       <span># 处理中，比如正在部署或销毁 Pod 实例</span>\nComplete          <span># 处理完成，比如部署完所有 Pod 实例且可用，或者该 Deployment 是停止运行的旧版本</span>\nAvailable         <span># 可用，即达到 ReplicaSet 的 Pod 实例最小可用数</span>\nReplicaFailure    <span># 处理失败，比如不能部署 Pod 实例、Progressing 超时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>一个资源可能同时处于多种 condition ，但只能处于一种 phrase 。\n<ul>\n<li>比如 Deployment 处于 Available 状态时，可能同时处于 Progressing 或 Complete 状态。</li>\n</ul>\n</li>\n<li>根据 <code>.status.conditions</code> 判断 <code>.status.phase</code>\n</li>\n</ul>\n</li>\n<li>\n<p>Deployment 的状态示例：</p>\n<div><pre><code><span>status</span><span>:</span>\n  <span>availableReplicas</span><span>:</span> <span>1</span>    <span># 可用的 Pod 实例数，允许接收 service 的流量</span>\n  <span>observedGeneration</span><span>:</span> <span>3</span>   <span># 可用的 Pod 实例采用的 Deployment 版本，如果小于 metadata.generation 则说明不是最新版本</span>\n  <span>readyReplicas</span><span>:</span> <span>1</span>        <span># 处于 health 状态的 Pod 实例数</span>\n  <span>replicas</span><span>:</span> <span>1</span>             <span># 期望运行的实例数</span>\n  <span>updatedReplicas</span><span>:</span> <span>1</span>      <span># 采用最新版本 Deployment 的 Pod 实例数</span>\n  <span>conditions</span><span>:</span>\n  <span>-</span> <span>type</span><span>:</span> Progressing     <span># condition 类型</span>\n    <span>status</span><span>:</span> <span>\"True\"</span>        <span># 是否处于当前 condition ，可以取值为 True、False、Unknown</span>\n    <span>reason</span><span>:</span> NewReplicaSetAvailable  <span># status 的原因</span>\n    <span>message</span><span>:</span> ReplicaSet \"redis<span>-</span>bbf945bc9\" has successfully progressed.  <span># reason 的详细信息</span>\n    <span>lastTransitionTime</span><span>:</span> <span>\"2021-06-29T10:52:18Z\"</span>\n    <span>lastUpdateTime</span><span>:</span> <span>\"2022-02-10T02:34:38Z\"</span>\n  <span>-</span> <span>type</span><span>:</span> Available\n    <span>status</span><span>:</span> <span>\"True\"</span>\n    <span>reason</span><span>:</span> MinimumReplicasAvailable\n    <span>message</span><span>:</span> Deployment has minimum availability.\n    <span>lastTransitionTime</span><span>:</span> <span>\"2022-02-10T15:53:46Z\"</span>\n    <span>lastUpdateTime</span><span>:</span> <span>\"2022-02-10T15:53:46Z\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div></li>\n</ul>\n\n<h3 id=\"replicaset\"> ReplicaSet</h3>\n<p>：副本集（RC），用于控制一个应用的 Pod 实例数量。</p>\n<ul>\n<li>取代了 k8s 早期版本的副本控制器（Replication Controller，RS），会被 Deployment 调用。</li>\n<li>假设用户指定运行 n 个 Pod ，ReplicaSet 会自动控制可用的 Pod 数量，使其等于 n 。\n<ul>\n<li>通过健康检查的 Pod 才计入可用数量。</li>\n<li>如果可用的 Pod 数多于 n ，则停止多余的 Pod 。</li>\n<li>如果可用的 Pod 数少于 n ，则增加部署 Pod 。包括以下情况：\n<ul>\n<li>已有的 Pod 故障，比如部署失败、部署之后未通过健康检查。</li>\n<li>已有的 Pod 需要的部署资源不足，比如 Pod 所在 Node 故障。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>通过 ReplicaSet ，可以方便地调整 Pod 数量，实现横向扩容、缩容。</li>\n</ul>\n<h3 id=\"statefulset\"> StatefulSet</h3>\n<p>：与 Deployment 类似，但部署的是有状态服务。\n&lt;!-- - 无状态应用：不需要保持连续运行，可以随时销毁并从镜像重新创建。\n使用数据卷</p>\n<ul>\n<li>一个有状态服务的每个 Pod 实例使用独立的资源、配置文件，不能随时创建、销毁 Pod ，甚至连 Pod 名都不能改变。</li>\n<li>例如：以无状态服务的方式运行一个 CentOS 容器，所有状态都存储在容器里，不可靠。改成 StatefulSet 方式运行，就可以漂移到不同节点上，实现高可用。 --&gt;</li>\n</ul>\n<h3 id=\"daemonset\"> DaemonSet</h3>\n<p>：与 Deployment 类似，但部署的是宿主机上的 daemon 服务，例如监控、日志服务。</p>\n<ul>\n<li>一个 DaemonSet 服务通常在每个宿主机上只需部署一个 Pod 实例。</li>\n</ul>\n<h3 id=\"job\"> Job</h3>\n<p>：与 Deployment 类似，但部署的是只执行一次的任务。</p>\n<h3 id=\"cronjob\"> CronJob</h3>\n<p>：与 Deployment 类似，但部署的是定时任务或周期性任务。</p>\n<h2 id=\"sidecar\"> Sidecar</h2>\n<p>一个 Pod 中只运行一个容器的情况最简单（称为主容器），但有时也会运行一些辅助容器（Sidecar）。</p>\n<p>辅助容器有两种类型：</p>\n<ul>\n<li>标准容器：与主容器差不多。</li>\n<li>init 容器：在创建 Pod 时最先启动，执行一些初始化任务，执行完成之后会自动退出。\n<ul>\n<li>可以给一个 Pod 设置多个 init 容器，它们会按顺序串行执行。当一个 init 容器执行成功之后，才会启动下一个 init 容器或应用容器。</li>\n<li>如果某个 init 容器启动失败或异常退出，则 kubelet 会重新启动该 Pod 。</li>\n<li>重启 Pod 时会重新启动各个 init 容器。因此，为了避免多次重启 Pod 时出错，init 容器的行为应该满足幂等性。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"horizontal-pod-autoscaling\"> Horizontal Pod Autoscaling</h2>\n<p>：Pod 的水平方向上的自动伸缩（HPA）。</p>\n<ul>\n<li>k8s 会监控服务的一些 metrics 指标（比如 CPU 负载），当超过一定阙值时就自动增加 ReplicaSet 数量，从而实现服务的横向扩容。</li>\n</ul>\n<h2 id=\"主机调度\"> 主机调度</h2>\n<p>部署 Pod 时，k8s 的 scheduler 会给 Pod 自动分配一个 Node（这一过程称为主机调度），然后由 Node 上的 kubelet 部署该 Pod 。</p>\n<ul>\n<li>scheduler 会综合考虑 Affinity、Taint、Tolerations 等因素，从而选出一个 Node 。</li>\n<li>如果 Pod 所在的 Node 出现故障，该 Pod 会被立即迁移到其它 Node 运行。</li>\n</ul>\n<h3 id=\"affinity\"> Affinity</h3>\n<p>：节点的亲和性，表示 Pod 适合部署在什么样的 Node 上。</p>\n<ul>\n<li>用法：先给 Node 添加 Label ，然后在 Pod spec 中配置该 Pod 需要的 Node Label 。</li>\n<li>亲和性的主要分类：\n<ul>\n<li>requiredDuringScheduling ：当 Pod 开始部署时，只能部署到满足条件的 Node 上。如果没有这样的 Node ，则重新部署。（硬性要求）</li>\n<li>preferredDuringScheduling ：当 Pod 开始部署时，优先部署到符合条件的 Node 上。如果没有这样的 Node ，则部署到其它 Node 上。（软性要求）</li>\n<li>RequiredDuringExecution ：当 Pod 正在运行时，如果 Node 变得不满足条件，则重新部署。（硬性要求）</li>\n<li>IgnoredDuringExecution ：当 Pod 正在运行时，如果 Node 变得不满足条件，则忽略该问题，继续运行 Pod 。（软性要求）</li>\n</ul>\n</li>\n<li>例：</li>\n</ul>\n<div><pre><code><span>spec</span><span>:</span>\n  <span>affinity</span><span>:</span>\n    <span>nodeAffinity</span><span>:</span>\n      <span>requiredDuringSchedulingIgnoredDuringExecution</span><span>:</span>\n        <span>nodeSelectorTerms</span><span>:</span>\n        <span>-</span> <span>matchExpressions</span><span>:</span>\n          <span>-</span> <span>key</span><span>:</span> k1\n            <span>operator</span><span>:</span> In\n            <span>values</span><span>:</span>\n            <span>-</span> v1.0\n            <span>-</span> v1.1\n      <span>preferredDuringSchedulingIgnoredDuringExecution</span><span>:</span>\n      <span>-</span> <span>weight</span><span>:</span> <span>1</span>\n        <span>preference</span><span>:</span>\n          <span>matchExpressions</span><span>:</span>\n          <span>-</span> <span>key</span><span>:</span> k2\n            <span>operator</span><span>:</span> In\n            <span>values</span><span>:</span>\n            <span>-</span> v2\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div><ul>\n<li>上例中在 nodeAffinity 下定义了两个亲和性。</li>\n<li>nodeSelector 下的条件只要满足一个即可，matchExpressions 下的条件要全部满足。</li>\n<li>条件的 operator 可以是以下类型：\n<ul>\n<li>Exists ：Node 上存在该 key 。</li>\n<li>DoesNotExist ：与 Exists 相反。</li>\n<li>In ：Node 上存在该 key ，且其值在给定的列表中。</li>\n<li>NotIn ：与 In 相反。</li>\n<li>Gt ：Node 上存在该 key ，且其值大于给定值。</li>\n<li>Lt ：与 Gt 相反，是小于。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"taint、tolerations\"> Taint、Tolerations</h3>\n<ul>\n<li>Node Taint ：Node 的污点。</li>\n<li>Pod Tolerations ：Pod 的容忍度。\n<ul>\n<li>scheduler 不会在将 Pod 调度到有污点的节点上，除非 Pod 能容忍该污点。</li>\n<li>搭配使用污点和容忍度，可以限制某个 Pod 只能被调度到指定 Node 上。</li>\n</ul>\n</li>\n</ul>\n<p>例：</p>\n<ul>\n<li>给 Node 添加污点：<div><pre><code>kubectl taint nodes node1 <span>k1</span><span>=</span>v1:NoSchedule\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>在 Pod spec 中配置容忍度：<div><pre><code><span>spec</span><span>:</span>\n  <span>containers</span><span>:</span>\n    <span>...</span>\n  <span>tolerations</span><span>:</span>\n  <span>-</span> <span>key</span><span>:</span> <span>\"k1\"</span>\n    <span>operator</span><span>:</span> <span>\"Equal\"</span>\n    <span>value</span><span>:</span> <span>\"v1\"</span>\n    <span>effect</span><span>:</span> <span>\"NoSchedule\"</span>\n  <span>-</span> <span>key</span><span>:</span> <span>\"k2\"</span>\n    <span>operator</span><span>:</span> <span>\"Exists\"</span>\n    <span>effect</span><span>:</span> <span>\"PreferNoSchedule\"</span>\n  <span>-</span> <span>key</span><span>:</span> <span>\"k3\"</span>\n    <span>operator</span><span>:</span> <span>\"Exists\"</span>\n    <span>effect</span><span>:</span> <span>\"NoExecute\"</span>\n    <span>tolerationSeconds</span><span>:</span> <span>3600</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>污点的效果分为三种：\n<ul>\n<li>NoSchedule ：如果 Pod 不容忍该污点，则不部署到该 Node 上。如果已经部署了，则继续运行该 Pod 。</li>\n<li>PreferNoSchedule ：如果 Pod 不容忍该污点，则优先部署到其它 Node 上，不行的话才部署到该 Node 上。</li>\n<li>NoExecute ：如果 Pod 不容忍该污点，则不部署到该 Node 上。如果已经部署了，则驱除该 Pod 。\n<ul>\n<li>可以额外设置 tolerationSeconds ，表示即使 Pod 容忍该污点，也最多只能保留指定秒数，超时之后就会被驱除，除非在此期间该污点消失。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>在 Tolerations 中：\n<ul>\n<li>当 operator 为 Equal 时，如果 effect、key、value 与 Taint 的相同，则匹配该 Taint 。</li>\n<li>当 operator 为 Exists 时，如果 effect、key 与 Taint 的相同，则匹配该 Taint 。</li>\n<li>如果不指定 key ，则匹配 Taint 的所有 key 。</li>\n<li>如果不指定 effect ，则匹配 Taint 的所有 effect 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"pod-的生命周期\"> Pod 的生命周期</h2>\n<p>Pod 被 kubelet 启动、终止的大致流程：</p>\n<ul>\n<li>初始化：按顺序启动各个 init 容器。</li>\n<li>启动  ：启动主容器、sidecar 容器。</li>\n<li>运行  ：会被探针定期探测。</li>\n<li>终止  ：终止各个容器。</li>\n<li>重启  ：kubelet 会按照 restartPolicy 重启容器。</li>\n</ul>\n<h3 id=\"状态-3\"> 状态</h3>\n<p>以下是一个 Pod 对象的状态示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Pod\n<span>metadata</span><span>:</span>\n  <span>...</span>\n<span>spec</span><span>:</span>\n  <span>containers</span><span>:</span>\n    <span>...</span>\n  <span>restartPolicy</span><span>:</span> Always   <span># Pod 中的容器 restartPolicy</span>\n  <span>schedulerName</span><span>:</span> default<span>-</span>scheduler\n  <span>...</span>\n<span>status</span><span>:</span>\n  <span>conditions</span><span>:</span>             <span># Pod 的状态</span>\n  <span>-</span> <span>type</span><span>:</span> Initialized\n    <span>status</span><span>:</span> <span>\"True\"</span>        <span># 结合 type、status 来看，该 Pod 已初始化</span>\n    <span>lastProbeTime</span><span>:</span> <span>null</span>   <span># 上次探测状态的时刻</span>\n    <span>lastTransitionTime</span><span>:</span> <span>\"2019-12-24T08:20:23Z\"</span>  <span># 上次状态改变的时刻</span>\n  <span>-</span> <span>type</span><span>:</span> Ready\n    <span>status</span><span>:</span> <span>\"True\"</span>\n    <span>lastProbeTime</span><span>:</span> <span>null</span>\n    <span>lastTransitionTime</span><span>:</span> <span>\"2019-12-24T08:21:24Z\"</span>\n  <span>...</span>\n  <span>containerStatuses</span><span>:</span>      <span># 容器的状态</span>\n  <span>-</span> <span>containerID</span><span>:</span> docker<span>:</span>//2bc5f548736046c64a10d9162024ed102fba0565ff742e16cd032c7a1b75cc29\n    <span>image</span><span>:</span> harbor.test.com/test/redis<span>:</span>5.0.6_1577092536\n    <span>imageID</span><span>:</span> docker<span>-</span>pullable<span>:</span>//harbor.test.com/test/redis@sha256<span>:</span>db3c9eb0f9bc7143d5995370afc23f7434f736a5ceda0d603e0132b4a6c7e2cd\n    <span>name</span><span>:</span> redis\n    <span>ready</span><span>:</span> <span>true</span>\n    <span>restartCount</span><span>:</span> <span>0</span>\n    <span>state</span><span>:</span>\n      <span>running</span><span>:</span>\n        <span>startedAt</span><span>:</span> <span>\"2019-12-24T08:21:23Z\"</span>\n  <span>hostIP</span><span>:</span> 192.168.120.23\n  <span>podIP</span><span>:</span> 10.244.57.150\n  <span>phase</span><span>:</span> Running\n  <span>startTime</span><span>:</span> <span>\"2019-12-24T08:20:23Z\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br></div></div><ul>\n<li>\n<p>status.phase 记录了 Pod 目前处于生命周期的哪一阶段，有以下几种取值：</p>\n<ul>\n<li>Pending ：待定。此时 kubelet 正在部署该 Pod ，包括分配 Node、拉取镜像、启动容器等。</li>\n<li>Running ：运行中。此时 kubelet 已经启动了该 Pod 的所有容器。</li>\n<li>Succeeded ：Pod 中的所有容器都已经正常终止。</li>\n<li>Failed ：Pod 中的所有容器都已经终止，且至少有一个容器是异常终止。\n<ul>\n<li>Failed 的 Pod 会被 kubelet 自动重启，如果重启成功则会变回 Running 。</li>\n</ul>\n</li>\n<li>Unkown ：状态未知。例如与 Pod 所在节点通信失败时就会不知道状态。</li>\n</ul>\n</li>\n<li>\n<p>status.conditions 是一个数组，包含了对 Pod 多种状态条件的判断，如下：</p>\n<ul>\n<li>PodScheduled ：Pod 已被调度到一个节点上。</li>\n<li>Unschedulable ：Pod 不能被调度到节点上。可能是缺乏可用节点、缺乏挂载卷等资源。</li>\n<li>Initialized ：Pod 中的所有 init 容器都已成功启动（不管是否运行结束）。\n<ul>\n<li>运行 init 容器的过程中，Pod 处于 pending 阶段，Initialized 条件为 True 。</li>\n</ul>\n</li>\n<li>ContainersReady ：Pod 中的所有容器已成功启动。</li>\n<li>Ready ：Pod 处于就绪状态。此时 k8s 才允许该 Pod 被 Service 发现。</li>\n</ul>\n</li>\n<li>\n<p>status.containerStatuses.state 记录了容器的状态，有以下几种取值：</p>\n<ul>\n<li>waiting ：正在准备启动。比如拉取镜像、取用 ConfigMap ，或者等待重启。</li>\n<li>running ：正在运行。</li>\n<li>terminated ：已终止。</li>\n</ul>\n</li>\n<li>\n<p>Pod 的状态取决于容器的状态。因此，分析 Pod 的状态时，需要考虑更细单位的容器。</p>\n<ul>\n<li>kubelet 创建一个容器之后，还要等容器中的业务进程成功启动，这个容器才算真正启动。可以通过 postStart 判断容器是否已创建，通过 readinessProbe 判断容器是否已成功启动。</li>\n<li>当 Pod 中的所有容器都处于 running 状态时，Pod 才能处于 Running 状态。</li>\n<li>当 Pod 中有某个容器处于 terminated 状态时，kubelet 会按照 restartPolicy 重启它。在重启完成之前，Pod 都处于 Unavailable 状态。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"探针\"> 探针</h3>\n<p>探针：又称为健康检查。在 spec.contaienrs 中定义，用于定期探测容器是否在正常运行。</p>\n<ul>\n<li>探针每次的探测结果有三种：\n<ul>\n<li>Success ：容器在正常运行。</li>\n<li>Failure ：容器没在正常运行。此时 kubelet 会按照 restartPolicy 重启它。</li>\n<li>Unknown ：未知结果，此时不采取行动。</li>\n</ul>\n</li>\n<li>探针有三种用途：\n<ul>\n<li>startupProbe ：启动探针，用于探测容器是否已成功启动。</li>\n<li>readinessProbe ：就绪探针，用于探测容器是否处于就绪状态，可以开始工作。</li>\n<li>livenessProbe ：存活探针，用于探测容器是否在正常运行。</li>\n</ul>\n</li>\n<li>探针的影响：\n<ul>\n<li>如果用户没定义探针，则容器刚创建时，可能尚未成功启动业务进程，kubelet 就会认为容器处于就绪状态，进而认为 Pod 处于就绪状态，提前接入 Service 的访问流量。</li>\n<li>如果 readinessProbe 的结果为 Farlure ，则 k8s 会认为该容器所属的 Pod 不处于就绪状态，不允许被 Service 发现。</li>\n<li>如果 startupProbe、livenessProbe 的结果为 Farlure ，则 k8s 会按照 restartPolicy 重启容器。</li>\n</ul>\n</li>\n<li>探针有三种实现方式：\n<ul>\n<li>ExecAction ：在容器中执行指定的命令，如果命令的退出码为 0 ，则检查结果为 Success 。</li>\n<li>TCPSocketAction ：访问容器的指定端口，如果能建立 TCP 连接，则检查结果为 Success 。</li>\n<li>HTTPGetAction ：向容器的指定 URL 发出 HTTP GET 请求，如果收到响应报文，且状态码为 2xx 或 3xx ，则检查结果为 Success 。</li>\n</ul>\n</li>\n</ul>\n<p>例：</p>\n<div><pre><code><span>contaienrs</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> redis\n  <span>livenessProbe</span><span>:</span>            <span># 定义 livenessProbe 用途、ExecAction 方式的探针</span>\n    <span>exec</span><span>:</span>\n      <span>command</span><span>:</span>              <span># 每次探测时，在容器中执行命令：ls /tmp/health</span>\n      <span>-</span> ls\n      <span>-</span> /tmp/health         <span># 可见，当/tmp/health 文件存在时，探测结果才会为 Success</span>\n    <span>initialDelaySeconds</span><span>:</span> <span>5</span>  <span># 容器刚创建之后，等待几秒才开始第一次探测（用于等待容器成功启动）</span>\n    <span>periodSeconds</span><span>:</span> <span>3</span>        <span># 每隔几秒探测一次</span>\n    <span>timeoutSeconds</span><span>:</span> <span>1</span>       <span># 每次探测的超时时间</span>\n    <span>failureThreshold</span><span>:</span> <span>3</span>     <span># 容器正常运行时，连续多少次探测为 Failure ，才判断容器为 Failure</span>\n    <span>successThreshold</span><span>:</span> <span>1</span>     <span># 容器启动时，或发现异常时，连续多少次探测为 Success ，才判断容器为 Success</span>\n  <span>readinessProbe</span><span>:</span>           <span># 定义 readinessProbe 用途、TCPSocketAction 方式的探针</span>\n    <span>tcpSocket</span><span>:</span>\n      <span>port</span><span>:</span> <span>8080</span>\n    <span>periodSeconds</span><span>:</span> <span>3</span>\n  <span>livenessProbe</span><span>:</span>            <span># 定义 livenessProbe 用途、HTTPGetAction 方式的探针</span>\n    <span>httpGet</span><span>:</span>\n      <span>path</span><span>:</span> /health\n      <span>port</span><span>:</span> <span>8080</span>\n      <span>httpHeaders</span><span>:</span>          <span># 添加请求报文的 Headers</span>\n      <span>-</span> <span>name</span><span>:</span> X<span>-</span>Custom<span>-</span>Header\n        <span>value</span><span>:</span> hello\n    <span>periodSeconds</span><span>:</span> <span>3</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br></div></div><h3 id=\"poststart、prestop\"> postStart、preStop</h3>\n<p>可以给 Pod 中的单个容器定义 postStart、preStop 钩子，在启动、终止过程中增加操作。如下：</p>\n<div><pre><code><span>contaienrs</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> redis\n  <span>lifecycle</span><span>:</span>\n    <span>postStart</span><span>:</span>\n      <span>exec</span><span>:</span>\n        <span>command</span><span>:</span>\n        <span>-</span> /bin/bash\n        <span>-</span> <span>-</span>c\n        <span>-</span> echo hello ; sleep 1\n    <span>preStop</span><span>:</span>\n      <span>exec</span><span>:</span>\n        <span>command</span><span>:</span>\n        <span>-</span> /bin/bash\n        <span>-</span> <span>-</span>c\n        <span>-</span> redis<span>-</span>cli shutdown\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>kubelet 刚创建一个容器之后，会立即执行其 postStart 钩子。\n<ul>\n<li>postStart 与容器的 ENTRYPOINT 是异步执行的，因此执行顺序不能确定。不过只有等 postStart 执行完成之后，k8s 才会将容器的状态标为 Running 。</li>\n</ul>\n</li>\n<li>kubelet 终止一个容器时，会先执行其 preStop 钩子。超过宽限期之后会发送 SIGTERM 信号并再宽限 2 秒，最后才发送 SIGKILL 信号。\n<ul>\n<li>没有定义 preStop 时，kubelet 会采用默认的终止方式：先向 Pod 中的所有容器的进程发送 SIGTERM 信号，并将 Pod 的状态标识为 Terminating 。超过宽限期（grace period ，默认为 30 秒）之后，如果仍有进程在运行，则发送 SIGKILL 信号，强制终止它们。</li>\n<li>这里说的终止是指容器被 kubelet 主动终止，不包括容器自己运行结束的情况。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"重启\"> 重启</h3>\n<p>容器的重启策略分为以下几种：</p>\n<ul>\n<li><code>restartPolicy: Always</code> ：当容器终止时，或者被探针判断为 Failure 时，总是会自动重启。这是默认策略。</li>\n<li><code>restartPolicy: OnFailure</code> ：只有当容器异常终止时，才会自动重启。</li>\n<li><code>restartPolicy: Never</code> ：总是不会自动重启。</li>\n</ul>\n<p>当容器重启时，</p>\n<ul>\n<li>如果多次重启失败，重启的间隔时间将按 10s、20s、40s 的形式倍增，上限为 5min 。当容器成功运行 10min 之后会重置。</li>\n<li>容器只会在当前 Node 上重启，除非因为 Node 故障等原因触发了主机调度。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Volume",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/Volume.html",
      "id": "/Hardware/DevOps/Container/k8s/Volume.html",
      "content_html": "<h1 id=\"volume\"> Volume</h1>\n<p>：存储卷。</p>\n<ul>\n<li>将 Volume 挂载到 Pod 中的某个目录之后，即使 Pod 被销毁，该目录下的文件依然会被持久化保存。</li>\n<li>同一个 Pod 中的多个容器会共享 Volume ，可通过 Volume 共享文件。</li>\n<li>给一个 Pod 挂载多个 Volume 时，它们的挂载目录不能重复。</li>\n</ul>\n<p>Docker 中的 Volume 概念比较简单，只是挂载宿主机的目录到容器中。而 k8s 中的 Volume 概念比较复杂，分为很多种类型，比如：hostPath、nfs、PVC、secret 等。</p>\n<h2 id=\"storageclass\"> StorageClass</h2>\n<p>：存储类。</p>\n<ul>\n<li>将不同的物理存储器抽象为存储类，相当于 PV 的模板。</li>\n</ul>\n<h2 id=\"persistent-volume-pv\"> Persistent Volume（PV）</h2>\n<p>：持久存储卷。</p>\n<ul>\n<li>一个存储类（Volume Class）上可以创建多个 PV 。</li>\n</ul>\n<p>PV 的访问模式：</p>\n<ul>\n<li>ReadWriteOnce ：被单主机读写。如果多个 Pod 运行在同一主机，则可以同时读写。</li>\n<li>ReadOnlyMany ：被多主机只读</li>\n<li>ReadWriteMany ：被多主机读写</li>\n<li>ReadWriteOncePod ：在 ReadWriteOnce 的基础上，限制了只能被单个 Pod 读写。</li>\n</ul>\n\n<h2 id=\"persistentvolumeclaim-pvc\"> PersistentVolumeClaim（PVC）</h2>\n<p>：持久存储卷声明，代表用户使用存储卷的请求。</p>\n<ul>\n<li>当用户给 Pod 挂载 PVC 时，k8s 会寻找符合该 PVC 需求的 PV ，\n<ul>\n<li>如果找到了，就把该 PV 与 PVC 一对一绑定，然后挂载到 Pod 上。</li>\n<li>如果没找到，则不能部署该 Pod 。</li>\n</ul>\n</li>\n</ul>\n<p>配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> PersistentVolumeClaim\n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> pvc1\n<span>spec</span><span>:</span>\n  <span>accessModes</span><span>:</span>\n    <span>-</span> ReadWriteMany   <span># 该 PVC 的访问模式</span>\n  <span>resources</span><span>:</span>\n    <span>requests</span><span>:</span>\n      <span>storage</span><span>:</span> 10Gi   <span># 该 PVC 需要的存储空间</span>\n  <span>storageClassName</span><span>:</span> local<span>-</span>volume  <span># 该 PVC 需要的存储类</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><p>例：在 Deployment 中挂载 PVC</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Deployment\n<span>spec</span><span>:</span>\n  <span>template</span><span>:</span>\n    <span>spec</span><span>:</span>\n      <span>containers</span><span>:</span>\n      <span>-</span> <span>name</span><span>:</span> redis\n        <span>image</span><span>:</span> redis<span>:</span>5.0.6\n        <span>volumeMounts</span><span>:</span>\n            <span>-</span> <span>name</span><span>:</span> volume1\n              <span>mountPath</span><span>:</span> /opt/volume    <span># 将 volume1 挂载到该目录</span>\n      <span>volumes</span><span>:</span>\n      <span>-</span> <span>name</span><span>:</span> volume1    <span># 创建一个名为 volume1 的 Volume ，基于 pvc1</span>\n        <span>persistentVolumeClaim</span><span>:</span>\n          <span>claimName</span><span>:</span> pvc1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><h2 id=\"configmap\"> ConfigMap</h2>\n<p>：用于保存配置信息，采用键值对格式，以明文形式保存在 etcd 中。</p>\n<ul>\n<li>可以在 Deployment 等控制器中引用 ConfigMap ，导入其中的参数作为环境变量，或 Volume 。</li>\n<li>修改 ConfigMap 时，不会导致挂载它的 Pod 自动重启。</li>\n</ul>\n<p>配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> ConfigMap \n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis<span>-</span>config\n<span>data</span><span>:</span>\n  <span>k1</span><span>:</span> hello\n  <span>k2</span><span>:</span> world\n  <span>redis.conf</span><span>:</span> <span>|</span><span>-</span>\n    bind 0.0.0.0\n    port 6379\n    daemonize yes\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>data 部分可以包含多个键值对。用 <code>|-</code> 声明的是文件内容。</li>\n<li>一个 ConfigMap 中可以保存多个配置文件。</li>\n</ul>\n<p>例：引用 ConfigMap 中的参数，生成环境变量</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Deployment\n<span>spec</span><span>:</span>\n  <span>template</span><span>:</span>\n    <span>spec</span><span>:</span>\n      <span>containers</span><span>:</span>\n      <span>-</span> <span>name</span><span>:</span> redis\n        <span>image</span><span>:</span> redis<span>:</span>5.0.6\n        <span>command</span><span>:</span> <span>[</span><span>\"echo\"</span><span>,</span> <span>\"$K1\"</span><span>,</span> <span>\"$K2\"</span><span>]</span> <span># 使用环境变量</span>\n        <span>env</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> K1                      <span># 创建一个环境变量 K1 ，</span>\n          <span>valueFrom</span><span>:</span>                    <span># 它的取值为，</span>\n            <span>configMapKeyRef</span><span>:</span>\n              <span>name</span><span>:</span> redis<span>-</span>config        <span># 名为 redis-config 的 ConfigMap 中，</span>\n              <span>key</span><span>:</span> k1                   <span># 参数 k1 的值</span>\n        <span>-</span> <span>name</span><span>:</span> K2\n          <span>valueFrom</span><span>:</span>\n            <span>configMapKeyRef</span><span>:</span>\n              <span>name</span><span>:</span> redis<span>-</span>config\n              <span>key</span><span>:</span> k2\n        <span>envFrom</span><span>:</span>\n        <span>-</span> <span>configMapRef</span><span>:</span>\n            <span>name</span><span>:</span> redis<span>-</span>config          <span># 导入名为 redis-config 的 ConfigMap 中的所有参数，生成环境变量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></div></div><p>例：引用 ConfigMap 中的参数，生成 Volume 并挂载</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Deployment\n<span>spec</span><span>:</span>\n  <span>template</span><span>:</span>\n    <span>spec</span><span>:</span>\n      <span>containers</span><span>:</span>\n      <span>-</span> <span>name</span><span>:</span> redis\n        <span>image</span><span>:</span> redis<span>:</span>5.0.6\n        <span>volumeMounts</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> volume1\n          <span>mountPath</span><span>:</span> /opt/redis/volume1     <span># 将名为 volume1 的存储卷挂载到该目录</span>\n        <span>-</span> <span>name</span><span>:</span> volume2\n          <span>mountPath</span><span>:</span> /opt/redis/volume2\n      <span>volumes</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> volume1             <span># 创建一个名为 volume1 的 Volume</span>\n          <span>configMap</span><span>:</span>\n            <span>name</span><span>:</span> redis<span>-</span>config      <span># 引用名为 redis-config 的 ConfigMap 中，</span>\n            <span>items</span><span>:</span>\n            <span>-</span> <span>key</span><span>:</span> sentinel.conf    <span># 参数 sentinel.conf 的值</span>\n              <span>path</span><span>:</span> sentinel.conf   <span># 将该参数的值保存到 mountPath/path 文件中</span>\n        <span>-</span> <span>name</span><span>:</span> volume2             <span># 创建一个名为 volume2 的 Volume</span>\n          <span>configMap</span><span>:</span>\n            <span>name</span><span>:</span> redis<span>-</span>config      <span># 导入名为 redis-config 的 ConfigMap 中的所有参数，生成 Volume</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></div></div><h2 id=\"secret\"> Secret</h2>\n<p>：与 ConfigMap 类似，但用于保存密码等私密信息。</p>\n<ul>\n<li>保存时会自动将参数值转换成 Base64 编码，挂载时会自动从 Base64 解码。</li>\n</ul>\n<p>配置示例：</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Secret \n<span>metadata</span><span>:</span>\n  <span>name</span><span>:</span> redis<span>-</span>secret\n<span>type</span><span>:</span> Opaque\n<span>data</span><span>:</span>\n  <span>username</span><span>:</span> bGVvCg==\n  <span>password</span><span>:</span> MTIzNDU2Cg==\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><p>例：引用 secret 中的参数，生成环境变量、Volume</p>\n<div><pre><code><span>apiVersion</span><span>:</span> v1\n<span>kind</span><span>:</span> Deployment\n<span>spec</span><span>:</span>\n  <span>template</span><span>:</span>\n    <span>spec</span><span>:</span>\n      <span>containers</span><span>:</span>\n      <span>-</span> <span>name</span><span>:</span> redis\n        <span>image</span><span>:</span> redis<span>:</span>5.0.6\n        <span>env</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> username\n          <span>valueFrom</span><span>:</span>\n            <span>secretKeyRef</span><span>:</span>\n              <span>name</span><span>:</span> redis<span>-</span>secret\n              <span>key</span><span>:</span> username\n        <span>volumeMounts</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> volume1\n          <span>mountPath</span><span>:</span> /opt/redis/secret\n      <span>volumes</span><span>:</span>\n        <span>-</span> <span>name</span><span>:</span> volume1\n          <span>secret</span><span>:</span>\n            <span>secretName</span><span>:</span> redis<span>-</span>secret\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "部署",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/deploy.html",
      "id": "/Hardware/DevOps/Container/k8s/deploy.html",
      "content_html": "<h1 id=\"部署\"> 部署</h1>\n<ul>\n<li>\n<p>可使用官方的部署工具 kubeadm ，部署标准的 k8s 。</p>\n</li>\n<li>\n<p>也可部署其它 k8s 发行版。它们在 k8s 的基础上封装了其它组件，比如 Web UI、网络插件。</p>\n<ul>\n<li>minikube ：用于部署测试用途的 k8s 。</li>\n<li>Rancher ：由 Rancher Labs 公司开源。</li>\n<li>OpenShift ：由 Red Hat 公司开源。</li>\n<li>kubesphere ：由青云公司开源。</li>\n<li>KubeOperator ：由飞致云公司开源。</li>\n</ul>\n</li>\n<li>\n<p>也可使用云平台托管的 k8s 发行版，不需要用户部署维护。</p>\n<ul>\n<li>Elastic Kubernetes Service（EKS）：由 AWS 云提供。</li>\n<li>Azure Kubernetes Service（AKS）：由 Azure 云提供。</li>\n<li>Google Kubernetes Engine（GKE）：由 Google 云提供。</li>\n<li>Tencent Kubernetes Engine（TKE）：由腾讯云提供。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"kubeadm\"> kubeadm</h2>\n<p>：一个命令行工具，用于部署标准的 k8s 集群。</p>\n<ul>\n<li>本身不会安装 kubelet、kubectl、网络插件。</li>\n</ul>\n<h3 id=\"安装\"> 安装</h3>\n<ul>\n<li>用 yum 安装：<div><pre><code><span># 采用阿里的镜像源，因为谷歌的镜像源需要翻墙访问</span>\n<span>cat</span> <span>&lt;&lt;</span><span>EOF<span> <span>></span> /etc/yum.repos.d/kubernetes.repo</span>\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF</span>\n\n<span># 安装</span>\nyum <span>install</span> -y kubeadm\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>这会同时安装依赖的 kubelet、kubectl 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"命令\"> 命令</h3>\n<div><pre><code>kubeadm\n        version\n        config        <span># 管理配置。这些配置会保存为一个名为 kubeadm-config 的 ConfigMap ，位于 kube-system 命名空间</span>\n          print       <span># 打印配置</span>\n            init-defaults\n            join-defaults\n\n        init          <span># 将本机初始化为主节点</span>\n        <span>join</span>          <span># 使本机连接到主节点，加入 k8s 集群</span>\n        reset         <span># 撤销 init、join 命令对本机的影响</span>\n\n        token         <span># 管理 token ，用于一个节点 join 主节点时的认证</span>\n          create\n            --ttl     <span># 有效时长，过期则自动删除。默认为 24h</span>\n          delete <span>&lt;</span>token<span>></span><span>..</span>.\n          list\n\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div><h3 id=\"部署-2\"> 部署</h3>\n<ol>\n<li>\n<p>部署 k8s 时，主机需要满足以下条件：</p>\n<ul>\n<li>至少 2v CPU、2G RAM 。\n<ul>\n<li>空载时，主节点的全部进程大概占用 500M 内存，而工作节点的 kubelet 占用 100M 内存。</li>\n</ul>\n</li>\n<li>禁用 Swap 分区。</li>\n<li>每个主机的 hostname、MAC 地址不同。</li>\n<li>安装 docker 引擎。\n<ul>\n<li>dockerd 采用的 Cgroup 驱动默认为 cgroupfs ，而 k8s 默认为 systemd 。因此需要修改 dockerd 的配置，并重启 dockerd ：<div><pre><code><span>{</span>\n  <span>\"exec-opts\"</span><span>:</span> <span>[</span><span>\"native.cgroupdriver=systemd\"</span><span>]</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n<li>主机的防火墙开通了 k8s 所需的端口 6443、10250 。</li>\n<li>在集群的一个主机上安装 kubeadm、kubectl 。</li>\n<li>在集群的每个主机上安装 kubelet ，并启动：<div><pre><code>systemctl start  kubelet\nsystemctl <span>enable</span> kubelet\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>下载 Docker 镜像：</p>\n<div><pre><code>kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>在一个主机上执行以下命令，初始化为主节点：</p>\n<div><pre><code>kubeadm init\n            --config                            <span># 指定配置文件</span>\n            --kubernetes-version <span>&lt;</span>string<span>></span>       <span># k8s 版本。默认为最新的 stable 版本</span>\n            --image-repository registry.aliyuncs.com/google_containers  <span># 镜像仓库，默认为 k8s.gcr.io ，但它需要翻墙访问</span>\n            --node-name <span>&lt;</span>name<span>></span>                  <span># 指定当前节点名</span>\n            --pod-network-cidr <span>10.244</span>.0.0/16    <span># Pod IP 的子网范围，也会被用于设置 cluster-cidr 。默认为空，不会分配 CIDR</span>\n            --service-cidr <span>&lt;</span>string<span>></span>             <span># Service IP 的子网范围，默认为 10.96.0.0/12</span>\n            --service-dns-domain <span>&lt;</span>string<span>></span>       <span># Service 的域名起点，默认为 cluster.local</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>这会生成管理员的 kubeconfig 配置文件，将它拷贝到默认路径：<div><pre><code><span>mkdir</span> -p ~/.kube\n<span>cp</span> /etc/kubernetes/admin.conf ~/.kube/config\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>在其它主机上执行以下命令，加入 k8s 集群：</p>\n<div><pre><code>kubeadm <span>join</span> <span>10.0</span>.0.1:6443\n      --token ****** --discovery-token-ca-cert-hash sha256:******   <span># 加入集群时需要使用 token 认证</span>\n      --control-plane     <span># 加入之后成为控制平面节点，默认是工作节点</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>至少需要部署一个主节点和一个工作节点。</li>\n<li>默认给主节点设置了污点，不允许用作工作节点，降低主节点故障的风险。可以移除污点：<div><pre><code>kubectl taint nodes --all node-role.kubernetes.io/master-\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>部署多个主节点时，可以实现 k8s 的高可用。\n<ul>\n<li>此时需要给多个 kube-apiserver 实例创建一个负载均衡 IP 或 DNS ，用于访问。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>启用一种 CNI 网络插件：</p>\n<div><pre><code><span>curl</span> https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml <span>|</span> kubectl apply -f -\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n<h2 id=\"kubectl\"> kubectl</h2>\n<p>：一个命令行工具，用于管理已部署的 k8s 集群。</p>\n<h3 id=\"安装-2\"> 安装</h3>\n<ul>\n<li>下载二进制文件：<div><pre><code><span>wget</span> https://dl.k8s.io/release/v1.23.1/bin/linux/amd64/kubectl\n<span>sudo</span> <span>install</span> kubectl /usr/local/bin/\n\nkubectl completion <span>bash</span> <span>></span> /etc/bash_completion.d/kubectl  <span># 启用 kubectl 命令补全，保存为 bash_completion 脚本</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>kubectl 命令通过访问 kube-apiserver 来控制 k8s 集群，此时需要读取一种配置文件，称为 kubeconfig 。\n<ul>\n<li>kubeconfig 配置了要连接的 kube-apiserver 地址，以及使用的集群名、命名空间、账号。</li>\n<li>默认读取 ~/.kube/config 文件作为 kubeconfig ，也可以在执行命令时加上 <code>--kubeconfig &lt;path&gt;</code> 参数，或声明环境变量 <code>export KUBECONFIG=&lt;path&gt;</code> 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"命令-2\"> 命令</h3>\n<div><pre><code>kubectl\n        <span># 查看集群</span>\n        cluster-info      <span># 显示集群信息</span>\n        version           <span># 显示 client 和 server 的版本</span>\n        config            <span># 访问 kubeconfig</span>\n            view          <span># 显示 kubeconfig 的内容</span>\n              --raw       <span># 是否显示完整内容，默认省略 token</span>\n        proxy             <span># 运行一个 HTTP 服务器，反向代理 apiserver</span>\n            --port<span>=</span><span>8001</span>\n            --address<span>=</span><span>127.0</span>.0.1     <span># 监听的地址</span>\n            --accept-hosts<span>=</span><span>'^localhost$,^127\\.0\\.0\\.1$'</span> <span># 允许 HTTP 请求采用的目标地址，采用正则匹配</span>\n\n        <span># 修改资源</span>\n        create                      <span># 创建资源</span>\n            -f <span>&lt;</span>file<span>></span>               <span># 指定一个配置文件。不支持指定多个文件，支持指定配置文件的 URL</span>\n            -f <span>&lt;</span>dir<span>></span>                <span># 指定一个目录，读取其下所有文件</span>\n              -R                    <span># 递归处理目录</span>\n        replace                     <span># 替换资源的配置文件。如果该资源不存在则报错</span>\n            -f <span>&lt;</span>file<span>></span>\n            --force                 <span># 先删除旧资源，再创建</span>\n        apply                       <span># 更新资源的配置文件。如果该资源不存在则自动创建，如果该资源没有变化则显示 unchanged</span>\n            -f <span>&lt;</span>file<span>></span>\n        patch -p <span>'{\"spec\":{\"unschedulable\":true}}'</span>  <span># 更新资源的配置文件中的指定字段，而不是修改整个配置文件</span>\n        delete                      <span># 删除资源</span>\n            -f <span>&lt;</span>file<span>></span>               <span># 删除配置文件中指定的资源</span>\n            pod <span>&lt;</span>name<span>></span><span>..</span>.           <span># 删除指定名称的 pod</span>\n            deployment <span>&lt;</span>name<span>></span><span>..</span>.    <span># 删除指定名称的 deployment</span>\n\n        <span># 查看资源</span>\n        describe <span>&lt;</span>resource<span>></span>         <span># 查看资源的信息，包括主要配置、event</span>\n        get <span>&lt;</span>resource<span>></span> <span>[</span>name<span>]</span><span>..</span>.    <span># 查看资源的信息。不指定 name 则显示这种资源的所有实例</span>\n            --kubeconfig ~/.kube/config <span># 指定 kubeconfig 的文件路径</span>\n            -n default              <span># --namespace ，指定命名空间，只查看该命名空间中的资源</span>\n            -A                      <span># --all-namespaces ，查看所有命名空间</span>\n            -l <span>key1</span><span>=</span>value1,<span>..</span>.      <span># --selector ，根据标签筛选</span>\n            --field-selector status.phase<span>!=</span>Running  <span># 根据字段筛选</span>\n\n            -o wide                 <span># --output ，输出格式。默认显示列表格式的简介，wide 是显示更多列</span>\n            -o name                 <span># 只显示名称</span>\n            -o json                 <span># 显示 JSON 格式的详细配置</span>\n            -o yaml                 <span># 显示 YAML 格式的详细配置</span>\n            -o template --template<span>=</span><span>{</span><span>{</span>.spec.replicas<span>}</span><span>}</span> <span># 按自定义的 Golang 模板显示</span>\n\n        <span># 管理 pod</span>\n        expose                      <span># 创建 service ，映射端口</span>\n        <span>exec</span> <span>&lt;</span>pod<span>></span> -- <span>&lt;</span>command<span>></span>     <span># 在 pod 中执行命令。注意在 command 之前加上分隔符 --</span>\n            -c <span>&lt;</span>name<span>></span>               <span># --container ，选择 pod 中的某个容器。默认选择第一个容器</span>\n            -it                     <span># 进入容器内终端</span>\n        restart <span>&lt;</span>pod<span>></span><span>..</span>.            <span># 重启 pod ，实际上是创建新 Pod</span>\n        rollout restart <span>&lt;</span>daemonset<span>|</span>deployment<span>|</span>statefulset<span>></span> <span>&lt;</span>name<span>></span><span>..</span>.  <span># 滚动重启 pod 。这会异步地根据 spec.strategy 创建新 pod</span>\n        scale <span>&lt;</span>deployment<span>|</span>statefulset<span>></span> <span>&lt;</span>name<span>></span><span>..</span>. --replicas<span>=</span><span>0</span>         <span># 改变某个应用的 Pod 的数量</span>\n        logs <span>&lt;</span>pod<span>></span>                  <span># 查看日志</span>\n            -c <span>&lt;</span>name<span>></span>               <span># --container ，选择 pod 中的某个容器</span>\n            --all-containers        <span># 选择 pod 中的所有容器</span>\n            -f                      <span># --follow ，保持显示</span>\n            --tail <span>10</span>               <span># 只显示最后几行。默认从头开始显示</span>\n            --timestamps            <span># 增加显示时间戳</span>\n            --since 1h              <span># 只显示最近一段时间的日志</span>\n            --since-time <span>2021</span>-01-01T08:00:00Z <span># 只显示指定时刻开始的日志</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br></div></div><ul>\n<li>resource 类型可以是 nodes、pods、services 等。\n<ul>\n<li>不区分单复数，比如 node 等价于 nodes 。</li>\n<li>支持通过逗号分隔符指定多个，比如 nodes,pods 。</li>\n</ul>\n</li>\n<li>例：<div><pre><code>kubectl create deployment nginx --image<span>=</span>nginx:1.20          <span># 部署一个应用</span>\nkubectl <span>exec</span> nginx-6d777db949-5b77c -c nginx -it -- <span>bash</span>    <span># 进入容器内终端</span>\nkubectl expose deployment nginx --port<span>=</span><span>80</span> --target-port<span>=</span><span>80</span>  <span># 为应用 Nginx 创建 service ，默认为 ClusterIP 类型，并映射端口</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>关于配置文件的版本：\n<ul>\n<li>用户修改配置文件时可以指定 resourceVersion 字段，如果与 k8s 存储的不同，则说明用户不是在最新版本上编辑，会被 k8s 拒绝。\n<ul>\n<li>如果省略 resourceVersion ，或者采用 kubectl patch 方式，则不会检查版本。</li>\n</ul>\n</li>\n<li>kubectl apply 可能会在 annotations 中增加一个 <code>kubectl.kubernetes.io/last-applied-configuration</code> 字段，记录资源的当前配置，用于比较差异，找出更新了哪些字段。</li>\n<li>Deployment 资源还会增加一个 generation 字段，用于记录版本序号。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"minikube\"> minikube</h2>\n<p>：一个命令行工具，用于部署单节点的 k8s 集群，常用于测试。</p>\n<ul>\n<li>可以在本机部署多个 k8s 集群。每个 k8s 集群位于一个容器内，包含多个进程。</li>\n</ul>\n<h3 id=\"部署-3\"> 部署</h3>\n<ol>\n<li>\n<p>安装 docker</p>\n</li>\n<li>\n<p>下载 minikube ：</p>\n<div><pre><code><span>wget</span> https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\n<span>sudo</span> <span>install</span> minikube-linux-amd64 /usr/local/bin/\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>以非 root 用户部署 k8s ：</p>\n<div><pre><code><span>useradd</span> leo\n<span>usermod</span> leo -G <span>docker</span>\n<span>su</span> - leo\nminikube start\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>在本机安装 kubectl ，或使用 minikube 内置的 kubectl ：</p>\n<div><pre><code>minikube kubectl -- get pods -A\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n<h3 id=\"命令-3\"> 命令</h3>\n<div><pre><code>minikube\n        start                             <span># 部署一个 k8s 集群</span>\n            -p <span>&lt;</span>name<span>></span>                     <span># --profile ，指定 k8s 集群的名称，默认为 minikube</span>\n            --driver <span>docker</span>               <span># 驱动，默认会自动选择</span>\n            --kubernetes-version v1.2.3   <span># k8s 版本。默认为最新的 stable 版本</span>\n        stop\n        delete          <span># 删除当前 k8s 集群</span>\n            -p <span>&lt;</span>name<span>></span>   <span># 指定 k8s 集群的名称</span>\n            --all       <span># 删除所有 k8s 集群</span>\n        pause           <span># 暂停运行</span>\n        unpase\n\n        profile         <span># 显示当前 k8s 集群的名称</span>\n            list        <span># 显示所有 k8s 集群</span>\n        status\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><h2 id=\"rancher\"> Rancher</h2>\n<p>：一个 Web 网站，可以创建、管理多个 k8s 集群。</p>\n<ul>\n<li><a href=\"https://rancher.com/docs/rancher/v2.6/en/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Golang 开发。</li>\n<li>架构：\n<ul>\n<li>先部署 Rancher server 。</li>\n<li>然后在一些主机上运行 Rancher agent ，连接到 server ，被 server 控制。\n<ul>\n<li>Rancher 可以在多个主机上创建、管理多个 k8s 集群，称为下游集群。也可以导入已部署的集群。</li>\n<li>当 Rancher server 故障时，下游集群依然会正常运行，可以被用户直接访问。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Rancher 提供了多种 k8s 发行版：\n<ul>\n<li>RKE（Rancher Kubernetes Engine）：一个 k8s 发行版。包含了一个命令行工具，用于部署 k8s 。</li>\n<li>k3s ：一个轻量级的 k8s 发行版。\n<ul>\n<li>主节点只需运行 k3s server 进程，工作节点只需运行 k3s agent 进程。</li>\n<li>默认采用 sqlite3 作为数据库。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"部署-4\"> 部署</h3>\n<ul>\n<li>\n<p>用 docker 部署一个单节点的 Rancher ：</p>\n<div><pre><code><span>docker</span> run -d <span>\\</span>\n    -p <span>80</span>:80 -p <span>443</span>:443 <span>\\</span>\n    --name rancher <span>\\</span>\n    --privileged <span>\\</span>\n    rancher/rancher:v2.6.3-linux-amd64\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>此时 Rancher 会在容器内运行一个 k3s 集群。</li>\n</ul>\n</li>\n<li>\n<p>或者在 k8s 中用 helm 部署单节点的 Rancher 。也可以部署成多节点，实现高可用。</p>\n</li>\n</ul>\n<h3 id=\"配置\"> 配置</h3>\n<ul>\n<li>Rancer 增加了项目（project）的概念，用于对命名空间分组。</li>\n<li>可以让 Rancher 采用私有的镜像仓库。</li>\n<li>Rancher 默认在 default 命名空间创建了一个 kubernetes 服务，用于反向代理 apiserver ，访问地址为 <code>https://10.43.0.1:443</code> 。</li>\n<li>Rancher 的默认配置：<div><pre><code><span>services</span><span>:</span>\n  <span>kube-api</span><span>:</span>\n    <span>service_cluster_ip_range</span><span>:</span> 10.43.0.0/16\n    <span>service_node_port_range</span><span>:</span> 30000<span>-</span><span>32767</span>\n  <span>kube-controller</span><span>:</span>\n    <span>cluster_cidr</span><span>:</span> 10.42.0.0/16              <span># Pod IP 的子网范围</span>\n    <span>extra_args</span><span>:</span>\n      <span>node-cidr-mask-size</span><span>:</span> <span>'24'</span>             <span># 每个 Node 的子网掩码长度</span>\n    <span>service_cluster_ip_range</span><span>:</span> 10.43.0.0/16  <span># Service IP 的子网范围</span>\n  <span>kubelet</span><span>:</span>\n    <span>cluster_domain</span><span>:</span> cluster.local\n    <span>cluster_dns_server</span><span>:</span> 10.43.0.10\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Kubernetes",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Container/k8s/",
      "id": "/Hardware/DevOps/Container/k8s/",
      "content_html": "<h1 id=\"kubernetes\"> Kubernetes</h1>\n<p>：一个大型的容器编排系统，采用 Golang 开发。</p>\n<ul>\n<li><a href=\"https://kubernetes.io/docs\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>简称为 k8s ，8 表示中间的 8 个字母。</li>\n<li>用于管理大量主机上的大量容器，进行自动编排。\n<ul>\n<li>传统部署方式中，每个主机专用于部署某个项目，且项目暂时停用时也不能收回主机，因此资源冗余大。</li>\n<li>使用 k8s 部署时，可以自动寻找空闲的主机，部署容器化的应用，提高资源使用率。。</li>\n</ul>\n</li>\n<li>支持 Linux、MacOS、Windows 系统。</li>\n<li>提供了滚动更新、一键回滚、服务发现、负载均衡、自动伸缩等功能，提高部署效率。</li>\n</ul>\n<h2 id=\"版本\"> 版本</h2>\n<ul>\n<li>2014 年，Google 公司开源了 k8s 项目，它借鉴了 Google 内部的大规模集群管理系统 Borg、Omega 。</li>\n<li>2015 年，Google 公司将 k8s 项目捐赠给 Linux 基金会下属的云原生计算基金会（CNCF）托管。</li>\n<li>v1.20\n<ul>\n<li>2020 年 12 月发布。</li>\n<li>CRI 不再支持 Docker 引擎，建议改用 containerd 或 CRI-O ，工作效率更高，但不能再通过 docker 命令查看、管理容器。\n<ul>\n<li>这是因为 Docker 没有直接支持 CRI 接口，导致 k8s 只能通过 Dockershim 模块间接与 Docker 通信，但维护该模块比较麻烦，现在停止维护该模块。</li>\n<li>使用 Docker 构建出的镜像符合 OCI 标准，因此依然可以被 containerd 或 CRI-O 运行。</li>\n<li>如果用户继续使用 Docker 运行镜像，则启动 kubelet 时会显示一条警告。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>v1.23\n<ul>\n<li>2021 年 12 月发布。</li>\n<li>默认启用 PSA（Pod Security admission）服务，在创建 Pod 时根据 Pod 安全标准进行审核。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>\n<p>k8s 包含多个组件进程，通常部署在多个主机上，组成分布式集群。</p>\n<ul>\n<li>用户可以与 k8s 系统交互，部署自定义的应用，称为工作负载（workload）。</li>\n</ul>\n</li>\n<li>\n<p>每个主机称为节点（Node），分为两种：</p>\n<ul>\n<li>主节点（master node）：又称为控制平面节点（control plane node），负责控制整个集群、管理所有节点。</li>\n<li>工作节点（worker node）：负责部署 Pod 。</li>\n</ul>\n</li>\n<li>\n<p>主节点运行以下进程：</p>\n<ul>\n<li>kube-apiserver\n<ul>\n<li>：负责提供 Restful API ，供用户访问、控制 k8s 集群。</li>\n<li>默认监听 6443 端口，会被其它 kube 服务访问。</li>\n</ul>\n</li>\n<li>kube-controller-manager\n<ul>\n<li>：负责监控、管理 Node、Namespace、Pod、Service 等各种 k8s 资源。</li>\n<li>管理 Pod 时，主要根据 Controller 配置。</li>\n</ul>\n</li>\n<li>kube-scheduler\n<ul>\n<li>：负责调度 Pod ，根据一些策略决定将 Pod 分配到哪个节点上部署。</li>\n</ul>\n</li>\n<li>etcd\n<ul>\n<li>：分布式数据库。</li>\n<li>默认监听 2379、2380 端口，只被本机的 kube-apiserver 访问，用于存储 k8s 的配置、状态数据。</li>\n<li>也可以将 etcd 部署在主节点之外，或集群之外。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>所有节点运行以下进程：</p>\n<ul>\n<li>kubelet</li>\n<li>kube-proxy\n<ul>\n<li>：负责管理节点的逻辑网络，基于 iptables 规则。如果节点收到一个发向某个 Pod 的网络包，则自动转发给该 Pod 。\n\n\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>用户可使用 kubectl 命令，作为客户端与 apiserver 交互，从而管理 k8s 。</p>\n</li>\n</ul>\n<h3 id=\"kubelet\"> kubelet</h3>\n<ul>\n<li>默认监听 10250 端口。</li>\n<li>主要工作：\n<ul>\n<li>将当前节点注册到 kube-apiserver 。</li>\n<li>监控当前节点。</li>\n<li>创建、管理、监控 Pod ，基于容器运行时。</li>\n</ul>\n</li>\n<li>kubelet 部署 Pod 时，会调用 CRI 接口 RuntimeService.RunPodSandbox ，先创建一个沙盒（Pod Sandbox），再启动 Pod 中的容器。\n<ul>\n<li>Sandbox 负责提供一个 Pod 运行环境，比如设置网络。</li>\n<li>Sandbox 可以基于 Linux namespace 实现，也可以基于虚拟机实现，比如 kata-containers 。</li>\n<li>基于 Linux namespace 实现 Sandbox 时，kubelet 会先在每个 Pod 中运行一个 pause 容器。\n<ul>\n<li>pause 容器是一个简单程序，便于管理 Linux namespace ，比如创建 network namespace 并共享给其它容器。</li>\n<li>pause 容器一直以睡眠状态保持运行，避免 Pod 中所有容器进程停止时，Linux namespace 被自动删除。</li>\n<li>如果停止 pause 容器，则会导致 kubelet 认为该 Pod 失败，触发重启事件，创建新 Pod 。</li>\n<li>pause 容器可以与其它容器共用一个 PID namespace ，从而为其它容器启动 1 号进程、清理僵尸进程。不过 k8s 默认禁用了该共享功能，使得其它容器的 1 号进程的 PID 依然为 1 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>kubelet 中的 PLEG（Pod Lifecycle Event Generator）模块负责执行 relist 任务：获取本机的容器列表，检查所有 Pod 的状态，如果状态变化则生成 Pod 的生命周期事件。\n<ul>\n<li>每执行一次 relist ，会等 1s 再执行下一次 list 。</li>\n<li>如果某次 relist 耗时超过 3min ，则报错 <code>PLEG is not healthy</code> ，并将当前 Node 标记为 NotReady 状态。</li>\n</ul>\n</li>\n<li>kubelet 的配置示例：<div><pre><code><span>failSwapOn</span><span>:</span> <span>true</span>                  <span># 如果节点启用了 swap 内存，则拒绝启动 kubelet</span>\n<span>maxPods</span><span>:</span> <span>110</span>                      <span># 该 kubelet 节点上最多运行的 Pod 数</span>\n<span>containerLogMaxSize</span><span>:</span> 10Mi         <span># 当容器日志文件达到该值时，切割一次</span>\n<span>containerLogMaxFiles</span><span>:</span> <span>5</span>           <span># 容器日志文件被切割之后，最多保留几个文件</span>\n\n<span>imageGCHighThresholdPercent</span><span>:</span> <span>85</span>   <span># 一个百分数。如果节点的磁盘使用率达到高水位，则自动清理未被使用的镜像，从最旧的镜像开始删除，直到磁盘使用率降至低水位</span>\n<span>image-gc-low-threshold</span><span>:</span> <span>80</span>\n<span>evictionMaxPodGracePeriod</span><span>:</span> <span>0</span>      <span># 软驱逐 Pod 的最大宽限期，单位为秒。默认为 0 ，即不限制</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n</ul>\n<h2 id=\"资源\"> 资源</h2>\n<ul>\n<li>\n<p>k8s 会管理主机、容器等多种对象，又称为资源（resource）。例如：</p>\n<ul>\n<li>Cluster\n<ul>\n<li>：集群，由 k8s 联系在一起的一组主机。</li>\n</ul>\n</li>\n<li>Node\n<ul>\n<li>：节点，k8s 集群中的一个主机。</li>\n</ul>\n</li>\n<li>Namespace</li>\n<li>Pod\n<ul>\n<li>：容器组，是 k8s 的最小管理单元。</li>\n<li>Docker 以容器形式部署应用，而 k8s 以 Pod 形式部署应用。</li>\n</ul>\n</li>\n<li>Service\n<ul>\n<li>：对某些 Pod 的反向代理，代表一个抽象的应用服务。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>一些 k8s 对象之间存在上下级依赖关系，上级称为 Owner ，下级称为 Dependent 。</p>\n<ul>\n<li>删除一个 Owner 时，默认会级联删除它的所有 Dependent ，反之没有影响。</li>\n<li>比如一个 Deployment 是一组 Pod 的 Owner 。如果删除这些 Pod ，但保留 Deployment ，则会自动重新创建这些 Pod 。</li>\n<li>依赖关系不允许跨命名空间。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"namespace\"> Namespace</h3>\n<p>：命名空间，用于对某些资源进行分组管理，又称为项目（project）。</p>\n<ul>\n<li>命名空间可以管理 Pod、Service、PVC 等资源，不同命名空间下的这些资源相互隔离，互不可见。\n<ul>\n<li>删除一个命名空间时，会删除其下的所有资源。</li>\n<li>可执行 <code>kubectl api-resources --namespaced=true</code> 查看被命名空间管理的所有资源类型。</li>\n<li>Node、IP、StorageClass、PersistentVolumes 不受命名空间影响。</li>\n</ul>\n</li>\n<li>一个 k8s 中可以创建多个命名空间。初始有四个：<div><pre><code>default         <span># 供用户使用</span>\nkube-system     <span># 供 k8s 系统内部使用，比如部署 apiserver、etcd 等系统服务</span>\nkube-node-lease <span># 包含各个节点的 lease 对象</span>\nkube-public     <span># 公开，未认证的用户也可访问</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"配置\"> 配置</h3>\n<ul>\n<li>每种 k8s 对象通过一种配置文件进行管理。\n<ul>\n<li>配置文件可以是 JSON 或 YAML 格式。</li>\n</ul>\n</li>\n<li>配置文件的一般结构：<div><pre><code><span>apiVersion</span><span>:</span> v1              <span># 与 kube-apiserver 交互时，采用的 API 版本</span>\n<span>kind</span><span>:</span> &lt;sting<span>></span>               <span># 对象的类型</span>\n<span>metadata</span><span>:</span>                   <span># 对象的元数据</span>\n  <span>name</span><span>:</span> &lt;sting<span>></span>             <span># 名称，必填</span>\n  <span>namespace</span><span>:</span> default        <span># 所属的命名空间</span>\n  <span>annotations</span><span>:</span>              <span># 注释</span>\n    <span>&lt;key></span><span>:</span> &lt;value<span>></span>\n  <span>labels</span><span>:</span>                   <span># 标签，用于筛选对象</span>\n    <span>&lt;key></span><span>:</span> &lt;value<span>></span>\n  <span># resourceVersion: xx     # 配置文件的版本号，由 k8s 自动更新，是一串随机数字（不是哈希值），全局唯一</span>\n<span>spec</span><span>:</span>                       <span># 规格，描述对象的期望状态</span>\n  &lt;<span>...</span><span>></span>\n\n<span># status:                   # 描述对象的实际状态，这部分字段由 k8s 自动写入</span>\n<span>#   &lt;...></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>在同一 namespace 下，同种对象的 name 不能重复。\n<ul>\n<li>每个对象会被自动分配一个 UUID ，在整个 k8s 集群的所有 namespace 中唯一。</li>\n</ul>\n</li>\n<li>annotations、labels 采用键值对格式。\n<ul>\n<li>key、value 都是 String 类型，不能为 bool 等类型。</li>\n<li>key 只能包含 <code>[a-zA-Z0-9._-]</code> 字符，必须以字母、数字开头和结尾。</li>\n<li>可以给 key 加上一个 <code>&lt;dns_domain&gt;/</code> 格式的前缀。\n<ul>\n<li>前缀 <code>kubernetes.io/</code> 、<code>k8s.io/</code> 保留，供 k8s 系统内部使用。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Filebeat",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/ELK/Filebeat.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/ELK/Filebeat.html",
      "content_html": "<h1 id=\"filebeat\"> Filebeat</h1>\n<h2 id=\"原理\"> 原理</h2>\n<h3 id=\"采集日志\"> 采集日志</h3>\n<ul>\n<li>\n<p>Filebeat 每采集一条日志文本，都会保存为 JSON 格式的对象，称为日志事件（event）。</p>\n</li>\n<li>\n<p>Filebeat 的主要模块：</p>\n<ul>\n<li>input ：输入端。</li>\n<li>output ：输出端。</li>\n<li>harvester ：收割机，负责采集日志。</li>\n</ul>\n</li>\n<li>\n<p>Filebeat 会定期扫描（scan）日志文件，如果发现其最后修改时间改变，则创建 harvester 去采集日志。</p>\n<ul>\n<li>对每个日志文件创建一个 harvester ，逐行读取文本，转换成日志事件，发送到输出端。\n<ul>\n<li>每行日志文本必须以换行符分隔，最后一行也要加上换行符才能视作一行。</li>\n</ul>\n</li>\n<li>harvester 开始读取时会打开文件描述符，读取结束时才关闭文件描述符。\n<ul>\n<li>默认会一直读取到文件末尾，如果文件未更新的时长超过 close_inactive ，才关闭。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>假设让 Filebeat 采集日志文件 A 。切割日志时，可能经常出现将文件 A 重命名为 B 的情况，比如 <code>mv A B</code> 。Filebeat 会按以下规则处理：</p>\n<ul>\n<li>如果没打开文件 A ，则以后会因为文件 A 不存在而采集不了。\n<ul>\n<li>在类 Unix 系统上，当 Filebeat 打开文件时，允许其它进程重命名文件。而在 Windows 系统上不允许，因此总是这种情况。</li>\n</ul>\n</li>\n<li>如果打开了文件 A ，则会继续读取到文件末尾，然后每隔 backoff 时间检查一次文件：\n<ul>\n<li>如果在 backoff 时长之内又创建文件 A ，比如 <code>touch A</code> 。则 Filebeat 会认为文件被重命名（renamed）。\n<ul>\n<li>默认配置了 <code>close_renamed: false</code> ，因此会既采集文件 A ，又采集文件 B ，直到因为 close_inactive 超时等原因才关闭文件 B 。</li>\n<li>此时两个文件的状态都会记录在 registry 中，文件路径 source 相同，只是 inode 不同。</li>\n</ul>\n</li>\n<li>如果在 backoff 时长之后，依然没有创建文件 A 。则 Filebeat 会认为文件被删除（removed）。\n<ul>\n<li>默认配置了 <code>close_removed: true</code> ，因此会立即关闭文件 B 而不采集，而文件 A 又因为不存在而采集不了。此时 Filebeat 的日志如下：<div><pre><code><span>2021</span>-02-02T15:49:49.446+0800    INFO    log/harvester.go:302    Harvester started <span>for</span> file: /var/log/A.log      <span># 开始采集文件 A</span>\n<span>2021</span>-02-02T15:50:55.457+0800    INFO    log/harvester.go:325    File was removed: /var/log/A.log. Closing because close_removed is enabled.   <span># 发现文件 A 被删除了，停止采集</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"注册表\"> 注册表</h3>\n<ul>\n<li>Filebeat 会通过 registry 文件记录所有日志文件的当前状态信息（State）。\n<ul>\n<li>即使只有一个日志文件被修改了，也会在 registry 文件中写入一次所有日志文件的当前状态。</li>\n<li>registry 保存在 <code>data/registry/</code> 目录下，如下：<div><pre><code>data/registry/filebeat/\n├── <span>237302</span>.json         <span># 快照文件，使用最后一次动作的编号作为文件名</span>\n├── active.dat          <span># 记录快照文件的路径</span>\n├── log.json            <span># 记录日志文件的状态。该文件体积超过 10 MB 时会自动清空，并将此时所有文件的状态保存到快照文件中</span>\n└── meta.json           <span># 记录一些元数据</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>删除该目录就会重新采集所有日志文件，这会导致重复采集。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>registry 中一个记录的示例：<div><pre><code><span>{</span><span>\"op\"</span><span>:</span><span>\"set\"</span><span>,</span> <span>\"id\"</span><span>:</span><span>237302</span><span>}</span>                             <span>// 本次动作的编号</span>\n<span>{</span>\n  <span>\"k\"</span><span>:</span> <span>\"filebeat::logs::native::778887-64768\"</span><span>,</span>        <span>// key ，由 beat 类型、日志文件的 id 组成</span>\n  <span>\"v\"</span><span>:</span> <span>{</span>\n    <span>\"id\"</span><span>:</span> <span>\"native::778887-64768\"</span><span>,</span>                     <span>// 日志文件的 id ，由 identifier_name、inode、device 组成</span>\n    <span>\"prev_id\"</span><span>:</span> <span>\"\"</span><span>,</span>\n    <span>\"ttl\"</span><span>:</span> <span>-1</span><span>,</span>                                        <span>// -1 表示永不失效</span>\n    <span>\"type\"</span><span>:</span> <span>\"log\"</span><span>,</span>\n    <span>\"source\"</span><span>:</span> <span>\"/var/log/supervisor/supervisord.log\"</span><span>,</span>  <span>// 日志文件的路径（文件被重命名之后，并不会更新该参数）</span>\n    <span>\"timestamp\"</span><span>:</span> <span>[</span><span>2061628216741</span><span>,</span> <span>1611303609</span><span>]</span><span>,</span>         <span>// 日志文件最后一次修改的 Unix 时间戳</span>\n    <span>\"offset\"</span><span>:</span> <span>1343</span><span>,</span>                                   <span>// 当前采集的字节偏移量，表示最后一次采集的日志行的末尾位置</span>\n    <span>\"identifier_name\"</span><span>:</span> <span>\"native\"</span><span>,</span>                      <span>// 识别日志文件的方式，native 表示原生方式，即根据 inode 和 device 编号识别</span>\n    <span>\"FileStateOS\"</span><span>:</span> <span>{</span>                                  <span>// 文件的状态</span>\n      <span>\"inode\"</span><span>:</span> <span>778887</span><span>,</span>                                <span>// 文件的 inode 编号</span>\n      <span>\"device\"</span><span>:</span> <span>64768</span>                                 <span>// 文件所在的磁盘编号</span>\n    <span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>采集每个日志文件时，会记录已采集的字节偏移量（bytes offset）。\n<ul>\n<li>每次 harvester 读取日志文件时，会从 offset 处继续采集。</li>\n<li>如果 harvester 发现文件体积小于已采集的 offset ，则认为文件被截断了，会从 offset 0 处重新开始读取。这可能会导致重复采集。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"发送日志\"> 发送日志</h3>\n<ul>\n<li>\n<p>Filebeat 将采集的日志事件经过处理之后，会发送到输出端，该过程称为发布事件（publish event）。</p>\n<ul>\n<li>event 保存在内存中，不会写入磁盘。</li>\n<li>每个 event 只有成功发送到输出端，且收到确认接收的回复，才视作发送成功。\n<ul>\n<li>如果发送 event 到输出端失败，则会自动重试。直到发送成功，才更新记录。</li>\n<li>因此，采集到的 event 至少会被发送一次。但如果在确认接收之前重启 Filebeat ，则可能重复发送。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>一个 event 的内容示例：</p>\n<div><pre><code><span>{</span>\n  <span>\"@timestamp\"</span><span>:</span><span>\"2021-02-02T12:03:21.027Z\"</span><span>,</span>  <span>// 自动加上该字段，记录当前时间戳</span>\n  <span>\"@metadata\"</span><span>:</span><span>{</span>\n    <span>\"beat\"</span><span>:</span> <span>\"filebeat\"</span><span>,</span>\n    <span>\"type\"</span><span>:</span> <span>\"_doc\"</span><span>,</span>\n    <span>\"version\"</span><span>:</span> <span>\"7.14.0\"</span>\n  <span>}</span><span>,</span>\n  <span>\"agent\"</span><span>:</span> <span>{</span>                                <span>// Beats 的信息</span>\n    <span>\"type\"</span><span>:</span> <span>\"filebeat\"</span><span>,</span>\n    <span>\"version\"</span><span>:</span> <span>\"7.14.0\"</span><span>,</span>\n    <span>\"name\"</span><span>:</span> <span>\"CentOS-1\"</span><span>,</span>\n    <span>\"hostname\"</span><span>:</span> <span>\"CentOS-1\"</span><span>,</span>\n    <span>\"ephemeral_id\"</span><span>:</span> <span>\"ed02583b-0823-4e25-bed3-e8af69ad7d82\"</span><span>,</span>\n    <span>\"id\"</span><span>:</span> <span>\"49f74a3e-bfec-452c-b119-32c8014b19b2\"</span>\n  <span>}</span><span>,</span>\n  <span>\"log\"</span><span>:</span> <span>{</span>\n    <span>\"file\"</span><span>:</span> <span>{</span>                               <span>// 采集的日志文件的路径</span>\n        <span>\"path\"</span><span>:</span> <span>\"/var/log/nginx/access.log\"</span>\n    <span>}</span><span>,</span>\n    <span>\"offset\"</span><span>:</span> <span>765072</span>                        <span>// 采集的偏移量</span>\n  <span>}</span><span>,</span>\n  <span>\"message\"</span><span>:</span> <span>\"127.0.0.1 - [2/Feb/2021:12:02:34 +0000] GET /static/bg.jpg HTTP/1.1 200 0\"</span><span>,</span> <span>// 日志的原始内容，之后可以进行解析</span>\n  <span>\"fields\"</span><span>:</span> <span>{</span><span>}</span><span>,</span>                             <span>// 可以给 event 加上一些字段</span>\n  <span>\"tags\"</span><span>:</span> <span>[</span><span>]</span><span>,</span>                               <span>// 可以给 event 加上一些标签，便于筛选</span>\n  ...\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br></div></div></li>\n</ul>\n<h3 id=\"相关源码\"> 相关源码</h3>\n<p>这里分析 <a href=\"https://github.com/elastic/beats/blob/master/filebeat/input/log/log.go\" target=\"_blank\" rel=\"noopener noreferrer\">filebeat/input/log/log.go</a> 中的部分源码：</p>\n<ul>\n<li>\n<p>记录日志文件的结构体如下：</p>\n<div><pre><code><span>type</span> Log <span>struct</span> <span>{</span>\n    fs           harvester<span>.</span>Source   <span>// 指向日志文件的接口</span>\n    offset       <span>int64</span>              <span>// 采集的偏移量</span>\n    config       LogConfig          <span>// 配置参数</span>\n    lastTimeRead time<span>.</span>Time          <span>// 最后修改时间</span>\n    backoff      time<span>.</span>Duration      <span>// backoff 的时长</span>\n    done         <span>chan</span> <span>struct</span><span>{</span><span>}</span>      <span>// 一个通道，用于判断文件是否被关闭</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>\n<p>读取日志文件的主要逻辑如下：</p>\n<div><pre><code><span>func</span> <span>(</span>f <span>*</span>Log<span>)</span> <span>Read</span><span>(</span>buf <span>[</span><span>]</span><span>byte</span><span>)</span> <span>(</span><span>int</span><span>,</span> <span>error</span><span>)</span> <span>{</span>\n    totalN <span>:=</span> <span>0</span>                           <span>// 记录总共读取的字节数</span>\n\n    <span>for</span> <span>{</span>                                 <span>// 循环读取日志文件，一直读取到装满 buf 缓冲区</span>\n        <span>select</span> <span>{</span>\n        <span>case</span> <span>&lt;-</span>f<span>.</span>done<span>:</span>\n            <span>return</span> <span>0</span><span>,</span> ErrClosed\n        <span>default</span><span>:</span>\n        <span>}</span>\n\n        <span>// 开始读取之前，先检查文件是否存在</span>\n        err <span>:=</span> f<span>.</span><span>checkFileDisappearedErrors</span><span>(</span><span>)</span>\n        <span>if</span> err <span>!=</span> <span>nil</span> <span>{</span>\n            <span>return</span> totalN<span>,</span> err\n        <span>}</span>\n\n        <span>// 读取文件的内容，存储到 buf 缓冲区中</span>\n        n<span>,</span> err <span>:=</span> f<span>.</span>fs<span>.</span><span>Read</span><span>(</span>buf<span>)</span>          <span>// 最多读取 len(buf) 个字节，并返回实际读取的字节数 n</span>\n        <span>if</span> n <span>></span> <span>0</span> <span>{</span>                        <span>// 如果读取到的内容不为空，则更新偏移量、最后读取时间</span>\n            f<span>.</span>offset <span>+=</span> <span>int64</span><span>(</span>n<span>)</span>\n            f<span>.</span>lastTimeRead <span>=</span> time<span>.</span><span>Now</span><span>(</span><span>)</span>\n        <span>}</span>\n        totalN <span>+=</span> n                       <span>// 更新 totalN 的值</span>\n\n        <span>// 如果 err == nil ，则代表读取没有出错，此时要么 buf 读取满了，要么读取到了文件末尾 EOF</span>\n        <span>if</span> err <span>==</span> <span>nil</span> <span>{</span>\n            f<span>.</span>backoff <span>=</span> f<span>.</span>config<span>.</span>Backoff  <span>// 重置 backoff 的时长，以供下次读取</span>\n            <span>return</span> totalN<span>,</span> <span>nil</span>            <span>// 结束读取，返回总共读取的字节数</span>\n        <span>}</span>\n        buf <span>=</span> buf<span>[</span>n<span>:</span><span>]</span>                     <span>// 更新 buf 指向的位置，从而使用剩下的缓冲区</span>\n\n        <span>// 检查 err 的类型，如果它是 EOF 则进行处理</span>\n        err <span>=</span> f<span>.</span><span>errorChecks</span><span>(</span>err<span>)</span>\n\n        <span>// 如果读取出错，或者 buf 满了，则结束读取</span>\n        <span>if</span> err <span>!=</span> <span>nil</span> <span>||</span> <span>len</span><span>(</span>buf<span>)</span> <span>==</span> <span>0</span> <span>{</span>\n            <span>return</span> totalN<span>,</span> err\n        <span>}</span>\n\n        <span>// 如果读取没出错，buf 也没满，只是读取到了文件末尾，则等待 backoff 时长再循环读取</span>\n        logp<span>.</span><span>Debug</span><span>(</span><span>\"harvester\"</span><span>,</span> <span>\"End of file reached: %s; Backoff now.\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>)</span>\n        f<span>.</span><span>wait</span><span>(</span><span>)</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br></div></div></li>\n<li>\n<p><code>checkFileDisappearedErrors()</code> 方法的定义如下：</p>\n<div><pre><code><span>func</span> <span>(</span>f <span>*</span>Log<span>)</span> <span>checkFileDisappearedErrors</span><span>(</span><span>)</span> <span>error</span> <span>{</span>\n    <span>// 如果没启用 close_renamed、close_removed 配置，则不进行检查</span>\n    <span>if</span> <span>!</span>f<span>.</span>config<span>.</span>CloseRenamed <span>&amp;&amp;</span> <span>!</span>f<span>.</span>config<span>.</span>CloseRemoved <span>{</span>\n        <span>return</span> <span>nil</span>\n    <span>}</span>\n\n    <span>// 获取文件的状态信息（State），包括文件名、大小、文件模式、最后修改时间、是否为目录等</span>\n    info<span>,</span> statErr <span>:=</span> f<span>.</span>fs<span>.</span><span>Stat</span><span>(</span><span>)</span>\n    <span>if</span> statErr <span>!=</span> <span>nil</span> <span>{</span>                   <span>// 如果不能获取状态，则结束执行</span>\n        logp<span>.</span><span>Err</span><span>(</span><span>\"Unexpected error reading from %s; error: %s\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>,</span> statErr<span>)</span>\n        <span>return</span> statErr\n    <span>}</span>\n\n    <span>// 检查文件是否被重命名</span>\n    <span>// 原理为：获取已打开的文件 f 的 State ，再获取磁盘中当前路径为 f.Name() 的文件的 State ，如果两者的 inode、device 不同，则说明文件 f 当前的路径已经不是 f.Name()</span>\n    <span>if</span> f<span>.</span>config<span>.</span>CloseRenamed <span>{</span>\n        <span>if</span> <span>!</span>file<span>.</span><span>IsSameFile</span><span>(</span>f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>,</span> info<span>)</span> <span>{</span>\n            logp<span>.</span><span>Debug</span><span>(</span><span>\"harvester\"</span><span>,</span> <span>\"close_renamed is enabled and file %s has been renamed\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>)</span>\n            <span>return</span> ErrRenamed\n        <span>}</span>\n    <span>}</span>\n\n    <span>// 检查文件是否被删除</span>\n    <span>// 原理为：执行 os.Stat(f.Name()) ，如果没报错则说明磁盘中路径为 f.Name() 的文件依然存在</span>\n    <span>if</span> f<span>.</span>config<span>.</span>CloseRemoved <span>{</span>\n        <span>if</span> f<span>.</span>fs<span>.</span><span>Removed</span><span>(</span><span>)</span> <span>{</span>\n            logp<span>.</span><span>Debug</span><span>(</span><span>\"harvester\"</span><span>,</span> <span>\"close_removed is enabled and file %s has been removed\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>)</span>\n            <span>return</span> ErrRemoved\n        <span>}</span>\n    <span>}</span>\n\n    <span>// 如果检查没问题，则返回 nil ，表示没有错误</span>\n    <span>return</span> <span>nil</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br></div></div></li>\n<li>\n<p><code>errorChecks()</code> 方法的定义如下：</p>\n<div><pre><code><span>func</span> <span>(</span>f <span>*</span>Log<span>)</span> <span>errorChecks</span><span>(</span>err <span>error</span><span>)</span> <span>error</span> <span>{</span>\n    <span>// 处理 err 不是 EOF 的情况</span>\n    <span>if</span> err <span>!=</span> io<span>.</span>EOF <span>{</span>\n        logp<span>.</span><span>Err</span><span>(</span><span>\"Unexpected state reading from %s; error: %s\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>,</span> err<span>)</span>\n        <span>return</span> err\n    <span>}</span>\n\n    <span>// 以下处理 err 是 EOF 的情况</span>\n\n    <span>// 判断文件是否支持继续读取，比如 stdin 就不支持</span>\n    <span>if</span> <span>!</span>f<span>.</span>fs<span>.</span><span>Continuable</span><span>(</span><span>)</span> <span>{</span>\n        logp<span>.</span><span>Debug</span><span>(</span><span>\"harvester\"</span><span>,</span> <span>\"Source is not continuable: %s\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>)</span>\n        <span>return</span> err\n    <span>}</span>\n\n    <span>// 如果启用了 close_eof 配置，则结束执行</span>\n    <span>if</span> f<span>.</span>config<span>.</span>CloseEOF <span>{</span>\n        <span>return</span> err\n    <span>}</span>\n\n    <span>// 获取文件的状态信息</span>\n    info<span>,</span> statErr <span>:=</span> f<span>.</span>fs<span>.</span><span>Stat</span><span>(</span><span>)</span>\n    <span>if</span> statErr <span>!=</span> <span>nil</span> <span>{</span>\n        logp<span>.</span><span>Err</span><span>(</span><span>\"Unexpected error reading from %s; error: %s\"</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>,</span> statErr<span>)</span>\n        <span>return</span> statErr\n    <span>}</span>\n\n    <span>// 如果文件的体积小于采集的偏移量，则认为发生了日志截断，结束执行</span>\n    <span>if</span> info<span>.</span><span>Size</span><span>(</span><span>)</span> <span>&lt;</span> f<span>.</span>offset <span>{</span>\n        logp<span>.</span><span>Debug</span><span>(</span><span>\"harvester\"</span><span>,</span>\n            <span>\"File was truncated as offset (%d) > size (%d): %s\"</span><span>,</span> f<span>.</span>offset<span>,</span> info<span>.</span><span>Size</span><span>(</span><span>)</span><span>,</span> f<span>.</span>fs<span>.</span><span>Name</span><span>(</span><span>)</span><span>)</span>\n        <span>return</span> ErrFileTruncate\n    <span>}</span>\n\n    <span>// 如果最后一次读取日志的时间，距离现在的时长超过 close_inactive ，则结束执行</span>\n    age <span>:=</span> time<span>.</span><span>Since</span><span>(</span>f<span>.</span>lastTimeRead<span>)</span>\n    <span>if</span> age <span>></span> f<span>.</span>config<span>.</span>CloseInactive <span>{</span>\n        <span>return</span> ErrInactive\n    <span>}</span>\n\n    <span>// 此时，忽略 EOF 的错误，从而继续读取</span>\n    <span>return</span> <span>nil</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br></div></div></li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 yum 安装：<div><pre><code>yum <span>install</span> https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.14.0-x86_64.rpm\n</code></pre>\n<div><span>1</span><br></div></div>然后启动：<div><pre><code><span># ./filebeat setup    # 可选择进行初始化。这会先连接到 ES 创建索引模板，再连接到 Kibana 创建仪表盘</span>\n./filebeat            <span># 在前台运行</span>\n          -c /etc/filebeat/filebeat.yml <span># 指定配置文件</span>\n          -e          <span># 将 filebeat 自身的日志输出到 stderr</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>在 k8s 中部署时，可参考<a href=\"https://github.com/elastic/beats/blob/main/deploy/kubernetes/filebeat-kubernetes.yaml\" target=\"_blank\" rel=\"noopener noreferrer\">官方配置</a> 。</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>所有类型的 beats 都支持以下 General 配置项：</p>\n<div><pre><code><span>name</span><span>:</span> <span>'filebeat-001'</span>        <span># 该 Beat 的名称，默认使用当前主机名</span>\n<span>tags</span><span>:</span> <span>[</span><span>'json'</span><span>]</span>              <span># 给每条日志加上标签，保存到一个名为 tags 的字段中，便于筛选日志</span>\n<span>fields</span><span>:</span>                     <span># 给每条日志加上字段，这些字段默认保存到一个名为 fields 的字段的子字典中</span>\n  <span>project</span><span>:</span> test\n<span>fields_under_root</span><span>:</span> <span>false</span>    <span># 是否将 fields 的各个字段保存为日志的顶级字段，此时如果与已有字段重名则会覆盖</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>这些参数可以配置全局的，也可以给某个日志源单独配置。</li>\n</ul>\n</li>\n<li>\n<p>filebeat.yml 的基本配置：</p>\n<div><pre><code><span># path.config: ${path.home}                     # 配置文件的路径，默认是项目根目录</span>\n<span># filebeat.shutdown_timeout: 0s                 # 当 Filebeat 关闭时，如果有 event 正在发送，则等待一定时间直到其完成。默认不等待</span>\n<span># filebeat.registry.path: ${path.data}/registry # registry 文件的保存目录</span>\n<span># filebeat.registry.file_permissions: 0600      # registry 文件的权限</span>\n<span># filebeat.registry.flush: 0s                   # 每当 Filebeat 发布一个 event 到输出端，隔多久才刷新 registry 文件</span>\n\n<span># 配置 filebeat 自身的日志</span>\n<span>logging.level</span><span>:</span> info                     <span># 只记录不低于该级别的日志</span>\n<span>logging.json</span><span>:</span> <span>true</span>                      <span># 输出的日志采用 JSON 格式</span>\n<span>logging.to_files</span><span>:</span> <span>true</span>                  <span># 将日志保存到文件 ./logs/filebeat</span>\n<span># logging.to_stderr: true               # 将日志输出到终端</span>\n<span># logging.metrics.enabled: true         # 是否在日志中记录监控信息，包括 filebeat 的状态、系统负载</span>\n<span># logging.metrics.period: 30s           # 记录监控信息的时间间隔</span>\n\n<span>filebeat.config.modules</span><span>:</span>                <span># 加载模块</span>\n  <span>path</span><span>:</span> $<span>{</span>path.config<span>}</span>/modules.d/<span>*.yml</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n</ul>\n<h3 id=\"output\"> output</h3>\n<ul>\n<li>Filebeat 支持多种输出端：<div><pre><code><span># 输出到终端，便于调试</span>\n<span># output.console:</span>\n<span>#   pretty: true</span>\n\n<span># 输出到 Logstash</span>\n<span>output.logstash</span><span>:</span>\n  <span>hosts</span><span>:</span> <span>[</span><span>'localhost:5044'</span><span>]</span>\n\n<span># 输出到 ES</span>\n<span># output.elasticsearch:</span>\n<span>#   hosts: ['10.0.0.1:9200']</span>\n<span>#   username: 'admin'</span>\n<span>#   password: '******'</span>\n<span>#   index: 'filebeat-%{[agent.version]}-%{+yyyy.MM.dd}-%{index_num}'   # 用于存储 event 的索引名</span>\n\n<span># 输出到 kafka</span>\n<span># output.kafka:</span>\n<span>#   hosts:</span>\n<span>#     - 10.0.0.1:9092</span>\n<span>#   topic: '%{[fields.project]}_log'</span>\n<span>#   partition.random:             # 随机选择每个消息输出的 kafka 分区</span>\n<span>#     reachable_only: true        # 是否只输出到可访问的分区。默认为 false ，可能输出到所有分区，如果分区不可访问则阻塞</span>\n<span>#   compression: gzip             # 消息的压缩格式，默认为 gzip 。设置为 none 则不压缩</span>\n<span>#   keep_alive: 10                # 保持 TCP 连接的时长，默认为 0 秒</span>\n<span>#   max_message_bytes: 10485760   # 限制单个消息的大小为 10M ，超过则丢弃</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br></div></div><ul>\n<li>同时只能启用一种输出端。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"processors\"> processors</h3>\n<ul>\n<li>可以配置 processors ，在输出 event 之前进行处理：<div><pre><code><span>processors</span><span>:</span>\n  <span>-</span> <span>add_host_metadata</span><span>:</span>                  <span># 添加当前主机的信息，包括 os、hostname、ip 等</span>\n      <span>when.not.contains.tags</span><span>:</span> forwarded <span># 如果该日志不属于转发的</span>\n  <span>-</span> <span>add_docker_metadata</span><span>:</span> <span>~</span>              <span># 如果存在 Docker 环境，则自动添加容器、镜像的信息。默认将 labels 中的点 . 替换成下划线 _</span>\n  <span>-</span> <span>add_kubernetes_metadata</span><span>:</span> <span>~</span>          <span># 如果存在 k8s 环境，则则自动添加 Pod 等信息</span>\n  <span>-</span> <span>drop_event</span><span>:</span>                         <span># 丢弃 event ，如果它满足条件</span>\n      <span>when</span><span>:</span>\n        <span>regexp</span><span>:</span>\n          <span>message</span><span>:</span> <span>\"^DEBUG\"</span>\n  <span>-</span> <span>drop_fields</span><span>:</span>                        <span># 丢弃一些字段</span>\n      <span>ignore_missing</span><span>:</span> <span>true</span>              <span># 是否忽略指定字段不存在的错误，默认为 false</span>\n      <span>fields</span><span>:</span>\n        <span>-</span> cpu.user\n        <span>-</span> cpu.system\n  <span>-</span> <span>rate_limit</span><span>:</span>\n      <span>limit</span><span>:</span> 1000/m                     <span># 限制发送 event 的速率，时间单位可以是 s、m、h</span>\n      <span># fields:                         # 设置 fields 时，则考虑指定的所有字段的组合值，对每组不同的值分别限制速率</span>\n      <span>#   - message</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>processors 的详细语法见 <a href=\"https://www.elastic.co/guide/en/beats/filebeat/current/defining-processors.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a> 。</li>\n<li>可以配置全局的 processors ，作用于采集的所有日志事件，也可以给某个日志源单独配置。</li>\n<li>配置了多个 processors 时，会按顺序执行。</li>\n<li>支持声明 processors 的触发条件：<div><pre><code><span>processors</span><span>:</span>\n  <span>-</span> <span>&lt;processor_name></span><span>:</span>\n      &lt;parameters<span>></span>\n      <span>when</span><span>:</span>\n        &lt;condition<span>></span>\n  <span>-</span> <span>if</span><span>:</span>\n      &lt;condition<span>></span>\n    <span>then</span><span>:</span>\n      <span>-</span> <span>&lt;processor></span><span>:</span>\n          &lt;parameters<span>></span>\n      <span>-</span> <span>&lt;processor></span><span>:</span>\n          &lt;parameters<span>></span>\n    <span>else</span><span>:</span>\n      <span>-</span> <span>&lt;processor></span><span>:</span>\n          &lt;parameters<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"文件日志\"> 文件日志</h3>\n<ul>\n<li>\n<p>采集文件日志的配置示例：</p>\n<div><pre><code><span>filebeat.inputs</span><span>:</span>                  <span># 关于输入项的配置</span>\n<span>-</span> <span>type</span><span>:</span> log                       <span># 定义一个输入项，类型为普通的日志文件</span>\n  <span>paths</span><span>:</span>                          <span># 指定日志文件的路径</span>\n  <span>-</span> /var/log/mysql.log\n  <span>-</span> <span>'/var/log/nginx/*'</span>            <span># 可以使用通配符</span>\n\n<span>-</span> <span>type</span><span>:</span> log\n  <span># enabled: true                 # 是否启用该输入项</span>\n  <span>paths</span><span>:</span>\n    <span>-</span> <span>'/var/log/apache/*'</span>\n\n  <span># fields:                       # 覆盖全局的 General 配置项</span>\n  <span>#   project: test</span>\n  <span>#   logformat: apache</span>\n  <span># fields_under_root: true</span>\n\n  <span># 如果启用任何一个以 json 开头的配置项，则会将每行日志文本按 JSON 格式解析，解析的字段默认保存到一个名为 json 的字段的子字典中</span>\n  <span># 解析 JSON 的操作会在 multiline 之前执行。因此建议让 filebeat 只执行 multiline 操作，将日志发送到 Logstash 时才解析 JSON</span>\n  <span># 如果 JSON 解析失败，则会将日志文本保存在 message 字段，然后输出</span>\n  <span># json.add_error_key: true      # 如果解析出错，则加入 error.message 等字段</span>\n  <span># json.message_key: log         # 指定存储日志内容的字段名。如果指定了该字段，当该字段为顶级字段、取值为字符串类型时，会进行 multiline、include、exclude 操作</span>\n  <span># json.keys_under_root: false   # 是否将解析的字典保存为日志的顶级字段</span>\n  <span># json.overwrite_keys: false    # 在启用了 keys_under_root 时，如果解析出的字段与原有字段冲突，是否覆盖</span>\n\n  <span># 默认将每行日志文本视作一个日志事件，可以通过 multiline 规则将连续的多行文本记录成同一个日志事件</span>\n  <span># multiline 操作会在 include_lines 之前执行</span>\n  <span># multiline.type: pattern       # 采用 pattern 方式，根据正则匹配处理多行。也可以采用 count 方式，根据指定行数处理多行</span>\n  <span># multiline.pattern: '^\\s\\s'    # 如果一行文本与 pattern 正则匹配，则按 match 规则与上一行或下一行合并</span>\n  <span># multiline.negate: false       # 是否反向匹配</span>\n  <span># multiline.match: after        # 取值为 after 则放到上一行之后，取值为 before 则放到下一行之前</span>\n  <span># multiline.max_lines: 500      # 多行日志最多包含多少行，超过的行数不会采集。默认为 500</span>\n\n  <span># exclude_files: ['\\.tgz$']           # 排除一些正则匹配的文件</span>\n  <span># exclude_lines: ['^DEBUG', '^INFO']  # 排除日志文件中正则匹配的那些行</span>\n  <span># include_lines: ['^WARN', '^ERROR']  # 只采集日志文件中正则匹配的那些行。默认采集所有非空的行。该操作会在 exclude_lines 之前执行</span>\n\n  <span># encoding: utf-8               # 编码格式</span>\n  <span># scan_frequency: 10s           # 每隔多久扫描一次日志文件，如果有变动则创建 harvester 进行采集</span>\n  <span># ignore_older: 0s              # 不扫描最后修改时间在多久之前的文件，默认不限制时间。其值应该大于 close_inactive</span>\n  <span># harvester_buffer_size: 16384  # 每个 harvester 在采集日志时的缓冲区大小，单位 bytes</span>\n  <span># max_bytes: 102400             # 每条日志的 message 部分的最大字节数，超过的部分不会发送（但依然会读取）。默认为 10 M ，这里设置为 100 K</span>\n  <span># tail_files: false             # 是否从文件的末尾开始，倒序读取</span>\n  <span># backoff: 1s                   # 如果 harvester 读取到文件末尾，则每隔多久检查一次文件是否更新</span>\n\n  <span># 配置 close_* 参数可以让 harvester 尽早关闭文件，但不利于实时采集日志</span>\n  <span># close_timeout: 0s             # harvester 每次读取文件的超时时间，超时之后立即关闭。默认不限制</span>\n  <span># close_eof: false              # 如果 harvester 读取到文件末尾，则立即关闭</span>\n  <span># close_inactive: 5m            # 如果 harvester 读取到文件末尾之后，超过该时长没有读取到新日志，则立即关闭</span>\n  <span># close_removed: true           # 如果 harvester 读取到文件末尾之后，检查发现日志文件被删除，则立即关闭</span>\n  <span># close_renamed: false          # 如果 harvester 读取到文件末尾之后，检查发现日志文件被重命名，则立即关闭</span>\n\n  <span># 配置 clean_* 参数可以自动清理 registry 文件，但可能导致遗漏采集，或重复采集</span>\n  <span># clean_removed: true           # 如果日志文件在磁盘中被删除，则从 registry 中删除它</span>\n  <span># clean_inactive: 0s            # 如果日志文件长时间未活动，则从 registry 中删除它。默认不限制时间。其值应该大于 scan_frequency + ignore_older</span>\n\n  <span># 给该日志源单独配置 processors</span>\n  <span># processors:</span>\n  <span># - drop_event: ...</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br></div></div><ul>\n<li>配置时间时，默认单位为秒，可使用 1、1s、2m、3h 等格式的值。</li>\n</ul>\n</li>\n<li>\n<p>可以启用 filebeat 的一些内置模块，自动采集一些系统或流行软件的日志文件，此时不需要用户自行配置。</p>\n<ul>\n<li>命令：<div><pre><code>./filebeat modules\n                  <span>enable</span>  <span>[</span>module<span>]</span><span>..</span>.   <span># 启用一些模块</span>\n                  disable <span>[</span>module<span>]</span><span>..</span>.   <span># 禁用一些模块</span>\n                  list                  <span># 列出启用、禁用的所有模块</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>filebeat 支持的 <a href=\"https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-modules.html\" target=\"_blank\" rel=\"noopener noreferrer\">模块列表</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"容器日志\"> 容器日志</h3>\n<ul>\n<li>\n<p>采集容器日志的配置示例：</p>\n<div><pre><code><span>filebeat.inputs</span><span>:</span>\n<span>-</span> <span>type</span><span>:</span> container\n  <span>paths</span><span>:</span>\n    <span>-</span> /var/lib/docker/containers/<span>*/*.log</span>\n  <span># stream: all                   # 从哪个流读取日志，可以取值为 stdout、stderr、all ，默认为 all</span>\n  <span># 兼容 type: log 的配置参数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>注意 docker 的日志文件默认需要 root 权限才能查看。</li>\n</ul>\n</li>\n<li>\n<p>上述配置会采集所有容器的日志，而使用以下自动发现（autodiscover）的配置，可以只采集部分容器的日志：</p>\n</li>\n<li>\n<p>filebeat 支持对容器的自动发现（autodiscover），还支持从容器的元数据中加载配置，称为基于提示（hints）的自动发现。</p>\n<ul>\n<li>配置示例：<div><pre><code><span>filebeat.autodiscover</span><span>:</span>\n  <span>providers</span><span>:</span>\n    <span>-</span> <span>type</span><span>:</span> docker                <span># 声明一个自动发现的日志源，为 docker 类型。这会调用内置 docker 变量模板</span>\n      <span># templates:</span>\n      <span>#   - condition:            # 只采集满足该条件的日志</span>\n      <span>#       contains:</span>\n      <span>#         docker.container.name: elasticsearch</span>\n      <span>#     config:</span>\n      <span>#       - type: container   # 该 container 是指 filebeat.inputs 类型，不是指 providers 类型</span>\n      <span>#         paths:</span>\n      <span>#           - /var/lib/docker/containers/${data.docker.container.id}/*.log</span>\n      <span># hints.enabled: false      # 是否启用 hints ，从 Docker 容器的 Labels 加载配置</span>\n      <span># hints.default_config:     # 设置默认的 hints 配置</span>\n      <span>#   enabled: true           # 是否采集容器的日志，默认为 true 。如果禁用，则需要容器启用 co.elastic.logs/enabled 配置</span>\n      <span>#   type: container</span>\n      <span>#   paths:</span>\n      <span>#     - /var/lib/docker/containers/${data.docker.container.id}/*.log</span>\n\n    <span>-</span> <span>type</span><span>:</span> kubernetes\n      <span># hints.enabled: false      # 从 k8s Pod 的 Annotations 加载配置</span>\n      <span># hints.default_config:</span>\n      <span>#   type: container</span>\n      <span>#   paths:</span>\n      <span>#     - /var/log/containers/*${data.kubernetes.container.id}.log</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br></div></div></li>\n<li>provider 为 docker 类型时，可以引用以下变量：<div><pre><code>docker.container.id\ndocker.container.image\ndocker.container.name\ndocker.container.labels\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>使用 hints 功能时，可以在容器的 Labels 或 Annotations 中添加配置参数：<div><pre><code>co.elastic.logs/enabled: <span>true</span>     <span># 是否采集容器的日志，默认为 true</span>\nco.elastic.logs/json.*: <span>..</span>.\nco.elastic.logs/multiline.*: <span>..</span>.\nco.elastic.logs/exclude_lines: <span>'^DEBUG'</span>\nco.elastic.logs/include_lines: <span>..</span>.\nco.elastic.logs/processors.dissect.tokenizer: <span>\"%{key2} %{key1}\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Kibana",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/ELK/Kibana.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/ELK/Kibana.html",
      "content_html": "<h1 id=\"kibana\"> Kibana</h1>\n<h2 id=\"部署\"> 部署</h2>\n<ol>\n<li>\n<p>下载二进制版：</p>\n<div><pre><code><span>wget</span> https://artifacts.elastic.co/downloads/kibana/kibana-7.10.0-linux-x86_64.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>解压后，编辑配置文件 config/kibana.yml ：</p>\n<div><pre><code><span>server.port</span><span>:</span> <span>5601</span>           <span># Kibana 监听的端口</span>\n<span>server.host</span><span>:</span> <span>'0.0.0.0'</span>      <span># Kibana 监听的 IP</span>\n<span>server.name</span><span>:</span> kibana         <span># 服务器显示的名称</span>\n\n<span>elasticsearch.hosts</span><span>:</span> <span>[</span><span>'http://10.0.0.1:9200'</span><span>]</span>   <span># 要连接的 ES 地址。可以指定多个 host ，但必须属于同一集群，如果前一个不能访问则使用后一个</span>\n<span># elasticsearch.username: 'admin'</span>\n<span># elasticsearch.password: '123456'</span>\n\n<span># kibana.index: '.kibana'   # 在 ES 中创建该索引，存储 Kibana 的数据</span>\n\n<span>i18n.locale</span><span>:</span> <span>'zh-CN'</span>        <span># 让 Kibana 网站显示中文</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>如果 ES 集群包含多个节点，为了对 Kibana 发向 ES 的查询请求进行负载均衡，建议在 Kibana 所在主机上部署一个 ES 节点，只担任 coordinating 角色，然后让 Kibana 将查询请求都发给它。</li>\n</ul>\n</li>\n<li>\n<p>启动：</p>\n<div><pre><code>bin/kibana\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>Kibana 的主要功能：\n<ul>\n<li>查询 ES 中的数据，并可以创建仪表盘，便于分析。</li>\n<li>管理 ES 的索引，进行多种配置。</li>\n<li>支持在网页上上传日志文件，解析后存储到 ES ，便于测试。</li>\n</ul>\n</li>\n<li>访问 URL <code>/status</code> 可查看 Kibana 自身的状态。</li>\n<li>Kibana 会将自身的数据存储在 ES 中名为 .kibana 的索引中。</li>\n<li>Kibana 网站是单页面应用，但是加载网页时很慢，刷新首页都需要 5 秒。</li>\n<li>建议在 Kibana 网站上进行以下设置：\n<ul>\n<li>设置 Default 工作区，只显示 Kibana、Observability 中需要用到的部分功能。</li>\n<li>Date format ：显示的日期格式，比如 <code>YYYY/MM/D HH:mm:ss.SSS</code> 。</li>\n<li>defaultRoute ：Kibana 网站登录之后默认跳转的页面，比如 <code>/app/discover</code> 。</li>\n<li>Maximum table cell height ：Discover 页面每个文档显示的最大高度。建议设置为 0 ，即取消限制。否则一个文档包含的内容过长时，可能显示不全。</li>\n<li>Number of rows ：Discover 页面查询时返回的文档最大数量。\n<ul>\n<li>默认值为 500 ，减小该值可以降低查询的耗时，特别是每个文档体积较大时。</li>\n<li>查询到文档之后，会先在浏览器中显示一部分文档。当用户向下翻页时，才动态加载后续的文档，直到显示出查询到的所有文档。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"discover\"> Discover</h3>\n<ul>\n<li>\n<p>Kibana 的 Discover 页面原本名为 Logs UI ，用于查询、查看日志。但现在扩展了用途，可对所有 ES 文档进行可视化查询。</p>\n</li>\n<li>\n<p>页面示例：</p>\n<p><img src=\"./kibana_discover.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>页面左上方是搜索栏，支持输入任意字符串进行全文查询，也支持复杂的查询表达式。</li>\n<li>页面右上方是时间筛选，支持筛选任意时间范围，或最近一段时间，还支持设置自动刷新的时间间隔。\n<ul>\n<li>注意要选择有效的时间范围，否则查询结果可能为空。</li>\n</ul>\n</li>\n<li>页面左侧可选择索引模式、显示的字段。\n<ul>\n<li>需要事先在 Kibana 管理页面创建 index pattern ，且字段列表变化时，需要手动点击刷新按钮。</li>\n</ul>\n</li>\n<li>页面中央是一个时间轴，显示每个时刻命中的 document 数量。</li>\n<li>页面中下方是一个列表，显示所有查询结果。\n<ul>\n<li>每行一条 document ，点击某个 document 左侧的下拉按钮，就会显示其详细信息。</li>\n<li>默认显示 Time 和 _source 字段，可以在左侧栏中指定其它字段用作显示。</li>\n</ul>\n</li>\n<li>点击搜索栏前端的保存按钮，可以保存当前的 query 配置，包括查询表达式、字段筛选、时间筛选。</li>\n<li>点击页面右上角的 Save 按钮，可以会保存当前的搜索页面，包括查询表达式、字段筛选、显示的字段，但不包括时间筛选。</li>\n</ul>\n</li>\n<li>\n<p>搜索时，默认采用 Kibana 自带的查询语言 KQL 。</p>\n<ul>\n<li>例：<div><pre><code>elastic                   <span># 查询任一字段的值包含该单词的文档。必须是分词之后完全相同的单词，比如 elasticsearch 多了字母就不匹配</span>\nelastic*                  <span># 可以使用通配符</span>\n<span>\"elastic search\"</span>          <span># 查询一个包含空格的字符串时，需要加上定界符</span>\nelastic AND NOT search    <span># 支持使用 and、or、not 逻辑运算符</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>支持用 <code>:</code> 对指定字段进行查询：<div><pre><code>agent_* <span>:</span> <span>\"filebeat-00*\"</span>            <span># 支持在字段名、值中使用通配符</span>\nagent_name: *                       <span># agent_name 字段存在</span>\nNOT agent_name: *                   <span># agent_name 字段不存在</span>\nstatus_code <span>:</span> <span>(</span><span>401</span> OR <span>403</span> OR <span>404</span><span>)</span>\nstatus_code <span>:</span> <span>200</span> AND NOT <span>(</span>tags <span>:</span> <span>(</span>success AND info<span>))</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>点击页面右上角的 Inspect ，可以查看查询的耗时、对应的 query 语句。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"fleet\"> Fleet</h3>\n<ul>\n<li>Kibana 的 Fleet 页面原本名为 Ingest Manager ，用于批量管理 Elastic Agent 。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Logstash",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/ELK/Logstash.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/ELK/Logstash.html",
      "content_html": "<h1 id=\"logstash\"> Logstash</h1>\n<p>：一个数据处理程序。可以收集多种格式的数据，加工处理之后，写入多种数据库。</p>\n<ul>\n<li>采用 Ruby 开发，通过 JRuby 解释器运行在 JVM 上。</li>\n<li>2009 年，Jordan Sissel 发布了 Logstash ，成为了流行的日志采集工具，也可处理其它类型的数据。</li>\n<li>2013 年，Logstash 被 Elastic 公司收购，组成了 ELK 系统。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制版：</p>\n<div><pre><code><span>wget</span> https://artifacts.elastic.co/downloads/logstash/logstash-7.10.0-linux-x86_64.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div><p>然后启动：</p>\n<div><pre><code>bin/logstash\n              -f <span>PATH</span>                     <span># --path.config ，指定配置文件的目录，会加载其下所有 *.conf 文件</span>\n              -e STRING                   <span># --config.string ，传入一个字符串作为配置</span>\n              --log.level<span>=</span>info            <span># 指定日志等级</span>\n              -V                          <span># 显示版本号</span>\n              -r                          <span># --config.reload.automatic ，自动加载发生变化的配置文件</span>\n              --config.reload.interval <span>3</span>  <span># 默认每隔 3 秒检查一次配置文件是否变化</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>如果启用了 -r 选项，则 logstash 检查到配置文件发生变化时，会重新加载。\n<ul>\n<li>重新加载时，logstash 会根据新的配置文件，尝试创建新管道并使用。如果新管道可以正常运行（比如语法没报错），则用新管道替换旧管道。否则，继续运行旧管道。</li>\n<li>用 <code>kill -SIGHUP</code> 发送信号，也会使其重新加载一次配置文件。</li>\n<li>插件不一定能重新加载，可能依然需要重启 logstash 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>logstash</span><span>:</span>\n    <span>container_name</span><span>:</span> logstash\n    <span>image</span><span>:</span> logstash<span>:</span>7.10.1\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 5044<span>:</span><span>5044</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config<span>:</span>/usr/share/logstash/config\n      <span>-</span> ./data<span>:</span>/usr/share/logstash/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>容器内以非 root 用户运行服务，需要调整挂载目录的权限：<div><pre><code><span>mkdir</span> -p  config data\n<span>chown</span> -R  <span>1000</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>Logstash 的配置目录的结构如下：</p>\n<div><pre><code>config/\n├── conf.d/               <span># 存放一些管道的定义文件</span>\n<span>|</span>   ├── a.conf\n<span>|</span>   └── b.conf\n├── jvm.options           <span># JVM 的配置，比如限制内存 -Xmx</span>\n├── log4j2.properties     <span># Java 日志的配置</span>\n├── logstash.yml          <span># logstash 本身的配置</span>\n├── pipelines.yml         <span># 定义管道</span>\n└── startup.options       <span># 自定义 logstash 启动命令的配置，供 systemd 读取</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>\n<p>logstash.yml 默认为空，配置示例：</p>\n<div><pre><code><span># path.data: /var/lib/logstash</span>\n<span># path.logs: /var/log/logstash</span>\n<span># log.level: info</span>\n<span># log.format: plain</span>\n\n<span># dead_letter_queue.enable: false    # 是否启用死信队列，默认为 false</span>\n<span>pipeline</span><span>:</span>\n  <span>batch</span><span>:</span>\n    <span>size</span><span>:</span> <span>125</span>   <span># input 阶段每接收指定数量的事件，才打包成一个 batch ，供 filter、output 阶段的一个 worker 处理。增加该值会提高处理速度</span>\n    <span>delay</span><span>:</span> <span>50</span>   <span># 收集 batch 时，等待接收新事件的超时时间，单位 ms 。如果等待超时，则立即打包成一个 batch 。每个新事件会单独考虑超时时间</span>\n  <span>workers</span><span>:</span> <span>4</span>    <span># 处理 filter、output 阶段的线程数，默认等于 CPU 核数。可以大于 CPU 核数，因为输出阶段的 worker 会等待网络 IO 而不占用 CPU</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>pipeline 在内存中处理的 event 最大数量为 size * workers 。</li>\n<li>接收一个 batch 的最长耗时为 size * delay 。</li>\n</ul>\n</li>\n<li>\n<p>pipelines.yml 的配置示例：</p>\n<div><pre><code><span>-</span> <span>pipeline.id</span><span>:</span> main                     <span># 创建一个管道</span>\n  <span>path.config</span><span>:</span> <span>\"config/conf.d/*.conf\"</span>   <span># 导入配置文件</span>\n  <span># pipeline.output.workers: 1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>pipelines.yml 可通过 - 创建多个管道，默认会继承 logstash.yml 全局作用域的配置。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"pipeline\"> pipeline</h2>\n<h3 id=\"原理\"> 原理</h3>\n<ul>\n<li>Linux 系统上通常通过管道符筛选日志，比如 <code>cat test.log | grep ERROR'</code> 。而 Logstash 处理数据的机制也称为管道（pipeline），每条数据称为一个事件（event）。</li>\n<li>Logstash 可以运行多个管道，每个管道分为三个阶段：\n<ul>\n<li>input ：输入数据。</li>\n<li>filter ：过滤、修改数据。该阶段可以省略。</li>\n<li>output ：输出数据。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"示例\"> 示例</h3>\n<p>通过命令行创建管道的示例：</p>\n<ol>\n<li>\n<p>启动 Logstash ，运行一个简单的管道：</p>\n<div><pre><code>bin/logstash -e <span>'input { stdin { } } output { stdout {} }'</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>这里接收 stdin 输入的数据，没有 filter ，直接输出到 stdout 。</p>\n</li>\n<li>\n<p>此时在终端输入一个字符串 Hello ，按下回车，显示的输出如下：</p>\n<div><pre><code><span>{</span>\n    <span>\"@timestamp\"</span> <span>=</span><span>></span> <span>2020</span>-01-12T07:37:00.045Z,\n          <span>\"host\"</span> <span>=</span><span>></span> <span>\"CentOS-1\"</span>,\n        <span>\"message\"</span> <span>=</span><span>></span> <span>\"Hello\"</span>,\n      <span>\"@version\"</span> <span>=</span><span>></span> <span>\"1\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ol>\n<p>通过配置文件创建管道的示例：</p>\n<ol>\n<li>\n<p>创建一个配置文件 <code>config/pipeline.conf</code> ，定义一个管道：</p>\n<div><pre><code>input <span>{</span>\n  <span># file {              # 读取文件作为输入</span>\n  <span>#   path => \"/var/log/http.log\"</span>\n  <span># }</span>\n  beats <span>{</span>               <span># 接收 beats 的输入</span>\n    port <span>=</span><span>></span> <span>\"5044\"</span>      <span># 监听一个端口，供 beats 发送数据进来。这里采用 TCP 协议通信，而不是 HTTP 协议</span>\n    <span>host</span> <span>=</span><span>></span> <span>\"0.0.0.0\"</span>\n    <span># client_inactivity_timeout => 60       # 如果 beats 连续多久未活动，则关闭 TCP 连接，单位为秒</span>\n    <span># codec => \"plain\"                      # 设置处理输入数据的格式。默认为 plain</span>\n    <span># include_codec_tag => true             # 是否给数据添加一个 tag ，记录 codec 信息。默认为 true ，使得每个 event 都有一个 beats_input_codec_plain_applied 标签</span>\n  <span>}</span>\n  <span># kafka {             # 从 kafka 获取消息</span>\n  <span>#   bootstrap_servers       => \"localhost:9092\"</span>\n  <span>#   auto_commit_interval_ms => 5000</span>\n  <span>#   auto_offset_reset       => \"latest\"</span>\n  <span>#   codec                   => \"json\"</span>\n  <span>#   consumer_threads        => 1</span>\n  <span>#   group_id                => \"logstash\"</span>\n  <span>#   topics_pattern          => \"logstash.*\"  # 根据正则表达式，订阅一些 topic</span>\n  <span># }</span>\n<span>}</span>\n\n<span># filter {</span>\n<span># }</span>\n\noutput <span>{</span>\n  stdout <span>{</span>                                  <span># 输出到终端，便于调试</span>\n    <span># codec => rubydebug                    # 输出时默认采用 rubydebug 格式</span>\n  <span>}</span>\n  <span># file {                                  # 输出到文件</span>\n  <span>#   path  => \"/tmp/http.log\"</span>\n  <span>#   codec => line { format => \"custom format: %{message}\"}    # 设置处理数据的格式。默认为 json_lines</span>\n  <span># }</span>\n  elasticsearch <span>{</span>                           <span># 输出到 ES</span>\n    <span># 该插件会将 pipeline 的一组 batch event 放在一个 bulk 请求中发出，如果单个请求超过 20M 则拆分成多个请求</span>\n    hosts <span>=</span><span>></span> <span>[</span><span>\"http://10.0.0.1:9200\"</span><span>]</span>\n    <span># user                => \"admin\"</span>\n    <span># password            => \"123456\"</span>\n    <span># ssl_certificate_verification => true                            # 使用 HTTPS 连接时，是否验证 SSL 证书</span>\n    <span># http_compression    => false                                    # 是否对请求 body 进行 gzip 压缩</span>\n    <span># index               => \"logstash-%{+yyyy.MM.dd}\"                # 指定写入的索引名。可通过 %{} 插入变量，比如 %{[field]][sub_field]}</span>\n    <span># document_id         => \"%{[@metadata][_id]}\"                    # 指定写入的文档 id 。如果已存在相同 id 的文档，则会覆盖它</span>\n    <span># manage_template     => true                                     # Logstash 启动时，是否自动在 ES 中创建索引模板</span>\n    <span># template            => \"/path/to/logstash/logstash-apache.json\" # template 的配置文件，默认使用内置的模板</span>\n    <span># template_name       => \"logstash\"                               # template 的名称</span>\n    <span># template_overwrite  => false                                    # 如果 ES 中已存在同名 template ，是否覆盖它</span>\n    <span># retry_initial_interval  => 2                                    # 第 n 次重试之前等待 n*retry_initial_interval 秒</span>\n    <span># retry_max_interval      => 64                                   # 重试时的最大间隔时间</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br></div></div><ul>\n<li>output 阶段，如果某个 event 输出失败，有几种处理措施：\n<ul>\n<li>大部分情况下，会无限重试。</li>\n<li>如果 HTTP 响应码为 409 conflict ，则不会重试，丢弃 event 。</li>\n<li>如果 HTTP 响应码为 400 mapper_parsing_exception 或 404 ，表示不能重试，则打印报错日志，丢弃 event 。\n<ul>\n<li>可以启用死信队列，将这些 event 保存到 data/dead_letter_queue/ 目录下，然后可通过 input.dead_letter_queue 插件读取。</li>\n</ul>\n</li>\n<li>如果 HTTP 响应码为 403 pressure too high ，表示 ES 负载过大，拒绝了 bulk 请求。此时会自动重试，但这会导致 ES 的负载更大，可能返回 503 Unavailable ，最终导致 Logstash 放弃重试。建议增加 retry 的间隔。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>启动 Logstash ，运行指定的管道：</p>\n<div><pre><code>bin/logstash -f config/pipeline.conf --log.level<span>=</span>debug\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n<h3 id=\"语法\"> 语法</h3>\n<p>pipeline 的语法与 Ruby 相似，特点如下：</p>\n<ul>\n<li>Hash 字典的键值对之间通过空格分隔，比如 <code>{&quot;field1&quot; =&gt; &quot;A&quot; &quot;field2&quot; =&gt; &quot;B&quot;}</code> 。</li>\n<li>支持引用变量：\n<ul>\n<li>用 <code>filed</code> 或 <code>[filed]</code> 的格式引用 event 的顶级字段。</li>\n<li>用 <code>[filed][sub_filed]...</code> 的格式引用子字段。\n<ul>\n<li>引用子字段时，如果父字段不存在，则会自动创建它，因此应该先检查父字段是否存在。如下：<div><pre><code><span>if</span> <span>[</span>json<span>]</span> and <span>[</span>json<span>]</span><span>[</span>version<span>]</span> <span>==</span> <span>\"null\"</span> <span>{</span>\n  mutate <span>{</span>\n    remove_field <span>=</span><span>></span> <span>[</span> <span>\"[json][version]\"</span> <span>]</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n<li>用 <code>%{filed}</code> 的格式获取字段的值。</li>\n<li>用 <code>${VAR}</code> 的格式获取终端环境变量的值。</li>\n<li>例：<div><pre><code>filter <span>{</span>\n  <span>if</span> <span>[</span>agent_name<span>]</span> and <span>[</span>@metadata<span>]</span><span>[</span>time<span>]</span> <span>{</span>\n    mutate <span>{</span>\n      add_field <span>{</span>\n        <span>\"port\"</span> <span>=</span><span>></span> <span>\"<span>${TCP_PORT}</span>\"</span>\n        <span>\"[@metadata][tmp_name]\"</span> <span>=</span><span>></span> <span>\"%{agent_name} %{[@metadata][time]}\"</span>\n      <span>}</span>\n    <span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li><code>@metadata</code> 字段不会被 output 阶段输出，因此可以存储一些临时的子字段。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>支持使用 if 语句：\n<ul>\n<li>支持 <code>&lt;</code>、<code>&gt;</code>、<code>&lt;=</code>、<code>&gt;=</code>、<code>==</code>、<code>!=</code> 比较运算符。</li>\n<li>支持 <code>=~</code> <code>!~</code> 运算符，判断左侧的字符串是否匹配右侧的正则表达式。</li>\n<li>支持 <code>and</code>、<code>or</code>、<code>!</code>、<code>not</code>、<code>not in</code> 逻辑运算符。</li>\n<li>例：<div><pre><code>filter <span>{</span>\n  <span>if</span> <span>[</span>level<span>]</span> <span>==</span> <span>\"DEBUG\"</span> <span>{</span>\n    grok <span>{</span><span>..</span>.<span>}</span>\n  <span>}</span>\n  <span>else</span> <span>if</span> <span>[</span>level<span>]</span> <span>==</span> <span>\"WARN\"</span> <span>{</span>\n    grok <span>{</span><span>..</span>.<span>}</span>\n  <span>}</span>\n  <span>else</span> <span>{</span>\n    grok <span>{</span><span>..</span>.<span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><div><pre><code><span>if</span> <span>[</span>level<span>]</span> <span>=~</span> <span>\"DEBUG\"</span> or <span>[</span>level<span>]</span> <span>=~</span> <span>\"WARN\"</span> or <span>[</span>level<span>]</span> <span>=~</span> <span>\"ERROR\"</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code><span>if</span> <span>[</span>level<span>]</span> <span>in</span> <span>[</span><span>\"DEBUG\"</span>, <span>\"WARN\"</span>, <span>\"ERROR\"</span><span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code><span>if</span> <span>\"_grokparsefailure\"</span> not <span>in</span> <span>[</span>tags<span>]</span>    <span># 判断一个 tag 是否在 tags 字段中存在</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code><span>if</span> <span>[</span>level<span>]</span>                              <span># 判断一个字段是否存在，且取值不为 false、null</span>\n</code></pre>\n<div><span>1</span><br></div></div><div><pre><code><span>if</span> <span>!</span><span>[</span>level<span>]</span> <span>{</span>                           <span># 如果字段不存在，则添加它</span>\n  add_field <span>=</span><span>></span> <span>{</span> <span>\"level\"</span> <span>=</span><span>></span> <span>\"DEBUG\"</span> <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"插件\"> 插件</h2>\n<h3 id=\"codec\"> codec</h3>\n<ul>\n<li>codec 类型的插件用于按特定的文本格式编码、解码数据，可以用于 pipeline 的 input 或 output 阶段。</li>\n<li>codec 插件举例：<div><pre><code>plain         <span># 纯文本，即不进行处理</span>\nline          <span># 用于解码输入时，将每行文本视作一个 event 。用于编码输出时，将每个 event 保存成一行文本</span>\nmultiline     <span># 将连续的多行文本视作同一个 event 。不过该操作可以由 Beats 完成，减轻 Logstash 的工作量</span>\njson          <span># 按 JSON 格式处理，忽略换行符、缩进</span>\njson_lines    <span># 根据换行符 `\\n` 将文本分成多行，每行视作一个 JSON 格式的 event</span>\nrubydebug     <span># 按 Ruby 调试信息的格式处理</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"grok\"> grok</h3>\n<p>：一个 filter 插件，用于按正则表达式解析 event 中的某些字段。</p>\n<ul>\n<li>\n<p>Kibana 网页上提供的开发工具包含了 grok debugger ，便于调试 grok pattern 。</p>\n</li>\n<li>\n<p>例：</p>\n<ol>\n<li>\n<p>假设输入数据是一行纯文本格式的日志：</p>\n<div><pre><code><span>2020</span>-01-12 07:24:43.659+0000  INFO  <span>10.0</span>.0.1 User login successfully\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>编写一个 grok 表达式来解析：</p>\n<div><pre><code>%<span>{</span>TIMESTAMP_ISO8601:timestamp<span>}</span><span>\\</span>s+<span>(</span>?<span>&lt;</span>level<span>></span><span>\\</span>S+<span>)</span><span>\\</span>s+<span>(</span>?<span>&lt;</span>client_ip<span>></span><span>\\</span>S+<span>)</span><span>\\</span>s+<span>(</span>?<span>&lt;</span>message<span>></span>.*<span>)</span>$\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>可以按 <code>(?&lt;field&gt;pattern)</code> 的格式匹配字段。例如 <code>(?&lt;level&gt;\\S+)</code> 表示使用正则表达式 <code>\\S+</code> 进行匹配，将匹配结果赋值给名为 level 的字段。</li>\n<li>可以按 <code>%{NAME:field}</code> 的格式调用事先定义的正则表达式。例如 <code>%{TIMESTAMP_ISO8601:timestamp}</code> 表示使用一个名为 TIMESTAMP_ISO8601 的正则表达式进行匹配，将匹配结果赋值给名为 timestamp 的字段。</li>\n</ul>\n</li>\n<li>\n<p>grok 输出的结构化数据为：</p>\n<div><pre><code><span>{</span>\n  <span>\"level\"</span><span>:</span> <span>\"INFO\"</span>,\n  <span>\"client_ip\"</span><span>:</span> <span>\"10.0.0.1\"</span>,\n  <span>\"message\"</span><span>:</span> <span>\"User login successfully\"</span>,\n  <span>\"timestamp\"</span><span>:</span> <span>\"2020-01-12 07:24:43.659+0000\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ol>\n</li>\n<li>\n<p>可以事先定义一些正则表达式，然后通过名称调用它们。</p>\n<ul>\n<li>定义格式为：<div><pre><code>NAME  pattern\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>例：<div><pre><code>INT         <span>(</span>?:<span>[</span>+-<span>]</span>?<span>(</span>?:<span>[</span><span>0</span>-9<span>]</span>+<span>))</span>\nWORD        <span>\\</span>b<span>\\</span>w+<span>\\</span>b\nSPACE       <span>\\</span>s*\nNOTSPACE    <span>\\</span>S+\nGREEDYDATA  .*\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>grok 内置了一些 <a href=\"https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/ecs-v1/grok-patterns\" target=\"_blank\" rel=\"noopener noreferrer\">patterns</a> 。</li>\n</ul>\n</li>\n<li>\n<p>例：在 pipeline 的 filter 中使用 grok 插件</p>\n<div><pre><code>filter <span>{</span>\n  grok <span>{</span>\n    match <span>=</span><span>></span> <span>{</span> <span>\"message\"</span> <span>=</span><span>></span> <span>\"%{TIMESTAMP_ISO8601:timestamp}\\s+(?&lt;level>\\S+)\\s+(?&lt;client_ip>\\S+)\\s+(?&lt;message>.*)$\"</span> <span>}</span>  <span># 解析 message 字段，通过正则匹配提取内容另存为字段</span>\n    overwrite <span>=</span><span>></span> <span>[</span> <span>\"message\"</span> <span>]</span>                        <span># 允许提取的这些字段覆盖 event 中已存在的字段</span>\n    <span># patterns_dir => [\"config/patterns\"]             # 加载 patterns 的定义文件</span>\n    <span># keep_empty_captures => false                    # 如果匹配到的字段为空，是否依然保留该字段</span>\n    <span># tag_on_failure => [\"_grokparsefailure\"]         # 如果匹配失败，则给 event 添加这些 tag</span>\n    <span># tag_on_timeout => [\"_groktimeout\"]              # 如果匹配超时，则给 event 添加这些 tag</span>\n    <span># timeout_millis => 30000                         # 匹配的超时时间，单位 ms</span>\n\n    <span># 以下是所有 filter 插件通用的配置参数</span>\n    <span># add_field       => {                            # 添加字段</span>\n    <span>#   \"test_field\"  => \"Hello\"</span>\n    <span>#   \"from_%{IP}\"  => \"this is from %{IP}\"</span>\n    <span># }</span>\n    <span># add_tag         => [\"test_tag\", \"from_%{IP}\"]   # 添加标签</span>\n    <span># remove_field    => [\"field_1\" , \"from_%{IP}\"]   # 删除字段</span>\n    <span># remove_tag      => [\"test_tag\", \"from_%{IP}\"]   # 删除标签</span>\n    <span># id              => \"ABC\"                        # 该插件的唯一 id ，默认会自动生成</span>\n    <span># enable_metric   => true                         # 是否记录该插件的指标</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br></div></div><ul>\n<li>在 if 语句内可以调用 filter 插件，但反之不行。可以写成以下形式：<div><pre><code><span>if</span> xxx <span>{</span>\n  grok <span>{</span><span>}</span>\n  <span>if</span> xxx <span>{</span>\n    grok <span>{</span><span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>如果输入数据的每行格式可能不同，则可以在 match 中指定多个表达式用于尝试匹配：<div><pre><code>match <span>=</span><span>></span> <span>{</span>\n  <span>\"message\"</span> <span>=</span><span>></span> <span>[</span>\n    <span>\"DEBUG (?&lt;message>.*)$\"</span>,\n    <span>\"INFO  (?&lt;message>.*)$\"</span>\n  <span>]</span>\n  <span># break_on_match => true    # 当表达式匹配成功时，不再尝试匹配之后的表达式</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div>不过这样会多次执行正则表达式，比如第一个正则表达式总是会被执行，开销较大。不如通过 if 语句选择性地执行 grok 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"json\"> json</h3>\n<p>：一个 filter 插件，用于按 JSON 格式解析 event 的一个字段。</p>\n<ul>\n<li>例：<div><pre><code>json <span>{</span>\n  <span>source</span> <span>=</span><span>></span> <span>\"message\"</span>                         <span># 按 JSON 格式解析 message 字段的值</span>\n  <span># target => \"json\"                          # 将解析之后的 JSON 字典保存到该字段.如果该字段已存在，则覆盖它。如果不配置，则存储为顶级字段</span>\n  <span># skip_on_invalid_json => false             # 解析失败时，不发出警告</span>\n  <span># tag_on_failure => [\"_jsonparsefailure\"]</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"date\"> date</h3>\n<p>：一个 filter 插件，用于解析 event 的一个字段，获取时间。</p>\n<ul>\n<li>例：<div><pre><code><span>if</span> <span>[</span>timestamp<span>]</span> <span>{</span>\n  <span>date</span> <span>{</span>\n    match <span>=</span><span>></span> <span>[</span><span>\"timestamp\"</span>, <span>\"ISO8601\"</span>, <span>\"yyyy-MM-dd HH:mm:ss.SSSZ\"</span>, <span>\"UNIX\"</span>, <span>\"UNIX_MS\"</span><span>]</span>   <span># 指定源字段，然后可以指定多个尝试匹配的时间字符串格式</span>\n    remove_field <span>=</span><span>></span> <span>[</span><span>\"timestamp\"</span><span>]</span>\n    <span># target => \"@timestamp\"                      # 将解析之后的时间保存到该字段。如果该字段已存在，则覆盖它</span>\n    <span># tag_on_failure => [\"_dateparsefailure\"]</span>\n    timezone <span>=</span><span>></span> <span>\"Asia/Shanghai\"</span>                   <span># 如果没有从源字段解析出时区，则采用该默认时区</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h3 id=\"drop\"> drop</h3>\n<p>：一个 filter 插件，用于丢弃一些 event 。</p>\n<ul>\n<li>例：<div><pre><code><span>if</span> <span>[</span>level<span>]</span> <span>==</span> <span>\"DEBUG\"</span> <span>{</span>\n  drop <span>{</span>\n    <span># percentage => 40      # 丢弃的概率大概为 40%</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n<h3 id=\"mutate\"> mutate</h3>\n<p>：一个 filter 插件，用于修改 event 的一些字段。</p>\n<ul>\n<li>例：<div><pre><code>mutate <span>{</span>\n  copy       <span>=</span><span>></span> <span>{</span> <span>\"field1\"</span> <span>=</span><span>></span> <span>\"field2\"</span> <span>}</span>         <span># 拷贝一个字段的值，赋值给另一个字段</span>\n  <span>rename</span>     <span>=</span><span>></span> <span>{</span> <span>\"field1\"</span> <span>=</span><span>></span> <span>\"field2\"</span> <span>}</span>         <span># 重命名一个字段</span>\n  replace    <span>=</span><span>></span> <span>{</span> <span>\"field1\"</span> <span>=</span><span>></span> <span>\"new: %{field2}\"</span> <span>}</span> <span># 替换一个字段的值</span>\n  convert    <span>=</span><span>></span> <span>{</span>                                <span># 转换字段的数据类型，默认都是字符串类型</span>\n    <span>\"field1\"</span> <span>=</span><span>></span> <span>\"boolean\"</span>\n    <span>\"field2\"</span> <span>=</span><span>></span> <span>\"integer\"</span>                        <span># 可以按这种格式同时处理多个字段</span>\n  <span>}</span>\n  lowercase  <span>=</span><span>></span> <span>[</span> <span>\"field1\"</span> <span>]</span>                     <span># 将字段的值改为小写</span>\n  uppercase  <span>=</span><span>></span> <span>[</span> <span>\"field1\"</span> <span>]</span>                     <span># 将字段的值改为大写</span>\n  strip      <span>=</span><span>></span> <span>[</span> <span>\"field1\"</span> <span>]</span>                     <span># 删掉字段的值前后的空白字符</span>\n  <span>split</span>      <span>=</span><span>></span> <span>{</span> <span>\"[json][version]\"</span> <span>=</span><span>></span> <span>\".\"</span> <span>}</span>     <span># 根据指定的字符分割一个字段的值，保存为数组形式</span>\n  <span># tag_on_failure => [\"_mutate_error\"]</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<h3 id=\"geoip\"> geoip</h3>\n<p>：一个 filter 插件，用于查询 IP 地址对应地理位置，包括经纬度坐标、国家名、城市名等。</p>\n<ul>\n<li>查询时的开销比较大。</li>\n<li>例：<div><pre><code>geoip <span>{</span>\n  <span>source</span> <span>=</span><span>></span> <span>\"client_ip\"</span>                         <span># 存储 IP 地址的字段</span>\n  target <span>=</span><span>></span> <span>\"geoip\"</span>                             <span># 存储查询结果的字段</span>\n  <span># database => \"xx/xx/GeoLite2-City.mmdb\"      # 用于查询的数据库文件。默认使用自带的免费 GeoLite2 数据库，并每天自动更新</span>\n  <span># cache_size => 1000                          # 缓存区的大小。查询一些重复 IP 或相邻 IP 时，使用缓存可以提高效率</span>\n  <span># tag_on_failure => [\"_geoip_lookup_failure\"]</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n<h3 id=\"ruby\"> ruby</h3>\n<p>：一个 filter 插件，用于嵌入 Ruby 代码。</p>\n<ul>\n<li>例：<div><pre><code>ruby <span>{</span>\n  code <span>=</span><span>></span> <span>\"event.cancel if rand &lt;= 0.90\"</span>    <span># 执行 Ruby 代码，这里是 90% 的概率取消 event</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>可以导入一个 Ruby 脚本文件：<div><pre><code>ruby <span>{</span>\n  path <span>=</span><span>></span> <span>\"test_filter.rb\"</span>\n  script_params <span>=</span><span>></span> <span>{</span> <span>\"percentage\"</span> <span>=</span><span>></span> <span>0.9</span> <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div>脚本的内容示例：<div><pre><code><span>def</span> <span><span>register</span></span><span>(</span>params<span>)</span>        <span># 可以定义一个 register(params) 函数，接收传给脚本的参数</span>\n  <span>@drop_percentage</span> <span>=</span> params<span>[</span><span><span>\"percentage\"</span></span><span>]</span>\n<span>end</span>\n\n<span>def</span> <span><span>filter</span></span><span>(</span>event<span>)</span>           <span># 必须定义一个 filter(event) 函数，输入 event ，返回一个包含事件的数组</span>\n  <span>if</span> rand <span>>=</span> <span>@drop_percentage</span>\n    <span>return</span> <span>[</span>event<span>]</span>\n  <span>else</span>\n    <span>return</span> <span>[</span><span>]</span>               <span># 返回一个空数组，这会取消 event</span>\n  <span>end</span>\n<span>end</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "OpenSearch",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/ELK/OpenSearch.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/ELK/OpenSearch.html",
      "content_html": "<h1 id=\"opensearch\"> OpenSearch</h1>\n<ul>\n<li>ELK 软件分为社区版（OSS）、收费版（X-Pack）。\n<ul>\n<li>Elastic 公司加大了商业化的程度，逐渐对软件的部分功能收费，导致 OSS 版缺少一些重要功能，比如身份认证、用户权限控制、告警。</li>\n</ul>\n</li>\n<li>2019 年，AWS 公司创建了 Open Distro for Elasticsearch 项目，通过给 ES、Kibana 的 OSS 版安装一些插件，扩展出 X-Pack 版的功能。\n<ul>\n<li>功能、配置有些小差异，这是为了回避 Elastic 公司的版权。</li>\n</ul>\n</li>\n<li>2021 年初，Elastic 公司宣布从 v7.11 版本开始，将 ES、Kibana 软件的开源协议从 Apache V2 改为 SSPL 。\n<ul>\n<li>SSPL 是一种未被 OSI（Open Source Initiative）组织认可的开源协议，禁止用户将该软件作为服务出售，除非购买商业许可证。</li>\n<li>对此，AWS 公司宣布从 ES、Kibana 分叉出 <a href=\"https://opensearch.org\" target=\"_blank\" rel=\"noopener noreferrer\">OpenSearch</a> 项目，取代之前的 Open Distro for Elasticsearch 项目，采用 Apache V2 开源协议。主要发布了以下软件：\n<ul>\n<li><a href=\"https://github.com/opensearch-project/OpenSearch\" target=\"_blank\" rel=\"noopener noreferrer\">OpenSearch</a> ：对标 ES 。</li>\n<li><a href=\"https://github.com/opensearch-project/OpenSearch-Dashboards\" target=\"_blank\" rel=\"noopener noreferrer\">OpenSearch-Dashboards</a> ：对标 Kibana 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>opensearch</span><span>:</span>\n    <span>container_name</span><span>:</span> opensearch\n    <span>image</span><span>:</span> opensearchproject/opensearch<span>:</span>1.1.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 9200<span>:</span><span>9200</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config<span>:</span>/usr/share/opensearch/config\n      <span>-</span> ./data<span>:</span>/usr/share/opensearch/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>opensearch_dashboards</span><span>:</span>\n    <span>container_name</span><span>:</span> opensearch_dashboards\n    <span>image</span><span>:</span> opensearchproject/opensearch<span>-</span>dashboards<span>:</span>1.1.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 5601<span>:</span><span>5601</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config<span>:</span>/usr/share/opensearch<span>-</span>dashboards/config\n      <span>-</span> ./data<span>:</span>/usr/share/opensearch<span>-</span>dashboards/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>可以先用 docker run 启动一个容器，将其中的 config 目录拷贝出来，修改之后再挂载。</li>\n<li>容器内以非 root 用户运行服务，需要调整挂载目录的权限：<div><pre><code><span>mkdir</span> -p  config data\n<span>chown</span> -R  <span>1000</span>  <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>elasticsearch.yml 的配置示例：</p>\n<div><pre><code><span>cluster.name</span><span>:</span> test\n<span>discovery.type</span><span>:</span> single<span>-</span>node\n<span>node.name</span><span>:</span> node<span>-</span><span>1</span>\n<span>network.host</span><span>:</span> 0.0.0.0\n<span>network.publish_host</span><span>:</span> 10.0.0.1\n\n<span>compatibility.override_main_response_version</span><span>:</span> <span>true</span>  <span># 提供 version.number ，且固定为 7.10.2 ，从而与其它客户端软件兼容</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>opensearch_dashboards.yml 的配置示例：</p>\n<div><pre><code><span>server.port</span><span>:</span> <span>5601</span>\n<span>server.host</span><span>:</span> 0.0.0.0\n<span>server.name</span><span>:</span> opensearch_dashboards\n\n<span>elasticsearch.hosts</span><span>:</span> <span>[</span><span>'https://10.0.0.1:9200'</span><span>]</span>  <span># 连接 ES 时采用 HTTPS 协议</span>\n<span>elasticsearch.ssl.verificationMode</span><span>:</span> none        <span># 不验证 ES 的 SSL 证书是否有效</span>\n<span>elasticsearch.username</span><span>:</span> kibanaserver\n<span>elasticsearch.password</span><span>:</span> <span>******</span>\n<span>elasticsearch.requestHeadersWhitelist</span><span>:</span> <span>[</span>securitytenant<span>,</span>Authorization<span>]</span>\n\n<span>opensearch_security.cookie.secure</span><span>:</span> <span>false</span>        <span># 当前端采用 HTTPS 时启用它</span>\n<span>opensearch_security.cookie.ttl</span><span>:</span> <span>86400000</span>        <span># cookie 的有效期，单位 ms ，默认为 1 小时</span>\n<span>opensearch_security.session.ttl</span><span>:</span> <span>86400000</span>       <span># session 的有效期，超时则需要用户重新登录。默认为 1 小时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n<li>\n<p>让 Logstash 输出到 OpenSearch 的方法：</p>\n<ol>\n<li>在 Logstash 中安装插件：<div><pre><code>logstash-plugin <span>install</span> logstash-output-opensearch\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>将 Logstash 的输出端从 elasticsearch 改名为 opensearch ：<div><pre><code>opensearch <span>{</span>\n    hosts <span>=></span> <span>[</span><span><span>\"http://10.0.0.1:9200\"</span></span><span>]</span>\n    <span>...</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"security-插件\"> Security 插件</h3>\n<ul>\n<li>\n<p>默认启用了 Security 插件，但还需要在 elasticsearch.yml 中加入配置：</p>\n<div><pre><code><span># plugins.security.disabled: false</span>\n<span>plugins.security.ssl.transport.pemcert_filepath</span><span>:</span> admin.pem            <span># SSL 证书文件。必须在 config 目录下，使用相对路径</span>\n<span>plugins.security.ssl.transport.pemkey_filepath</span><span>:</span> admin<span>-</span>key.pem         <span># SSL 私钥</span>\n<span>plugins.security.ssl.transport.pemtrustedcas_filepath</span><span>:</span> root<span>-</span>ca.pem    <span># SSL 根证书</span>\n<span>plugins.security.ssl.transport.enforce_hostname_verification</span><span>:</span> <span>false</span>   <span># 是否验证主机名</span>\n<span>plugins.security.ssl.http.enabled</span><span>:</span> <span>true</span>                               <span># 是否让 ES 监听 HTTPS 端口</span>\n<span>plugins.security.ssl.http.pemcert_filepath</span><span>:</span> admin.pem\n<span>plugins.security.ssl.http.pemkey_filepath</span><span>:</span> admin<span>-</span>key.pem\n<span>plugins.security.ssl.http.pemtrustedcas_filepath</span><span>:</span> root<span>-</span>ca.pem\n<span>plugins.security.allow_unsafe_democertificates</span><span>:</span> <span>true</span>\n<span>plugins.security.allow_default_init_securityindex</span><span>:</span> <span>true</span>\n<span>plugins.security.authcz.admin_dn</span><span>:</span>               <span># 将使用指定证书的客户端视作管理员</span>\n  <span>-</span> CN=ADMIN<span>,</span>OU=UNIT<span>,</span>O=ORG<span>,</span>L=TORONTO<span>,</span>ST=ONTARIO<span>,</span>C=CA\n<span>plugins.security.audit.type</span><span>:</span> internal_opensearch\n<span>plugins.security.enable_snapshot_restore_privilege</span><span>:</span> <span>true</span>\n<span>plugins.security.check_snapshot_restore_write_privileges</span><span>:</span> <span>true</span>\n<span>plugins.security.restapi.roles_enabled</span><span>:</span> <span>[</span><span>\"all_access\"</span><span>,</span> <span>\"security_rest_api_access\"</span><span>]</span>\n<span>plugins.security.system_indices.enabled</span><span>:</span> <span>true</span>\n<span>plugins.security.system_indices.indices</span><span>:</span> <span>[</span><span>\".opendistro-alerting-config\"</span><span>,</span> <span>\".opendistro-alerting-alert*\"</span><span>,</span> <span>\".opendistro-anomaly-results*\"</span><span>,</span> <span>\".opendistro-anomaly-detector*\"</span><span>,</span> <span>\".opendistro-anomaly-checkpoints\"</span><span>,</span> <span>\".opendistro-anomaly-detection-state\"</span><span>,</span> <span>\".opendistro-reports-*\"</span><span>,</span> <span>\".opendistro-notifications-*\"</span><span>,</span> <span>\".opendistro-notebooks\"</span><span>,</span> <span>\".opendistro-asynchronous-search-response*\"</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div><ul>\n<li>需要用 openssl 生成 SSL 自签名证书：<div><pre><code><span># 为网站生成 SSL 自签名证书</span>\nopenssl genrsa -out root-ca-key.pem <span>2048</span>\nopenssl req -new -x509 -sha256 -key root-ca-key.pem -subj <span>\"/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=ROOT\"</span> -out root-ca.pem -days <span>730</span>\n\n<span># 为管理员生成证书</span>\nopenssl genrsa -out admin-key-temp.pem <span>2048</span>\nopenssl pkcs8 -inform PEM -outform PEM -in admin-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out admin-key.pem\nopenssl req -new -key admin-key.pem -subj <span>\"/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=ADMIN\"</span> -out admin.csr\nopenssl x509 -req -in admin.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out admin.pem -days <span>730</span>\n\n<span># 删除不用的文件</span>\n<span>rm</span> -f root-ca-key.pem root-ca.srl\n<span>rm</span> -f admin.csr admin-key-temp.pem\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>当 ES 初次启动时，Security 插件会进行初始化：</p>\n<ul>\n<li>读取 <code>/usr/share/opensearch/plugins/opensearch-security/securityconfig/</code> 目录下的各个配置文件，随后一直将自身的数据存储在 ES 的名为 .opendistro_security 的索引中。</li>\n<li>根据 internal_users.yml 文件创建内部用户数据库，包含多个用户。</li>\n</ul>\n</li>\n<li>\n<p>如果想修改 Security 插件的配置，需要先使用 securityadmin.sh 从 ES 下载运行时的配置信息，修改之后再上传。如下：</p>\n<div><pre><code><span>bash</span> plugins/opensearch-security/tools/securityadmin.sh <span>\\</span>\n    <span># -h localhost \\              # ES 的地址</span>\n    -backup tmp/ <span>\\</span>                <span># 下载配置文件到该目录（会下载全部类型的配置文件）</span>\n    <span># -cd tmp/ \\                  # 上传该目录下的配置文件（该目录下必须包含全部类型的配置文件）</span>\n    -icl <span>\\</span>                        <span># 忽略 ES 集群的名称</span>\n    -nhnv <span>\\</span>                       <span># 不验证 SSL 证书是否有效</span>\n    -cacert config/root-ca.pem <span>\\</span>\n    -cert config/admin.pem <span>\\</span>\n    -key config/admin-key.pem\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h3 id=\"用户\"> 用户</h3>\n<ul>\n<li>\n<p>Security 插件支持多种认证后端，比如内部用户数据库（Internal users Database）、LDAP、Kerberos 等。</p>\n<ul>\n<li>如果启用了多个后端，当用户登录时，会依次尝试用各个后端进行身份认证，直到有一个认证成功，或者全部认证失败。</li>\n</ul>\n</li>\n<li>\n<p>可以通过 HTTP Basic Auth 方式进行身份认证：</p>\n<div><pre><code><span>curl</span> -u admin:admin --insecure https://127.0.0.1:9200/_cat/indices\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>admin、kibanaserver 两个用户是保留的（Reserved），不允许在网页上修改，只能在 internal_users.yml 中修改。步骤如下：</p>\n<ol>\n<li>使用 ES 自带的脚本，生成密码的哈希值：<div><pre><code><span>docker</span> <span>exec</span> -it elasticsearch <span>bash</span> plugins/opensearch-security/tools/hash.sh\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>修改 internal_users.yml 中的用户密码哈希值：</li>\n<li>让 Security 插件应用新的配置：\n<ul>\n<li>可以清空 ES 挂载的 data 目录，再重新启动容器，让 Security 插件重新初始化。</li>\n<li>或者使用 securityadmin.sh 脚本上传配置文件。</li>\n</ul>\n</li>\n<li>更新 opensearch_dashboards.yml 等文件中使用的用户密码。</li>\n</ol>\n</li>\n<li>\n<p>其他用户，比如 kibanaro、logstash ，都可以在网页上修改自己的密码。</p>\n<ul>\n<li>每个用户的初始密码与用户名相同。为了安全，应该都更新密码。</li>\n<li>admin 用户有权限查看 Security 插件的配置页面，管理所有用户。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"角色\"> 角色</h3>\n<ul>\n<li>Security 插件根据角色（Roles）控制每个用户的访问权限。</li>\n<li>创建一个角色时，可以配置该角色有权访问哪些资源。\n<ul>\n<li>可以限制访问的索引，还可以筛选可见的文档、字段，可以根据用户的属性值控制权限。</li>\n</ul>\n</li>\n<li>创建角色之后再点击查看它的 Mapped users 选项卡，配置它映射（Map）到哪些用户或后端角色。\n<ul>\n<li>编辑用户时，可以选择将该用户映射到 LDAP 等外部后端中的后端角色（Backend Roles），便于批量管理。</li>\n<li>如果一个用户映射了多个角色，权限较少的角色可能会覆盖权限较多的角色。</li>\n<li>修改了角色权限之后，用户要重新登录才会生效。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"权限\"> 权限</h3>\n<ul>\n<li>权限（Permissions）：表示允许某种操作，比如 <code>cluster:monitor/health</code>、<code>indices:data/read/get</code> 。</li>\n<li>还可以定义动作组（Action Group），包含一组权限或动作组。</li>\n<li>创建普通角色时，可以只分配以下权限：\n<ul>\n<li>对集群 cluster 没有权限</li>\n<li>对索引 .kibana* 的 read 权限（read 包括 get、mget、search）</li>\n<li>对索引 logstash* 的 read 权限，可以筛选可见的文档、字段</li>\n<li>对 Global tenant 的 Read only 权限</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"租户\"> 租户</h3>\n<ul>\n<li>租户（tenant）：一种命名空间，用于独立保存索引模式、可视化、仪表盘等配置。</li>\n<li>每个用户在登录之后，需要选用一个租户，并可以随时切换租户。</li>\n<li>可以控制一个用户有权读取、修改哪些租户。</li>\n<li>默认创建了两个特殊租户：\n<ul>\n<li>Global ：一个全局唯一的租户，被所有用户共享，可以同时修改。</li>\n<li>Private ：每个用户都会创建一个私有租户，不会被其它用户看到。</li>\n</ul>\n</li>\n<li>opensearch_dashboards.yml 的相关配置：<div><pre><code><span>opensearch_security.multitenancy.enabled</span><span>:</span> <span>true</span>                            <span># 是否启用多租户功能</span>\n<span>opensearch_security.multitenancy.tenants.preferred</span><span>:</span> <span>[</span><span>\"Private\"</span><span>,</span> <span>\"Global\"</span><span>]</span> <span># 默认显示的租户顺序</span>\n<span># opensearch_security.multitenancy.tenants.enable_global: true            # 是否启用 Global 租户</span>\n<span># opensearch_security.multitenancy.tenants.enable_private: true</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"ism\"> ISM</h3>\n<p>：索引状态管理（Index State Management），是一些自动管理索引的策略，对标 ES 社区版的 ILM 功能。</p>\n<ul>\n<li>\n<p>ISM 策略给索引定义了多个状态（state）。</p>\n<ul>\n<li>索引同时只能处于一个状态。</li>\n<li>每个状态的主要内容：\n<ul>\n<li>actions ：该状态需要执行的一组动作。</li>\n<li>transitions ：控制如何切换到下一个状态。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>默认每隔 5 分钟执行一次所有 ISM 策略。</p>\n<ul>\n<li>每个执行周期，只会执行 ISM 策略中的一个步骤，然后暂停执行，等待下一个执行周期。</li>\n</ul>\n</li>\n<li>\n<p>创建一个 ISM 策略之后，其工作步骤如下：</p>\n<ol>\n<li>初始化 ISM 策略，让索引进入初始状态。</li>\n<li>根据索引所处的状态，按顺序执行 actions 。</li>\n<li>根据索引所处的状态，执行 transitions 条件。\n<ul>\n<li>如果满足条件则切换到下一个状态，从第 2 步开始重复。</li>\n<li>如果不满足，则从第 3 步开始重复。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>例：创建一个 ISM 策略</p>\n<div><pre><code><span>{</span>\n    <span>\"policy\"</span><span>:</span> <span>{</span>\n        <span>\"description\"</span><span>:</span> <span>\"管理一般的日志索引\"</span><span>,</span>\n        <span>\"ism_template\"</span><span>:</span> <span>{</span>\n            <span>\"index_patterns\"</span><span>:</span> <span>[</span><span>\"logstash*\"</span><span>,</span> <span>\"filebeat*\"</span><span>]</span><span>,</span> <span>// 指定一些索引模式，被该 ISM 策略管理</span>\n            <span>// \"priority\": 100                            // 优先级，默认为 0 。如果一个索引匹配多个 ISM ，则采用优先级最高的那个</span>\n        <span>}</span><span>,</span>\n        <span>\"default_state\"</span><span>:</span> <span>\"creat\"</span><span>,</span>                         <span>// 执行该 ISM 策略时，索引的初始状态</span>\n        <span>\"states\"</span><span>:</span> <span>[</span><span>{</span>                                      <span>// 定义状态列表</span>\n                <span>\"name\"</span><span>:</span> <span>\"creat\"</span><span>,</span>                          <span>// 一个状态的名称</span>\n                <span>\"actions\"</span><span>:</span> <span>[</span><span>{</span>\n                    <span>\"replica_count\"</span><span>:</span> <span>{</span>                    <span>// 执行内置的 replica_count 动作，用于设置 replica shard 的数量</span>\n                        <span>\"number_of_replicas\"</span><span>:</span> <span>0</span>\n                    <span>}</span>\n                    <span>// \"timeout\": \"1h\",                   // 执行该动作的超时时间</span>\n                    <span>// \"retry\": {                         // 执行该动作失败时进行重试</span>\n                    <span>//    \"count\": 3,                     // 最多重试几次</span>\n                    <span>//    \"delay\": \"10m\"                  // 每次延迟一定时长再重试，默认为 1m</span>\n                    <span>// }</span>\n                <span>}</span><span>]</span><span>,</span>\n                <span>\"transitions\"</span><span>:</span> <span>[</span><span>{</span>                         <span>// 如果满足 conditions 条件，就切换到指定状态</span>\n                    <span>\"state_name\"</span><span>:</span> <span>\"keep\"</span><span>,</span>\n                    <span>// \"conditions\": {}                   // 如果省略条件，则会立即切换</span>\n                <span>}</span><span>]</span>\n            <span>}</span><span>,</span>\n            <span>{</span>\n                <span>\"name\"</span><span>:</span> <span>\"keep\"</span><span>,</span>\n                <span>\"actions\"</span><span>:</span> <span>[</span><span>]</span><span>,</span>\n                <span>\"transitions\"</span><span>:</span> <span>[</span><span>{</span>\n                    <span>\"state_name\"</span><span>:</span> <span>\"delete\"</span><span>,</span>\n                    <span>\"conditions\"</span><span>:</span> <span>{</span>\n                        <span>\"min_index_age\"</span><span>:</span> <span>\"30d\"</span>            <span>// 如果索引创建之后超过一定时长，则删除索引</span>\n                    <span>}</span>\n                <span>}</span><span>]</span>\n            <span>}</span><span>,</span>\n            <span>{</span>\n                <span>\"name\"</span><span>:</span> <span>\"delete\"</span><span>,</span>\n                <span>\"actions\"</span><span>:</span> <span>[</span><span>{</span>\n                    <span>\"delete\"</span><span>:</span> <span>{</span><span>}</span>\n                <span>}</span><span>]</span><span>,</span>\n                <span>\"transitions\"</span><span>:</span> <span>[</span><span>]</span>\n            <span>}</span>\n        <span>]</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br></div></div><ul>\n<li>创建 ISM 策略之后，会在每个索引创建时根据 index_patterns 自动应用，但不会影响已存在的索引，需要手动应用。</li>\n<li>当索引已经应用 ISM 策略之后，修改 ISM 策略并不会生效，需要移除策略，再重新应用。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "ELK",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/ELK/",
      "id": "/Hardware/DevOps/MonitoringAlarms/ELK/",
      "content_html": "<h1 id=\"elk\"> ELK</h1>\n<p>：一个对大量数据（通常是日志）进行采集、存储、展示的系统，又称为 ELK Stack 或 Elastic Stack ，由 Elastic 公司发布。</p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li><a href=\"https://www.elastic.co/cn/downloads/\" target=\"_blank\" rel=\"noopener noreferrer\">下载页面</a></li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<h3 id=\"组件\"> 组件</h3>\n<p>ELk 系统主要由以下软件组成：</p>\n<ul>\n<li>ElasticSearch\n<ul>\n<li>用于存储数据，并支持查询。</li>\n</ul>\n</li>\n<li>Logstash\n<ul>\n<li>用于收集日志数据，解析成格式化数据之后，发送到 ES 中存储。</li>\n</ul>\n</li>\n<li>Kibana\n<ul>\n<li>一个基于 node.js 运行的 Web 服务器，用于查询、展示 ES 中存储的数据。</li>\n</ul>\n</li>\n</ul>\n<p>ELK 系统还可以选择加入以下软件：</p>\n<ul>\n<li>Beats\n<ul>\n<li>采用 Golang 开发，用于采集日志数据。比 Logstash 更轻量级，但功能较少。</li>\n<li>Beats 程序有多种类型：\n<ul>\n<li>Filebeat ：用于采集日志文件。</li>\n<li>Packetbeat ：用于采集网络数据包的日志。</li>\n<li>Winlogbeat ：用于采集 Windows 的 event 日志。</li>\n<li>Metricbeat ：用于采集系统或软件的性能指标。</li>\n<li>Auditbeat ：用于采集 Linux Audit 进程的日志。</li>\n</ul>\n</li>\n<li>用户也可以基于 Beats 框架开发自定义的 Beats 程序。</li>\n</ul>\n</li>\n<li>Elastic Agent\n<ul>\n<li>v7.8 版本新增的软件，用于采集日志数据。它集成了不同类型的 Beats 的功能。</li>\n</ul>\n</li>\n<li>Observability\n<ul>\n<li>为 Kibana 扩展了一些日志可视化的功能，比如实时查看日志、设置告警规则。</li>\n</ul>\n</li>\n<li>Security\n<ul>\n<li>用于监控一些安全事项。</li>\n</ul>\n</li>\n<li>APM（Application Performance Monitoring）\n<ul>\n<li>用于采集、监控应用程序的性能指标。</li>\n</ul>\n</li>\n<li>Enterprise Search\n<ul>\n<li>提供搜索功能，可以集成到业务网站的搜索栏中。</li>\n</ul>\n</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>上述软件都是由 Elastic 公司开发。</li>\n<li>这些软件运行时可能需要 JDK、node.js 等环境，不过从 v7.0 版本开始，二进制发行版都已经自带了。</li>\n<li>部署时，ELk 系统中各个软件的版本应该尽量一致，否则可能不兼容。</li>\n</ul>\n<h3 id=\"工作流程\"> 工作流程</h3>\n<ul>\n<li>\n<p>ELK 的主要工作流程：</p>\n<ol>\n<li>在每个主机上部署 Beats 进程，自动采集日志，然后发送到 Logstash 。</li>\n<li>Logstash 将日志解析成 JSON 格式，然后发送到 ES 中存储。</li>\n<li>用户使用 Kibana ，从 ES 中查询日志数据并展示。</li>\n</ol>\n</li>\n<li>\n<p>考虑到整个工作流程的耗时，用户查看最新日志时存在大概 2s 的延迟。而且 Kibana 本身刷新网页需要几秒耗时。</p>\n</li>\n<li>\n<p>关于 Logstash 与 Beats ：</p>\n<ul>\n<li>早期，是用 Logstash 采集日志然后发送到 ES 中存储。</li>\n<li>后来，由于 Logstash 消耗内存较多，采集日志的效率较低，因此开发了轻量级的 Beats 程序来取代 Logstash 。\n<ul>\n<li>Beats 不擅长解析日志文本。因此通常不会让 Beats 直接将原始日志发送到 ES ，而是先发送到 Logstash 进行解析，再由 Logstash 发送到 ES 。</li>\n<li>如果日志的并发量太大，可以让 Beats 将采集的日志先发送到 Kafka 缓冲，然后让 Logstash 从 Kafka 获取数据。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>\n<p>Flume</p>\n<ul>\n<li>：一个命令行工具，用于日志采集。类似于 Logstash ，但功能较少。</li>\n<li>由 Cloudera 公司采用 Java 开发，2012 年成为 ASF 的顶级项目。</li>\n<li>通过 tail -f 的方式采集日志文件的内容，因此重启采集进程之后会重复采集。</li>\n</ul>\n</li>\n<li>\n<p>Fluentd</p>\n<ul>\n<li>：一个命令行工具，用于日志采集。类似于 Logstash ，也有丰富的插件。</li>\n<li>2011 年首次发布，由 Treasure Data 公司采用 Ruby 开发。</li>\n<li>采集的数据解析为 JSON 对象，可以输出到 ES、MongoDB、Kafka 等。</li>\n<li>可以替换 ELK 系统中的 Logstash ，组成 EFK 。</li>\n</ul>\n</li>\n<li>\n<p>Loki</p>\n<ul>\n<li>：一个包括日志采集、存储、展示的系统，由 Grafana Labs 公司发布。包括以下组件：\n<ul>\n<li>Promtail ：用于采集日志文件。</li>\n<li>Loki ：用于存储日志数据。</li>\n<li>Grafana ：用于展示日志数据。</li>\n</ul>\n</li>\n<li>借鉴了 Prometheus 的工作方式，给日志数据添加一些键值对格式的标签，从而筛选日志。比 ELK 的查询、显示速度快很多，但不支持全文查询。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Grafana",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Grafana.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Grafana.html",
      "content_html": "<h1 id=\"grafana\"> Grafana</h1>\n<p>：一个 Web 网站，可以显示丰富、美观的数据图表。</p>\n<ul>\n<li><a href=\"https://grafana.com/docs/grafana/latest/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>本身不存储数据，而是需要从 MySQL、ES、Prometheus 等数据源获取数据，再显示图表。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制包：</p>\n<div><pre><code><span>wget</span> https://dl.grafana.com/oss/release/grafana-7.0.0.linux-amd64.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div><p>解压后启动：</p>\n<div><pre><code>bin/grafana-server\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>默认的访问地址为 <a href=\"http://localhost1:3000\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost1:3000</a> 。默认的用户名、密码是 admin、admin 。</li>\n</ul>\n</li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>grafana</span><span>:</span>\n    <span>container_name</span><span>:</span> grafana\n    <span>image</span><span>:</span> grafana/grafana<span>:</span>8.2.2\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 3000<span>:</span><span>3000</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n      <span>-</span> ./grafana.ini<span>:</span>/etc/grafana/grafana.ini\n      <span>-</span> ./grafana.db<span>:</span>/var/lib/grafana/grafana.db\n      <span>-</span> ./plugins<span>:</span>/var/lib/grafana/plugins\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><p>需要配置挂载目录的权限：</p>\n<div><pre><code><span>chown</span> -R <span>472</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"dashboard\"> Dashboard</h3>\n<ul>\n<li>Grafana 可以创建多个仪表盘（Dashboard）页面，每个 DashBoard 页面可以显示多个面板（Panel）。\n<ul>\n<li>可以将 Dashboard 或 Panel 导出 JSON 配置文件。</li>\n<li>可以给 Dashboard 加上 tags 来分类管理，也可以创建 Folder 来分组管理。</li>\n<li><a href=\"https://grafana.com/grafana/dashboards\" target=\"_blank\" rel=\"noopener noreferrer\">官方及社区分享的 Dashboard </a></li>\n</ul>\n</li>\n<li>Grafana 支持从多种外部数据源获取数据，用于绘图显示，比如 MySQL、influxdb、Elasticsearch、Prometheus 。\n<ul>\n<li>默认有一个 TestData DB 数据源可供试用。</li>\n<li>某些数据源自带了一些 Dashboard 模板，可以导入试用。</li>\n</ul>\n</li>\n<li>Playlist ：用于自动循环显示一些 Dashboard 。</li>\n</ul>\n<h3 id=\"panel\"> Panel</h3>\n<p>：面板，是 Grafana 的基本显示模块。每个 Panel 显示一个图表。</p>\n<ul>\n<li>当 Panel 进入浏览器的显示范围时，Grafana 才开始加载它，从而节省开销。</li>\n<li>一个 Panel 中存在多个图例（legend）的曲线时，用鼠标单击某个图例的名字，就会只显示该图例的曲线。按住 Ctrl 再单击，就可以同时选择多个图例。</li>\n<li>修改 Panel 时，是以 Dashboard 为单位进行修改，要点击 Save 才会保存。\n<ul>\n<li>比如调整一个 Dashboard 显示的时间范围（time range）时，会影响到该 Dashboard 中的所有 Panel 。</li>\n</ul>\n</li>\n<li>用鼠标横向拖动选中 Panel 中的一块区域，可以缩小 time range ；按 Ctrl+Z 可以放大 time range 。\n<ul>\n<li>注意 time range 过大时，可能显示不出曲线的瞬时变化，需要缩小 time range 进行查看，即放大局部曲线。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"query\"> Query</h3>\n<p>：Panel 的查询模块。</p>\n<ul>\n<li>每个 Panel 可以添加多个 Query ，通过查询表达式从数据源获取数据，再作出显示。</li>\n<li>下例是从 MySQL 数据库中查询的配置：<div><pre><code>FROM process_num                      <span># 查询 process_num 表</span>\nTime <span>column</span> update_time               <span># 取 update_time 列作为时间轴</span>\nMetric <span>column</span> none\nSELECT Column: num    Alias: 数量     <span># 取 num 列的值，并设置别名</span>\nWHERE Macro: <span>$__timeFilter</span>            <span># 允许调整查询的时间范围</span>\nGROUP BY <span>time</span> <span>(</span><span>$__interval</span>, none<span>)</span>     <span># 将数据按特定时间间隔分组，采样点没有数据的话赋值为 none</span>\n\nMin <span>time</span> interval 1m                  <span># group by 分组的最短时间间隔（建议与查询间隔一致）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>查询到的数据主要分为以下几种形式：\n<ul>\n<li>Time Series ：时间序列，包含多个时间点的数据。\n勾选 &quot;Instant&quot; 选项之后，只会查询最后一个时间点的数据，从而减少大量查询耗时。</li>\n<li>Table</li>\n<li>Heatmap</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"visualization\"> Visualization</h3>\n<p>：Panel 的显示样式。主要包括：</p>\n<ul>\n<li>Graph ：曲线图。\n<ul>\n<li>适合显示呈时间序列的数据，方便看出数据的变化历史。</li>\n<li>输入的数据包含多个图例时，会显示成多条曲线。</li>\n<li>启用 Stack 选项，会将多个曲线堆叠显示。再启用 Percent 选项，则会将它们按百分比显示。</li>\n</ul>\n</li>\n<li>Time Series ：时间序列。\n<ul>\n<li>v8 版本新增的图表，用于取代 Graph 图表。</li>\n</ul>\n</li>\n<li>Stat ：数值。适合显示单个图例的值，还可以选择在背景中显示其变化曲线。</li>\n<li>Gauge ：度量。适合显示单个图例的值，并在背景中显示其取值范围。</li>\n<li>Bar Gauge ：条形图。</li>\n<li>Pie Chart ：饼状图。</li>\n<li>Table ：表格。</li>\n<li>Diagram ：流程图。</li>\n<li>Heatmap ：热图。适合显示大量同类型数据，方便看出各种数值的分布位置。</li>\n<li>Geomap ：地图。\n<ul>\n<li>v8.1 版本新增的图表。</li>\n<li>支持根据经纬度坐标，在地图上给每个 ip 描点。</li>\n<li>当用户浏览时，会向第三方网站发出 GET 请求，获取地图图片。</li>\n</ul>\n</li>\n<li>Text ：显示一段文本，支持 Markdown 格式。</li>\n</ul>\n<h3 id=\"axes\"> Axes</h3>\n<p>：Panel 显示的坐标轴。</p>\n<ul>\n<li>坐标轴有很多种单位（Unit），比如：\n<ul>\n<li>none ：不显示单位。</li>\n<li>short ：当数值达到千、百万等量级时，显示 k、m 等缩写单位。</li>\n<li>percent(0-100) ：显示百分数，数值 0-100 分别对应 0%-100% 。</li>\n<li>percent(0.0-1.0)</li>\n<li>bytes(IEC) ：按二进制转换千、百万等量级，即 <code>1 MiB = 1024 KiB = 1024^2 Bytes</code> 。</li>\n<li>bytes(Metric) ：按十进制转换千、百万等量级，即 <code>1 MB = 1000 KB = 1000^2 Bytes</code> 。</li>\n<li>seconds</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"transform\"> Transform</h3>\n<p>：Grafana 7.0 新增的模块，用于在 Panel 作出显示之前转换 Query 的数据，包括多种功能。</p>\n<p>筛选显示的数据：</p>\n<ul>\n<li>Filter data by query\n<ul>\n<li>：筛选显示当前 Panel 中的各个 Query 。</li>\n</ul>\n</li>\n<li>Filter by name\n<ul>\n<li>：筛选显示各个字段，支持正则匹配。</li>\n<li>可以同时作用于多个 Query 。</li>\n</ul>\n</li>\n<li>Filter data by values\n<ul>\n<li>：根据字段的值，筛选显示的数据。支持正则匹配。</li>\n</ul>\n</li>\n<li>Organize fields\n<ul>\n<li>：筛选显示各个字段，支持重命名、排序。</li>\n<li>当前 Panel 中只有一个 Query 时才能进行该配置。</li>\n</ul>\n</li>\n<li>Group by\n<ul>\n<li>：按某个字段的取值，对数据进行分组，取值相同的归为一组。</li>\n</ul>\n</li>\n<li>Sort by\n<ul>\n<li>：根据某个字段的取值，对数据进行排序。</li>\n</ul>\n</li>\n</ul>\n<p>合并输入的数据：</p>\n<ul>\n<li>Merge\n<ul>\n<li>：自动将当前 Panel 中的所有 Query 的数据合并成一个 Query 。</li>\n<li>例如：合并两个表格时，会将同名且取值相同的列只留一份，将同名且取值不同的列保留，将不同名称的列保留。</li>\n</ul>\n</li>\n<li>Outer join\n<ul>\n<li>：将输入的所有数据按某个字段合并。可用于合并多个时间序列、多个 Query 。</li>\n<li>例如：将所有数据按字段 A 合并后，会得到一个以字段 A 作为第一列的新表格，显示字段 A 每种取值时对应的其它字段的取值。</li>\n<li>与 Merge 功能相比，它不会自动去掉重复的列。但是如果有多行数据的第一列取值重复，则只会保留其中一行，丢失其它行，因此应该确保数据的第一列取值不会重复。</li>\n</ul>\n</li>\n<li>Series to row\n<ul>\n<li>：将输入的多个时间序列合并成一个时间序列。</li>\n<li>原理：将多个时间序列的所有值合并为一个 Value 字段，所有 Legend 名合并为一个 Metric 字段，其它字段则丢弃。</li>\n</ul>\n</li>\n<li>Concatenate fields\n<ul>\n<li>：将输入的多个表合并为一个表。</li>\n<li>原理：直接拼合，如果有重名的字段，则在字段名之后加上编号，比如 name 1 、name 2 。</li>\n</ul>\n</li>\n</ul>\n<p>修改字段：</p>\n<ul>\n<li>Reduce\n<ul>\n<li>：显示数据的每个字段的 Min、Max 等统计值，并隐藏具体的值。</li>\n<li>可用于将一个包含很多行数据的表格转换成一个行数较少的表格。</li>\n</ul>\n</li>\n<li>Add field from calculation\n<ul>\n<li>：增加一个新字段。其值可以是 Min、Max 等统计值，也可以是已有的某两个字段作加减乘除的运算结果。</li>\n<li>Reduce 功能是显示所有数据的字段 A 的统计值（即统计表格的每列），而该功能是显示每条数据的某些字段的统计值（即统计表格的每行）。</li>\n</ul>\n</li>\n<li>Rename by regex\n<ul>\n<li>：对字段名进行正则替换。</li>\n</ul>\n</li>\n<li>Labels to fields\n<ul>\n<li>：将时间序列中的标签转换成字段，从而将数据从 Time Series 转换成 Table 格式。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"share\"> Share</h3>\n<p>分享 Dashboard 或 Panel 给他人查看的多种方式：</p>\n<ul>\n<li>Link\n<ul>\n<li>：生成当前内容的 URL 。</li>\n<li>还支持在该 Link 后加一些参数，渲染成 PNG 图片。</li>\n</ul>\n</li>\n<li>Snapshot\n<ul>\n<li>：生成快照 URL ，供任何人查看。</li>\n<li>这样不需要用户通过 Grafana 的身份认证，但是只记录了当前时刻的数据，因此不支持动态查看。</li>\n</ul>\n</li>\n<li>Embed panel\n<ul>\n<li>：嵌入式面板。将 Grafana 仪表盘的 URL 链接通过 HTML iframe 标签嵌入到其它网页中。</li>\n<li>需要在配置文件中启用 <code>allow_embedding = true</code> ，</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"alert\"> Alert</h3>\n<ul>\n<li>\n<p>配置 Grafana 告警的步骤：</p>\n<ol>\n<li>进入 Alerting 页面，创建至少一个 &quot;Notification Channel&quot; ，表示发送告警信息到哪里。</li>\n<li>进入任意 Panel 的编辑页面，添加 Alert 告警规则。</li>\n</ol>\n</li>\n<li>\n<p>在 Alerting 页面可以看到用户创建的所有 Alert Rule 。</p>\n</li>\n<li>\n<p>在 Panel 的 Alert 编辑页面，</p>\n<ul>\n<li>点击 &quot;State history&quot; 可以查看告警历史。</li>\n<li>点击 &quot;Test Rule&quot; 可以测试告警条件。</li>\n</ul>\n</li>\n<li>\n<p>Grafana 告警功能的缺点：</p>\n<ul>\n<li>只有 Graph 类型的 pannel 支持设置告警。</li>\n<li>在 pannel 中使用变量时，不支持设置告警。</li>\n<li>不擅长处理大量告警。</li>\n</ul>\n</li>\n</ul>\n<p>告警规则示例：</p>\n<ul>\n<li>\n<p>下例是一种 Alert 的触发条件：</p>\n<div><pre><code>Evaluate every 1m, For 5m\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>它表示每隔 1m 查询一次，如果满足告警条件，则将该 Panel 从 OK 状态标为 Pending 状态；如果保持 Pending 状态超过 5m ，则标为 Alerting 状态，并发送告警信息。</li>\n<li>如果该 Panel 一直处于 Alerting 状态，Grafana 不会再重复告警，除非用户手动暂停再启用其 Alert Rule 。</li>\n<li>如果该 Panel 不再满足告警条件，Grafana 会立即将它的状态标为 OK ，并且默认也会发送一条告警消息。除非在配置&quot;Notification Channel&quot;时，勾选 &quot;Disable Resolve Message&quot; 。</li>\n</ul>\n</li>\n<li>\n<p>下例是一种 Alert 的告警条件：</p>\n<div><pre><code>WHEN avg() OF query(A, 5m, now-1m) IS ABOVE 10\n</code></pre>\n<div><span>1</span><br></div></div><p>它表示查询最近 5 分钟之内、1 分钟之前的图例 A 的数据，看平均值是否大于 10 。\n如果图例 A 包含多个 Metric ，则只要有一个 Metric 的值符合条件就会告警。\n截止时间设置成 now-1m 是为了避免最近 1 分钟之内尚未采集到数据，导致报错：NO DATA</p>\n</li>\n<li>\n<p>下例是查询最后一次数据，因此不必担心尚未采集到数据：</p>\n<div><pre><code>WHEN last() OF query(A, 5m, now) IS ABOVE 10\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>下例是查询当前数据减去 5 分钟之前的数据的差值（可能为负）：</p>\n<div><pre><code>WHEN diff() OF query(A, 5m, now) IS ABOVE 10\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"插件\"> 插件</h2>\n<ul>\n<li><a href=\"https://grafana.com/grafana/plugins\" target=\"_blank\" rel=\"noopener noreferrer\">官方的插件市场</a></li>\n<li>安装插件时，需要到 Grafana 工作目录下执行以下命令，然后重启 Grafana ：<div><pre><code>bin/grafana-cli plugins <span>install</span> <span>&lt;</span>plugin_name<span>></span>\n                --pluginsDir <span>$PWD</span>/data/plugins      <span># 指定插件的安装目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>常用插件：\n<ul>\n<li>Zabbix 插件：用于分析 Zabbix 的监控数据，包含 Dashboard 模板。</li>\n<li>grafana-image-renderer 插件\n<ul>\n<li>：运行一个 Chromium 无头浏览器，用于生成 Grafana 图表的 PNG 截图，常用于告警邮件。</li>\n<li>建议用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>grafana</span><span>:</span>\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>...</span>\n\n  <span>renderer</span><span>:</span>\n    <span>container_name</span><span>:</span> grafana<span>-</span>image<span>-</span>renderer\n    <span>image</span><span>:</span> grafana/grafana<span>-</span>image<span>-</span>renderer<span>:</span>3.2.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n\n<span>networks</span><span>:</span>\n  <span>net</span><span>:</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div></li>\n<li>需要在 grafana.ini 中配置：<div><pre><code><span><span>[</span><span>rendering</span><span>]</span></span>\n<span>server_url</span>   <span>=</span> <span>http://renderer:8081/render</span>\n<span>callback_url</span> <span>=</span> <span>http://grafana:3000/</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>以 rpm 包的方式部署 Grafana 时，有以下几个重要文件，拷贝它们就可以备份 Grafana ：<div><pre><code>/etc/grafana/grafana.ini      <span># 配置文件</span>\n/var/lib/grafana/grafana.db   <span># 一个 SQLite 数据库，保存 Grafana 自身的数据，比如用户表、仪表盘配置</span>\n/var/lib/grafana/plugins/     <span># 插件目录</span>\n/var/log/grafana/             <span># 日志目录。日志文件会自动按天切割，最多保存 7 天</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>以二进制包的方式部署 Grafana 时，上述文件都保存在工作目录下：<div><pre><code>conf/defaults.ini\ndata/grafana.db\ndata/plugins/\ndata/log/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>修改配置文件之后，要重启 Grafana 才会生效。</li>\n<li>配置文件示例：<div><pre><code><span><span>[</span><span>server</span><span>]</span></span>\n<span>protocol</span>  <span>=</span> <span>http</span>\n<span>http_addr</span> <span>=</span>                     <span># 默认绑定 0.0.0.0</span>\n<span>http_port</span> <span>=</span> <span>3000                # Grafana 对外的访问端口</span>\n<span>domain</span>    <span>=</span> <span>mygrafana.com       # Grafana 对外的访问 IP 或域名</span>\n<span># root_url = %(protocol)s://%(domain)s:%(http_port)s/ # Grafana URL 的格式，可以加上一个后缀作为 sub_path</span>\n<span># serve_from_sub_path = false                         # 是否允许 root_url 包含后缀，便于实现反向代理</span>\n\n<span><span>[</span><span>smtp</span><span>]</span></span>\n<span>enabled</span>      <span>=</span> <span>true                     # 启用 SMTP ，允许 Grafana 发送注册邮件、告警邮件</span>\n<span>host</span>         <span>=</span> <span>10.0.0.1:25              # SMTP 服务器的位置</span>\n<span>user</span>         <span>=</span>                          <span># 登录 SMTP 服务器的账号</span>\n<span>password</span>     <span>=</span>\n<span>; cert_file  =</span>\n<span>; key_file   =</span>\n<span>skip_verify</span>  <span>=</span> <span>false                    # 是否跳过验证 SMTP 服务器的 SSL</span>\n<span>from_address</span> <span>=</span> <span>admin@grafana.localhost  # 邮件的发件方邮箱</span>\n<span>from_name</span>    <span>=</span> <span>Grafana                  # 邮件的发送方名称</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div></li>\n</ul>\n<h3 id=\"身份认证\"> 身份认证</h3>\n<p>Grafana 支持多种身份认证方式，比如 OAuth、LDAP 等。</p>\n<ul>\n<li>默认启用了 HTTP Basic Auth ，可以使用在 Web 登录表单中输入的账号密码。如下：<div><pre><code><span>curl</span> -u admin:123456 http://10.0.0.1:3000/api/user\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>也可以在 Grafana 网站上创建 API Key ，放在请求报文的 Header 中，完成身份认证。如下：<div><pre><code><span>curl</span> -H <span>\"Authorization: Bearer eyJrIjoidUlzZjluMEdob3lUYWk1RTRYR2VDSlBuM1ZJaFgwYWIiLCJuIjoidGVzdCIsImlkIjoxfQ==\"</span> http://10.0.0.1:3000/api/user\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>例如，让 Nginx 采用以下反向代理配置，可以提供一个免登录的 Grafana ：<div><pre><code>server<span>{</span>\n    listen  <span>80</span><span>;</span>\n    location / <span>{</span>\n        proxy_set_header    Authorization   <span>'Bearer eyJrIjoidUlzZjluMEdob3lUYWk1RTRYR2VDSlBuM1ZJaFgwYWIiLCJuIjoidGVzdCIsImlkIjoxfQ=='</span><span>;</span>\n        proxy_pass          http://10.0.0.1:3000/<span>;</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n<h3 id=\"oauth\"> OAuth</h3>\n<p>启用 GitLab OAuth 的步骤：</p>\n<ol>\n<li>\n<p>进入 GitLab 的 &quot;admin&quot; -&gt; &quot;Applications&quot; 页面，添加一个应用：</p>\n<ul>\n<li>Name ：填 Grafana</li>\n<li>Redirect URI ：填入 Grafana 的 URI ，格式为：https://mygrafana.com/login/gitlab</li>\n<li>Scopes ：选择 read_api\n注册成功后，GitLab 将生成一对 Application ID 和 Secret 。</li>\n</ul>\n</li>\n<li>\n<p>修改 Grafana 配置文件：</p>\n<div><pre><code><span><span>[</span><span>auth.gitlab</span><span>]</span></span>\n<span>enabled</span>        <span>=</span> <span>true</span>\n<span>allow_sign_up</span>  <span>=</span> <span>true</span>\n<span>client_id</span>      <span>=</span> <span>9c6b79bf4714e5f8cdbcffad0e2d0fe74     # 填 Application ID</span>\n<span>client_secret</span>  <span>=</span> <span>86a39f5b9f779791aac631704ee0b0        # 填 Secret</span>\n<span>scopes</span>         <span>=</span> <span>read_api</span>\n<span>auth_url</span>       <span>=</span> <span>http://mygitlab.com/oauth/authorize   # 改为 Gitlab 的域名</span>\n<span>token_url</span>      <span>=</span> <span>http://mygitlab.com/oauth/token</span>\n<span>api_url</span>        <span>=</span> <span>http://mygitlab.com/api/v4</span>\n<span>allowed_groups</span> <span>=</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>通过 OAuth ，GitLab 用户可以登录 Grafana 中的同名账号。\n<ul>\n<li>开启 allow_sign_up 时，如果 Grafana 中不存在同名账号，则会自动创建，默认为 viewer 权限。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>访问 Grafana 网站，在它的登录页面可以看到一个新增的按钮：“Sign in with GitLab”</p>\n</li>\n</ol>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Alertmanager",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Prometheus/Alertmanager.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Prometheus/Alertmanager.html",
      "content_html": "<h1 id=\"alertmanager\"> Alertmanager</h1>\n<p>：作为一个 HTTP 服务器运行，用于将 Prometheus 产生的警报加工之后转发给用户。</p>\n<ul>\n<li><a href=\"https://github.com/prometheus/alertmanager\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>优点：\n<ul>\n<li>Prometheus 产生的警报是 JSON 格式的信息，Alertmanager 可以对它们进行分组管理，加工成某种格式的告警消息，再转发给用户。</li>\n<li>配置比较麻烦但是很灵活。</li>\n<li>可以在 Web 页面上搜索警报、分组管理。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>只能查看当前存在的警报，不能查看已发送的历史消息。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<h3 id=\"工作流程\"> 工作流程</h3>\n<ol>\n<li>Prometheus 每隔 interval 时长执行一次 alert rule 。如果执行结果包含 n 个时间序列，则认为存在 n 个警报，通过 HTTP 通信发送 alerting 状态的消息给 Alertmanager 。</li>\n<li>Alertmanager 收到之后，\n<ul>\n<li>先根据 route 判断它属于哪个 group 、应该发送给哪个 receiver 。</li>\n<li>再判断该 group 当前是否处于冷却阶段、是否被 Silence 静音、是否被 Inhibit 抑制。如果都没有，则立即发送告警消息给用户。</li>\n</ul>\n</li>\n<li>如果 Prometheus 再次执行 alert rule 时，发现执行结果为空，则认为警报已解决，立即产生 resolved 状态的消息，发送给 Alertmanager 。</li>\n<li>Alertmanager 收到之后，立即发送给用户。</li>\n</ol>\n<ul>\n<li>如果一个指标不再满足告警条件，或者 Prometheus 不再抓取相应的指标，或者不再执行相应的 alert rule ，都会让 Prometheus 认为该警报已解决，产生一个 resolved 状态的消息，发送给 Alertmanager 。</li>\n<li>目前在 Prometheus 端并不能控制是否产生 resolved 消息，只能在 Alertmanager 端控制是否发送 resolved 消息。</li>\n</ul>\n<h3 id=\"主要概念\"> 主要概念</h3>\n<ul>\n<li>Filter\n<ul>\n<li>：通过 label=value 的形式筛选警报。</li>\n<li>它方便在 Web 页面上进行查询。</li>\n</ul>\n</li>\n<li>Group\n<ul>\n<li>：根据 label 的值对警报进行分组。</li>\n<li>它需要在配置文件中定义，但也可以在 Web 页面上临时创建。</li>\n</ul>\n</li>\n<li>Silence\n<ul>\n<li>：不发送某个或某些警报，相当于静音。</li>\n<li>它需要在 Web 页面上配置，且重启 Alertmanager 之后不会丢失。</li>\n</ul>\n</li>\n<li>Inhibit\n<ul>\n<li>：用于设置多个警报之间的抑制关系。当发出某个警报时，使其它的某些警报静音。</li>\n<li>它需要在配置文件中定义。</li>\n<li>被静音、抑制的警报不会在 Alertmanager 的 Alerts 页面显示。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载后启动：</p>\n<div><pre><code>./alertmanager --config.file<span>=</span>alertmanager.yml\n              <span># --web.config.file=web.yml                   # web 配置</span>\n              <span># --web.listen-address \"0.0.0.0:9093\"         # 监听的地址</span>\n              <span># --web.external-url \"http://10.0.0.1:9093/\"  # 供外部访问的 URL</span>\n              <span># --cluster.listen-address \"0.0.0.0:9094\"     # 集群监听的地址（默认开启）</span>\n              <span># --data.retention 120h                       # 将数据保存多久</span>\n              --log.format<span>=</span>json\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>alertmanager</span><span>:</span>\n    <span>container_name</span><span>:</span> alertmanager\n    <span>image</span><span>:</span> prom/alertmanager<span>:</span>v0.22.2\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>command</span><span>:</span>\n      <span>-</span> <span>-</span><span>-</span>config.file=alertmanager.yml\n      <span>-</span> <span>-</span><span>-</span>web.config.file=web.yml\n    <span>ports</span><span>:</span>\n      <span>-</span> 9093<span>:</span><span>9093</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> .<span>:</span>/alertmanager\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><p>需要先配置挂载目录的权限：</p>\n<div><pre><code><span>mkdir</span> data\n<span>chown</span> -R <span>65534</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<p>使用 Alertmanager 时，需要在 Prometheus 的配置文件中加入如下配置，让 Prometheus 将警报转发给它处理。</p>\n<div><pre><code><span>alerting</span><span>:</span>\n  <span>alertmanagers</span><span>:</span>\n  <span>-</span> <span>static_configs</span><span>:</span>\n    <span>-</span> <span>targets</span><span>:</span>\n      <span>-</span> 10.0.0.1<span>:</span><span>9093</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>alertmanager.yml 的配置示例：</p>\n<div><pre><code><span>global</span><span>:</span>                           <span># 配置一些全局参数</span>\n  <span># resolve_timeout: 5m           # 如果 Alertmanager 收到的警报 JSON 中不包含 EndsAt ，则超过该时间之后就认为该警报已解决</span>\n  <span>smtp_smarthost</span><span>:</span> smtp.exmail.qq.com<span>:</span><span>465</span>\n  <span>smtp_from</span><span>:</span> 123456@qq.com\n  <span>smtp_auth_username</span><span>:</span> 123456@qq.com\n  <span>smtp_auth_password</span><span>:</span> <span>******</span>\n  <span>smtp_require_tls</span><span>:</span> <span>false</span>\n\n<span># templates:                      # 从文件中导入告警消息模板</span>\n<span>#   - templates/*</span>\n\n<span>receivers</span><span>:</span>                        <span># 定义告警消息的接受者</span>\n<span>-</span> <span>name</span><span>:</span> email_to_leo\n  <span>email_configs</span><span>:</span>                  <span># 只配置少量 smtp 参数，其余的参数则继承全局配置</span>\n  <span>-</span> <span>to</span><span>:</span> 123456@qq.com             <span># 收件人，如果有多个邮箱地址则用逗号分隔</span>\n    <span># send_resolved: false        # 是否在警报消失时发送 resolved 状态的消息</span>\n    <span># html: '{{ template \"email.default.html\" . }}'   # 设置 HTML 格式的邮件 body</span>\n    <span># headers:</span>\n    <span>#   subject: '[{{.GroupLabels.severity}}] {{.GroupLabels.alertname}}'       # 设置邮件标题</span>\n\n  <span># - to: 123456@test.com         # 可以指定多个发送地址</span>\n<span>-</span> <span>name</span><span>:</span> webhook_to_leo\n  <span>webhook_configs</span><span>:</span>\n  <span>-</span> <span>url</span><span>:</span> http<span>:</span>//localhost<span>:</span>80/\n\n<span>route</span><span>:</span>\n  <span>receiver</span><span>:</span> email_to_leo\n\n<span># inhibit_rules:                  # 设置一些警报之间的抑制关系</span>\n<span>#   - ...</span>\n\n<span># mute_time_intervals:            # 在某些时间段关闭告警</span>\n<span>#   - ...</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br></div></div><h3 id=\"templates\"> templates</h3>\n<p>告警消息模板的示例：</p>\n<div><pre><code><span>{</span><span>{</span> define <span>\"custom_email\"</span> <span>}</span><span>}</span>                   <span># 定义一个模板，指定名称</span>\n<span>&lt;</span><span>!</span>DOCTYPE html<span>></span>\n<span>&lt;</span>html<span>></span>\n\n<span>&lt;</span>body<span>></span>\n<span>&lt;</span>b<span>></span>目前有 <span>{</span><span>{</span> .Alerts <span>|</span> len <span>}</span><span>}</span> 个警报，其中 <span>{</span><span>{</span> .Alerts.Firing <span>|</span> len <span>}</span><span>}</span> 个为 firing 状态，<span>{</span><span>{</span> .Alerts.Resolved <span>|</span> len <span>}</span><span>}</span> 个为 Resolved 状态。警报列表如下：<span>&lt;</span>/b<span>></span>\n\n<span>{</span><span>{</span> range .Alerts.Firing <span>}</span><span>}</span>                    <span># 遍历每个 Firing 状态的警报</span>\n<span>&lt;</span>hr <span>style</span><span>=</span><span>\"opacity: 0.5;\"</span>/<span>></span>\n    StartsAt <span>:</span> <span>{</span><span>{</span> .StartsAt <span>}</span><span>}</span><span>&lt;</span>br /<span>></span>\n    instance <span>:</span> <span>{</span><span>{</span> .Labels.instance <span>}</span><span>}</span><span>&lt;</span>br /<span>></span>\n    <span>{</span><span>{</span> range .Annotations.SortedPairs <span>}</span><span>}</span>\n        <span>{</span><span>{</span> .Name <span>}</span><span>}</span> <span>:</span> <span>{</span><span>{</span> .Value <span>}</span><span>}</span><span>&lt;</span>br /<span>></span>\n    <span>{</span><span>{</span> end <span>}</span><span>}</span>\n<span>{</span><span>{</span> end <span>}</span><span>}</span>\n\n<span>&lt;</span>/body<span>></span>\n\n<span>&lt;</span>/html<span>></span>\n<span>{</span><span>{</span> end <span>}</span><span>}</span>                                     <span># 模板定义结束</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><h3 id=\"route\"> route</h3>\n<p>route 块定义了分组处理警报的规则，如下：</p>\n<div><pre><code><span>route</span><span>:</span>\n  <span>receiver</span><span>:</span> email_to_leo            <span># 只能指定一个接收方</span>\n  <span>group_wait</span><span>:</span> 1m\n  <span>group_interval</span><span>:</span> 1m\n  <span>repeat_interval</span><span>:</span> 24h\n  <span>group_by</span><span>:</span>                         <span># 根据标签的值对已匹配的警报进行分组（默认不会分组）</span>\n    <span>-</span> alertname\n  <span>routes</span><span>:</span>\n  <span>-</span> <span>receiver</span><span>:</span> webhook_to_leo\n    <span># group_by:</span>\n    <span>#   - alertname</span>\n    <span>matchers</span><span>:</span>                       <span># 筛选出目标警报，需要其 labels 同时匹配以下 PromQL 条件，如果 matchers 列表为空则选出所有警报。不支持匹配 annotations</span>\n      <span>-</span> job = prometheus            <span># 可选在运算符左右加空格</span>\n      <span>-</span> instance =~ 10.0.0.*        <span># 可选加上字符串定界符</span>\n      <span>-</span> <span>'{alertname !~ \"进程停止\"}'</span>  <span># 可选加上字符串定界符、花括号 {}</span>\n    <span># continue: false</span>\n  <span>-</span> <span>receiver</span><span>:</span> xxx\n    <span>...</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>上例中的大部分参数都不是必填项，最简单的 route 块如下：<div><pre><code><span>route</span><span>:</span>\n  <span>receiver</span><span>:</span> email_to_leo\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>配置文件中必须要定义 route 块，其中至少要定义一个 route 节点，称为根节点。\n<ul>\n<li>在根节点之下可以定义任意个嵌套的 route 块，构成一个树形结构的路由表。</li>\n<li>子节点会继承父节点的所有参数值，作为自己的默认值。</li>\n</ul>\n</li>\n<li>Alertmanager 每收到一个警报时，会从根节点往下逐个尝试匹配。\n<ul>\n<li>如果当前节点匹配：\n<ul>\n<li>如果子节点不匹配，则交给当前节点处理。</li>\n<li>如果子节点也匹配，则交给子节点处理。（相当于子节点覆盖了父节点）</li>\n<li>如果配置了 <code>continue: true</code> ，则还会继续尝试匹配之后的同级节点。否则结束匹配，退出路由表。</li>\n</ul>\n</li>\n<li>如果当前节点不匹配，则会继续尝试匹配之后的同级节点。</li>\n<li>警报默认匹配根节点。因此，如果所有节点都不匹配，则会交给根节点处理。</li>\n</ul>\n</li>\n<li>Alertmanager 以 group 为单位发送告警消息。\n<ul>\n<li>每次发送一个 group 的消息时，总是会将该 group 内现有的所有警报合并成一个告警消息，一起发送。</li>\n<li>当一个 group 中出现第一个警报时，会先等待 <code>group_wait</code> 时长再发送该 group 。\n<ul>\n<li>延长 group_wait 时间有利于收集属于同一 group 的其它警报，一起发送。</li>\n</ul>\n</li>\n<li>当一个 group 的警报一直存在时，要至少冷却 <code>repeat_interval</code> 时长才能重复发送该 group 。\n<ul>\n<li>实际上，是要求当前时刻与上一次发送时刻的差值大于 repeat_interval 。\n因此，即使重启 Alertmanager ，也不会影响 repeat_interval 的计时。\n不过，在配置文件中修改 group_wait、repeat_interval 等参数的值时，会立即生效。</li>\n</ul>\n</li>\n<li>当一个 group 处于冷却阶段时：\n<ul>\n<li>如果收到一个属于该 group 的新警报，则会等待 <code>group_interval</code> 时长之后让该 group 解除冷却，发送一次消息，并且从当前时刻开始重新计算 repeat_interval 。</li>\n<li>如果一个警报被解决了，也会让该 group 解除冷却，发送一次 resolved 消息。</li>\n<li>如果一个被解决的警报再次出现，也会让该 group 解除冷却，发送一次消息。</li>\n<li>因此，如果一个警报反复被解决又再次出现，则会绕过 repeat_interval 的限制，导致 Alertmanager 频繁发送消息给用户。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>特殊情况：</p>\n<ul>\n<li>假设 Prometheus 与 Alertmanager 正常连接，且存在一些警报：\n<ul>\n<li>如果两者断开连接，则大概两分钟之后 Alertmanager 会自行认为所有警报已解决，发送 resolved 状态的消息给用户。</li>\n<li>如果两者重新连接，则 Alertmanager 会认为这些警报的 group 是新出现的，立即发送 alerting 状态的消息给用户。</li>\n<li>因此，如果两者反复断开连接又重新连接，则会绕过 repeat_interval 的限制，导致 Alertmanager 频繁发送消息给用户。</li>\n</ul>\n</li>\n<li>假设一个新警报出现，Alertmanager 正常地发送一次告警消息给用户。\n<ul>\n<li>如果此时用 Silence 隐藏该警报，则 Alertmanager 的首页上不会显示该警报，但并不会发送 resolved 消息给用户。</li>\n<li>如果接着在 Prometheus 端解决该警报，则 Alertmanager 也不会发送 resolved 消息。</li>\n<li>如果接着取消 Silence ，则 Alertmanager 依然不会发送 resolved 消息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"inhibit-rules\"> inhibit_rules</h3>\n<p>例：</p>\n<div><pre><code><span>inhibit_rules</span><span>:</span>\n<span>-</span> <span>source_matchers</span><span>:</span>\n  <span>-</span> severity = error\n  <span>target_matchers</span><span>:</span>\n  <span>-</span> severity = warn\n  <span>equal</span><span>:</span>\n  <span>-</span> alertname\n  <span>-</span> instance\n\n<span>-</span> <span>source_matchers</span><span>:</span>\n    <span>-</span> alertname = target 离线\n    <span>-</span> job = node_exporter\n  <span>target_matchers</span><span>:</span>\n  <span>equal</span><span>:</span>\n  <span>-</span> nodename\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>工作原理： Alertmanager 会先根据 source_matchers 指定的 label:value 选中一些警报，再根据 target_matchers 选中一些警报。如果 source 警报存在，则抑制与它 equal 标签值相同的 target 警报。\n<ul>\n<li>如果 equal 列表为空，或者 source 警报与 target 警报都不具有 equal 标签（此时相当于它们的该标签值都为空），则抑制所有 target 警报。</li>\n<li>如果 target 警报与 source 警报相同，并不会抑制 source 警报本身。</li>\n</ul>\n</li>\n<li>上例中，第一条抑制规则的作用是：当出现 severity 为 error 的警报时，抑制与它同类型、但 severity 为 warn 的其它警报。</li>\n<li>上例中，第二条抑制规则的作用是：当某个主机离线时，抑制该主机的其它警报。</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<p>Prometheus 的 Alerts 页面示例：</p>\n<p><img src=\"./Alertmanager_1.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>上图中，处于 Inactive、Pending、Firing 状态的 alerting_rule 分别总共有 1、0、2 个。</li>\n<li>rules.yml 文件中定义了三条 alerting_rule 。\n<ul>\n<li>第一条 alerting_rule 名为 “测试告警-1” ，包含 1 个 active 的警报。\n<ul>\n<li>每个警报源自一个满足 alerting_rule 的时间序列。</li>\n<li>Active Since 表示警报从什么时候开始存在，即进入 pending 状态的时刻。如果警报中断，则会刷新该时刻。</li>\n</ul>\n</li>\n<li>第三条 alerting_rule 名为 “测试告警-3” ，包含 113 个 active 状态的警报。</li>\n</ul>\n</li>\n</ul>\n<p>Alertmanager 的 Alerts 页面示例：</p>\n<p><img src=\"./Alertmanager_2.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>上图中存在两个 group ：\n<ul>\n<li>第一个 group 是 job=&quot;node_exporter&quot; ，包含 1 个警报。</li>\n<li>第二个 group 是 job=&quot;process-exporter&quot; ，包含 113 个警报。</li>\n</ul>\n</li>\n<li>上图中存在一个 instance=&quot;10.0.0.1:9100&quot; 的警报：\n<ul>\n<li>09:15:45 UTC 表示该警报的产生时刻，即在 Prometheus 那边变成 Firing 状态的时刻。重启 Alertmanager 也不会影响该时刻。</li>\n<li>点击 Info 会显示该警报的详细信息。</li>\n<li>点击 Source 会跳转到 Prometheus ，查询该警报对应的指标数据。</li>\n<li>点击 Silence 可以静音该警报。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"http-api\"> HTTP API</h2>\n<div><pre><code>GET /-/healthy     <span># 用于健康检查，总是返回 Code 200</span>\nGET /-/ready       <span># 返回 Code 200 则代表可以处理 HTTP 请求</span>\nPOST /-/reload     <span># 重新加载配置文件</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Pushgateway",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Prometheus/Pushgateway.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Prometheus/Pushgateway.html",
      "content_html": "<h1 id=\"pushgateway\"> Pushgateway</h1>\n<p>：一个 Web 服务器，支持第三方推送监控数据到这里并缓存。</p>\n<ul>\n<li><a href=\"https://github.com/prometheus/pushgateway\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>Prometheus 只支持主动从 exporter 拉取数据，不支持被 exporter 推送数据。使用 Pushgateway 可以允许 exporter 推送数据到这里，再由 Prometheus 定时拉取。</li>\n<li>优点：\n<ul>\n<li>解耦了 exporter 与 Prometheus ，允许它们异步工作，允许 exporter 不保持运行。</li>\n<li>提供了 Web 页面，可以查看其状态。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>不能控制监控对象生成指标的间隔时间。</li>\n<li>只会抓取当前时刻的数据，不会同步历史数据。并且，如果监控对象离线，依然会将最后一次抓取的数据作为当前值。</li>\n<li>不能直接判断监控对象是否在线，需要根据 push_time_seconds 进行判断。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>pushgateway</span><span>:</span>\n    <span>container_name</span><span>:</span> pushgateway\n    <span>image</span><span>:</span> prom/pushgateway<span>:</span>v1.4.1\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span># command:</span>\n    <span>#   - --web.listen-address=:9091</span>\n    <span>#   - --web.telemetry-path=/metrics</span>\n    <span>#   - --persistence.file=metrics.bak     # 将指标数据备份到该文件中（默认不会备份，因此重启后会丢失）</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9091<span>:</span><span>9091</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>在 Prometheus 的配置文件中加入如下配置，使其抓取 Pushgateway ：<div><pre><code><span>scrape_configs</span><span>:</span>\n<span>-</span> <span>job_name</span><span>:</span> pushgateway\n  <span>honor_labels</span><span>:</span> <span>true</span>\n  <span>static_configs</span><span>:</span>\n  <span>-</span> <span>targets</span><span>:</span>\n    <span>-</span> 10.0.0.1<span>:</span><span>9091</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>例：推送指标到 Pushgateway</p>\n<div><pre><code><span>cat</span> <span>&lt;&lt;</span><span>EOF<span> <span>|</span> <span>curl</span> --data-binary @- http://localhost:9091/metrics/job/pushgateway/instance/10.0.0.1</span>\n# TYPE test_metric gauge\n# HELP test_metric Just an example.\ntest_metric{name=\"one\"} 42\nEOF</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>Pushgateway 会将收到的指标按 job、instance 的值进行分组。\n<ul>\n<li>如果 URL 中不指定 job ，则会报错 404 。</li>\n<li>如果 URL 中不指定 instance ，则会默认设置为 instance=&quot;&quot; 。</li>\n</ul>\n</li>\n<li>指标中：\n<ul>\n<li><code># TYPE &lt;metric_name&gt; &lt;type&gt;</code> 行必须存在，用于声明该指标的类型，否则指标会被视作无类型的。</li>\n<li><code># HELP &lt;metric_name&gt; &lt;comment&gt;</code> 行不是必要的，用作该指标的注释。</li>\n<li>标签的值只能用双引号 &quot; 作为定界符，不能用单引号 ' 。</li>\n<li>每行末尾不能存在空格，否则会被当作最后一个字段。</li>\n<li>每行末尾要有换行符，最后一行也需要换行。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>推送之后，Pushgateway 会记录以下指标：</p>\n<div><pre><code>test_metric<span>{</span>job<span>=</span><span>\"pushgateway\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1\"</span>, <span>name</span><span>=</span><span>\"one\"</span><span>}</span>  <span>42</span>               <span># 该 metric 最后一次推送的值</span>\npush_failure_time_seconds<span>{</span>job<span>=</span><span>\"pushgateway\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1\"</span><span>}</span>  <span>0</span>              <span># 该组 metric 最后一次失败推送的时间戳</span>\npush_time_seconds<span>{</span>job<span>=</span><span>\"pushgateway\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1\"</span><span>}</span>  <span>1</span>.5909774528190377e+09 <span># 该组 metric 最后一次成功推送的时间戳</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>重复推送 test_metric 指标时，只会更新这三个指标的值，不会保留旧值。</p>\n</li>\n</ul>\n<h2 id=\"http-api\"> HTTP API</h2>\n<div><pre><code><span>curl</span> -X DELETE http://localhost:9091/metrics/job/pushgateway/instance/10.0.0.1      <span># 删除某个指标</span>\n</code></pre>\n<div><span>1</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "exporter",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Prometheus/exporter.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Prometheus/exporter.html",
      "content_html": "<h1 id=\"exporter\"> exporter</h1>\n<ul>\n<li><a href=\"https://prometheus.io/docs/instrumenting/exporters/\" target=\"_blank\" rel=\"noopener noreferrer\">官方及社区的 exporter 列表</a></li>\n<li>主流软件大多提供了自己的 exporter 程序，比如 mysqld_exporter、redis_exporter 。有的软件甚至本身就集成了 exporter 格式的 HTTP API 。\n<ul>\n<li>没必要启用所有 exporter ，有的监控指标较少，不如自制。</li>\n<li>Prometheus 提供了多种编程语言的库，供用户开发 exporter 程序。例如 Python 的第三方库 prometheus-client 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"集成类型\"> 集成类型</h2>\n<h3 id=\"prometheus\"> Prometheus</h3>\n<ul>\n<li>本身集成了 exporter 格式的 API ，默认的 metrics_path 为 <code>/metrics</code> 。</li>\n<li>在 Grafana 上显示指标时，可参考 Prometheus 数据源自带的 &quot;Prometheus Stats&quot; 仪表盘。</li>\n<li>指标示例：<div><pre><code>prometheus_build_info<span>{</span>branch<span>=</span><span>\"HEAD\"</span>, <span>goversion</span><span>=</span><span>\"go1.14.2\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9090\"</span>, <span>job</span><span>=</span><span>\"prometheus\"</span>, <span>revision</span><span>=</span><span>\"ecee9c8abfd118f139014cb1b174b08db3f342cf\"</span>, <span>version</span><span>=</span><span>\"2.18.1\"</span><span>}</span>  <span># 版本信息</span>\n\ntime<span>(</span><span>)</span> - process_start_time_seconds                             <span># 运行时长（s）</span>\nrate<span>(</span>process_cpu_seconds_total<span>[</span>1m<span>]</span><span>)</span>                             <span># 占用 CPU 核数</span>\nprocess_resident_memory_bytes                                   <span># 占用内存</span>\nprometheus_tsdb_storage_blocks_bytes                            <span># tsdb block 占用的磁盘空间</span>\nsum<span>(</span>delta<span>(</span>prometheus_http_requests_total<span>[</span>1m<span>]</span><span>))</span> by <span>(</span>code<span>)</span>        <span># 每分钟收到 HTTP 请求的次数</span>\nsum<span>(</span>delta<span>(</span>prometheus_http_request_duration_seconds_sum<span>[</span>1m<span>]</span><span>))</span>    <span># 每分钟处理 HTTP 请求的耗时（s）</span>\n\ncount<span>(</span>up <span>==</span> <span>1</span><span>)</span>                                                  <span># target 在线数</span>\nsum<span>(</span>scrape_samples_scraped<span>)</span>                                     <span># scrape 的指标数</span>\nsum<span>(</span>scrape_duration_seconds<span>)</span>                                    <span># scrape 的耗时（s）</span>\nsum<span>(</span>delta<span>(</span>prometheus_rule_evaluations_total<span>[</span>1m<span>]</span><span>))</span> without <span>(</span>rule_group<span>)</span>          <span># rule 每分钟的执行次数</span>\nsum<span>(</span>delta<span>(</span>prometheus_rule_evaluation_failures_total<span>[</span>1m<span>]</span><span>))</span> without <span>(</span>rule_group<span>)</span>  <span># rule 每分钟的执行失败次数</span>\ndelta<span>(</span>prometheus_rule_evaluation_duration_seconds_sum<span>[</span>1m<span>]</span><span>)</span>                      <span># rule 每分钟的执行耗时（s）</span>\n\nALERTS<span>{</span>alertname<span>=</span><span>\"xxx\"</span>, <span>alertstate</span><span>=</span><span>\"pending|firing\"</span><span>}</span>            <span># 存在的警报</span>\nALERTS_FOR_STATE<span>{</span>alertname<span>=</span><span>\"xxx\"</span><span>}</span>                               <span># 警报开始的时间戳（这是 pending 状态的开始时间，不能区分 firing 状态）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div></li>\n</ul>\n<h3 id=\"alertmanager\"> Alertmanager</h3>\n<ul>\n<li>本身集成了 exporter 格式的 API ，默认的 metrics_path 为 <code>/metrics</code> 。</li>\n<li>指标示例：<div><pre><code>alertmanager_build_info<span>{</span>branch<span>=</span><span>\"HEAD\"</span>, <span>goversion</span><span>=</span><span>\"go1.13.5\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9093\"</span>, <span>job</span><span>=</span><span>\"alertmanager\"</span>, <span>revision</span><span>=</span><span>\"f74be0400a6243d10bb53812d6fa408ad71ff32d\"</span>, <span>version</span><span>=</span><span>\"0.20.0\"</span><span>}</span>   <span># 版本信息</span>\n\ntime<span>(</span><span>)</span> - process_start_time_seconds       <span># 运行时长（s）</span>\nirate<span>(</span>process_cpu_seconds_total<span>[</span>5m<span>]</span><span>)</span>      <span># 占用 CPU 核数</span>\nprocess_resident_memory_bytes             <span># 占用内存</span>\nsum<span>(</span>delta<span>(</span>alertmanager_http_request_duration_seconds_sum<span>[</span>1m<span>]</span><span>))</span>  <span># 处理 HTTP 请求的耗时（s）</span>\n\nalertmanager_alerts                       <span># 存在的警报数（包括激活的、被抑制的）</span>\nalertmanager_silences<span>{</span>state<span>=</span><span>\"active\"</span><span>}</span>     <span># Silences 数量</span>\nalertmanager_notifications_total          <span># 发送的消息数</span>\nalertmanager_notifications_failed_total   <span># 发送失败的消息数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>如果重启 Alertmanager ，则会使一些计数的指标归零。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"grafana\"> Grafana</h3>\n<ul>\n<li>本身集成了 exporter 格式的 API ，默认的 metrics_path 为 <code>/metrics</code> 。\n<ul>\n<li>访问时不需要身份认证，但只提供了关于 Grafana 运行状态的指标。</li>\n</ul>\n</li>\n<li>在 Grafana 上显示指标时，可参考 Prometheus 数据源自带的 &quot;Grafana metrics&quot; 仪表盘。</li>\n<li>指标示例：<div><pre><code>grafana_build_info<span>{</span>branch<span>=</span><span>\"HEAD\"</span>, <span>edition</span><span>=</span><span>\"oss\"</span>, <span>goversion</span><span>=</span><span>\"go1.14.1\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:3000\"</span>, <span>job</span><span>=</span><span>\"grafana\"</span>, <span>revision</span><span>=</span><span>\"aee1438ff2\"</span>, <span>version</span><span>=</span><span>\"7.0.0\"</span><span>}</span>  <span># 版本信息</span>\n\ntime<span>(</span><span>)</span> - process_start_time_seconds       <span># 运行时长（s）</span>\nirate<span>(</span>process_cpu_seconds_total<span>[</span>5m<span>]</span><span>)</span>      <span># 占用 CPU 核数</span>\nprocess_resident_memory_bytes             <span># 占用内存</span>\n\ngrafana_alerting_active_configurations    <span># Alert Rule 的总数</span>\ngrafana_alerting_active_alerts            <span># Alert Rule 的激活数量</span>\ngrafana_emails_sent_total\ngrafana_emails_sent_failed\n\ndelta<span>(</span>grafana_http_request_duration_seconds_count<span>{</span>handler<span>=</span><span>\"/\"</span>,method<span>=</span><span>\"GET\"</span>,status_code<span>=</span><span>\"200\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>  <span># 每分钟收到的 HTTP 请求数</span>\ndelta<span>(</span>grafana_http_request_duration_seconds_sum<span>{</span>handler<span>=</span><span>\"/\"</span>,method<span>=</span><span>\"GET\"</span>,status_code<span>=</span><span>\"200\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>    <span># 每分钟处理 HTTP 请求的耗时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n<h3 id=\"jenkins\"> Jenkins</h3>\n<ul>\n<li>安装插件 &quot;Prometheus metrics&quot; 可提供 exporter 格式的 API ，默认的 metrics_path 为 <code>/prometheus/</code> 。\n<ul>\n<li>在 Jenkins 的 &quot;Configure System&quot; 页面可以对 &quot;Prometheus&quot; 栏进行配置。</li>\n<li>不能统计到安装该插件以前的 Jenkins 指标。</li>\n</ul>\n</li>\n<li>指标示例：<div><pre><code>time<span>(</span><span>)</span> - process_start_time_seconds     <span># 运行时长（s）</span>\nirate<span>(</span>process_cpu_seconds_total<span>[</span>5m<span>]</span><span>)</span>    <span># 占用 CPU 核数</span>\nprocess_resident_memory_bytes           <span># 占用内存</span>\ndelta<span>(</span>http_requests_count<span>[</span>1m<span>]</span><span>)</span>          <span># 每分钟收到 HTTP 请求的次数</span>\nhttp_requests<span>{</span>quantile<span>=~</span><span>\"0.5|0.99\"</span><span>}</span>     <span># 每分钟处理 HTTP 请求的耗时（s）</span>\n\njenkins_node_count_value                <span># node 总数</span>\njenkins_node_online_value               <span># node 在线数</span>\njenkins_executor_count_value            <span># 执行器的总数</span>\njenkins_executor_in_use_value           <span># 执行器正在使用的数量</span>\njenkins_node_builds_count               <span># Jenkins 本次启动以来的构建总次数</span>\n\njenkins_job_count_value                 <span># Job 总数</span>\njenkins_queue_size_value                <span># 构建队列中的 Job 数（最好为 0 ）</span>\ndefault_jenkins_builds_duration_milliseconds_summary_count<span>{</span>, <span>jenkins_job</span><span>=</span><span>'xxx'</span><span>}</span>  <span># Job 的构建总次数（当构建结束时才记录）</span>\ndefault_jenkins_builds_duration_milliseconds_summary_sum<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>      <span># Job 的构建总耗时（包括被阻塞的时长）</span>\ndefault_jenkins_builds_success_build_count<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>                    <span># Job 构建成功的次数</span>\ndefault_jenkins_builds_failed_build_count<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>                     <span># Job 构建失败的次数</span>\ndefault_jenkins_builds_last_build_start_time_milliseconds<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>     <span># Job 最近一次构建的开始时间</span>\ndefault_jenkins_builds_last_build_duration_milliseconds<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>       <span># Job 最近一次构建的持续时长</span>\ndefault_jenkins_builds_last_build_result<span>{</span>jenkins_job<span>=</span><span>'xxx'</span><span>}</span>                      <span># Job 最近一次构建的结果（ 1 代表 success 、0 代表其它状态）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div><ul>\n<li>如果删除某个 Job 的构建记录，则会使其总的构建次数减少。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"zookeeper\"> ZooKeeper</h3>\n<ul>\n<li>可启用 exporter API ，默认监听 7000 端口， metrics_path 为 <code>/metrics</code> 。</li>\n<li>指标示例：<div><pre><code><span># 关于 zk 集群</span>\nquorum_size               <span># 非 observer 的 server 数量。这取决于配置文件，不会监控在线的 server 数</span>\nsynced_observers          <span># observer 数量</span>\nelection_time_sum         <span># 最近一次选举的耗时，单位 ms</span>\n<span>uptime</span>                    <span># leader 的任期时长，单位 ms</span>\n\n<span># 关于 znode</span>\nznode_count               <span># 节点的数量</span>\nephemerals_count          <span># 临时节点的数量</span>\nwrite_per_namespace_sum<span>{</span>key<span>=</span><span>\"brokers\"</span><span>}</span>    <span># 每个一级节点的写数据量</span>\nread_per_namespace_sum<span>{</span>key<span>=</span><span>\"brokers\"</span><span>}</span>     <span># 每个一级节点的读数据量</span>\nreadlatency_count         <span># 读操作的数量。仅统计当前 server 收到的请求</span>\nreadlatency_sum           <span># 读操作的耗时</span>\nupdatelatency_count       <span># 读操作的数量</span>\nupdatelatency_sum         <span># 写操作的耗时，包括等待 quorum 投票</span>\n\n<span># 关于客户端</span>\nconnection_request_count  <span># 客户端发出连接请求的累计数量</span>\nglobal_sessions           <span># 客户端会话数</span>\nwatch_count               <span># watch 的数量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></li>\n</ul>\n<h2 id=\"通用类型\"> 通用类型</h2>\n<h3 id=\"node-exporter\"> node_exporter</h3>\n<p>：用于监控类 Unix 主机。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/prometheus/node_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>下载后启动：</p>\n<div><pre><code>./node_exporter\n               <span># --web.listen-address=\":9100\"</span>\n               <span># --web.telemetry-path=\"/metrics\"</span>\n               <span># --log.level=info</span>\n               <span># --log.format=logfmt</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>默认的访问地址为 <a href=\"http://localhost:9100/metrics\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:9100/metrics</a></p>\n</li>\n<li>\n<p>指标示例：</p>\n<div><pre><code>node_exporter_build_info<span>{</span>branch<span>=</span><span>\"HEAD\"</span>, <span>goversion</span><span>=</span><span>\"go1.15.8\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9100\"</span>, <span>job</span><span>=</span><span>\"node_exporter\"</span>, <span>revision</span><span>=</span><span>\"b597c1244d7bef49e6f3359c87a56dd7707f6719\"</span>, <span>version</span><span>=</span><span>\"1.1.2\"</span><span>}</span>  <span># 版本信息</span>\nnode_uname_info<span>{</span>domainname<span>=</span><span>\"(none)\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9100\"</span>, <span>job</span><span>=</span><span>\"node_exporter\"</span>, <span>machine</span><span>=</span><span>\"x86_64\"</span>, <span>nodename</span><span>=</span><span>\"Centos-1\"</span>, <span>release</span><span>=</span><span>\"3.10.0-862.el7.x86_64\"</span>, <span>sysname</span><span>=</span><span>\"Linux\"</span>, <span>version</span><span>=</span><span>\"#1 SMP Fri Apr 20 16:44:24 UTC 2018\"</span><span>}</span>  <span># 主机信息</span>\n\n<span># 关于时间</span>\nnode_boot_time_seconds                        <span># 主机的启动时刻</span>\nnode_time_seconds                             <span># 主机的当前时间（Unix 时间戳）</span>\nnode_time_seconds - node_boot_time_seconds    <span># 主机的运行时长（s）</span>\nnode_time_seconds - time<span>(</span><span>)</span> + T                <span># 主机的时间误差，其中 T 是估计每次抓取及传输的耗时</span>\n\n<span># 关于 CPU</span>\nnode_load1                                                                    <span># 每分钟的平均负载</span>\ncount<span>(</span>node_cpu_seconds_total<span>{</span>mode<span>=</span><span>'idle'</span><span>}</span><span>)</span>                                    <span># CPU 核数</span>\navg<span>(</span>irate<span>(</span>node_cpu_seconds_total<span>[</span>5m<span>]</span><span>))</span> without <span>(</span>cpu<span>)</span> * <span>100</span>                    <span># CPU 各模式占比（%）</span>\n<span>(</span><span>1</span> - avg<span>(</span>irate<span>(</span>node_cpu_seconds_total<span>{</span>mode<span>=</span><span>\"idle\"</span><span>}</span><span>[</span>5m<span>]</span><span>))</span> without<span>(</span>cpu<span>))</span> * <span>100</span>  <span># CPU 使用率（%）</span>\n\n<span># 关于内存</span>\nnode_memory_MemTotal_bytes                    <span># 内存总量，单位 bytes</span>\nnode_memory_MemAvailable_bytes                <span># 内存可用量，CentOS 7 以上版本才支持该指标</span>\nnode_memory_SwapTotal_bytes                   <span># swap 内存总量</span>\nnode_memory_SwapFree_bytes                    <span># swap 内存可用量</span>\n\n<span># 关于磁盘</span>\nsum<span>(</span>node_filesystem_size_bytes<span>{</span>fstype<span>=~</span><span><span>`</span>ext<span>\\</span>d<span>|</span>xfs<span>`</span></span>, mountpoint<span>!</span>~<span><span>`</span>/boot<span>`</span></span><span>}</span><span>)</span> without<span>(</span>device, fstype, mountpoint<span>)</span>  <span># 磁盘总量</span>\nsum<span>(</span>node_filesystem_avail_bytes<span>{</span>fstype<span>=~</span><span><span>`</span>ext<span>\\</span>d<span>|</span>xfs<span>`</span></span>, mountpoint<span>!</span>~<span><span>`</span>/boot<span>`</span></span><span>}</span><span>)</span> without<span>(</span>device, fstype, mountpoint<span>)</span> <span># 磁盘可用量</span>\nsum<span>(</span>rate<span>(</span>node_disk_read_bytes_total<span>[</span>1m<span>]</span><span>))</span>     <span># 磁盘每秒读取量</span>\nsum<span>(</span>rate<span>(</span>node_disk_written_bytes_total<span>[</span>1m<span>]</span><span>))</span>  <span># 磁盘每秒写入量</span>\nnode_filefd_maximum                           <span># 文件描述符的数量上限</span>\nnode_filefd_allocated                         <span># 文件描述符的使用数量</span>\n\n<span># 关于网卡</span>\nnode_network_info<span>{</span>address<span>=</span><span>\"00:60:F6:71:20:18\"</span>,broadcast<span>=</span><span>\"ff:ff:ff:ff:ff:ff\"</span>,device<span>=</span><span>\"eth0\"</span>,duplex<span>=</span><span>\"full\"</span>,ifalias<span>=</span><span>\"\"</span>,operstate<span>=</span><span>\"up\"</span><span>}</span> <span># 网卡的信息（broadcast 是广播地址，duplex 是双工模式，）</span>\nnode_network_up                                                     <span># 网卡的状态，取值 1、0 表示是否正在启用</span>\nnode_network_mtu_bytes                                              <span># MTU 大小</span>\nrate<span>(</span>node_network_receive_bytes_total<span>{</span>device<span>!</span>~<span><span>`</span>lo<span>|</span>docker0<span>`</span></span><span>}</span><span>[</span>1m<span>]</span><span>)</span>   <span># 网卡每秒接收量</span>\nrate<span>(</span>node_network_transmit_bytes_total<span>{</span>device<span>!</span>~<span><span>`</span>lo<span>|</span>docker0<span>`</span></span><span>}</span><span>[</span>1m<span>]</span><span>)</span>  <span># 网卡每秒发送量</span>\n\n<span># 关于 IP 协议</span>\nnode_network_receive_packets_total        <span># 网卡接收的数据包数</span>\nnode_network_receive_errs_total           <span># 网卡接收的错误包数</span>\nnode_network_receive_drop_total           <span># 网卡接收时的丢弃包数</span>\nnode_network_receive_compressed_total     <span># 网卡接收的压缩包数</span>\nnode_network_receive_multicast_total      <span># 网卡接收的多播包数</span>\nnode_network_transmit_packets_total       <span># 网卡发送的数据包数</span>\nnode_network_transmit_errs_total\nnode_network_transmit_drop_total\nnode_network_transmit_compressed_total\nnode_netstat_Icmp_InMsgs                  <span># 接收的 ICMP 包数</span>\nnode_netstat_Icmp_InErrors                <span># 接收的 ICMP 错误包数</span>\nnode_netstat_Icmp_OutMsgs                 <span># 发送的 ICMP 包数</span>\n\n<span># 关于 Socket</span>\nnode_sockstat_sockets_used                <span># 使用的 Socket 数</span>\nnode_sockstat_TCP_inuse                   <span># 监听的 TCP Socket 数</span>\nnode_sockstat_TCP_tw\n\n<span># 关于 TCP/UDP 协议</span>\nnode_netstat_Tcp_CurrEstab                <span># ESTABLISHED 加 CLOSE_WAIT 状态的 TCP 连接数</span>\nnode_netstat_Tcp_InSegs                   <span># 接收的 TCP 包数（包括错误的）</span>\nnode_netstat_Tcp_InErrs                   <span># 接收的 TCP 错误包数（比如校验和错误）</span>\nnode_netstat_Tcp_OutSegs                  <span># 发送的 TCP 包数</span>\nnode_netstat_Udp_InDatagrams              <span># 接收的 UDP 包数</span>\nnode_netstat_Udp_InErrors                 <span># 接收的 UDP 错误包数</span>\nnode_netstat_Udp_OutDatagrams             <span># 发送的 UDP 包数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br></div></div></li>\n</ul>\n<h3 id=\"process-exporter\"> process-exporter</h3>\n<p>：用于监控 Linux 主机上的进程、线程。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/ncabatoff/process-exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>它主要通过读取 <code>/proc/&lt;pid&gt;/</code> 目录下的信息，来收集进程指标。</p>\n</li>\n<li>\n<p>下载后启动：</p>\n<div><pre><code>./process-exporter -config.path<span>=</span>process-exporter.yml\n                  <span># -web.listen-address :9256</span>\n                  <span># -web.telemetry-path /metrics</span>\n                  -children<span>=</span>false                 <span># 是否将子进程占用的资源统计到父进程名下，默认为 true</span>\n                  -threads<span>=</span>false                  <span># 是否采集每个线程的指标，默认为 true</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<p>在配置文件中定义需要监控的进程：</p>\n<div><pre><code><span>process_names</span><span>:</span>\n<span>-</span> <span>exe</span><span>:</span>\n  <span>-</span> top                           <span># 定义多行条件，匹配任一条件的进程都会被监控</span>\n  <span>-</span> /bin/ping\n\n<span>-</span> <span>comm</span><span>:</span>\n  <span>-</span> bash\n\n<span>-</span> <span>name</span><span>:</span> <span>\"{{.ExeBase}}\"</span>            <span># 定义进程组的 name ，这里调用了模板变量</span>\n  <span>cmdline</span><span>:</span>\n  <span>-</span> /bin/ping localhost\n\n<span>-</span> <span>name</span><span>:</span> <span>\"ping {{.Matches.name}}\"</span>  <span># 这里调用正则匹配的元素组作为 name</span>\n  <span>cmdline</span><span>:</span>\n  <span>-</span> ping www.(<span>?</span>P&lt;name<span>></span>\\w<span>*).com</span>    <span># 用 ?P&lt;name> 的格式命名正则匹配的元素组</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>process-exporter 运行时，会将主机上每个进程尝试匹配配置文件中的规则。\n<ul>\n<li>如果匹配某个条件，则监控该进程。</li>\n<li>如果匹配多个条件，则只采用最先匹配的条件。</li>\n<li>如果所有条件都不匹配，则不监控该进程。</li>\n</ul>\n</li>\n<li>匹配规则分为 3 种类型：\n<ul>\n<li>exe ：对进程启动命令中的可执行文件路径，即 <code>argv[0]</code> ，进行匹配（必须完全相同）。</li>\n<li>comm ：对进程的可执行文件的文件名，即 <code>/proc/&lt;PID&gt;/comm</code> 进行匹配（必须完全相同）。</li>\n<li>cmdline ：对进程的启动命令，即 <code>/proc/&lt;PID&gt;/cmdline</code> ， 进行正则匹配（只要匹配部分字符串即可）。\n<ul>\n<li>exe、comm 可以定义多行匹配条件，匹配任一条件的进程都会被监控。</li>\n<li>cmdline 也可以定义多行匹配条件，只有同时匹配所有条件的进程才会被监控。</li>\n<li>exe、comm 会自动使用匹配条件作为被监控进程的名称，即 groupname 。而 cmdline 需要手动定义 name 。</li>\n</ul>\n</li>\n<li>可以将 cmdline 与一个 exe 或 comm 组合使用，既要求进程的启动命令匹配，也要求可执行文件匹配。如下：<div><pre><code><span>-</span> <span>name</span><span>:</span> jenkins\n  <span>comm</span><span>:</span>\n    <span>-</span> java\n  <span>cmdline</span><span>:</span>\n    <span>-</span> java .* <span>-</span>jar /usr/share/jenkins/jenkins.war\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n<li>定义 cmdline 的 name 时，可调用以下模板变量：<div><pre><code>.Comm         <span># 可执行文件的文件名，比如 ping</span>\n.ExeBase      <span># 进程启动命令中的可执行文件的文件名，比如 ping</span>\n.ExeFull      <span># 进程启动命令中的可执行文件路径，比如 /bin/ping</span>\n.Username     <span># 启动进程的用户名</span>\n.Matches      <span># 一个字典，存储 cmdline 正则匹配的结果</span>\n.PID          <span># 进程的 PID</span>\n.StartTime    <span># 进程的启动时刻，比如 2021-01-01 07:40:29.22 +0000 UTC</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>指标示例：</p>\n<div><pre><code>process_exporter_build_info<span>{</span>branch<span>=</span><span>\"\"</span>,goversion<span>=</span><span>\"go1.15.3\"</span>,revision<span>=</span><span>\"\"</span>,version<span>=</span><span>\"0.7.5\"</span><span>}</span>   <span># 版本信息</span>\n\nnamedprocess_namegroup_num_procs                                                <span># 进程数（统计属于同一个 groupname 的进程实例数量）</span>\ntimestamp<span>(</span>namedprocess_namegroup_oldest_start_time_seconds<span>)</span> - <span>(</span>namedprocess_namegroup_oldest_start_time_seconds<span>></span><span>0</span><span>)</span>  <span># 运行时长。如果同一个 groupname 中存在多个进程，则考虑最老的那个进程</span>\nsum<span>(</span>irate<span>(</span>namedprocess_namegroup_cpu_seconds_total<span>[</span>5m<span>]</span><span>))</span> without <span>(</span>mode<span>)</span>         <span># 进程占用的 CPU 核数</span>\nnamedprocess_namegroup_memory_bytes<span>{</span>memtype<span>=</span><span>\"virtual\"</span><span>}</span>                          <span># 进程申请的虚拟内存</span>\nnamedprocess_namegroup_memory_bytes<span>{</span>memtype<span>=</span><span>\"resident\"</span><span>}</span>                         <span># 进程占用的 RAM 内存</span>\nnamedprocess_namegroup_memory_bytes<span>{</span>memtype<span>=</span><span>\"swapped\"</span><span>}</span>                          <span># 进程占用的 Swap 内存</span>\nrate<span>(</span>namedprocess_namegroup_read_bytes_total<span>[</span>1m<span>]</span><span>)</span>                               <span># 进程的磁盘每秒读取量</span>\nrate<span>(</span>namedprocess_namegroup_write_bytes_total<span>[</span>1m<span>]</span><span>)</span>                              <span># 进程的磁盘每秒写入量</span>\n\nnamedprocess_namegroup_num_threads                                              <span># 进程包含的线程数</span>\nnamedprocess_namegroup_states<span>{</span>state<span>=</span><span>\"Sleeping\"</span><span>}</span>                                 <span># Sleeping 状态的线程数</span>\nnamedprocess_namegroup_open_filedesc                                            <span># 打开的文件描述符数量</span>\n\nnamedprocess_namegroup_thread_count<span>{</span>groupname<span>=</span><span>\"python\"</span>, <span>threadname</span><span>=</span><span>\"thread-1\"</span><span>}</span>  <span># 指定进程包含的，同一名称的线程数</span>\nsum<span>(</span>irate<span>(</span>namedprocess_namegroup_thread_cpu_seconds_total<span>[</span>5m<span>]</span><span>))</span> without <span>(</span>mode<span>)</span>  <span># 线程占用的 CPU 核数</span>\nrate<span>(</span>namedprocess_namegroup_thread_io_bytes_total<span>{</span>iomode<span>=</span><span>\"read\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>           <span># 线程的磁盘每秒读取量</span>\nrate<span>(</span>namedprocess_namegroup_thread_io_bytes_total<span>{</span>iomode<span>=</span><span>\"write\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>          <span># 线程的磁盘每秒写入量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div><ul>\n<li>当 process-exporter 发现进程 A 之后，就会一直记录它的指标。即使进程 A 停止，也会记录它的 namedprocess_namegroup_num_procs 为 0 。\n<ul>\n<li>如果重启 process-exporter ，则只会发现此时存在的进程，不会再记录进程 A 。</li>\n<li>如果主机重启之后，进程没有启动，则它不能发现进程没有恢复，不会发出警报。</li>\n</ul>\n</li>\n<li>xx_total 之类的指标是累计值，当 process-exporter 重启时会清零，重新累计。</li>\n<li>不能监控进程的网络 IO 。</li>\n<li>启动 process-exporter 之后，可尝试执行以下命令，查看当前监控的进程：<div><pre><code><span>curl</span> <span>127.0</span>.0.1:9256/metrics <span>|</span> <span>grep</span> num_procs\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"windows-exporter\"> windows_exporter</h3>\n<p>：用于监控 Windows 主机，也可监控其进程。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/prometheus-community/windows_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>下载 exe 版后启动：</p>\n<div><pre><code>windows_exporter.exe\n                    <span># --telemetry.addr :9182</span>\n                    <span># --telemetry.path /metrics</span>\n                    --collectors.enabled cpu,cs,logical_disk,net,os,process,system  <span># 启用指定的指标采集器</span>\n                    <span># --collector.process.whitelist=\"firefox|chrome\"                # 指定要监控的进程的白名单（对进程名进行正则匹配）</span>\n                    <span># --collector.process.blacklist=\"\"                              # 指定要监控的进程的黑名单</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>或者下载 msi 版。执行它会安装 windows_exporter ，并作为后台服务运行、自动开通防火墙。</p>\n<div><pre><code>windows_exporter.msi\n                    <span># LISTEN_ADDR 0.0.0.0</span>\n                    <span># LISTEN_PORT 9182</span>\n                    <span># METRICS_PATH /metrics</span>\n                    <span>ENABLED_COLLECTORS</span><span>=</span>cpu,cs,logical_disk,net,os,process,system\n                    <span>EXTRA_FLAGS</span><span>=</span><span>\"--collector.process.whitelist=firefox|chrome\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>指标示例：</p>\n<div><pre><code>windows_exporter_build_info<span>{</span>branch<span>=</span><span>\"master\"</span>, <span>goversion</span><span>=</span><span>\"go1.13.3\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9182\"</span>, <span>job</span><span>=</span><span>\"windows_exporter\"</span>, <span>revision</span><span>=</span><span>\"c62fe4477fb5072e569abb44144b77f1c6154016\"</span>, <span>version</span><span>=</span><span>\"0.13.0\"</span><span>}</span>  <span># 版本信息</span>\n\n<span># os collector</span>\nwindows_os_info<span>{</span>instance<span>=</span><span>\"10.0.0.1:9182\"</span>, <span>job</span><span>=</span><span>\"windows_exporter\"</span>, <span>product</span><span>=</span><span>\"Microsoft Windows Server 2016 Standard\"</span>, <span>version</span><span>=</span><span>\"10.0.14393\"</span><span>}</span> <span># 主机信息</span>\nwindows_os_time                           <span># 主机的当前时间（Unix 时间戳）</span>\nwindows_os_timezone<span>{</span>timezone<span>=</span><span>\"CST\"</span><span>}</span>       <span># 采用的时区</span>\nwindows_os_visible_memory_bytes           <span># 可见的物理内存的总量，可能小于实际容量</span>\nwindows_os_physical_memory_free_bytes     <span># 物理内存的可用量</span>\nwindows_os_virtual_memory_bytes           <span># 虚拟内存的总量</span>\nwindows_os_virtual_memory_free_bytes      <span># 虚拟内存的可用量</span>\n\n<span># cs collector</span>\nwindows_cs_logical_processors             <span># CPU 核数</span>\n\n<span># system collector</span>\nwindows_system_system_up_time             <span># 主机的启动时刻</span>\n\n<span># cpu collector</span>\nwindows_cpu_core_frequency_mhz                                                <span># CPU 频率</span>\navg<span>(</span>irate<span>(</span>windows_cpu_time_total<span>[</span>5m<span>]</span><span>))</span> without<span>(</span>core<span>)</span> * <span>100</span>                    <span># CPU 各模式占比（%）</span>\n<span>(</span><span>1</span> - avg<span>(</span>irate<span>(</span>windows_cpu_time_total<span>{</span>mode<span>=</span><span>\"idle\"</span><span>}</span><span>[</span>5m<span>]</span><span>))</span> without<span>(</span>core<span>))</span> * <span>100</span> <span># CPU 使用率（%）</span>\n\n<span># logical_disk collector 的指标</span>\nsum<span>(</span>windows_logical_disk_size_bytes<span>)</span> without<span>(</span>volume<span>)</span>                    <span># 磁盘的总量</span>\nwindows_logical_disk_free_bytes<span>{</span>volume<span>!</span>~<span>'HarddiskVolume.*'</span><span>}</span>             <span># 磁盘的可用量，磁盘分区 HarddiskVolume 一般是系统保留分区</span>\nrate<span>(</span>windows_logical_disk_read_bytes_total<span>[</span>1m<span>]</span><span>)</span>                         <span># 磁盘每秒读取量</span>\nrate<span>(</span>windows_logical_disk_write_bytes_total<span>[</span>1m<span>]</span><span>)</span>                        <span># 磁盘每秒写入量</span>\n\n<span># net collector</span>\nrate<span>(</span>windows_net_bytes_received_total<span>{</span>nic<span>=</span><span>\"xxx\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>                   <span># 网卡每秒接收量</span>\nrate<span>(</span>windows_net_bytes_sent_total<span>{</span>nic<span>=</span><span>\"xxx\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span>                       <span># 网卡每秒发送量</span>\n\n<span># process collector</span>\ntimestamp<span>(</span>windows_process_start_time<span>)</span> - <span>(</span>windows_process_start_time<span>></span><span>0</span><span>)</span>  <span># 进程的运行时长</span>\nsum<span>(</span>rate<span>(</span>windows_process_cpu_time_total<span>[</span>1m<span>]</span><span>))</span> without <span>(</span>mode<span>)</span>            <span># 进程占用的 CPU 核数</span>\nwindows_process_private_bytes                                           <span># 进程独占的内存，即进程总共提交的内存，包括物理内存、虚拟内存</span>\nwindows_process_working_set                                             <span># 进程可用的内存，包括独占的内存、与其它进程的共享内存</span>\nwindows_process_thread_count                                            <span># 进程的线程数</span>\nwindows_process_io_bytes_total                                          <span># 进程的 handle 数量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br></div></div><ul>\n<li>当 windows_exporter 发现进程 A 之后，就会一直记录它的指标。但是如果进程 A 停止，则不会再记录它的指标。</li>\n<li>不能监控进程的网络 IO 。</li>\n<li>不能通过启动命令区分相同名字的进程，只能通过 PID 区分。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"cadvisor\"> cAdvisor</h3>\n<p>：用于监控容器。</p>\n<ul>\n<li><a href=\"https://github.com/google/cadvisor\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>该工具由 Google 公司开发，支持将监控数据输出到 Prometheus、InfluxDB、Kafka、ES 等存储服务。</li>\n<li>下载后启动：<div><pre><code>./cadvisor\n          <span># --listen_ip 0.0.0.0</span>\n          <span># --port 8080</span>\n          <span># --prometheus_endpoint  /metrics</span>\n          --docker_only<span>=</span>true    <span># 不输出 raw cgourp 的指标，除了 root gourp ，即 id=\"/\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>它依赖版本较新的 glibc 库，因此建议运行官方 Docker 镜像。</li>\n</ul>\n</li>\n<li>它提供了 Web 监控页面，默认只允许从 localhost 访问，可以加上 HTTP Basic Auth 后公开：<div><pre><code>htpasswd -cb <span>passwd</span> admin <span>123456</span>\n./cadvisor --http_auth_file <span>passwd</span> --http_auth_realm <span>0.0</span>.0.0\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div>访问地址为 <code>127.0.0.1:8080/containers/</code> 。</li>\n<li>指标示例：<div><pre><code>container_start_time_seconds              <span># 容器的创建时刻（不是启动时刻），采用 Unix 时间戳</span>\ncontainer_last_seen                       <span># 最后一次监控该容器的时刻。cadvisor 不会监控已停止的容器，但会在容器停止之后的几分钟内依然记录该指标</span>\ncontainer_tasks_state<span>{</span>state<span>=</span><span>\"xx\"</span><span>}</span>         <span># 容器是否处于某种状态</span>\ncontainer_processes                       <span># 进程数</span>\ncontainer_threads                         <span># 线程数</span>\n\ncontainer_cpu_usage_seconds_total         <span># 容器占用 CPU 的累计时长</span>\ncontainer_cpu_user_seconds_total          <span># 占用用户态 CPU 的时长</span>\ncontainer_cpu_system_seconds_total\ncontainer_cpu_load_average_10s            <span># 容器占用 CPU 的 10 秒平均负载</span>\ncontainer_cpu_cfs_throttled_seconds_total <span># 容器超出 cpu.cfs_quota_us 限额之后申请的 CPU 时长</span>\n\ncontainer_memory_usage_bytes              <span># 容器占用的全部内存，包括 RSS、swap、Page Cache 等</span>\ncontainer_memory_rss                      <span># 容器的 rss 内存。超过 Cgroup 限制时会被 OOM 杀死</span>\ncontainer_memory_swap                     <span># 容器占用的 swap 分区</span>\ncontainer_memory_cache                    <span># 容器占用的 Page Cache</span>\ncontainer_memory_working_set_bytes        <span># 容器的工作集内存，即最近访问的内存，等于 container_memory_usage_bytes - inactive_page</span>\n\ncontainer_file_descriptors                <span># 打开的文件数</span>\ncontainer_fs_usage_bytes                  <span># 容器占用的磁盘，包括 rootfs、终端日志，不包括挂载的 volume</span>\ncontainer_fs_reads_total                  <span># 磁盘读的累计次数</span>\ncontainer_fs_reads_bytes_total            <span># 磁盘读的累计字节量</span>\ncontainer_fs_read_seconds_total           <span># 磁盘读的累计耗时</span>\ncontainer_fs_writes_total<span>{</span>device<span>=</span><span>\"xx\"</span><span>}</span>    <span># 磁盘写的累计次数，按 device 划分，包括 rootfs、volume ，不包括终端日志，不包括 Page Cache 缓冲区的数据</span>\ncontainer_fs_write_seconds_total\ncontainer_fs_writes_bytes_total\n\ncontainer_sockets                                       <span># 打开的 Socket 数</span>\ncontainer_network_receive_bytes_total<span>{</span>interface<span>=</span><span>\"xx\"</span><span>}</span>   <span># 网络收的累计字节量</span>\ncontainer_network_receive_packets_total                 <span># 网络收的累计数据包数</span>\ncontainer_network_transmit_bytes_total                  <span># 网卡发</span>\ncontainer_network_transmit_packets_total\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>假设容器启动之后不断增加内存，则当 container_memory_usage_bytes 达到 Cgroup 上限时，不会触发 OOM ，而是停止增长。\n<ul>\n<li>此时容器可以减少 Page Cache ，继续增加 container_memory_working_set_bytes 。</li>\n<li>当 container_memory_working_set_bytes 达到 Cgroup 上限时，会触发 OOM ，杀死容器。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"blackbox-exporter\"> blackbox_exporter</h3>\n<p>：提供探针（probe）的功能，可以通过 DNS、ICMP、TCP、HTTP 等通信监控服务的状态。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/prometheus/blackbox_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>blackbox_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> blackbox_exporter\n    <span>image</span><span>:</span> prom/blackbox<span>-</span>exporter<span>:</span>v0.19.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span># command:</span>\n    <span>#   - --web.listen-address=:9115</span>\n    <span>#   - --config.file=/etc/blackbox_exporter/config.yml</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9115<span>:</span><span>9115</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n      <span># - ./config.yml:/etc/blackbox_exporter/config.yml</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n<li>\n<p>可以手动发出 HTTP 请求，调用探针：</p>\n<ul>\n<li>使用 icmp 模块，检测目标主机能否 ping 通，也会检测出 DNS 耗时：<div><pre><code><span>curl</span> <span>'http://localhost:9115/probe?module=icmp&amp;target=baidu.com'</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>使用 tcp_connect 模块，检测目标主机的 TCP 端口能否连通：<div><pre><code><span>curl</span> <span>'http://localhost:9115/probe?module=tcp_connect&amp;target=baidu.com:80'</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>使用 http_2xx 模块，检测目标网站的 HTTP 状态码是否为 2xx ：<div><pre><code><span>curl</span> <span>'http://localhost:9115/probe?module=http_2xx&amp;target=http://baidu.com'</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>在 Prometheus 中加入 job 配置，调用探针：</p>\n<div><pre><code><span>-</span> <span>job_name</span><span>:</span> blackbox_exporter\n  <span>metrics_path</span><span>:</span> /probe\n  <span>params</span><span>:</span>\n    <span>module</span><span>:</span> <span>[</span>http_2xx<span>]</span>                <span># 使用的模块</span>\n  <span>relabel_configs</span><span>:</span>\n    <span>-</span> <span>source_labels</span><span>:</span> <span>[</span>__address__<span>]</span>\n      <span>target_label</span><span>:</span> __param_target\n    <span>-</span> <span>source_labels</span><span>:</span> <span>[</span>__param_target<span>]</span>\n      <span>target_label</span><span>:</span> instance\n    <span>-</span> <span>target_label</span><span>:</span> __address__\n      <span>replacement</span><span>:</span> <span>'10.0.0.1:9115'</span>    <span># blackbox_exporter 的地址</span>\n  <span>static_configs</span><span>:</span>\n    <span>-</span> <span>targets</span><span>:</span> <span>[</span><span>'10.0.0.2'</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n<li>\n<p>blackbox_exporter 的配置文件中默认定义了一些功能模块，可以在其中加入自定义的模块，如下：</p>\n<div><pre><code><span>modules</span><span>:</span>\n  <span>http_2xx_example</span><span>:</span>                   <span># 定义一个功能模块</span>\n    <span>prober</span><span>:</span> http                      <span># 探针的类型，可以是 dns、icmp、tcp、http</span>\n    <span>timeout</span><span>:</span> 2m                       <span># 每次探测的超时时间，超过则放弃。默认为 2 m</span>\n    <span>http</span><span>:</span>                             <span># 对应 prober 类型的配置参数</span>\n      <span># 关于每次探测时发出的 HTTP 请求</span>\n      <span>method</span><span>:</span> GET                     <span># 请求方法，默认为 GET</span>\n      <span>headers</span><span>:</span>\n        <span>&lt;string></span><span>:</span> &lt;string<span>></span>\n      <span>body</span><span>:</span> &lt;string<span>></span>\n      <span>basic_auth</span><span>:</span>\n        <span>username</span><span>:</span> &lt;string<span>></span>\n        <span>password</span><span>:</span> &lt;string<span>></span>\n      <span>proxy_url</span><span>:</span> &lt;string<span>></span>\n      <span>preferred_ip_protocol</span><span>:</span> ip6      <span># DNS 解析时，优先采用的 IP 协议，默认为 IPv6</span>\n      <span>ip_protocol_fallback</span><span>:</span> <span>true</span>      <span># 当 preferred_ip_protocol 不可用时，是否允许另一种 IP 协议。默认为 true</span>\n\n      <span># 关于 HTTPS</span>\n      <span>fail_if_ssl</span><span>:</span> <span>false</span>              <span># 如果采用 SSL ，是否探测失败</span>\n      <span>fail_if_not_ssl</span><span>:</span> <span>false</span>          <span># 如果不采用 SSL ，是否探测失败</span>\n      <span>tls_config</span><span>:</span>\n        <span>insecure_skip_verify</span><span>:</span> <span>false</span>   <span># 是否跳过检验证书</span>\n\n      <span># 关于每次探测时收到的 HTTP 响应</span>\n      <span>valid_status_codes</span><span>:</span> &lt;int<span>></span><span>,</span><span>...</span>   <span># 有效的状态码，默认为 2xx 。如果出现其它值，则探测失败</span>\n      <span>valid_http_versions</span><span>:</span>            <span># 有效的 HTTP 协议版本</span>\n        <span>-</span> HTTP/1.1\n        <span>-</span> HTTP/2.0\n      <span>compression</span><span>:</span> <span>'gzip'</span>             <span># 响应 body 的解压算法，默认为 ''</span>\n      <span>follow_redirects</span><span>:</span> <span>true</span>          <span># 是否跟随重定向</span>\n      <span>fail_if_body_matches_regexp</span><span>:</span>    <span># 如果响应 body 与正则表达式匹配，则探测失败</span>\n        <span>-</span> &lt;regex<span>></span>\n      <span>fail_if_body_not_matches_regexp</span><span>:</span>\n        <span>-</span> &lt;regex<span>></span>\n      <span>fail_if_header_matches</span><span>:</span>         <span># 如果响应 header 与正则表达式匹配，则探测失败</span>\n        <span>-</span> <span>header</span><span>:</span> &lt;string<span>></span>\n          <span>regexp</span><span>:</span> &lt;regex<span>></span>\n          <span>allow_missing</span><span>:</span> <span>false</span>\n      <span>fail_if_header_not_matches</span><span>:</span>\n      <span># - header: Set-Cookie</span>\n      <span>#   regexp: 'Test.*'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br></div></div></li>\n<li>\n<p>指标示例：</p>\n<div><pre><code>probe_success                   <span># 是否探测成功（取值 1、0 分别表示成功、失败）</span>\nprobe_duration_seconds          <span># 探测的耗时</span>\n\n<span># 关于 DNS</span>\nprobe_dns_lookup_time_seconds   <span># DNS 解析的耗时</span>\nprobe_ip_protocol               <span># IP 协议，取值为 4、6</span>\nprobe_ip_addr_hash              <span># IP 地址的哈希值，用于判断 IP 是否变化</span>\n\n<span># 关于 HTTP</span>\nprobe_http_status_code          <span># HTTP 响应的状态码。如果发生重定向，则取决于最后一次响应</span>\nprobe_http_content_length       <span># HTTP 响应的 body 长度，单位 bytes</span>\nprobe_http_version              <span># HTTP 响应的协议版本，比如 1.1</span>\nprobe_http_ssl                  <span># HTTP 响应是否采用 SSL ，取值为 1、0</span>\nprobe_ssl_earliest_cert_expiry  <span># SSL 证书的过期时间，为 Unix 时间戳</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div></li>\n</ul>\n<h3 id=\"jmx-exporter\"> jmx_exporter</h3>\n<p>：用于从 JMX 端口获取监控指标。</p>\n<ul>\n<li><a href=\"https://github.com/prometheus/jmx_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n</ul>\n<h2 id=\"专用类型\"> 专用类型</h2>\n<h3 id=\"consul-exporter\"> consul_exporter</h3>\n<p>：用于监控 Consul 服务器。</p>\n<ul>\n<li><a href=\"https://github.com/prometheus/consul_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>consul_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> consul_exporter\n    <span>image</span><span>:</span> prom/consul<span>-</span>exporter<span>:</span>v0.7.1\n    <span>command</span><span>:</span>\n      <span>-</span> <span>-</span><span>-</span>web.listen<span>-</span>address=<span>:</span><span>9107</span>\n      <span>-</span> <span>-</span><span>-</span>web.telemetry<span>-</span>path=/metrics\n      <span>-</span> <span>-</span><span>-</span>consul.server=http<span>:</span>//localhost<span>:</span><span>8500</span>\n      <span># - --kv.prefix=\"\"  # 采集前缀匹配的 key 的 value</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 9107<span>:</span><span>9107</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div></li>\n<li>指标示例：<div><pre><code><span># 关于节点</span>\nconsul_up                                       <span># 当前 agent 节点是否在线</span>\nconsul_raft_peers                               <span># 集群的 server 节点数</span>\nconsul_serf_lan_members                         <span># 集群的节点数</span>\nconsul_serf_lan_member_status<span>{</span>member<span>=</span><span>\"node1\"</span><span>}</span>   <span># 各个节点的 gossip 状态，取值 1、2、3、4 分别表示 Alive、Leaving、Left、Failed</span>\n\n<span># 关于服务</span>\nconsul_catalog_services                                                                           <span># 已注册的 service 总数，不考虑 service_id 实例数量</span>\nconsul_catalog_service_node_healthy<span>{</span>node<span>=</span><span>\"node1\"</span>, <span>service_id</span><span>=</span><span>\"xx\"</span>, <span>service_name</span><span>=</span><span>\"xx\"</span><span>}</span>             <span># 某个 node 上的某个 service_id 是否健康，取值为 1 或 0</span>\nconsul_health_node_status<span>{</span>check<span>=</span><span>\"serfHealth\"</span>, <span>node</span><span>=</span><span>\"node1\"</span>, <span>status</span><span>=</span><span>\"passing\"</span><span>}</span>                     <span># 某个 node 是否为 status 状态，取值为 1 或 0</span>\nconsul_health_service_status<span>{</span>node<span>=</span><span>\"node1\"</span>, <span>service_id</span><span>=</span><span>\"xx\"</span>, <span>service_name</span><span>=</span><span>\"xx\"</span>, <span>status</span><span>=</span><span>\"passing\"</span><span>}</span>  <span># 某个 node 上的 service_id 是否为 status 状态，取值为 1 或 0</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n</ul>\n<h3 id=\"elasticsearch-exporter\"> elasticsearch_exporter</h3>\n<p>：用于监控 ES 服务器。</p>\n<ul>\n<li><a href=\"https://github.com/prometheus-community/elasticsearch_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>elasticsearch_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> elasticsearch_exporter\n    <span>image</span><span>:</span> quay.io/prometheuscommunity/elasticsearch<span>-</span>exporter<span>:</span>v1.2.1\n    <span>command</span><span>:</span>\n      <span># - --web.listen-address=:9114</span>\n      <span># - --web.telemetry-path=/metrics</span>\n      <span>-</span> <span>-</span><span>-</span>es.uri=http<span>:</span>//&lt;user<span>></span><span>:</span>&lt;password<span>></span>@elasticsearch<span>:</span><span>9200</span>\n      <span>-</span> <span>-</span><span>-</span>es.all                    <span># 是否监控集群的所有 node 。默认为 false ，只监控当前 node</span>\n      <span># - --es.cluster_settings     # 是否监控集群的配置</span>\n      <span># - --es.indices              # 是否监控所有 index</span>\n      <span># - --es.indices_settings</span>\n      <span># - --es.indices_mappings</span>\n      <span>-</span> <span>-</span><span>-</span>es.shards\n      <span># - --es.snapshots</span>\n      <span># - --es.timeout  5s          # 从 ES 采集信息的超时时间</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 9114<span>:</span><span>9114</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></div></div></li>\n<li>指标示例：<div><pre><code>elasticsearch_clusterinfo_version_info<span>{</span>build_date<span>=</span><span>\"2018-10-30T23:17:19.084789Z\"</span>,build_hash<span>=</span><span>\"fe40335\"</span>,cluster<span>=</span><span>\"cluster-1\"</span>,lucene_version<span>=</span><span>\"8.7.0\"</span>,version<span>=</span><span>\"7.10.2\"</span><span>}</span>  <span># 版本信息</span>\n\n<span># 关于集群</span>\nelasticsearch_clusterinfo_up                          <span># 服务器是否在线，可以采集监控指标</span>\nelasticsearch_cluster_health_status<span>{</span>color<span>=</span><span>\"green\"</span><span>}</span>    <span># 集群的状态是否为 green</span>\nelasticsearch_cluster_health_number_of_nodes          <span># node 数量</span>\nelasticsearch_cluster_health_number_of_data_nodes     <span># data node 数量</span>\nelasticsearch_cluster_health_number_of_pending_tasks  <span># 等待执行的 task 数量</span>\nelasticsearch_cluster_health_active_shards            <span># shard 总数</span>\nelasticsearch_cluster_health_active_primary_shards    <span># primary shard 数量</span>\nelasticsearch_cluster_health_unassigned_shards        <span># unassigned shard 数量</span>\nelasticsearch_cluster_health_initializing_shards\nelasticsearch_cluster_health_relocating_shards\n\n<span># 关于 index</span>\nelasticsearch_indices_docs_total<span>{</span>index<span>=</span><span>\".kibana\"</span><span>}</span>     <span># index 的可见文档数，包括主分片、副分片的文档，不包括 delete 文档</span>\nelasticsearch_indices_deleted_docs_total              <span># index 的 deleted 文档数</span>\nelasticsearch_indices_store_size_bytes_total          <span># index 占用的磁盘空间，累计所有 node</span>\nelasticsearch_index_stats_flush_total                         <span># index flush 的次数</span>\nelasticsearch_index_stats_flush_time_seconds_total            <span># index flush 的耗时</span>\nelasticsearch_index_stats_get_total                           <span># index GET 的次数</span>\nelasticsearch_index_stats_get_time_seconds_total              <span># index GET 的耗时</span>\nelasticsearch_index_stats_indexing_delete_total               <span># index delete 的次数</span>\nelasticsearch_index_stats_indexing_delete_time_seconds_total\nelasticsearch_index_stats_indexing_index_total                <span># index 新增文档的次数</span>\nelasticsearch_index_stats_indexing_index_time_seconds_total\nelasticsearch_index_stats_merge_total                         <span># index merge 的次数</span>\nelasticsearch_index_stats_merge_time_seconds_total\nelasticsearch_index_stats_refresh_total                       <span># index refresh 的次数</span>\nelasticsearch_index_stats_refresh_time_seconds_total\nelasticsearch_index_stats_search_fetch_time_seconds_total     <span># search fetch 的次数</span>\nelasticsearch_index_stats_search_fetch_total\nelasticsearch_index_stats_search_query_time_seconds_total     <span># search query 的次数</span>\nelasticsearch_index_stats_search_query_total\n\n<span># 关于 shard</span>\nelasticsearch_indices_shards_docs<span>{</span>index<span>=</span><span>\".kibana\"</span>, <span>node</span><span>=</span><span>\"qA5eXtIwQU6kbVc-ly5IKg\"</span>, <span>primary</span><span>=</span><span>\"true\"</span>, <span>shard</span><span>=</span><span>\"0\"</span><span>}</span>   <span># 某个 index 在某个 nodename 上，某个编号的 shard 的文档数</span>\n\n<span># 关于 segment</span>\nelasticsearch_indices_segment_count_total             <span># index 的 segment 数量</span>\n\n<span># 关于 Node</span>\nelasticsearch_os_cpu_percent\nelasticsearch_os_load1\nelasticsearch_filesystem_data_size_bytes                            <span># 磁盘总量</span>\nelasticsearch_filesystem_data_available_bytes<span>{</span>name<span>=</span><span>\"node-1\"</span>, <span>mount</span><span>=</span><span>\"/usr/share/elasticsearch/data (/dev/vdb)\"</span><span>}</span>    <span># 磁盘可用大小</span>\nelasticsearch_filesystem_io_stats_device_read_size_kilobytes_sum    <span># 磁盘累计读，单位为 KB</span>\nelasticsearch_filesystem_io_stats_device_write_size_kilobytes_sum   <span># 磁盘累计写</span>\nelasticsearch_transport_rx_size_bytes_total                         <span># 网络累计读</span>\nelasticsearch_transport_tx_size_bytes_total\nelasticsearch_process_max_files_descriptors\nelasticsearch_process_open_files_count\n\n<span># 关于 JVM</span>\nelasticsearch_jvm_memory_max_bytes                              <span># JVM 内存总量</span>\nelasticsearch_jvm_memory_used_bytes                             <span># JVM 已用内存</span>\nsum<span>(</span>elasticsearch_jvm_gc_collection_seconds_count<span>)</span> without<span>(</span>gc<span>)</span>  <span># GC 累计次数</span>\nelasticsearch_jvm_gc_collection_seconds_sum                     <span># GC 累计耗时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br></div></div></li>\n</ul>\n<h3 id=\"kafka-exporter\"> kafka_exporter</h3>\n<p>：用于监控 Kafka 。</p>\n<ul>\n<li><a href=\"https://github.com/danielqsj/kafka_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>kafka_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> kafka_exporter\n    <span>image</span><span>:</span> danielqsj/kafka<span>-</span>exporter<span>:</span>v1.4.2\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>command</span><span>:</span>\n      <span># - --web.listen-address=:9308</span>\n      <span># - --web.telemetry-path=/metrics</span>\n      <span>-</span> <span>-</span><span>-</span>kafka.server=10.0.0.1<span>:</span><span>9092</span>    <span># broker 的地址，可以多次使用该选项</span>\n      <span>-</span> <span>-</span><span>-</span>kafka.version=2.2.0\n      <span># - --sasl.enabled=false</span>\n      <span># - --sasl.username=xx</span>\n      <span># - --sasl.password=******</span>\n      <span># - --topic.filter=.*             # 通过正则表达式筛选要监控的 topic ，例如 filter=^[^_].*</span>\n      <span># - --group.filter=.*</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9308<span>:</span><span>9308</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></li>\n<li>指标示例：<div><pre><code>kafka_exporter_build_info<span>{</span>goversion<span>=</span><span>\"go1.16\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1:9308\"</span>, <span>job</span><span>=</span><span>\"kafka_exporter\"</span><span>}</span> <span># 版本信息</span>\nkafka_brokers                                                              <span># Kafka 集群的 broker 数量</span>\n\nkafka_topic_partitions<span>{</span>topic<span>=</span><span>\"x\"</span><span>}</span>                                          <span># 某个 topic 的 partition 数量</span>\nkafka_topic_partition_replicas<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>                   <span># partition 的副本数</span>\nkafka_topic_partition_in_sync_replica<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>            <span># partition 的已经同步的副本数</span>\nkafka_topic_partition_under_replicated_partition<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span> <span># partition 是否存在未同步的副本</span>\n\nkafka_topic_partition_leader<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>                     <span># partition 的 leader 的 ID</span>\nkafka_topic_partition_leader_is_preferred<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>        <span># partition 的 leader 是否为 preferred replica</span>\nkafka_topic_partition_current_offset<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>             <span># partition 的当前偏移量</span>\nkafka_topic_partition_oldest_offset<span>{</span>topic<span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>              <span># partition 的最早偏移量</span>\n\nkafka_consumergroup_members<span>{</span>consumergroup<span>=</span><span>\"x\"</span><span>}</span>                                    <span># 某个 consumergroup 的成员数</span>\nkafka_consumergroup_current_offset<span>{</span>consumergroup<span>=</span><span>\"x\"</span>, <span>topic</span><span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>   <span># 某个 consumergroup 在某个 partition 的偏移量</span>\nkafka_consumergroup_lag<span>{</span>consumergroup<span>=</span><span>\"x\"</span>, <span>topic</span><span>=</span><span>\"x\"</span>, <span>partition</span><span>=</span><span>\"x\"</span><span>}</span>              <span># 某个 consumergroup 在某个 partition 的滞后量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div><ul>\n<li>不支持监控 Topic 占用的磁盘空间。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"mongodb-exporter\"> mongodb_exporter</h3>\n<p>：用于监控 MongoDB 服务器。</p>\n<ul>\n<li><a href=\"https://github.com/percona/mongodb_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>mongodb_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> mongodb_exporter\n    <span>image</span><span>:</span> bitnami/mongodb<span>-</span>exporter<span>:</span>0.20.7\n    <span>command</span><span>:</span>\n      <span># - --web.listen-address=:9216</span>\n      <span># - --web.telemetry-path=/metrics</span>\n      <span>-</span> <span>-</span><span>-</span>mongodb.uri=mongodb<span>:</span>//127.0.0.1<span>:</span>27017/admin\n      <span>-</span> <span>-</span><span>-</span>mongodb.collstats<span>-</span>colls=db1.col1<span>,</span>db1.col2     <span># 监控指定集合，可以只指定库名</span>\n      <span># - --mongodb.indexstats-colls=db1.col1,db1.col2  # 监控指定索引</span>\n      <span># - --discovering-mode                            # 自动发现 collstats-colls、indexstats-colls 的数据库的其它集合</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 9216<span>:</span><span>9216</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div></li>\n<li>指标示例：<div><pre><code><span># 关于 server status</span>\nmongodb_up                                              <span># 服务器是否在线</span>\nmongodb_ss_ok<span>{</span>cl_id<span>=</span><span>\"\"</span>, <span>cl_role</span><span>=</span><span>\"mongod\"</span>, <span>rs_state</span><span>=</span><span>\"0\"</span><span>}</span> <span># 服务器是否正常运行，取值为 1、0 。标签中记录了 Cluster、ReplicaSet 的信息</span>\nmongodb_ss_uptime                                       <span># 服务器的运行时长，单位为秒</span>\nmongodb_ss_connections<span>{</span>conn_type<span>=</span><span>\"current\"</span><span>}</span>             <span># 客户端连接数</span>\n\n<span># 关于 collection</span>\n<span>{</span>__name__<span>=~</span><span>'mongodb_.*_storageStats_count'</span>         , <span>database</span><span>=</span><span>\"xx\"</span>, <span>collection</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 文档数</span>\n<span>{</span>__name__<span>=~</span><span>'mongodb_.*_storageStats_size'</span>          , <span>database</span><span>=</span><span>\"xx\"</span>, <span>collection</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 体积，单位 bytes</span>\n<span>{</span>__name__<span>=~</span><span>'mongodb_.*_storageStats_storageSize'</span>   , <span>database</span><span>=</span><span>\"xx\"</span>, <span>collection</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 占用的磁盘空间</span>\n<span>{</span>__name__<span>=~</span><span>'mongodb_.*_storageStats_totalIndexSize'</span>, <span>database</span><span>=</span><span>\"xx\"</span>, <span>collection</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 索引的体积</span>\n\n<span># 关于操作</span>\ndelta<span>(</span>mongodb_ss_opcounters<span>[</span>1m<span>]</span><span>)</span>                        <span># 执行各种操作的数量</span>\ndelta<span>(</span>mongodb_ss_opLatencies_latency<span>[</span>1m<span>]</span><span>)</span>               <span># 执行各种操作的延迟，单位为微秒</span>\ndelta<span>(</span>mongodb_ss_metrics_document<span>[</span>1m<span>]</span><span>)</span>                  <span># 各种文档的变化数量</span>\n\n<span># 关于锁</span>\ndelta<span>(</span>mongodb_ss_locks_acquireCount<span>{</span>lock_mode<span>=</span><span>\"w\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span> <span># 新加锁的数量。R 表示共享锁，W 表示独占锁，r 表示意向共享锁，w 表示意向独占锁</span>\nmongodb_ss_globalLock_currentQueue<span>{</span>count_type<span>=</span><span>\"total\"</span><span>}</span>  <span># 被锁阻塞的操作数</span>\n\n<span># 关于主机的状态</span>\nmongodb_sys_cpu_num_cpus    <span># 主机的 CPU 核数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></div></div></li>\n</ul>\n<h3 id=\"mysqld-exporter\"> mysqld_exporter</h3>\n<p>：用于监控 MySQL 服务器。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/prometheus/mysqld_exporter\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>mysqld_exporter</span><span>:</span>\n    <span>container_name</span><span>:</span> mysqld_exporter\n    <span>image</span><span>:</span> prom/mysqld<span>-</span>exporter<span>:</span>v0.13.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span># command:</span>\n    <span>#   - --web.listen-address=:9104</span>\n    <span>#   - --web.telemetry-path=/metrics</span>\n    <span>environment</span><span>:</span>\n      <span>DATA_SOURCE_NAME</span><span>:</span> <span>\"user:password@(10.0.0.1:3306)/\"</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9104<span>:</span><span>9104</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div><ul>\n<li>需要在 MySQL 中创建一个 exporter 用户：<div><pre><code><span>CREATE</span> <span>USER</span> exporter<span>@'%'</span> IDENTIFIED <span>BY</span> <span>'******'</span><span>;</span>\n<span>GRANT</span> PROCESS<span>,</span> <span>REPLICATION</span> CLIENT <span>ON</span> <span>*</span><span>.</span><span>*</span> <span>TO</span> exporter<span>@'%'</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>指标示例：</p>\n<div><pre><code><span># 关于服务器</span>\nmysql_up                                              <span># 服务器是否在线</span>\nmysql_global_status_uptime                            <span># 运行时长，单位 s</span>\ndelta<span>(</span>mysql_global_status_bytes_received<span>[</span>1m<span>]</span><span>)</span>         <span># 网络接收的 bytes</span>\ndelta<span>(</span>mysql_global_status_bytes_sent<span>[</span>1m<span>]</span><span>)</span>             <span># 网络发送的 bytes</span>\n\n<span># 关于客户端</span>\nmysql_global_status_threads_connected                 <span># 当前的客户端连接数</span>\nmysql_global_status_threads_running                   <span># 正在执行命令的客户端连接数，即非 sleep 状态</span>\ndelta<span>(</span>mysql_global_status_aborted_connects<span>[</span>1m<span>]</span><span>)</span>       <span># 客户端建立连接失败的连接数，比如登录失败</span>\ndelta<span>(</span>mysql_global_status_aborted_clients<span>[</span>1m<span>]</span><span>)</span>        <span># 客户端连接之后，未正常关闭的连接数</span>\n\n<span># 关于命令</span>\ndelta<span>(</span>mysql_global_status_commands_total<span>{</span>command<span>=</span><span>\"xx\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span> <span>></span> <span>0</span>     <span># 各种命令的数量</span>\ndelta<span>(</span>mysql_global_status_handlers_total<span>{</span>handler<span>=</span><span>\"xx\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span> <span>></span> <span>0</span>     <span># 各种操作的数量</span>\ndelta<span>(</span>mysql_global_status_handlers_total<span>{</span>handler<span>=</span><span>\"commit\"</span><span>}</span><span>[</span>1m<span>]</span><span>)</span> <span>></span> <span>0</span> <span># commit 的数量</span>\ndelta<span>(</span>mysql_global_status_table_locks_immediate<span>[</span>1m<span>]</span><span>)</span>  <span># 请求获取锁，且立即获得的请求数</span>\ndelta<span>(</span>mysql_global_status_table_locks_waited<span>[</span>1m<span>]</span><span>)</span>     <span># 请求获取锁，但需要等待的请求数。该值越少越好</span>\n\n<span># 关于查询</span>\ndelta<span>(</span>mysql_global_status_queries<span>[</span>1m<span>]</span><span>)</span>                <span># 每分钟的查询数</span>\ndelta<span>(</span>mysql_global_status_slow_queries<span>[</span>1m<span>]</span><span>)</span>           <span># 慢查询数。如果未启用慢查询日志，则为 0</span>\nmysql_global_status_innodb_page_size                  <span># innodb 数据页的大小，单位 bytes</span>\nmysql_global_variables_innodb_buffer_pool_size        <span># innodb_buffer_pool 的限制体积</span>\nmysql_global_status_buffer_pool_pages<span>{</span>state<span>=</span><span>\"data\"</span><span>}</span>   <span># 包含数据的数据页数，包括洁页、脏页</span>\nmysql_global_status_buffer_pool_dirty_pages           <span># 脏页数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br></div></div><ul>\n<li>这些监控指标主要从 MySQL 的 <code>SHOW GLOBAL STATUS</code> 和 <code>SHOW GLOBAL VARIABLES</code> 获得。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Prometheus",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Prometheus/",
      "id": "/Hardware/DevOps/MonitoringAlarms/Prometheus/",
      "content_html": "<h1 id=\"prometheus\"> Prometheus</h1>\n<p>：一个 Web 服务器，可以采集大量对象的监控指标。</p>\n<ul>\n<li><a href=\"https://prometheus.io/docs/introduction/overview/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Golang 开发。</li>\n<li>由 SoundCloud 公司的前 Google 员工于 2015 年发布，它起源于 Google 内部用于监控 Borg 系统的 Borgmon 系统。</li>\n<li>特点：\n<ul>\n<li>采集文本格式的监控指标。</li>\n<li>可以给指标数据添加一些键值对格式的标签，从而便于筛选。</li>\n<li>可监控主机、进程、容器等多种对象，可扩展性高，而且自带查询语言，配置比较灵活。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>\n<p>运行流程：</p>\n<ol>\n<li>在每个监控对象的主机上运行一个负责采集监控指标的程序，通过 HTTP API 输出纯文本格式的监控指标，作为 exporter 。</li>\n<li>Prometheus 服务器定期向每个 exporter 发出 HTTP GET 请求，获取监控指标，然后存储到自己的时序数据库 TSDB 中。。\n<ul>\n<li>Prometheus 属于离散采样，可能有遗漏、有延迟、有误差。</li>\n<li>exporter 一般收到 HTTP 请求时才采集一次当前时刻的监控指标，不负责存储数据。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>关于 TSDB ：</p>\n<ul>\n<li>数据默认保存在 <code>${prometheus}/data</code> 目录下，目录结构如下：<div><pre><code>data/\n├── 01E728KFZWGDM7HMY6M2D26QJD/   <span># 一个 block 目录</span>\n│   ├── chunks\n│   │   └── 000001                <span># 压缩后的数据，是二进制文件</span>\n│   ├── index\n│   ├── meta.json\n│   └── tombstones\n├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K/\n├── lock\n├── queries.active\n└── wal/\n    ├──00000003\n    └──checkpoint.000002/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n<li>最新获得的数据尚未写入 tsdb ，会暂时保存在 wal/ 目录下。</li>\n<li>每隔两个小时会创建一个随机编号的 block 目录，将 wal/ 目录下的数据经过压缩之后保存到 <code>xxx_block/chunks</code> 目录下。此时才算写入 tsdb 。</li>\n<li>每过一段时间， block 目录还会被进一步压缩、合并。</li>\n</ul>\n</li>\n<li>\n<p>Prometheus 的图表功能很少，建议将它的数据交给 Grafana 显示。</p>\n</li>\n<li>\n<p>Prometheus 及其插件都采用 UTC 时间，不支持修改时区。用户可以自行将查询结果中的时间字符串改成本地时区。</p>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制版：</p>\n<div><pre><code><span>wget</span> https://github.com/prometheus/prometheus/releases/download/v2.27.1/prometheus-2.27.1.linux-amd64.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div><p>解压后启动：</p>\n<div><pre><code>./prometheus\n            --config.file /etc/prometheus/prometheus.yml  <span># 使用指定的配置文件</span>\n            <span># --web.config.file=web.yml                   # web 配置</span>\n            <span># --web.listen-address 0.0.0.0:9090           # 监听的地址</span>\n            <span># --web.external-url http://10.0.0.1:9090/    # 供外部访问的 URL</span>\n            <span># --web.enable-admin-api                      # 启用管理员的 HTTP API .比如删除 tsdb 的数据</span>\n            <span># --web.enable-lifecycle                      # 启用 reload、quit 等 HTTP API</span>\n\n            <span># --storage.tsdb.retention.time=15d           # TSDB 的最大保存时长</span>\n            <span># --storage.tsdb.retention.size=500GB         # TSDB 的最大保存体积</span>\n            <span># --query.timeout=2m                          # 每次查询的超时时间</span>\n            <span># --query.max-samples=50000000                # 每次查询时最多将多少个指标载入内存，如果超过该数量，则查询失败</span>\n            --log.format<span>=</span>json\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>配置文件 prometheus.yml 主要用于控制 Prometheus 的监控任务，而 Prometheus 自身的运行状态只能通过命令行参数控制。</li>\n<li>配置文件 web.yml 用于启用身份认证，如下：<div><pre><code><span>basic_auth_users</span><span>:</span>\n  <span>&lt;username></span><span>:</span> &lt;password<span>></span>   <span># 这里需要填密码的哈希值，可用命令 htpasswd -nbB &lt;username> &lt;password> 生成</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>prometheus</span><span>:</span>\n    <span>container_name</span><span>:</span> prometheus\n    <span>image</span><span>:</span> prom/prometheus<span>:</span>v2.27.1\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>command</span><span>:</span>\n      <span>-</span> <span>-</span><span>-</span>web.external<span>-</span>url=http<span>:</span>//10.0.0.1<span>:</span><span>9090</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9090<span>:</span><span>9090</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> .<span>:</span>/prometheus\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><p>需要先配置挂载目录的权限：</p>\n<div><pre><code><span>mkdir</span> data\n<span>chown</span> -R <span>65534</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h3 id=\"集群\"> 集群</h3>\n<ul>\n<li>Prometheus 支持抓取其它 Prometheus 的数据，因此可以部署成集群。</li>\n<li>在 prometheus.yml 中按如下格式定义一个 job ，即可抓取其它 Prometheus 的数据：<div><pre><code><span>scrape_configs</span><span>:</span>\n<span>-</span> <span>job_name</span><span>:</span> federate\n  <span>honor_labels</span><span>:</span> <span>true</span>            <span># 设置 true ，以保存原指标中的 job 、instance 标签</span>\n  <span>metrics_path</span><span>:</span> /federate\n  <span>params</span><span>:</span>\n    match<span>[</span><span>]</span><span>:</span>                    <span># 指定筛选表达式。至少指定一个，指定多个时会分别抓取</span>\n      <span>-</span> <span>\"{job!=''}\"</span>\n      <span>-</span> go_goroutines\n  <span>static_configs</span><span>:</span>\n    <span>-</span> <span>targets</span><span>:</span>                  <span># 目标 Prometheus 的地址</span>\n      <span>-</span> 10.0.0.2<span>:</span><span>9090</span>\n      <span>-</span> 10.0.0.3<span>:</span><span>9090</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>只能抓取目标 Prometheus 最新时刻的指标，就像抓取一般的 exporter 。</li>\n<li>如果目标 Prometheus 掉线一段时间，则重新连接之后并不会同步掉线期间的指标。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<h3 id=\"示例\"> 示例</h3>\n<p>以下是用 Prometheus 监控自身的步骤：</p>\n<ol>\n<li>\n<p>在配置文件 prometheus.yml 中加入监控任务：</p>\n<div><pre><code><span>global</span><span>:</span>\n  <span>scrape_interval</span><span>:</span> 30s          <span># 每隔多久采集一次指标，默认为 1m（这是全局值，可以被局部值覆盖）</span>\n  <span>scrape_timeout</span><span>:</span> 10s           <span># 每次采集的超时时间。默认为 10s ，不允许超过 scrape_interval</span>\n  <span>evaluation_interval</span><span>:</span> 30s      <span># 每隔多久执行一次 rules ，默认为 1m</span>\n  <span># external_labels:            # 与 Alertmanager 等外部组件通信时，会加上这些标签</span>\n  <span>#   monitor: codelab-monitor</span>\n\n<span># rule_files:                   # 导入 rules 文件</span>\n<span># - rules_1.yml</span>\n\n<span>scrape_configs</span><span>:</span>\n<span>-</span> <span>job_name</span><span>:</span> prometheus\n  <span>static_configs</span><span>:</span>\n  <span>-</span> <span>targets</span><span>:</span>\n    <span>-</span> 10.0.0.1<span>:</span><span>9090</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n<li>\n<p>重启 Prometheus 以重新加载配置文件，然后访问其 Web 页面。</p>\n<ul>\n<li>在 Status -&gt; Targets 页面，可以看到所有监控对象及其状态。</li>\n<li>在 Graph 页面，执行一个查询表达式即可获得监控数据，比如 <code>go_goroutines</code> 。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"监控对象\"> 监控对象</h3>\n<ul>\n<li>例：在 prometheus.yml 中配置需要监控的对象（称为 targets ）<div><pre><code><span>scrape_configs</span><span>:</span>\n<span>-</span> <span>job_name</span><span>:</span> prometheus              <span># 一项监控任务的名字（可以包含多组监控对象）</span>\n  <span># honor_labels: false</span>\n  <span># metrics_path: /metrics</span>\n  <span># follow_redirects: true          # 是否跟随状态码为 3xx 的重定向</span>\n  <span># scheme: http                    # 通信协议</span>\n  <span># scrape_interval: 30s</span>\n  <span># scrape_timeout: 10s</span>\n  <span># basic_auth:</span>\n  <span>#   username: &lt;string></span>\n  <span>#   password: &lt;string></span>\n  <span># proxy_url: &lt;string></span>\n  <span># tls_config:</span>\n  <span>#   insecure_skip_verify: false   # 是否不认证 HTTPS 证书</span>\n  <span>static_configs</span><span>:</span>\n  <span>-</span> <span>targets</span><span>:</span>                        <span># 一组监控对象的 IP:Port</span>\n    <span>-</span> 10.0.0.1<span>:</span><span>9090</span>\n    <span>-</span> 10.0.0.1<span>:</span><span>9091</span>\n    <span># labels:                       # 为这些监控对象的数据加上额外的标签</span>\n    <span>#   nodename: CentOS-1</span>\n  <span>-</span> <span>targets</span><span>:</span> <span>[</span><span>'10.0.0.2:9090'</span><span>]</span>      <span># 下一组监控对象</span>\n\n<span>-</span> <span>job_name</span><span>:</span> node_exporter\n  <span>file_sd_configs</span><span>:</span>                  <span># 从文件读取配置，这样修改配置时不必重启 Prometheus</span>\n  <span>-</span> <span>files</span><span>:</span>\n    <span>-</span> targets/node_exporter<span>*.json</span>\n    <span># refresh_interval: 5m          # 每隔多久重新读取一次</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br></div></div></li>\n<li>Prometheus 从每个监控对象处抓取指标数据时，默认会自动加上 <code>job: &quot;$job_name&quot;</code>、<code>instance: &quot;$target&quot;</code> 两个标签。\n还会自动记录以下指标：<div><pre><code>up<span>{</span>job<span>=</span><span>\"<span>$job_name</span>\"</span>, <span>instance</span><span>=</span><span>\"<span>$target</span>\"</span><span>}</span>                       <span># 该监控对象是否在线（取值 1、0 分别代表在线、离线）</span>\nscrape_samples_scraped<span>{</span>job<span>=</span><span>\"<span>$job_name</span>\"</span>, <span>instance</span><span>=</span><span>\"<span>$target</span>\"</span><span>}</span>   <span># 本次抓取的指标数</span>\nscrape_duration_seconds<span>{</span>job<span>=</span><span>\"<span>$job_name</span>\"</span>, <span>instance</span><span>=</span><span>\"<span>$target</span>\"</span><span>}</span>  <span># 本次抓取的耗时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>给抓取的指标添加标签时，如果原指标中已存在同名 label ，则根据 honor_labels 的值进行处理：\n<ul>\n<li><code>honor_labels: false</code> ：默认值，将原指标中的同名 label 改名为 <code>exported_&lt;label_name&gt;</code> ，再添加新标签。</li>\n<li><code>honor_labels: true</code> ：保留原指标不变，不添加新标签。</li>\n</ul>\n</li>\n<li>考虑到监控对象的 IP 地址不方便记忆，而且可能变化，应该添加 nodename 等额外的标签便于筛选。</li>\n<li>通过 file_sd_configs 方式读取的文件可以是 YAML 或 JSON 格式，如下：<div><pre><code><span>-</span> <span>targets</span><span>:</span>\n  <span>-</span> 10.0.0.1<span>:</span><span>9090</span>\n  <span>labels</span><span>:</span>\n    <span>nodename</span><span>:</span> CentOS<span>-</span><span>1</span>\n<span>-</span> <span>targets</span><span>:</span>\n  <span>-</span> 10.0.0.2<span>:</span><span>9090</span>\n  <span>labels</span><span>:</span>\n    <span>nodename</span><span>:</span> CentOS<span>-</span><span>2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><div><pre><code><span>[</span><span>{</span>\n    <span>\"targets\"</span><span>:</span> <span>[</span>\n        <span>\"10.0.0.1:9100\"</span>\n    <span>]</span><span>,</span>\n    <span>\"labels\"</span><span>:</span> <span>{</span>\n        <span>\"nodename\"</span><span>:</span> <span>\"CentOS-1\"</span>\n    <span>}</span>\n<span>}</span><span>,</span> <span>{</span>\n    <span>\"targets\"</span><span>:</span> <span>[</span>\n        <span>\"10.0.0.2:9100\"</span>\n    <span>]</span><span>,</span>\n    <span>\"labels\"</span><span>:</span> <span>{</span>\n        <span>\"nodename\"</span><span>:</span> <span>\"CentOS-2\"</span>\n    <span>}</span>\n<span>}</span><span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n<h3 id=\"rules\"> Rules</h3>\n<ul>\n<li>\n<p>规则分为两类：</p>\n<ul>\n<li>Recording Rules ：用于将某个查询表达式的结果保存为新指标。这样可以避免在用户查询时才计算，减少开销。</li>\n<li>Alerting Rules ：用于在满足某个条件时进行告警。（它只是产生警报，需要由 Alertmanager 加工之后转发给用户）</li>\n</ul>\n</li>\n<li>\n<p>可以在 prometheus.yml 中导入自定义的 rules.yml 文件，格式如下：</p>\n<div><pre><code><span>groups</span><span>:</span>\n<span>-</span> <span>name</span><span>:</span> recording_rules               <span># 规则组的名称</span>\n  <span># interval: 15s                     # 每隔多久执行一次该 rules</span>\n  <span>rules</span><span>:</span>\n  <span>-</span> <span>record</span><span>:</span> go_goroutines<span>:</span>sum_by_job  <span># 定义一个新指标</span>\n    <span>expr</span><span>:</span> sum(go_goroutines) by (job) <span># 查询表达式</span>\n\n<span>-</span> <span>name</span><span>:</span> alerting_rules                <span># 规则组的名称</span>\n  <span>rules</span><span>:</span>\n  <span>-</span> <span>alert</span><span>:</span> 测试告警<span>-</span><span>1</span>                  <span># 定义一个告警规则</span>\n    <span>expr</span><span>:</span> go_goroutines <span>></span> 100         <span># 设置告警条件（只要表达式的执行结果是矢量，就会报警）</span>\n    <span>for</span><span>:</span> 5m                           <span># 连续满足条件 5 分钟之后才告警</span>\n    <span># labels:</span>\n    <span>#   severity: error</span>\n    <span>annotations</span><span>:</span>\n      <span>summary</span><span>:</span> <span>\"节点地址：{{$labels.instance}}, 协程数：{{$value}}\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div><ul>\n<li>可以重复定义同样内容的 rules ，但最终输出时，多个重复的数据会合并为一个。</li>\n<li>Prometheus 会在每次抓取指标时自动检查一次 Alerting Rules ，因此不需要设置 interval 。</li>\n<li>默认会将 expr 计算结果中的所有 label 添加到告警信息中。\n<ul>\n<li>可以通过 labels 子句添加一些标签到告警信息中，但是如果与已有的 label 重名则不会生效。</li>\n<li>可以通过 annotations 子句添加一些标签作为注释。</li>\n<li>给这些标签赋值时允许引用变量（基于 Golang 的模板语法）。</li>\n</ul>\n</li>\n<li>上例中，最终生成的警报包含以下信息：<div><pre><code><span>{</span>\n    <span>\"status\"</span><span>:</span> <span>\"firing\"</span><span>,</span>\n    <span>\"labels\"</span><span>:</span> <span>{</span>\n        <span>\"alertname\"</span><span>:</span> <span>\"进程数归零\"</span><span>,</span>\n        <span>\"instance\"</span><span>:</span><span>\"10.0.0.1:9090\"</span><span>,</span>\n        <span>\"job\"</span><span>:</span><span>\"prometheus\"</span><span>,</span>\n    <span>}</span><span>,</span>\n    <span>\"annotations\"</span><span>:</span> <span>{</span>\n        <span>\"summary\"</span><span>:</span><span>\"节点地址：10.0.0.1:9090, 协程数：90\"</span><span>,</span>\n    <span>}</span><span>,</span>\n    <span>\"startsAt\"</span><span>:</span> <span>\"2020-07-09T01:23:22.627587301Z\"</span><span>,</span>\n    <span>\"endsAt\"</span><span>:</span> <span>\"0001-01-01T00:00:00Z\"</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>当异常开始时，Prometheus 会产生 <code>&quot;status&quot;: &quot;firing&quot;</code> 的警报。当异常结束时，还会产生 <code>&quot;status&quot;: &quot;resolved&quot;</code> 的警报。</p>\n<ul>\n<li>startsAt 参数表示警报的开始时间，但根据 alerting_rules ，可能等监控指标持续异常一段时间之后才产生警报。</li>\n<li>resolved 类型的警报中，会增加一个 endsAt 参数。</li>\n</ul>\n</li>\n<li>\n<p>在 Web 页面上可以看到 Alerting Rules 的状态：</p>\n<ul>\n<li>不满足告警条件时，属于 Inactive 状态。</li>\n<li>满足告警条件时，属于 Active 状态。\n<ul>\n<li>如果不超过阙值时间，则属于 Pending 状态。</li>\n<li>如果超过阙值时间，则属于 Firing 状态。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>可参考的告警规则：<a href=\"https://github.com/samber/awesome-prometheus-alerts\" target=\"_blank\" rel=\"noopener noreferrer\">awesome-prometheus-alerts</a></p>\n</li>\n</ul>\n<h2 id=\"指标\"> 指标</h2>\n<ul>\n<li>\n<p>每条指标数据是如下格式的字符串：</p>\n<div><pre><code><span>&lt;</span>metric_name<span>></span><span>{</span><span>&lt;</span>label_name<span>>=</span><span>&lt;</span>label_value<span>></span>, <span>..</span>.<span>}</span>     metric_value\n</code></pre>\n<div><span>1</span><br></div></div><p>例如：</p>\n<div><pre><code>go_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9090\"</span>, <span>job</span><span>=</span><span>\"prometheus\"</span><span>}</span>    <span>80</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>metric_name 必须匹配正则表达式 <code>[a-zA-Z_:][a-zA-Z0-9_:]*</code> ，一般通过 Recording Rules 定义的指标名称才包含冒号 : 。</li>\n<li>标签（label）的作用是便于筛选指标。</li>\n<li>label_value 可以包含任意 Unicode 字符。</li>\n</ul>\n</li>\n<li>\n<p>根据用途的不同对指标分类：</p>\n<ul>\n<li>Counter ：计数器，数值单调递增。</li>\n<li>Gauge ：仪表，数值可以任意加减变化。</li>\n<li>Histogram ：直方图。将时间平均分成一段段区间，将每段时间内的多个采样点取平均值再返回（由 Server 计算），相当于从散点图变成直方图。例如：\n<ul>\n<li><code>prometheus_http_request_duration_seconds_count{} 10</code> 表示 HTTP 请求的样本总数有 10 个。</li>\n<li><code>prometheus_http_request_duration_seconds_sum{} 0.1</code> 表示 HTTP 请求的耗时总和为 0.1s 。</li>\n<li><code>prometheus_http_request_duration_seconds_bucket{le=&quot;60&quot;} 10</code> 表示 HTTP 请求中，耗时低于 60s 的有 10 个。</li>\n</ul>\n</li>\n<li>Summary ：汇总。将所有采样点按数值从小到大排列，然后返回其中几个关键位置的采样点的值（由 exporter 计算），相当于正态分布图。例如：\n<ul>\n<li><code>..._count</code></li>\n<li><code>..._sum</code></li>\n<li><code>http_request_duration_microseconds{handler=&quot;prometheus&quot;,quantile=&quot;0.5&quot;} 3246.518</code> 表示 HTTP 请求中，排在 50% 位置处的耗时（即中位数）。</li>\n<li><code>http_request_duration_microseconds{handler=&quot;prometheus&quot;,quantile=&quot;0.9&quot;} 3525.421</code> 表示 HTTP 请求中，排在 90% 位置处的耗时。</li>\n<li><code>http_request_duration_microseconds{handler=&quot;prometheus&quot;,quantile=&quot;0.99&quot;} 3657.138</code> 表示 HTTP 请求中，排在 99% 位置处的耗时。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>根据是否随时间变化对指标分类：</p>\n<ul>\n<li>标量（scalar）：包含一个或一些散列的值。</li>\n<li>矢量（vector）：包含一系列随时间变化的值。\n<ul>\n<li>一个矢量由 n≥1 个时间序列组成，显示成曲线图时有 n 条曲线，在每个时刻处最多有 n 个数据点（又称为元素），不过也可能缺少数据点（为空值）。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"查询\"> 查询</h2>\n<ul>\n<li>\n<p>Prometheus 提供了一种查询语言 PromQL ，使得用户可以通过一个查询表达式，就查询到指标数据，还可以进行加工计算。</p>\n<ul>\n<li>用户在 Graph 页面执行一个查询表达式之后，默认会将查询到的数据显示成表格（Table），用户也可以切换显示成曲线图（Graph）。</li>\n<li>显示曲线图的开销要大得多，可能会导致 Web 页面卡顿。</li>\n<li>大部分标量都不支持显示成曲线图。</li>\n</ul>\n</li>\n<li>\n<p>查询表达式中，选取指标的语法如下：</p>\n<div><pre><code>go_goroutines                                   <span># 查询具有该名称的指标</span>\n<span>{</span>job<span>=</span><span>\"prometheus\"</span><span>}</span>                              <span># 查询具有指定标签值的指标</span>\n<span>{</span>job<span>!</span>~<span>'_.*'</span>, job<span>!</span>~<span>'prometheus'</span><span>}</span>                 <span># 支持查询重复的指标名</span>\n<span>{</span>__name__<span>=</span><span>\"go_goroutines\"</span>, <span>job</span><span>=</span><span>'prometheus'</span><span>}</span>    <span># 通过内置的 __name__ 标签，可以匹配指标名</span>\n\ngo_goroutines<span>{</span>job <span>=</span><span>\"prometheus\"</span><span>}</span>                <span># 查询该名称、该标签值的指标</span>\ngo_goroutines<span>{</span>job<span>!=</span><span>\"prometheus\"</span><span>}</span>                <span># 要求具有 job 标签，且值不等于 prometheus</span>\ngo_goroutines<span>{</span>job <span>=</span><span>\"\"</span><span>}</span>                          <span># 要求 job 标签的值为空字符串（这等价于不具有 job 标签）</span>\ngo_goroutines<span>{</span>job<span>!=</span><span>\"\"</span><span>}</span>                          <span># 要求具有 job 标签且值不为空</span>\ngo_goroutines<span>{</span>job<span>=~</span><span><span>`</span>prometheu<span>\\</span>w<span>`</span></span><span>}</span>               <span># 要求标签的值匹配正则表达式</span>\ngo_goroutines<span>{</span>job<span>!</span>~<span><span>`</span>prometheu<span>\\</span>w<span>`</span></span><span>}</span>               <span># 要求标签的值不匹配正则表达式</span>\n\ngo_goroutines<span>{</span>job<span>=</span><span>\"prometheus\"</span><span>}</span><span>[</span>1m<span>]</span>             <span># 查询 1 分钟以内的数据</span>\ngo_goroutines<span>{</span>job<span>=</span><span>\"prometheus\"</span><span>}</span><span>[</span>30m:1m<span>]</span>         <span># 查询 30 分钟以内、1 分钟以前的数据</span>\n\ngo_goroutines<span>{</span>job<span>=</span><span>\"prometheus\"</span><span>}</span> offset 1m       <span># 相当于在 1 分钟之前查询</span>\nsum<span>(</span>go_goroutines<span>{</span>job<span>=</span><span>\"prometheus\"</span><span>}</span> offset 1m<span>)</span>  <span># 使用函数时，offset 符号要放在函数括号内</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div><ul>\n<li>用 # 声明单行注释。</li>\n<li>将字符串用反引号包住时，不会让反斜杠转义。</li>\n<li>查询表达式不能为空的 <code>{}</code> ，同理也不能使用 <code>{__name__=~&quot;.*&quot;}</code> 选中所有指标。</li>\n</ul>\n</li>\n<li>\n<p>可以使用以下时间单位：</p>\n<ul>\n<li>s ：秒</li>\n<li>m ：分钟</li>\n<li>h ：小时</li>\n<li>d ：天</li>\n<li>w ：周</li>\n<li>y ：年</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"运算符\"> 运算符</h3>\n<ul>\n<li>\n<p>运算符的优先级从高到低如下，同一优先级的采用左结合性：</p>\n<div><pre><code>^\n* /  %\n+ -\n<span>==</span> <span>!=</span> <span>&lt;=</span> <span>&lt;</span> <span>>=</span> <span>></span>\nand unless\nor\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>可以进行如下算术运算：</p>\n<div><pre><code>go_goroutines + <span>1</span>   <span># 加</span>\n<span>1</span> - <span>2</span>               <span># 减</span>\n<span>1</span> * <span>2</span>               <span># 乘</span>\n<span>1</span> / <span>3</span>               <span># 除法（小数点后会保留十多位）</span>\n<span>1</span> % <span>3</span>               <span># 取模</span>\n<span>2</span> ^ <span>3</span>               <span># 取幂</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>只能对指标的值进行运算，不能对标签的值进行运算。</li>\n<li>关于 0 的除法运算：<div><pre><code><span>0</span> / 任意正数    <span># 结果为 0</span>\n<span>0</span> / 任意负数    <span># 结果为 -0</span>\n<span>0</span> / <span>0</span>          <span># 结果为 NaN</span>\n任意正数 / <span>0</span>    <span># 结果为 +Inf</span>\n任意负数 / <span>0</span>    <span># 结果为 -Inf</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>对于特殊值，可以用 expression &gt; 0 等方式过滤掉。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>可以进行如下比较运算：</p>\n<div><pre><code>go_goroutines <span>==</span> <span>2</span>\ngo_goroutines <span>!=</span> <span>2</span>\ngo_goroutines <span>></span>  <span>2</span>  <span># 返回大于 2 的部分曲线</span>\ngo_goroutines <span>&lt;</span>  <span>2</span>\ngo_goroutines <span>>=</span> <span>2</span>\ngo_goroutines <span>&lt;=</span> <span>2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>比较运算默认是过滤掉不符合条件的数据。</li>\n<li>如果在比较运算符之后加上关键字 bool ，比如 <code>1 == bool 2</code> ，就会返回比较运算的结果，用 1、0 分别表示 true、flase 。</li>\n</ul>\n</li>\n<li>\n<p>矢量之间可以进行如下集合运算：</p>\n<div><pre><code>go_goroutines<span>{</span>job<span>=</span><span>'prometheus'</span><span>}</span> and     go_goroutines                     <span># 交集（返回两个矢量中标签列表相同的时间序列，取第一个矢量中的值）</span>\ngo_goroutines<span>{</span>job<span>=</span><span>'prometheus'</span><span>}</span> or      go_goroutines<span>{</span>job<span>=</span><span>'prometheus'</span><span>}</span>   <span># 并集（将两个矢量中的所有时间序列合并，如果存在标签列表重复的时间序列，则取第一个矢量中的值）</span>\ngo_goroutines<span>{</span>job<span>=</span><span>'prometheus'</span><span>}</span> unless  go_goroutines<span>{</span>job<span>!=</span><span>'prometheus'</span><span>}</span>  <span># 补集（返回在第一个矢量中存在、但在第二个矢量中不存在的时间序列）</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>\n<p>矢量之间进行运算时，默认只会对两个矢量中标签列表相同的时间序列（即标签名、标签值完全相同）进行运算。如下：</p>\n<div><pre><code>go_goroutines - go_goroutines\ngo_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> - go_goroutines                            <span># 两个矢量中存在匹配的时间序列，可以进行运算</span>\ngo_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> - go_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.2:9100\"</span><span>}</span>  <span># 两个矢量中不存在匹配的时间序列，因此运算结果为空</span>\ngo_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> - go_gc_duration_seconds_sum<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span>  <span># 指标名不同，但标签列表相同，依然可以运算</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>可以按以下格式，将两个只有部分标签匹配的时间序列进行运算：</p>\n<div><pre><code>go_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> - on<span>(</span>job<span>)</span> go_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.2:9100\"</span><span>}</span>             <span># 只考虑 job 标签，则能找到匹配的时间序列</span>\ngo_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> - ignoring<span>(</span>instance<span>)</span> go_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.2:9100\"</span><span>}</span>  <span># 忽略 instance 标签，则能找到匹配的时间序列</span>\ngo_goroutines<span>{</span>instance<span>=</span><span>\"10.0.0.1:9100\"</span><span>}</span> and on<span>(</span><span>)</span> hour<span>(</span><span>)</span> <span>==</span> <span>8</span>                                          <span># 只获取 8 点时的时间序列</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>以上只是对时间序列进行一对一匹配，可以按下格式进行一对多的匹配：</p>\n<div><pre><code>go_goroutines - on<span>(</span><span>)</span> group_left vector<span>(</span><span>1</span><span>)</span>       <span># 不考虑任何标签，用右边的一个时间序列匹配左边的多个时间序列，分别进行运算，相当于 go_goroutines - 1</span>\nvector<span>(</span><span>1</span><span>)</span>     + on<span>(</span><span>)</span> group_right go_goroutines  <span># group_right 表示用左边的一个时间序列匹配右边的多个时间序列，group_left 则相反</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h3 id=\"函数\"> 函数</h3>\n<ul>\n<li>\n<p>矢量与标量的转换：</p>\n<div><pre><code>vector<span>(</span><span>1</span><span>)</span>                 <span># 输入标量，返回一个矢量</span>\nscalar<span>(</span>vector<span>(</span><span>1</span><span>))</span>         <span># 输入一个单时间序列的矢量，以标量的形式返回当前时刻处的值</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>关于时间：</p>\n<div><pre><code>time<span>(</span><span>)</span>                    <span># 返回当前的 Unix 时间戳（标量），单位为秒</span>\ntimestamp<span>(</span>vector<span>(</span><span>1</span><span>))</span>      <span># 返回矢量中每个数据点的时间戳（矢量）</span>\n\n<span># 以下函数用于获取某个时间信息（注意为 UTC 时区）。可以输入一个时间矢量，不输入时默认采用当前时间，比如 hour( timestamp(vector(1)) )</span>\nminute<span>(</span><span>[</span>vector<span>]</span><span>)</span>          <span># 分钟，取值为 0~59</span>\nhour  <span>(</span><span>[</span>vector<span>]</span><span>)</span>          <span># 小时，取值为 0~23</span>\nmonth <span>(</span><span>[</span>vector<span>]</span><span>)</span>          <span># 月份，取值为 1~31</span>\nyear  <span>(</span><span>[</span>vector<span>]</span><span>)</span>          <span># 年份</span>\nday_of_month<span>(</span><span>[</span>vector<span>]</span><span>)</span>    <span># 该月中的日期，取值为 1~31</span>\nday_of_week <span>(</span><span>[</span>vector<span>]</span><span>)</span>    <span># 周几，取值为 0~6 ，其中 0 表示周日</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><p>例：</p>\n<div><pre><code>hour<span>(</span><span>)</span> <span>==</span> <span>16</span> and minute<span>(</span><span>)</span> <span>&lt;</span> <span>5</span>   <span># 仅在 UTC+8 时区每天的前 5 分钟，表达式结果不为空，采取第一段的值，即 16</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>关于排序：</p>\n<div><pre><code>sort<span>(</span>go_goroutines<span>)</span>       <span># 按指标值升序排列</span>\nsort_desc<span>(</span>go_goroutines<span>)</span>  <span># 按指标值降序排列</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>在 Promtheus 的 Table 视图中，显示的指标默认是无序的，只能通过 sort() 函数按指标值排序。不支持按 label 进行排序。</li>\n<li>在 Graph 视图中，显示的图例是按第一个标签的值进行排序的，且不受 sort() 函数影响。</li>\n</ul>\n</li>\n<li>\n<p>修改矢量的标签：</p>\n<div><pre><code>label_join<span>(</span>go_goroutines, <span>\"new_label\"</span>, <span>\",\"</span>, <span>\"instance\"</span>, <span>\"job\"</span><span>)</span>               <span># 给矢量 go_goroutines 添加一个标签，其名为 new_label ，其值为 instance、job 标签的值的组合，用 , 分隔</span>\nlabel_replace<span>(</span>go_goroutines, <span>\"new_label\"</span>, <span>\"<span>$1</span>-<span>$2</span>\"</span>, <span>\"instance\"</span>, <span>\"(.*):(.*)\"</span><span>)</span>  <span># 给矢量 go_goroutines 添加一个标签，其名为 new_label ，其值为 instance 标签的值的正则匹配的结果</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h4 id=\"算术函数\"> 算术函数</h4>\n<ul>\n<li>矢量可以使用以下算术函数：<div><pre><code>abs<span>(</span>go_goroutines<span>)</span>                    <span># 返回每个时刻处，数据点的绝对值</span>\nround<span>(</span>go_goroutines<span>)</span>                  <span># 返回每个时刻处，数据点四舍五入之后的整数值</span>\nabsent<span>(</span>go_goroutines<span>)</span>                 <span># 在每个时刻处，如果矢量为空（不存在任何数据点），则返回 1 ，否则返回空值</span>\nabsent_over_time<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>   <span># 在每个时刻处，如果过去 1m 以内矢量一直为空，则返回 1 ，否则返回空值</span>\nchanges<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>            <span># 返回每个时刻处，最近 1m 以内的数据点变化的次数</span>\ndelta<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>              <span># 返回每个时刻处，该数据点减去 1m 之前数据点的差值（可能为负），适合计算变化量</span>\nidelta<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>             <span># 返回每个时刻处，过去 1m 以内最后两个数据点的差值（可能为负）</span>\n\n<span># 以下算术函数适用于 Counter 类型，即单调递增的矢量</span>\nresets<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>             <span># 返回每个时刻处，过去 1m 以内计数器重置（即数值减少）的次数</span>\nincrease<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>           <span># 返回每个时刻处，过去 1m 以内的数值增量</span>\nrate<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>               <span># 返回每个时刻处，过去 1m 以内的每秒平均增量（时间间隔越长，曲线越平缓）</span>\nirate<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>              <span># 返回每个时刻处，过去 1m 以内最后两个数据点之间的每秒平均增量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>使用算术函数时，时间间隔 <code>[t]</code> 必须要大于 scrape_interval ，否则计算结果为空。</li>\n<li>例：正常情况下 node_time_seconds 的值是每秒加 1 ，因此：\n<ul>\n<li><code>delta(node_time_seconds[1m])</code> 计算结果的每个数据点的值都是 60 。</li>\n<li><code>rate(node_time_seconds[1m])</code> 每个点的值都是 1 。</li>\n<li><code>irate(node_time_seconds[xx])</code> 每个点的值也都是 1 。</li>\n<li>如果 scrape_interval 为 30s ，则 <code>idelta(node_time_seconds[xx])</code> 每个点的值都是 30 。</li>\n</ul>\n</li>\n<li>increase() 实际上是 rate() 乘以时间间隔的语法糖。\n<ul>\n<li>如果矢量为单调递增，\n<ul>\n<li>则 increase() 与 delta() 的计算结果几乎相同，但可能存在轻微的误差，因为要先计算 rate() 。</li>\n</ul>\n</li>\n<li>如果矢量为非单调递增，\n<ul>\n<li>则 delta() 的计算结果可能为负，可以只取 &gt;= 0 部分的值。</li>\n<li>而 rate() 只会计算出第一段单调递增部分的增长率 k ，然后认为该矢量在 t 时间内的增量等于 k × t ，最终得到的 increase() 值比 delta() 大。</li>\n</ul>\n</li>\n<li>综上，计算增量时，使用 delta() 比 increase() 更好。</li>\n</ul>\n</li>\n<li>关于 idelta()、irate() ：\n<ul>\n<li>应该尽量使用大一些的时间间隔，因为时间间隔过大时不影响计算精度，但时间间隔过小时可能缺少数据点。</li>\n<li>曲线比 delta()、rate() 更尖锐，更接近瞬时值。但是只考虑到最近的两个数据点，更容易产生误差。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"聚合函数\"> 聚合函数</h4>\n<ul>\n<li>如果矢量包含多个时间序列，用算术函数会分别对这些时间序列进行运算，而用聚合函数会将它们合并成一个或多个时间序列。</li>\n<li>矢量可以使用以下聚合函数：<div><pre><code><span># 基本统计</span>\ncount<span>(</span>go_goroutines<span>)</span>                  <span># 返回每个时刻处，该矢量的数据点的数量（即包含几个时间序列）</span>\ncount_values<span>(</span><span>\"value\"</span>, go_goroutines<span>)</span>  <span># 返回每个时刻处，各种值的数据点的数量，并按 {value=\"x\"} 的命名格式生成多个时间序列</span>\nsum<span>(</span>go_goroutines<span>)</span>                    <span># 返回每个时刻处，所有数据点的总和（即将曲线图中所有曲线叠加为一条曲线）</span>\nmin<span>(</span>go_goroutines<span>)</span>                    <span># 返回每个时刻处，数据点的最小值</span>\nmax<span>(</span>go_goroutines<span>)</span>                    <span># 返回每个时刻处，数据点的最大值</span>\navg<span>(</span>go_goroutines<span>)</span>                    <span># 返回每个时刻处，数据点的平均值</span>\n\n<span># 高级统计</span>\nstddev<span>(</span>go_goroutines<span>)</span>                 <span># 返回每个时刻处，数据点之间的标准差</span>\nstdvar<span>(</span>go_goroutines<span>)</span>                 <span># 返回每个时刻处，数据点之间的方差</span>\ntopk<span>(</span><span>3</span>, go_goroutines<span>)</span>                <span># 返回每个时刻处，最大的 3 个数据点</span>\nbottomk<span>(</span><span>3</span>, go_goroutines<span>)</span>             <span># 返回每个时刻处，最小的 3 个数据点</span>\nquantile<span>(</span><span>0.5</span>, go_goroutines<span>)</span>          <span># 返回每个时刻处，大小排在 50% 位置处的数据点</span>\n\n<span># 修改数据点的值</span>\nlast_over_time<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>     <span># 返回每个时刻处，过去 1m 内最新数据点的值</span>\ngroup<span>(</span>go_goroutines<span>)</span>                  <span># 将每个数据点的取值置为 1</span>\nsgn<span>(</span>go_goroutines<span>)</span>                    <span># 判断每个数据点取值的正负。如果为正数、负数、0 ，则分别置为 1、-1、0</span>\nclamp<span>(</span>go_goroutines, <span>0</span>, <span>10</span><span>)</span>           <span># 限制每个数据点取值的最小值、最大值，语法为 clamp(vector, min, max)</span>\nclamp_min<span>(</span>go_goroutines, <span>0</span><span>)</span>           <span># 限制最小值</span>\nclamp_max<span>(</span>go_goroutines, <span>10</span><span>)</span>          <span># 限制最大值</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br></div></div><ul>\n<li>聚合函数默认不支持输入有限时间范围内的矢量，需要使用带 <code>_over_time</code> 后缀的函数，如下：<div><pre><code>sum_over_time<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>    <span># 返回每个时刻处，过去 1m 内数据点的总和（分别计算每个时间序列）</span>\navg_over_time<span>(</span>go_goroutines<span>[</span>1m<span>]</span><span>)</span>    <span># 返回每个时刻处，过去 1m 内的平均值</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>聚合函数可以与关键字 by、without 组合使用，如下：<div><pre><code>sum<span>(</span>go_goroutines<span>)</span> by<span>(</span>job<span>)</span>          <span># 将所有曲线按 job 标签的值分组，分别执行 sum() 函数</span>\nsum<span>(</span>go_goroutines<span>)</span> without<span>(</span>job<span>)</span>     <span># 将所有曲线按除了 job 以外的标签分组，分别执行 sum() 函数</span>\nsum<span>(</span>go_goroutines<span>)</span> by<span>(</span>Time<span>)</span>         <span># Time 是隐式 label ，这里相当于 sum(go_goroutines)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"http-api\"> HTTP API</h2>\n<ul>\n<li>\n<p>用于管理 Prometheus 的 HTTP API ：</p>\n<div><pre><code>GET   /-/healthy  <span># 用于健康检查，总是返回 Code 200</span>\nGET   /-/ready    <span># 返回 Code 200 则代表可以处理 HTTP 请求</span>\nPOST  /-/reload   <span># 重新加载配置文件</span>\nPOST  /-/quit     <span># 终止</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>关于数据的 API ：</p>\n<div><pre><code>GET   /api/v1/query?query<span>=</span>go_goroutines<span>{</span>instance<span>=</span><span>'10.0.0.1:9090'</span><span>}</span><span>&amp;</span><span>time</span><span>=</span><span>1589241600</span>               <span># 查询 query 表达式在指定时刻的值。如果不指定时刻，则采用当前时刻</span>\nGET   /api/v1/query_range?query<span>=</span>go_goroutines<span>{</span>instance<span>=</span><span>'10.0.0.1:9090'</span><span>}</span><span>&amp;</span><span>start</span><span>=</span><span>1589241600</span><span>&amp;</span><span>end</span><span>=</span><span>1589266000</span><span>&amp;</span><span>step</span><span>=</span>1m  <span># 查询一段时间内的所有值</span>\nPOST  /api/v1/admin/tsdb/delete_series?match<span>[</span><span>]</span><span>=</span>go_goroutines<span>&amp;</span><span>start</span><span>=</span><span>1589241600</span><span>&amp;</span><span>end</span><span>=</span><span>1589266000</span>    <span># 删除数据。如果不指定时间，则删除所有时间的数据</span>\nPOST  /api/v1/admin/tsdb/clean_tombstones                                                       <span># 让 TSDB 立即释放被删除数据的磁盘空间</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "监控 k8s",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Prometheus/monitorK8s.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Prometheus/monitorK8s.html",
      "content_html": "<h1 id=\"监控-k8s\"> 监控 k8s</h1>\n<ul>\n<li>k8s 的 apiserver、kubelet 等组件本身集成了 exporter 格式的 API 。</li>\n<li>用户也可部署额外的 exporter 服务：\n<ul>\n<li>cAdvisor ：kubelet 已经集成了 cadvisor ，可通过 /metrics/cadvisor 路径访问。</li>\n<li>Heapster ：已淘汰。</li>\n<li>metrics-server ：借鉴了 Heapster ，从 apiserver 获取 CPU、内存使用率等指标，供 HPA 调用。</li>\n<li>kube-state-metrics ：从 apiserver 获取 node、pod 等资源的状态，生成 Metrics 。</li>\n</ul>\n</li>\n<li>相关工具：\n<ul>\n<li>Prometheus Operator ：用于在 k8s 中自动安装 Prometheus、Alertmanager、node_exporter 堆栈。</li>\n<li>kube-prometheus ：调用 Prometheus Operator ，还会安装 kube-state-metrics、Grafana 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"集成指标\"> 集成指标</h2>\n<h3 id=\"配置\"> 配置</h3>\n<ul>\n<li>\n<p>用 Prometheus 监控 k8s 时，需要在 k8s 中创建一个 RBAC 角色，参考 <a href=\"https://github.com/prometheus/prometheus/blob/main/documentation/examples/rbac-setup.yml\" target=\"_blank\" rel=\"noopener noreferrer\">官方配置</a> 。</p>\n<ul>\n<li>建议采用 <code>namespace: kube-system</code> 。</li>\n<li>然后获取 ServiceAccount 对应的 secret 中的 ca.crt 和 token ：<div><pre><code><span>secret</span><span>=</span><span><span>`</span>kubectl get secrets -n kube-system <span>|</span> <span>grep</span> prometheus-token <span>|</span> <span>awk</span> <span>'{print $1}'</span><span>`</span></span>\nkubectl get secrets -n kube-system <span>$secret</span> -o yaml <span>|</span> yq <span>'.data.token'</span> <span>|</span> base64 -d <span>></span> token\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div>尝试访问 API ：<div><pre><code><span>curl</span> https://apiserver/metrics -H <span>\"Authorization: Bearer <span><span>$(</span><span>cat</span> token<span>)</span></span>\"</span> -k\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>在 prometheus.yml 中添加配置：</p>\n<div><pre><code><span>scrape_configs</span><span>:</span>\n<span>-</span> <span>job_name</span><span>:</span> k8s<span>-</span>apiserver\n  <span>kubernetes_sd_configs</span><span>:</span>        <span># 从 k8s 的 HTTP API 发现配置</span>\n  <span>-</span> <span>role</span><span>:</span> endpoints             <span># 将每个 service endpoints 作为 target</span>\n    <span>api_server</span><span>:</span> https<span>:</span>//apiserver\n    <span>authorization</span><span>:</span>\n      <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n    <span>tls_config</span><span>:</span>\n      <span># ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>\n      <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n    <span># namespaces:               # 要监控的 namespace ，默认监控所有 namespace</span>\n    <span>#   names:</span>\n    <span>#   - default</span>\n  <span># - role: pod                 # 将 pod_ip:expose_port 作为 target</span>\n  <span># - role: service             # 将 service_ip:expose_port 作为 target</span>\n  <span># - role: ingress             # 将每个 ingress path 作为 target</span>\n  <span># 通过 kubernetes_sd_configs 获取 target 之后，以下配置用于采集这些 target</span>\n  <span>scheme</span><span>:</span> https\n  <span>authorization</span><span>:</span>\n    <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n  <span>tls_config</span><span>:</span>\n    <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n  <span>relabel_configs</span><span>:</span>              <span># 每个 target 有一些元数据标签 __meta* ，Prometheus 采集之后不会保存</span>\n  <span>-</span> <span>action</span><span>:</span> keep                <span># 根据标签筛选 target ，保留匹配的 target ，丢弃其它 target</span>\n    <span>source_labels</span><span>:</span>\n      <span>[</span>\n        __meta_kubernetes_namespace<span>,</span>\n        __meta_kubernetes_service_name<span>,</span>\n        __meta_kubernetes_endpoint_port_name<span>,</span>\n      <span>]</span>\n    <span>regex</span><span>:</span> default;kubernetes;https\n  <span># - action: replace             # 将 __meta* 标签重命名，从而被 Prometheus 保存</span>\n  <span>#   source_labels: [__meta_kubernetes_pod_ip]</span>\n  <span>#   target_label: pod_ip</span>\n\n<span>-</span> <span>job_name</span><span>:</span> k8s<span>-</span>node\n  <span>kubernetes_sd_configs</span><span>:</span>\n  <span>-</span> <span>role</span><span>:</span> node                  <span># 将 node_ip:kubelet_port 作为 target</span>\n    <span>api_server</span><span>:</span> https<span>:</span>//apiserver\n    <span>authorization</span><span>:</span>\n      <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n    <span>tls_config</span><span>:</span>\n      <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n  <span>scheme</span><span>:</span> https\n  <span>authorization</span><span>:</span>\n    <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n  <span>tls_config</span><span>:</span>\n    <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n\n<span>-</span> <span>job_name</span><span>:</span> k8s<span>-</span>cadvisor\n  <span>kubernetes_sd_configs</span><span>:</span>\n  <span>-</span> <span>role</span><span>:</span> node                  <span># 将 node_ip:kubelet_port 作为 target</span>\n    <span>api_server</span><span>:</span> https<span>:</span>//apiserver\n    <span>authorization</span><span>:</span>\n      <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n    <span>tls_config</span><span>:</span>\n      <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n  <span>scheme</span><span>:</span> https\n  <span>metrics_path</span><span>:</span> /metrics/cadvisor\n  <span>authorization</span><span>:</span>\n    <span>credentials_file</span><span>:</span> /var/run/secrets/kubernetes.io/serviceaccount/token\n  <span>tls_config</span><span>:</span>\n    <span>insecure_skip_verify</span><span>:</span> <span>true</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br></div></div></li>\n</ul>\n<h3 id=\"指标\"> 指标</h3>\n<ul>\n<li>指标示例：<div><pre><code><span># 关于 apiserver</span>\napiserver_request_duration_seconds_count      <span># 各种 HTTP 请求的次数</span>\napiserver_request_duration_seconds_sum        <span># 各种 HTTP 请求的耗时</span>\netcd_request_duration_seconds_count\netcd_request_duration_seconds_sum\n\n<span># 关于 kubelet</span>\nkubernetes_build_info                                                     <span># k8s 版本信息</span>\nkubelet_node_name<span>{</span>job<span>=</span><span>\"k8s-node\"</span>, <span>instance</span><span>=</span><span>\"10.0.0.1\"</span>, <span>node</span><span>=</span><span>\"10.0.0.1\"</span><span>}</span>   <span># 通过 node 标签记录该 kubelet 所在的 node ip</span>\nkubelet_evictions<span>{</span>eviction_signal<span>=</span><span>\"xx\"</span><span>}</span>                                   <span># 发出的各种驱逐 pod 信号的次数</span>\nkubelet_http_requests_total                                               <span># 各种 HTTP 请求的次数</span>\nkubelet_http_requests_duration_seconds_sum\nkubelet_pleg_relist_duration_seconds_count                                <span># PLEG relist 的次数</span>\nkubelet_pleg_relist_duration_seconds_sum\nkubelet_runtime_operations_duration_seconds_count<span>{</span>operation_type<span>=</span><span>\"xx\"</span><span>}</span>    <span># 各种操作的次数</span>\nkubelet_runtime_operations_duration_seconds_sum<span>{</span>operation_type<span>=</span><span>\"xx\"</span><span>}</span>\nkubelet_runtime_operations_errors_total<span>{</span>operation_type<span>=</span><span>\"xx\"</span><span>}</span>              <span># 各种操作出错的次数</span>\nkubelet_running_pod_count\nkubelet_running_container_count<span>{</span>container_state<span>=</span><span>\"xx\"</span><span>}</span>\nkubelet_container_log_filesystem_used_bytes                               <span># 每个 container 的日志占用的磁盘空间</span>\n\n<span># 关于 cadvisor 的指标略</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br></div></div></li>\n</ul>\n<h2 id=\"kube-state-metrics\"> kube-state-metrics</h2>\n<ul>\n<li><a href=\"https://github.com/kubernetes/kube-state-metrics\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n</ul>\n<h3 id=\"部署\"> 部署</h3>\n<ul>\n<li>\n<p>用官方配置文件部署：</p>\n<div><pre><code><span>version</span><span>=</span><span>2.2</span>.4\n<span>wget</span> https://github.com/kubernetes/kube-state-metrics/archive/refs/tags/v<span>${version}</span>.tar.gz\n<span>tar</span> -xf <span>v</span><span>${version}</span>.tar.gz\n<span>cd</span> kube-state-metrics-<span>${version}</span>/examples/standard\n<span>sed</span> -i <span>\"s#image: .*#image: bitnami/kube-state-metrics:<span>${version}</span>#g\"</span> deployment.yaml\n<span>sed</span> -i <span>'s#clusterIP: None##g'</span> service.yaml\nkubectl apply -f <span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>启动命令：</p>\n<div><pre><code>kube-state-metrics\n    --host<span>=</span>::\n    --port<span>=</span><span>8080</span>                   <span># metrics 端口</span>\n    --telemetry-port<span>=</span><span>8081</span>         <span># 在该端口暴露 kube-state-metrics 自身的指标</span>\n    <span># --namespaces ''             # 监控的命名空间，默认监控所有</span>\n    <span># --namespaces-denylist ''    # 不监控的命名空间</span>\n    <span># --resources configmaps,cronjobs,daemonsets,deployments,...  # 监控哪几种资源，默认监控所有</span>\n    <span># --metric-annotations-allowlist namespaces=[kubernetes.io/*,...],pods=[*]  # 将哪些资源的哪些 annotations 加入监控指标，默认禁用</span>\n    <span># --metric-labels-allowlist pods=[k8s-app,...] # 将哪些资源的哪些 labels 加入监控指标，默认禁用</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>\n<p>在 prometheus.yml 中添加配置：</p>\n<div><pre><code><span>-</span> <span>job_name</span><span>:</span> kube<span>-</span>state<span>-</span>metrics\n  <span>static_configs</span><span>:</span>\n  <span>-</span> <span>targets</span><span>:</span>\n    <span>-</span> kube<span>-</span>state<span>-</span>metrics<span>:</span><span>8080</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"指标-2\"> 指标</h3>\n<ul>\n<li>指标示例：<div><pre><code><span># 几种资源都存在的指标</span>\n*_created                       <span># 资源的创建时间，取值为 Unix 时间戳</span>\n*_metadata_resource_version     <span># 资源的 resourceVersion</span>\n*_annotations\n*_labels\n\n<span># 各种资源</span>\nkube_node_spec_unschedulable    <span># Node 是否不可调度</span>\nkube_node_status_condition<span>{</span>condition<span>=</span><span>\"xx\"</span>, <span>status</span><span>=</span><span>\"true\"</span><span>}</span> <span># 是否处于某种状态</span>\nkube_node_status_allocatable<span>{</span>resource<span>=</span><span>\"cpu\"</span>, <span>unit</span><span>=</span><span>\"core\"</span><span>}</span> <span># node 各种资源的容量</span>\n\nkube_pod_info\nkube_pod_owner<span>{</span>owner_kind<span>=</span><span>\"ReplicaSet\"</span>, <span>owner_name</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 父资源</span>\nkube_pod_status_scheduled<span>{</span>condition<span>=</span><span>\"true\"</span><span>}</span> <span># Pod 是否已被调度</span>\nkube_pod_status_scheduled_time              <span># Pod 被调度的时刻</span>\nkube_pod_start_time\nkube_pod_completion_time\nkube_pod_status_phase<span>{</span>phase<span>=</span><span>\"xx\"</span><span>}</span>           <span># Pod 是否处于某个生命周期</span>\nkube_pod_status_ready<span>{</span>condition<span>=</span><span>\"true\"</span><span>}</span>     <span># Pod 是否就绪</span>\nkube_pod_status_reason<span>{</span>reason<span>=</span><span>\"xx\"</span><span>}</span>         <span># Pod 处于当前状态的原因</span>\n\nkube_pod_container_info<span>{</span>pod<span>=</span><span>\"xx\"</span>, <span>container</span><span>=</span><span>\"xx\"</span>, <span>image</span><span>=</span><span>\"xx\"</span><span>}</span>     <span># Pod 中容器信息</span>\nkube_pod_container_resource_requests<span>{</span>resource<span>=</span><span>\"cpu\"</span>, <span>unit</span><span>=</span><span>\"core\"</span><span>}</span> <span># Pod 中容器的资源需求</span>\nkube_pod_container_resource_limits<span>{</span>resource<span>=</span><span>\"cpu\"</span>, <span>unit</span><span>=</span><span>\"core\"</span><span>}</span>   <span># Pod 中容器的资源限制</span>\nkube_pod_container_state_started            <span># Pod 中容器的启动时刻</span>\nkube_pod_container_status_running           <span># Pod 中容器是否处于 Running 状态</span>\nkube_pod_container_status_ready             <span># Pod 中容器是否就绪，即通过 readinessProbe 探针</span>\nkube_pod_container_status_restarts_total    <span># Pod 中容器的重启次数</span>\n\nkube_deployment_spec_replicas               <span># 期待运行的实例数</span>\nkube_deployment_status_replicas_available   <span># 实际可用的实例数</span>\nkube_deployment_status_replicas_updated     <span># 最新版本的实例数</span>\nkube_deployment_status_condition<span>{</span>condition<span>=</span><span>\"xx\"</span>, <span>status</span><span>=</span><span>\"true\"</span><span>}</span>  <span># 是否处于某种状态</span>\n\nkube_statefulset_replicas                   <span># 期待运行的实例数</span>\nkube_statefulset_status_replicas_available  <span># 实际可用的实例数</span>\nkube_statefulset_status_replicas_updated    <span># 最新版本的实例数</span>\n\nkube_daemonset_status_desired_number_scheduled    <span># 期待运行的实例数</span>\nkube_daemonset_status_number_available            <span># 实际可用的实例数</span>\n\nkube_job_owner<span>{</span>owner_kind<span>=</span><span>\"CronJob\"</span>, <span>owner_name</span><span>=</span><span>\"xx\"</span><span>}</span>  <span># 父资源</span>\nkube_job_complete<span>{</span>condition<span>=</span><span>\"true\"</span><span>}</span>         <span># 是否结束执行</span>\nkube_job_failed<span>{</span>condition<span>=</span><span>\"true\"</span><span>}</span>           <span># 结果是否失败</span>\nkube_job_status_start_time                  <span># 开始时刻</span>\nkube_job_status_completion_time             <span># 结束时刻</span>\nkube_job_status_active                      <span># 正在运行的 Pod 实例数</span>\n\nkube_cronjob_status_last_schedule_time      <span># 上次触发的时刻</span>\nkube_cronjob_status_active                  <span># 正在运行的 Pod 实例数</span>\n\nkube_endpoint_address_available             <span># 可用的 endpoint 数量</span>\nkube_endpoint_address_not_ready             <span># 不可用的 endpoint 数量</span>\n\nkube_service_info\nkube_service_spec_type\nkube_service_status_load_balancer_ingress\n\nkube_horizontalpodautoscaler_status_current_replicas\nkube_horizontalpodautoscaler_status_desired_replicas\nkube_horizontalpodautoscaler_spec_min_replicas\nkube_horizontalpodautoscaler_spec_max_replicas\nkube_horizontalpodautoscaler_status_condition\nkube_horizontalpodautoscaler_spec_target_metric<span>{</span>metric_name<span>=</span><span>\"k8s_pod_mem_usage_bytes\"</span>, <span>metric_target_type</span><span>=</span><span>\"average\"</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Zabbix",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/Zabbix.html",
      "id": "/Hardware/DevOps/MonitoringAlarms/Zabbix.html",
      "content_html": "<h1 id=\"zabbix\"> Zabbix</h1>\n<p>：一个 Web 服务器，可以监控大量设备的运行状态。</p>\n<ul>\n<li>使用范围广，但是技术比较旧，配置比较繁琐。</li>\n</ul>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>zabbix server 负责收集各个被监控设备的信息，保存到 MySQL 数据库中，并通过 Web 页面显示给用户看。\n<ul>\n<li>当被监控设备数量很多时，可以分成几个区域，每个区域运行一个 zabbix proxy 充当小型 server ，再将所有 proxy 的信息汇总到核心的 zabbix server 。</li>\n<li>zabbix server 既可以等待 agent 发送信息过来，也可以主动拉取信息。</li>\n</ul>\n</li>\n<li>zabbix server 与被监控设备的通信方式：\n<ul>\n<li>agent ：在被监控设备上安装相应的 agent 程序，将监控信息发送给 zabbix server 。这是最常用的方式。</li>\n<li>ssh/telnet</li>\n<li>SNMP</li>\n<li>IPMI</li>\n<li>JMX</li>\n</ul>\n</li>\n<li>用户可以手动在 zabbix server 上添加 agent ，也可以让 agent 主动将监控数据推送到 zabbix server ，实现自动注册。</li>\n<li>添加一个 agent 之后，可以给它创建多个监控项、触发器。\n<ul>\n<li>触发器用于在满足特定条件时发出告警消息。</li>\n</ul>\n</li>\n<li>用户可以通过修改 agent 的配置文件，自定义它的监控指标，比如执行某个脚本去采集监控数据。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "监控工具",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/MonitoringAlarms/",
      "id": "/Hardware/DevOps/MonitoringAlarms/",
      "content_html": "<h1 id=\"监控工具\"> 监控工具</h1>\n<ul>\n<li>Zabbix ：于 2001 年发布。</li>\n<li>Nagios ：于 2002 年发布。</li>\n<li>Graphite ：于 2008 年发布。</li>\n<li>Datadog ：于 2009 年发布。</li>\n<li>Promethues ：于 2015 年发布。</li>\n<li>Open-Falcon ：于 2015 年由小米公司开源，采用 Golang 开发。</li>\n<li>Grafana ：于 2014 年发布。不能采集监控数据，只负责显示监控图表，通常与 MySQL、InfluxDB、Promethues 等监控数据源组合使用。</li>\n</ul>\n<h2 id=\"监控策略\"> 监控策略</h2>\n<ul>\n<li>采用自动化的监控工具取代人工巡检，可以更直观地查看系统状态、记录日志，更及时地发现异常。</li>\n<li>有的监控指标可能平时不会关注，如果开销不大，则应该也记录下来，有备无患。</li>\n<li>从多个层面进行监控：\n<ul>\n<li>服务器状态：比如 CPU 使用率、IO 速率、Socket 数量。</li>\n<li>进程外部状态：比如进程数、CPU 使用率。</li>\n<li>进程内部状态：比如异常数、日志中是否报错。</li>\n<li>中间件状态：即 MySQL、Redis 等中间件的内部状态。流行的中间件一般能自己提供这些监控信息。</li>\n<li>业务状态：比如用户数、请求数、响应速度。</li>\n</ul>\n</li>\n<li>显示监控指标的几种图表：\n<ul>\n<li>文本</li>\n<li>曲线图：适合每秒都在变化的指标。</li>\n<li>条状图：适合几分钟才变化一次的指标。</li>\n<li>饼状图：适合总量固定的多个指标，表示百分比关系。</li>\n</ul>\n</li>\n<li>将不同的监控指标用不同的颜色标明：\n<ul>\n<li>绿色：代表良好状态，或者取值越大越好的指标。</li>\n<li>灰色：代表不需要关注。</li>\n<li>蓝色：代表正常状态，但是取值越小越好的指标。</li>\n<li>黄色：代表轻微异常，可以忽视。</li>\n<li>橙色：代表明显异常，需要处理，但并不紧急。</li>\n<li>红色：代表危险状态，需要立即处理。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"告警策略\"> 告警策略</h2>\n<ul>\n<li>\n<p>当监控系统发现某个指标的值不符合预期时，应该标识为异常状态，并发送警报（Alert）。</p>\n</li>\n<li>\n<p>发送警报的策略：</p>\n<ul>\n<li>允许暂停发送警报，便于调试。</li>\n<li>在 m 时长内 n 次满足告警条件，才发送警报，从而减少误报。</li>\n<li>发送一个警报之后，如果一直满足告警条件，则需要间隔一段时间才能重复发送，从而避免告警风暴。</li>\n<li>尽量对警报去重，比如同一应用的不同实例共用一个警报、同一对象的严重警报会覆盖不严重警报。</li>\n<li>当告警解除时，应该再发送一个消息通知用户。</li>\n</ul>\n</li>\n<li>\n<p>应该为警报划分几种严重等级，例如：</p>\n<table>\n<thead>\n<tr>\n<th>等级</th>\n<th>含义</th>\n<th>处理措施</th>\n<th>通知人</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>FATAL</td>\n<td>很严重</td>\n<td>应该立即处理，紧急</td>\n<td>发送邮件+短信给相关负责人，甚至更高级的负责人</td>\n</tr>\n<tr>\n<td>ERROR</td>\n<td>错误</td>\n<td>需要处理，但并不紧急</td>\n<td>发送邮件给相关负责人</td>\n</tr>\n<tr>\n<td>WARN</td>\n<td>警告</td>\n<td>不一定要处理</td>\n<td>发送邮件给相关负责人</td>\n</tr>\n<tr>\n<td>INFO</td>\n<td>提示</td>\n<td>可以忽略，相当于日志</td>\n<td>默认不会发送给用户</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>\n<p>平时查看警报的需求：</p>\n<ul>\n<li>先查看当前存在的警报\n<ul>\n<li>先查看包含多个警报的简介列表，再点击单个警报查看其详情</li>\n</ul>\n</li>\n<li>再查看出现过的所有警报，并标明它们是否已处理</li>\n</ul>\n</li>\n<li>\n<p>处理警报的策略：</p>\n<ul>\n<li>警报出现之后应该尽早解决，不要忽视警报而一直保留它，否则就失去了告警的意义。</li>\n<li>对于经常重复出现的告警，可以尝试用脚本自动化解决，比如当进程异常退出时自动重启。</li>\n<li>使用一个告警平台，统一接收不同来源的警报（比如 HTTP 、SMTP 方式的警报），然后按自定义的告警策略转发出去。</li>\n<li>每条警报应该记录这些信息：简短标题、具体描述、开始时间、结束时间、负责人、处理人、处理方法。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "VS Code",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Other/VSCode.html",
      "id": "/Hardware/DevOps/Other/VSCode.html",
      "content_html": "<h1 id=\"vs-code\"> VS Code</h1>\n<p>：Visual Studio Code ，是微软公司于 2015 年发布的一款开源、轻量级的 IDE 。</p>\n<ul>\n<li><a href=\"https://code.visualstudio.com/\" target=\"_blank\" rel=\"noopener noreferrer\">官网</a></li>\n<li>基于 Electron 框架开发，跨平台，支持 Web IDE 。</li>\n<li>支持远程终端。</li>\n<li>本身是一个轻量级的代码编辑器，但可以通过安装插件扩展很多功能，比如搭建任意编程语言的开发环境。</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>在 VS Code 中打开一个项目目录，即可操作其下的文件。</p>\n</li>\n<li>\n<p>界面的左侧显示了几个主要按钮，点击它们会显示不同内容的侧边栏：</p>\n<ul>\n<li>Explorer ：显示项目目录的文件列表。</li>\n<li>Search ：显示搜索栏。支持对项目目录下的所有文件进行全文搜索，支持替换、正则匹配。</li>\n<li>Source Control ：显示 Git 的暂存区文件。</li>\n<li>Run ：运行项目代码。可能需要配置合适的编译器、解释器。</li>\n<li>Remote Explorer ：显示可用的远程开发环境。</li>\n<li>Extensions ：显示插件列表。</li>\n</ul>\n</li>\n<li>\n<p>状态栏的左下角包含几个按钮，比如切换 Git 分支、显示报错栏。</p>\n</li>\n<li>\n<p>状态栏的右下角如下：</p>\n<p><img src=\"./vscode1.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li><code>Ln 12, Col 1</code> ：表示当前光标位于第 12 行、第 1 列。</li>\n<li><code>Spaces: 4</code> ：表示按下一个 Tab 键会输入 4 个空格。点击它可以设置空格数。</li>\n<li><code>UTF-8</code> ：表示当前文件的编码格式。点击它可以切换成其它编码格式。</li>\n<li><code>CRLF</code> ：表示当前文件的换行符风格。点击它可以改成 LF 风格。</li>\n<li><code>MarkDown</code> ：表示当前文件的语言。点击它可以切换成其它语言。</li>\n</ul>\n</li>\n<li>\n<p>支持使用正则替换，例如：</p>\n<div><pre><code>log-<span>(</span><span>\\</span>d*<span>)</span>.txt   <span># 查找表达式</span>\nlog-<span>(</span><span>$1</span><span>)</span>.log    <span># 替换表达式，用 $1 的格式引用元素组</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n<h3 id=\"设置\"> 设置</h3>\n<ul>\n<li>点击页面左下角的齿轮按钮，即可打开设置页面。\n<ul>\n<li>可以进行全局设置，也可以只对某个项目进行设置。</li>\n<li>如果对某个项目进行了个性化设置，则会在该项目的根目录下创建一个 .vscode 目录，用于保存设置信息。</li>\n</ul>\n</li>\n<li>建议的设置：\n<ul>\n<li>启用 Settings Sync 功能，将 VS Code 的主题、快捷键、插件等配置信息备份到云端，跟 GitHub 账号绑定。</li>\n<li>在输入代码时时会自动弹出补全窗口，默认可以按 Tab 或 Enter 键进行补全，也可以按 Esc 键忽略。建议在设置中关闭 &quot;Accept Suggestion On Enter&quot; 选项，这样按 Enter 键的作用总是换行。</li>\n<li>启用 &quot;Format On Type&quot; 选项，允许在输入换行符时自动格式化代码。再设置手动格式化的快捷键为 <code>Alt + F</code> 。</li>\n<li>设置 &quot;Run Selected Text in Active Terminal&quot; 的快捷键为 <code>Shift + Enter</code> ，便于快速在当前激活的终端中（没有则自动创建）执行光标所在行或选中的内容。</li>\n<li>设置切换行注释的快捷键为 <code>Ctrl + Q</code> ，切换块注释的快捷键为 <code>Ctrl + Shift + Q</code> ，与 NotePad++ 的注释快捷键一致。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常用快捷键\"> 常用快捷键</h3>\n<ul>\n<li><code>F1</code> ：打开命令面板，用于快速执行一些命令。例如：\n<ul>\n<li><code>Fold All</code> ：将代码块全部折叠。</li>\n<li><code>Unfold All</code> ：将代码块全部展开。</li>\n<li><code>Trim Trailing Whitespace</code> ：去掉每行末尾的空字符。</li>\n</ul>\n</li>\n<li><code>Ctrl + `</code> ：打开终端。终端可以是 CMD、PowerShell、WSL 等类型。</li>\n<li><code>F2</code> ：重命名光标所在的标识符。</li>\n<li><code>F3</code> 或 <code>Ctrl + F</code> ：在当前文件中打开搜索栏。</li>\n<li><code>F11</code> ：切换至全屏显示。</li>\n<li><code>F12</code> ：转到光标所在的标识符的定义位置。</li>\n<li><code>Alt + ↑/↓</code> ：向上、向下移动光标所在行或选中的多行。</li>\n<li><code>Alt + ←/→</code> ：将光标切换到上一次、下一次编辑的位置，甚至可以切换到其它文件。</li>\n<li>按住 <code>Alt</code> 时，可以用鼠标连续拖选多处文本，同时选中它们。</li>\n<li>按住 <code>Shift</code> 时，可以按 <code>↑/↓</code> 键改变选中的文本范围。</li>\n<li><code>Alt + Shift + ↓</code> ：复制并粘贴当前行，或选中的多行。</li>\n<li>选中一行或多行之后：\n<ul>\n<li><code>Tab</code> ：向右移动文本，调整缩进。</li>\n<li><code>Shift + Tab</code> ：向左移动文本，调整缩进。</li>\n</ul>\n</li>\n<li><code>Ctrl + [/]</code> ：向左、向右移动文本，调整缩进。</li>\n<li><code>Ctrl + Shift + [/]</code> ：折叠、展开代码块。</li>\n<li><code>Ctrl + ←/→</code> ：以单词为单位左右移动光标。</li>\n<li><code>Ctrl + Backspace/Delete</code> ：以单词为单位删除代码。</li>\n</ul>\n<h3 id=\"常用插件\"> 常用插件</h3>\n<ul>\n<li>One Dark Pro ：提供几种界面主题。</li>\n<li>vscode-icon ：给不同类型的文件加上美观的图标。</li>\n<li>Align by RegEx ：用于自动添加空格以对齐多行中的某个字符，比如对齐注释符号 # 。</li>\n<li>Beautify ：用于格式化 JS、CSS、HTML 代码。</li>\n<li>Markdown Preview Enhance ：一个增强型的 Markdown 阅读器，支持实时预览、显示目录、导出成 HTML、PDF 等格式。</li>\n<li>Code Spell Checker ：检查单词拼写错误。建议将它禁用避免干扰，要检查时再启用。</li>\n<li>hexdump for VSCode ：用于按十六进制查看文件内容，并且右键某个字节可进行修改。</li>\n</ul>\n<h3 id=\"远程开发\"> 远程开发</h3>\n<p>VS Code 支持远程开发模式。</p>\n<ul>\n<li><a href=\"https://code.visualstudio.com/blogs/2019/05/02/remote-development\" target=\"_blank\" rel=\"noopener noreferrer\">官方教程</a></li>\n<li>可以在本机的 VS Code 界面中打开其它主机上的文件目录，进行编辑、编译、调试等操作。</li>\n<li>远程目录可以位于物理机、虚机，甚至 Docker 容器中。</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>Electron\n<ul>\n<li>：一个跨平台的 GUI 应用开发框架。</li>\n<li>原名为 Atom Shel ，于 2013 年由 GitHub 公司发布。</li>\n<li>采用 JavaScript、HTML、CSS 等前端技术开发应用，用 Chromium 显示前端，用 node.js 运行后端。</li>\n</ul>\n</li>\n<li>Atom\n<ul>\n<li>：一个代码编辑器，基于 Electron 框架开发。</li>\n<li>于 2014 年由 GitHub 公司发布。</li>\n</ul>\n</li>\n<li>Monaco Editor\n<ul>\n<li>：VS Code 的代码编辑器，现已作为一个独立项目开源。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/conwnet/github1s\" target=\"_blank\" rel=\"noopener noreferrer\">github1s</a>\n<ul>\n<li>：一个 2021 年发布的开源项目，用于通过 Web IDE 查看任意 GitHub 项目的文件。</li>\n<li>用法：在浏览器中访问任意 GitHub 项目，将域名 github.com 改为 github1s.com ，即可进入基于 VS Code 构建的 Web IDE 页面。</li>\n</ul>\n</li>\n<li>Jupyter Notebook\n<ul>\n<li>：一个 Web 服务器，提供了 Web IDE 。</li>\n<li>2014 年，IPython 解释器的 Notebook 改名为 Jupyter Notebook ，成为一个独立项目，扩展支持几十种编程语言。</li>\n<li>可以创建、编辑 Notebook 文档：\n<ul>\n<li>支持多种编程语言的交互式编程。</li>\n<li>支持显示像 MarkDown 的富文本，方便绘制数学公式、编写教程文档。</li>\n<li>文档保存为 JSON 格式，扩展名为 .ipynb 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"wsl\"> WSL</h3>\n<p>：Windows 的 Linux 子系统（Windows Subsystem for Linux ，WSL），是 Windows 10 提供的一种虚拟机服务。</p>\n<ul>\n<li><a href=\"https://docs.microsoft.com/zh-cn/windows/wsl/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>开启 WSL 服务之后，可以在 Windows 中启动一个虚拟的 Linux 子系统。\n<ul>\n<li>例如安装 Ubuntu 类型的 WSL 之后，在 CMD 命令行中执行 ubuntu 命令即可进入 shell 终端。</li>\n<li>启动只需要几秒，并且比虚拟机的开销小很多。</li>\n<li>兼容大部分的 Linux 接口，因此可以安装、运行大部分 Linux 程序。</li>\n<li>将 Windows 磁盘文件挂载在 /mnt/ 目录下，可以直接访问。</li>\n</ul>\n</li>\n<li>WSL 2 版本比 WSL 1 版本的功能更强：\n<ul>\n<li>具有完整的 Linux 内核，可以运行 Docker 容器。</li>\n<li>可以调用 Windows 程序。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "YApi",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Other/YApi.html",
      "id": "/Hardware/DevOps/Other/YApi.html",
      "content_html": "<h1 id=\"yapi\"> YApi</h1>\n<p>：一个 API 管理网站，兼容 swagger 文档，且功能更多。</p>\n<ul>\n<li><a href=\"https://github.com/YMFE/yapi\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>2018 年由去哪儿网开源。</li>\n<li>可用于管理大量 API 的文档，方便前后端开发人员联调。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>mongo</span><span>:</span>\n    <span>container_name</span><span>:</span> mongo\n    <span>image</span><span>:</span> mongo<span>:</span>4.4.10\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span>MONGO_INITDB_ROOT_USERNAME</span><span>:</span> root\n      <span>MONGO_INITDB_ROOT_PASSWORD</span><span>:</span> <span>******</span>\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>volumes</span><span>:</span>\n      <span>-</span> /etc/localtime<span>:</span>/etc/localtime<span>:</span>ro\n      <span>-</span> ./data<span>:</span>/data/db\n\n  <span>yapi</span><span>:</span>\n    <span>container_name</span><span>:</span> yapi\n    <span>image</span><span>:</span> yapipro/yapi<span>:</span>1.9.5\n    <span>init</span><span>:</span> <span>true</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>command</span><span>:</span>\n      <span>-</span> server/app.js\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>ports</span><span>:</span>\n      <span>-</span> <span>80:80</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config.json<span>:</span>/yapi/config.json\n\n<span>networks</span><span>:</span>\n  <span>net</span><span>:</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>需要调整挂载目录的权限：<div><pre><code><span>chown</span> -R <span>999</span> data\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>yapi 的配置文件 config.json 示例：<div><pre><code><span>{</span>\n  <span>\"port\"</span><span>:</span> <span>\"80\"</span><span>,</span>\n  <span>\"closeRegister\"</span><span>:</span> <span>true</span><span>,</span>              <span>// 是否禁止新用户注册。目前 yapi 不支持管理员创建用户</span>\n  <span>\"adminAccount\"</span><span>:</span> <span>\"admin@test.com\"</span><span>,</span>   <span>// 管理员的邮箱地址</span>\n  <span>\"db\"</span><span>:</span> <span>{</span>\n    <span>\"connectString\"</span><span>:</span> <span>\"mongodb://mongo:27017/yapi?authSource=admin\"</span><span>,</span>\n    <span>\"user\"</span><span>:</span> <span>\"root\"</span><span>,</span>\n    <span>\"pass\"</span><span>:</span> <span>\"******\"</span>\n  <span>}</span><span>,</span>\n  <span>\"mail\"</span><span>:</span> <span>{</span>\n    <span>\"enable\"</span><span>:</span> <span>true</span><span>,</span>\n    <span>\"host\"</span><span>:</span> <span>\"smtp.gmail.com\"</span><span>,</span>\n    <span>\"port\"</span><span>:</span> <span>465</span><span>,</span>\n    <span>\"from\"</span><span>:</span> <span>\"*\"</span><span>,</span>\n    <span>\"auth\"</span><span>:</span> <span>{</span>\n      <span>\"user\"</span><span>:</span> <span>\"xxx@test.com\"</span><span>,</span>\n      <span>\"pass\"</span><span>:</span> <span>\"******\"</span>\n    <span>}</span>\n  <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></li>\n<li>初次部署时，需要初始化数据库：<div><pre><code><span>docker</span> <span>exec</span> -it yapi <span>node</span> server/install.js\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>忘记管理员密码时，需要到 MongoDB 中修改密码：<div><pre><code><span>docker</span> <span>exec</span> -it mongo -u root -p\nuse yapi\ndb.user.update<span>(</span><span>{</span><span>'username'</span><span>:</span><span>'admin'</span><span>}</span>,<span>{</span><span>$set</span>:<span>{</span><span>'password'</span><span>:</span><span>'******'</span><span>}</span><span>}</span><span>)</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>支持搜索 API 。</li>\n<li>支持自动生成 Mock 接口。\n<ul>\n<li>当用户调用 Mock 接口时，yapi 会返回一个模拟响应，其中的响应参数是基于 Mock.js 生成的随机值。</li>\n<li>用户可以通过两种方式配置 Mock 响应：\n<ul>\n<li>Mock.js 模板</li>\n<li>JS 脚本</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>支持创建多个项目。</li>\n<li>支持给一个项目定义多个配置环境，包括域名、Headers、全局变量。</li>\n</ul>\n<h2 id=\"swagger\"> Swagger</h2>\n<ul>\n<li>Swagger 项目定义了一种接口描述语言，用于编写 HTTP API 的描述文档。\n<ul>\n<li>该文档采用 JSON 或 YAML 格式。</li>\n<li>该文档容易被程序解析，但不方便供人阅读。</li>\n<li>2016 年，Swagger API 规范独立为一个项目，改名为 OpenAPI 。</li>\n</ul>\n</li>\n<li>Swagger 项目包含多个工具，比如：\n<ul>\n<li><a href=\"https://github.com/swagger-api/swagger-editor\" target=\"_blank\" rel=\"noopener noreferrer\">swagger-editor</a>\n<ul>\n<li>：一个静态网站，用于在 Web UI 中编辑 Swagger 文档，并进行实时预览、语法检查。</li>\n<li>可自己部署，也可访问官方网站 <a href=\"https://editor.swagger.io\" target=\"_blank\" rel=\"noopener noreferrer\">https://editor.swagger.io</a> 。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/swagger-api/swagger-ui\" target=\"_blank\" rel=\"noopener noreferrer\">swagger-ui</a>\n<ul>\n<li>：一个静态网站，用于在 Web UI 中查看 Swagger 文档。</li>\n<li>可自己部署，也可访问官方网站 <a href=\"https://petstore.swagger.io\" target=\"_blank\" rel=\"noopener noreferrer\">https://petstore.swagger.io</a> 。</li>\n<li>支持通过 URL 导入一个文档文件，进行显示。</li>\n<li>支持构造 API 的输入参数，测试调用。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/swagger-api/swagger-codegen\" target=\"_blank\" rel=\"noopener noreferrer\">swagger-codegen</a>\n<ul>\n<li>：一个 Java 程序，用于根据 Swagger 文档，自动生成符合描述的服务器、客户端代码，支持 Java(Spring)、Python(Flask) 等多种语言、框架。</li>\n</ul>\n</li>\n<li>Swagger 提供了多种编程语言的插件，支持根据项目代码中符合 swagger 规范的注释，自动生成 Swagger 文档。</li>\n</ul>\n</li>\n<li>Swagger 文档的部分示例：<div><pre><code><span>paths</span><span>:</span>\n  <span>/user</span><span>:</span>                      <span># API 路径</span>\n    <span>post</span><span>:</span>\n      <span>summary</span><span>:</span> <span>\"Add a new user\"</span>\n      <span>description</span><span>:</span> <span>\"\"</span>\n      <span>consumes</span><span>:</span>               <span># request body 的类型</span>\n      <span>-</span> <span>\"application/json\"</span>\n      <span>produces</span><span>:</span>               <span># response body 的类型</span>\n      <span>-</span> <span>\"application/json\"</span>\n      <span>parameters</span><span>:</span>             <span># 输入参数</span>\n      <span>-</span> <span>in</span><span>:</span> <span>\"body\"</span>            <span># 参数的位置，是在报文 body 还是 query</span>\n        <span>name</span><span>:</span> <span>\"username\"</span>\n        <span>description</span><span>:</span> <span>\"\"</span>\n        <span>required</span><span>:</span> <span>true</span>\n        <span>type</span><span>:</span> <span>\"string\"</span>\n      <span>responses</span><span>:</span>              <span># 响应</span>\n        <span>\"200\"</span><span>:</span>\n          <span>description</span><span>:</span> <span>\"success\"</span>\n        <span>\"405\"</span><span>:</span>\n          <span>description</span><span>:</span> <span>\"Invalid input\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "其他",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Other/",
      "id": "/Hardware/DevOps/Other/",
      "content_html": "<h1 id=\"其他\"> 其他</h1>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Selenium",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Test/Selenium.html",
      "id": "/Hardware/DevOps/Test/Selenium.html",
      "content_html": "<h1 id=\"selenium\"> Selenium</h1>\n<p>：一个用于 Web 自动化测试的开源项目。</p>\n<ul>\n<li><a href=\"https://www.selenium.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">官网</a></li>\n<li>发音为 <code>/səˈliːniəm/</code> 。</li>\n<li>Selenium 项目提供了多个工具：\n<ul>\n<li>WebDriver</li>\n<li>IDE ：一个浏览器插件，用于记录用户在浏览器中的操作，记录成 Selenium 命令，便于快速创建测试用例。</li>\n<li>Grid</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"webdriver\"> WebDriver</h2>\n<p>：一个 HTTP 服务器，用于调用浏览器的 API 来访问网站。</p>\n<ul>\n<li>支持调用 Firefox、Chrome 等浏览器。</li>\n</ul>\n<h3 id=\"安装\"> 安装</h3>\n<ol>\n<li>\n<p>安装 webdriver 。</p>\n<ul>\n<li>如果安装在本机，则需要安装某种浏览器，再下载对应版本的 webdriver 二进制文件。</li>\n<li>也可以在其它主机部署 Grid 服务器，然后在本机调用。</li>\n</ul>\n</li>\n<li>\n<p>安装 Python 的第三方库作为客户端：<code>pip install selenium</code></p>\n</li>\n</ol>\n<h3 id=\"用法\"> 用法</h3>\n<ul>\n<li>\n<p><a href=\"https://selenium-python.readthedocs.io/\" target=\"_blank\" rel=\"noopener noreferrer\">参考文档</a></p>\n</li>\n<li>\n<p>例：在本机启动 webdriver 服务器</p>\n<div><pre><code><span>from</span> selenium <span>import</span> webdriver\n\ndriver <span>=</span> webdriver<span>.</span>Chrome<span>(</span><span>)</span>   <span># 启动 webdriver 。这会创建一个 webdriver 子进程，它又会创建几个 Chrome 子进程</span>\ndriver<span>.</span>quit<span>(</span><span>)</span>                 <span># 终止 webdriver</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>例：调用远程的 Grid 服务器</p>\n<div><pre><code><span>from</span> selenium <span>import</span> webdriver\n<span>from</span> selenium<span>.</span>webdriver<span>.</span>common<span>.</span>desired_capabilities <span>import</span> DesiredCapabilities\n\ndriver <span>=</span> webdriver<span>.</span>Remote<span>(</span>\n    command_executor<span>=</span><span>\"http://10.0.0.1:4444\"</span><span>,</span>\n    desired_capabilities<span>=</span>DesiredCapabilities<span>.</span>CHROME\n<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>例：浏览网页</p>\n<div><pre><code><span>>></span><span>></span> driver<span>.</span>get<span>(</span><span>'http://www.baidu.com'</span><span>)</span>   <span># 让浏览器返回一个 URL</span>\n<span>>></span><span>></span> driver<span>.</span>name            <span># 获取浏览器的名称</span>\n<span>'chrome'</span>\n<span>>></span><span>></span> driver<span>.</span>current_url     <span># 获取当前网页的 URL</span>\n<span>'https://www.baidu.com/'</span>\n<span>>></span><span>></span> driver<span>.</span>title           <span># 获取当前网页的标题</span>\n<span>'百度一下，你就知道'</span>\n<span>>></span><span>></span> driver<span>.</span>page_source     <span># 获取当前网页的 HTML 内容</span>\n'<span>&lt;</span>html<span>></span><span>&lt;</span>head<span>></span><span>&lt;</span>meta http<span>-</span>equiv<span>=</span><span>\"Content-Type\"</span> content<span>=</span><span>\"text/html;charset=utf-8\"</span><span>></span><span>.</span><span>.</span><span>.</span>\n<span>>></span><span>></span> driver<span>.</span>save_screenshot<span>(</span><span>'1.png'</span><span>)</span>      <span># 保存网页截图（即使调用 Grid ，也能保存到本机）</span>\n<span>True</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></li>\n<li>\n<p>例：在网页输入信息</p>\n<div><pre><code><span>>></span><span>></span> <span>from</span> selenium<span>.</span>webdriver<span>.</span>common<span>.</span>keys <span>import</span> Keys\n<span>>></span><span>></span> e <span>=</span> driver<span>.</span>find_element_by_id<span>(</span><span>'kw'</span><span>)</span>   <span># 查找 HTML 中的元素</span>\n<span>>></span><span>></span> e<span>.</span>send_keys<span>(</span><span>'hello'</span><span>)</span>                  <span># 输入字符串</span>\n<span>>></span><span>></span> e<span>.</span>send_keys<span>(</span>Keys<span>.</span>RETURN<span>)</span>              <span># 输入一个键盘快捷键</span>\n<span>>></span><span>></span> e<span>.</span>click<span>(</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<p>例：切换浏览器的窗口</p>\n<div><pre><code><span>>></span><span>></span> driver<span>.</span>current_window_handle        <span># 获取当前窗口的句柄</span>\n<span>'CDwindow-C88E17197FCFDE3459E9E81F7498A3EA'</span>\n<span>>></span><span>></span> windows <span>=</span> driver<span>.</span>window_handles     <span># 获取浏览器所有窗口的句柄，返回一个 list</span>\n<span>>></span><span>></span> driver<span>.</span>close<span>(</span><span>)</span>                      <span># 关闭当前窗口</span>\n<span>>></span><span>></span> driver<span>.</span>switch_to<span>.</span>window<span>(</span>windows<span>[</span><span>0</span><span>]</span><span>)</span> <span># 切换窗口</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>浏览器可以打开多个窗口，而 driver 同时只能操纵一个窗口。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"grid\"> Grid</h2>\n<p>：一个 Web 服务器，采用 Java 开发，用于在多个主机上执行 WebDriver 任务。</p>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>\n<p>Grid 包含以下组件：</p>\n<ul>\n<li>Node\n<ul>\n<li>：负责执行 WebDriver 任务。</li>\n<li>默认会自动发现本机上可用的 WebDriver ，注册到 Distributor 。</li>\n<li>每个 Node 提供了一定数量的 slot ，用于执行客户端 session 的任务。</li>\n</ul>\n</li>\n<li>Hub ：包含以下组件：\n<ul>\n<li>Router\n<ul>\n<li>：作为 Grid 的入口，负责将客户端请求转发到对应的组件。</li>\n<li>例如收到客户端请求时，如果属于已有会话，则转发到 Session Map ，否则转发到 New Session Queue 。</li>\n</ul>\n</li>\n<li>Distributor\n<ul>\n<li>负责为每个新的会话分配 Node 来执行任务。</li>\n</ul>\n</li>\n<li>Session Map\n<ul>\n<li>负责记录每个 Session ID ，与执行该 Session 任务的 Node 的对应关系。</li>\n</ul>\n</li>\n<li>New Session Queue</li>\n<li>Event Bus\n<ul>\n<li>负责实现 Grid 各组件之间的通信。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Grid 可以部署成分布式集群，也可以以 Standalone 模式部署单节点。</p>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>\n<p>下载 jar 包，然后执行：</p>\n<div><pre><code>java -jar selenium-server.jar\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n\n  <span>selenium</span><span>:</span>\n    <span>container_name</span><span>:</span> selenium\n    <span>image</span><span>:</span> selenium/standalone<span>-</span>chrome<span>:</span>92.0<span>-</span><span>20210804</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>shm_size</span><span>:</span> 2g\n    <span>ports</span><span>:</span>\n      <span>-</span> 4444<span>:</span><span>4444</span>\n    <span># volumes:</span>\n    <span>#   - ./config.toml:/opt/selenium/config.toml</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>该 selenium 镜像会基于 supervisor 运行浏览器、webdriver、Grid 等多个进程。</li>\n<li>容器启动时总是会重新生成配置文件 config.toml ，除非没有写入权限。可以挂载 config.toml ，内容示例：<div><pre><code><span><span>[</span><span>network</span><span>]</span></span>\n<span>relax-checks</span> <span>=</span> <span>true               # 是否放宽检查客户端 HTTP 请求的 Headers、Content-Type</span>\n\n<span><span>[</span><span>node</span><span>]</span></span>\n<span># detect-drivers = true           # 是否自动发现本机上可用的 WebDriver</span>\n<span># session-timeout = \"300\"         # 删除超过一定时长未活动的 session</span>\n<span># max-sessions = 1                # 每个 node 可以分配的最大 session 数，默认等于 CPU 核数</span>\n<span># override-max-sessions = false   # 是否允许设置的 max-sessions 超过 CPU 核数</span>\n\n<span><span>[</span><span>router</span><span>]</span></span>\n<span>username</span> <span>=</span> <span>admin                  # 给网站开启 Basic Auth 认证</span>\n<span>password</span> <span>=</span> <span>******</span>\n\n<span># [server]</span>\n<span># port = 4444</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "SonarQube",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Test/SonarQube.html",
      "id": "/Hardware/DevOps/Test/SonarQube.html",
      "content_html": "<h1 id=\"sonarqube\"> SonarQube</h1>\n<p>：一个 Web 服务器，用于检查代码质量，采用 Java 开发。</p>\n<ul>\n<li><a href=\"https://docs.sonarqube.org/latest/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>主要用于扫描静态代码，找出语法错误、漏洞、可优化之处。</li>\n<li>支持扫描 C、C++、C#、Java、JavaScrip 等常见编程语言的代码。</li>\n<li>采用 C/S 架构：\n<ul>\n<li>先运行一个 SonarQube 服务器。</li>\n<li>然后执行一次 SonarScanner 扫描器，它会扫描代码，并上传到 SonarQube 服务器进行分析。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>扫描的规则较少，一些无关紧要的问题也会报错，一些语法错误却不会发现。</li>\n<li>相同的问题会重复报错，导致报错很多。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ol>\n<li>\n<p>配置以下内核参数：</p>\n<div><pre><code><span>sysctl vm.max_map_count</span><span>=</span><span>262144</span>\n<span>sysctl fs.file-max</span><span>=</span><span>65536</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>\"3\"</span>\n\n<span>services</span><span>:</span>\n  <span>sonarqube</span><span>:</span>\n    <span>image</span><span>:</span> sonarqube<span>:</span>8<span>-</span>community\n    <span>ports</span><span>:</span>\n      <span>-</span> 9000<span>:</span><span>9000</span>\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>environment</span><span>:</span>\n      <span>-</span> sonar.jdbc.url=jdbc<span>:</span>postgresql<span>:</span>//postgres<span>:</span>5432/sonarqube\n      <span>-</span> sonar.jdbc.username=sonarqube\n      <span>-</span> sonar.jdbc.password=<span>******</span>    <span># 密码</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./sonarqube/conf<span>:</span>/opt/sonarqube/conf\n      <span>-</span> ./sonarqube/data<span>:</span>/opt/sonarqube/data\n      <span>-</span> ./sonarqube/extensions<span>:</span>/opt/sonarqube/extensions\n      <span>-</span> ./sonarqube/logs<span>:</span>/opt/sonarqube/logs\n\n  <span>postgres</span><span>:</span>\n    <span>image</span><span>:</span> postgres<span>:</span><span>12</span>\n    <span>networks</span><span>:</span>\n      <span>-</span> net\n    <span>environment</span><span>:</span>\n      <span>-</span> POSTGRES_USER=sonarqube\n      <span>-</span> POSTGRES_PASSWORD=<span>******</span>    <span># 密码</span>\n      <span>-</span> POSTGRES_DB=sonarqube\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./postgres<span>:</span>/var/lib/postgresql/data\n\n<span>networks</span><span>:</span>\n  <span>net</span><span>:</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div><ul>\n<li>默认用户名、密码为 admin、admin 。</li>\n<li>SonarQube 支持的外部数据库包括：Oracle、PostgreSQL、SQL Server 。如果不配置外部数据库，则默认会使用内置数据库，但不方便迁移数据、不支持版本更新。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"用法\"> 用法</h2>\n<p>初次运行时的配置：</p>\n<ol>\n<li>进入 Administration -&gt; Security 页面，修改 admin 用户的密码，并取消 Anyone 用户组可以访问 SonarQube 。</li>\n<li>进入 Administration -&gt; Configuration -&gt; Security 页面，勾选 &quot;强制用户认证&quot; ，从而禁止匿名用户访问。</li>\n<li>进入 &quot;配置（Administration）&quot; -&gt; &quot;应用市场（Marketplace）&quot; 页面，下载有用的插件。\n<ul>\n<li>比如 &quot;Chinese Pack&quot; 插件可以汉化页面。</li>\n<li>下载插件之后，网页会提示需要重启服务器才能安装。</li>\n</ul>\n</li>\n</ol>\n<p>每个用户都可以在 SonarQube 首页看到所有项目。如下：</p>\n<p><img src=\"./sonarqube_1.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>每个项目都从 Bugs、漏洞、复审热点等多个方面进行了评分。</li>\n<li>SonarQube 会根据 “质量阀” 判断项目是否 “正常” 。</li>\n</ul>\n<p>点击项目的名字即可进入其详情页面，如下：</p>\n<p><img src=\"./sonarqube_2.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>在 “问题” 页面可以处理 Bugs、漏洞、异味，可以将它们的状态改为 “解决” 或 “标记为不会修复” 。\n<ul>\n<li>如果关闭了所有严重的问题（允许存在次要问题），相关的评分就会变成 A 。</li>\n</ul>\n</li>\n<li>在 “安全热点” 页面可以处理安全问题，可以将它们的状态改为 “已修复” 或 “安全”。\n<ul>\n<li>如果关闭了所有的安全问题，项目的 “安全复审比率” 就会变成 100% ，评分为 A 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"sonarscanner\"> SonarScanner</h2>\n<p>基本用法：</p>\n<ol>\n<li>从 <a href=\"https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/\" target=\"_blank\" rel=\"noopener noreferrer\">官网</a> 下载 SonarScanner 扫描器的发行版。</li>\n<li>按以下格式执行：<div><pre><code>./sonar-scanner <span>\\</span>\n    -Dsonar.projectKey<span>=</span>test <span>\\</span>                               <span># SonarQube 服务器上的项目名</span>\n    -Dsonar.projectBaseDir<span>=</span>. <span>\\</span>                              <span># 项目的根目录</span>\n    <span># -Dsonar.projectVersion=1.0 \\                          # 项目版本</span>\n    <span># -Dsonar.exclusions=dist \\                             # 不扫描这些目录</span>\n    <span># -Dsonar.sources=src,lib \\                             # 只扫描这些目录（必须在 projectBaseDir 之下）</span>\n    <span># -Dsonar.sourceEncoding=UTF-8 \\                        # 源文件的编码格式</span>\n    -Dsonar.host.url<span>=</span>http://10.0.0.1:9000 <span>\\</span>                 <span># SonarQube 服务器的 URL</span>\n    -Dsonar.login<span>=</span>31bbe4de2a8260ef2f427c6e318f05dbc8e92af6  <span># SonarQube 服务器上的用户密钥</span>\n    <span># -X                                                    # 显示 DEBUG 信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>如果 SonarQube 服务器上不存在该项目，则会自动创建。</li>\n<li>如果该项目的扫描结果没有通过质量阀（quality gate），则 sonar-scanner 命令的返回码为非 0 。</li>\n</ul>\n</li>\n</ol>\n<p>如果项目包含 Java 代码：</p>\n<ul>\n<li>不能直接扫描 .java 文件，需要先编译，再用 <code>-Dsonar.java.binaries=target</code> 命令选项指明 .class 文件的位置，不过这样手动操作很麻烦。</li>\n<li>使用 Maven 等构建工具时，可通过专用的 sonar-scanner 插件扫描，自动定位源文件和类文件。步骤如下：\n<ol>\n<li>安装 Maven 3.x ，并且它使用的 sonar-scanner 插件需要 JRE 11 。比如：<div><pre><code><span>docker</span> run -it --rm <span>\\</span>\n    -v maven-repo:/root/.m2 <span>\\</span>\n    -v <span>$PWD</span>:/app <span>\\</span>\n    --workdir /app <span>\\</span>\n    maven:3.6-jdk-11 <span>bash</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>进入项目目录，开始扫描：<div><pre><code>mvn clean compile\nmvn sonar:sonar <span>\\</span>                             <span># 不必配置 sonar.projectKey ，因为它会根据 pom.xml 自动配置</span>\n    -Dsonar.host.url<span>=</span>http://10.0.0.1:9000 <span>\\</span>\n    -Dsonar.login<span>=</span>31bbe4de2a8260ef2f427c6e318f05dbc8e92af6\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ol>\n</li>\n</ul>\n<p>在 Jenkins 上调用的步骤：</p>\n<ol>\n<li>在 Jenkins 上安装 &quot;SonarQube Scanner for Jenkins&quot; 插件。</li>\n<li>在 Jenkins 的 &quot;Configure System&quot; 页面配置 &quot;SonarQube servers&quot; ，在 &quot;Global Tool Configuration&quot; 页面配置 &quot;SonarQube Scanner&quot; 。</li>\n<li>在 Pipeline 中按如下格式调用：<div><pre><code><span>stage</span><span>(</span><span>'SonarQube analysis'</span><span>)</span> <span>{</span>\n    steps<span>{</span>\n        <span>withSonarQubeEnv</span><span>(</span><span>'SonarQube'</span><span>)</span> <span>{</span>   <span>// 输入已配置的 SonarQube 服务器的名称</span>\n            sh <span>\"\"\"\n                /opt/sonar-scanner/bin/sonar-scanner \\\n                    -Dsonar.projectBaseDir=/root/django\n            \"\"\"</span>\n        <span>}</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div>具体可参考官方教程：<a href=\"https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/\" target=\"_blank\" rel=\"noopener noreferrer\">SonarScanner for Jenkins</a></li>\n</ol>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "测试",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/Test/",
      "id": "/Hardware/DevOps/Test/",
      "content_html": "<h1 id=\"测试\"> 测试</h1>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Artifactory",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/WorkpieceWarehouse/Artifactory.html",
      "id": "/Hardware/DevOps/WorkpieceWarehouse/Artifactory.html",
      "content_html": "<h1 id=\"artifactory\"> Artifactory</h1>\n<p>：一个 Web 服务器，提供了多种格式的工件仓库。</p>\n<ul>\n<li><a href=\"https://www.jfrog.com/confluence/display/RTF6X\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Java 开发，由美国 Jfrog 公司发布。\n<ul>\n<li>分为社区版（OSS）、专业版（PRO）。</li>\n<li>OSS 版只支持创建少数几种仓库。</li>\n</ul>\n</li>\n<li>特点：\n<ul>\n<li>可以通过浏览器访问，也可以生成文件的 URL ，通过 HTTP API 上传、下载文件。</li>\n</ul>\n</li>\n<li>同类产品：\n<ul>\n<li>Nexus ：功能类似，属于竞品。支持多种格式的文件存储，不支持修改文件名、移动文件。</li>\n<li>FTP 服务器：只支持二进制格式的文件存储，而且 FTP 协议比 HTTP 协议的通用性低。</li>\n<li>Nextcloud ：网盘，只支持二进制格式的文件存储，而且访问时需要使用浏览器或专用客户端。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>artifactory</span><span>:</span>\n    <span>container_name</span><span>:</span> artifactory\n    <span>image</span><span>:</span> docker.bintray.io/jfrog/artifactory<span>-</span>oss<span>:</span>7.18.6\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span>JAVA_OPTS</span><span>:</span> <span>-</span>Duser.timezone=GMT+08\n    <span>ports</span><span>:</span>\n      <span>-</span> 8082<span>:</span><span>8082</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./data<span>:</span>/var/opt/jfrog/artifactory\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>需要调整挂载目录的权限：<div><pre><code><span>chown</span> -R <span>1030</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>默认用户名、密码为 admin、password 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"web-ui\"> Web UI</h3>\n<p>Web 页面示例：</p>\n<p><img src=\"./Artifactory_1.png\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>\n<p>在 Web 页面左侧，可选择一个仓库。点击右上角的 &quot;Deploy&quot; 就会弹出一个上传文件的窗口。</p>\n</li>\n<li>\n<p>上传文件时，会根据文件名自动生成上传路径（Target Path）。</p>\n<ul>\n<li>如果已存在该路径的文件，则会覆盖它。</li>\n<li>可以主动设置上传路径，比如划分出子目录。</li>\n</ul>\n</li>\n<li>\n<p>每个文件有一个唯一的 URL ，可供用户上传、下载该文件。</p>\n<ul>\n<li>文件的 URL 等于 <code>仓库 URL + 文件上传路径</code> 。可以从网页上拷贝该 URL ，也可以自己拼凑出来。</li>\n</ul>\n</li>\n<li>\n<p>每个文件会显示其修改时间。</p>\n<ul>\n<li>建议在 General Settings 页面设置 Date Format 为 <code>yyyy-MM-dd HH:mm:ss ZZ</code> 。</li>\n</ul>\n</li>\n<li>\n<p>在浏览器上访问仓库或目录的 URL ，会以 HTML 基本视图显示文件列表。如下：</p>\n<p><img src=\"./Artifactory_2.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n</ul>\n<h3 id=\"仓库\"> 仓库</h3>\n<ul>\n<li>\n<p>管理员可以创建仓库（Repository），设置哪些用户有权向该仓库上传、下载文件。</p>\n</li>\n<li>\n<p>仓库有多种存储类型：</p>\n<ul>\n<li>本地仓库(Local)</li>\n<li>远程仓库(Remote)：通过 URL 拉取其它仓库的内容，缓存到本地。</li>\n<li>虚拟仓库(Virtual)</li>\n</ul>\n</li>\n<li>\n<p>根据存储的文件格式对仓库分类：</p>\n<ul>\n<li>Generic ：按二进制格式保存文件。</li>\n<li>Gradle</li>\n<li>Maven</li>\n</ul>\n</li>\n<li>\n<p>节省存储空间的措施：</p>\n<ul>\n<li>Maven、Gradle 等类型的仓库，可以设置 &quot;Max Unique Snapshots&quot; 参数，只保留每个工件版本最大的 n 个快照（SNAPSHOT）。</li>\n<li>Artifactory Pro 版可以安装 artifactCleanup 插件，定时删除本地仓库中未使用的文件。</li>\n<li>Remote 类型的仓库可以设置 &quot;Unused Artifacts Cleanup Period&quot; 参数，将 n 小时未使用的缓存标记为 Unused 。然后在高级设置 Advanced -&gt; Maintenance 页面，设置定时执行 &quot;Cleanup Unused Cached Artifacts&quot; 。</li>\n<li>默认启用了 Backup 任务，每日备份所有数据库，可在设置页面取消。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"访问控制\"> 访问控制</h3>\n<ul>\n<li>采用基于角色的访问控制。</li>\n<li>默认定义了一个匿名用户（anonymous），代表没有登录的用户。\n<ul>\n<li>可以在 Security -&gt; Settings 页面中允许 &quot;Allow Anonymous Access&quot; 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"restful-api\"> Restful API</h3>\n<ul>\n<li>\n<p>上传文件：</p>\n<div><pre><code><span>curl</span> -u 用户名:密码 <span>'http://10.0.0.1:8082/artifactory/anonymous/test/1.zip'</span> -T <span>1</span>.zip <span>></span> /dev/null\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>下载文件：</p>\n<div><pre><code><span>curl</span> -O -u 用户名:密码 <span>&lt;</span>URL<span>></span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>删除文件：</p>\n<div><pre><code><span>curl</span> -X DELETE -u 用户名:密码 <span>&lt;</span>URL<span>></span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Harbor",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/WorkpieceWarehouse/Harbor.html",
      "id": "/Hardware/DevOps/WorkpieceWarehouse/Harbor.html",
      "content_html": "<h1 id=\"harbor\"> Harbor</h1>\n<p>：一个 Web 服务器，提供了 Docker 镜像仓库。</p>\n<ul>\n<li><a href=\"https://goharbor.io/docs/2.2.0/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Golang 开发，由 VMware 公司开源。</li>\n<li>支持存储 Docker Image 和 Helm Chart 。</li>\n</ul>\n<h2 id=\"同类产品\"> 同类产品</h2>\n<ul>\n<li>Docker Hub\n<ul>\n<li>：Docker 官方的镜像仓库，地址为 <code>https://hub.docker.com</code> 。</li>\n<li>公开的镜像不需登录就可以 Pull ，但 Push 镜像时需要登录。</li>\n</ul>\n</li>\n<li>Docker Registry\n<ul>\n<li>：一个提供私有镜像仓库的服务器，由 Docker 官方开源。</li>\n<li>功能比 Harbor 少，没有提供 Web UI 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>下载官方发行版：<div><pre><code><span>wget</span> https://github.com/goharbor/harbor/releases/download/v2.4.0/harbor-online-installer-v2.4.0.tgz\n</code></pre>\n<div><span>1</span><br></div></div>解压后，使用其中的脚本：<div><pre><code><span>sh</span> install.sh\n              <span># --with-notary       # 启用 notary ，检查镜像的数字签名。这需要 Harbor 采用 HTTPS</span>\n              --with-trivy          <span># 启用 trivy 漏洞扫描器</span>\n              --with-chartmuseum    <span># 启用 Chart 仓库</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>部署之后，会生成一个配置文件 harbor.yml 。</li>\n<li>Harbor 包含 harbor-core、harbor-db、registry、Nginx、Redis 等多个服务，基于 docker-compose 启动。\n<ul>\n<li>不会将日志输出到 docker 容器，而是保存到日志目录。</li>\n<li>部署时至少需要 4G 内存。</li>\n</ul>\n</li>\n<li>修改配置之后需要执行：<div><pre><code>./prepare --with-trivy  --with-chartmuseum\n<span>docker-compose</span> down\n<span>docker-compose</span> up -d\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n<li>用启用 HTTPS 的 Nginx 反向代理 Harbor 时，需要在 Nginx 中加入 <code>proxy_set_header X-Forwarded-Proto $scheme;</code> ，并在 <code>harbor/common/config/nginx/nginx.conf</code> 中删除相同配置。</li>\n</ul>\n<h2 id=\"功能\"> 功能</h2>\n<ul>\n<li>\n<p>项目（Projects）</p>\n<ul>\n<li>\n<p>每个项目是一个命名空间（namespace），其下可以存储多个镜像。</p>\n<ul>\n<li>默认存储在本机文件系统中。以 layer 为单位进行存储，因此存储多个相似的镜像时，只会占用少量存储空间。</li>\n</ul>\n</li>\n<li>\n<p>拉取镜像的命令格式如下：</p>\n<div><pre><code><span>docker</span> pull <span>&lt;</span>harbor_url<span>></span>/<span>&lt;</span>project<span>></span>/<span>&lt;</span>REPOSITORY<span>></span><span>[</span>:tag<span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>每个镜像 Image 划分一个镜像仓库（repository），其下可以存储多个 tag 的镜像。</li>\n<li>网页上显示的镜像大小是压缩之后的。</li>\n</ul>\n</li>\n<li>\n<p>每个项目可以添加多个用户作为成员，担任某种角色。角色按权限从高到低如下：</p>\n<div><pre><code>项目管理员  <span># 可以管理该项目的其他成员</span>\n维护人员    <span># 可以扫描镜像、复制镜像、删除镜像</span>\n开发者      <span># 可以读写镜像</span>\n访客        <span># 只能拉取镜像</span>\n受限访客    <span># 只能拉取镜像</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>如果项目的访问级别为 Private ，则允许被未登录用户拉取镜像。</li>\n</ul>\n</li>\n<li>\n<p>新建项目时，可以设置为对其它远程仓库的 &quot;代理&quot; 。</p>\n<ul>\n<li>当用户请求拉取该项目下的镜像时，会自动从远程仓库拉取同名镜像，并默认缓存 7 天。</li>\n<li>不过，拉取缓存镜像时，需要增加一层路径，声明远程镜像的命名空间。如下：<div><pre><code><span>docker</span> pull <span>&lt;</span>harbor_url<span>></span>/<span>&lt;</span>proxy_project<span>></span>/<span>&lt;</span>remote_namespace<span>></span>/<span>&lt;</span>REPOSITORY<span>></span><span>[</span>:tag<span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>支持设置 Tag 的保留规则、项目的磁盘定额，从而限制存储的镜像数量。</p>\n<ul>\n<li>推送镜像到 Harbor 时，默认会覆盖 image:tag 相同的 artifact 。可以将一些 tag 声明为不可变的，不允许被覆盖、删除。</li>\n</ul>\n</li>\n<li>\n<p>支持漏洞扫描。</p>\n</li>\n<li>\n<p>支持设置 Webhook ：当项目发生 push、pull 等事件时，发送一个 JSON 格式的消息到某个 URL 。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>仓库管理（Registries）</p>\n<ul>\n<li>：用于定义一些远程的仓库服务器，供其它功能调用。</li>\n</ul>\n</li>\n<li>\n<p>复制（Replications）</p>\n<ul>\n<li>：用于在本地 Harbor 仓库与其它远程仓库之间 Push 或 Pull 镜像。</li>\n<li>拉取 Docker Hub 的官方镜像时，需要指定源命名空间为 library ，比如 <code>library/hello-world</code> 。</li>\n<li>Pull 镜像时，如果不指定存储到哪个命名空间，则默认采用源命名空间的名称。\n<ul>\n<li>如果不存在该命名空间则自动创建，且访问级别为 Private 。</li>\n</ul>\n</li>\n<li>Pull 镜像时，指定的源镜像名支持模糊匹配。如下：<div><pre><code>library/*                 <span># 匹配 library 目录下的所有镜像，但不包括子目录</span>\nlibrary/*/*               <span># 匹配两级子目录</span>\nlibrary/**                <span># 匹配所有层级的子目录</span>\nlibrary/hello*            <span># 匹配 library 目录下，以 hello 开头的所有镜像</span>\nlibrary/hello?            <span># ? 匹配单个字符，不包括斜杆 /</span>\n<span>{</span>library,amazon<span>}</span>/**       <span># 匹配多个字符串，用逗号分隔</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>触发复制规则时，会创建一个复制任务，在队列中执行。\n<ul>\n<li>可以手动触发，也可以定时自动触发，或通过事件触发。</li>\n<li>如果任务执行失败，则会在几分钟之后重试。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>机器人账户（Robot）</p>\n<ul>\n<li>：供自动化脚本使用，可用于 docker login 命令，但不能用于访问 Harbor Web 页面。</li>\n</ul>\n</li>\n<li>\n<p>垃圾清理</p>\n<ul>\n<li>当用户删除镜像时，Harbor 并不会在磁盘中实际删除其使用的 layer 。</li>\n<li>可以在 Web 页面上手动执行垃圾清理，或者定时执行，找出可以删除的 layer ，然后删除。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Nexus",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/WorkpieceWarehouse/Nexus.html",
      "id": "/Hardware/DevOps/WorkpieceWarehouse/Nexus.html",
      "content_html": "<h1 id=\"nexus\"> Nexus</h1>\n<p>：NXRM（Nexus Repository Manager），一个 Web 服务器，提供了多种格式的工件仓库。</p>\n<ul>\n<li><a href=\"https://help.sonatype.com/repomanager3\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Java 开发，由 Sonatype 公司开源。\n<ul>\n<li>分为社区版（OSS）、专业版（PRO）。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>nexus</span><span>:</span>\n    <span>container_name</span><span>:</span> nexus\n    <span>image</span><span>:</span> sonatype/nexus3<span>:</span>3.37.3\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span>INSTALL4J_ADD_VM_PARAMS</span><span>:</span> <span>-</span>Xms2703m <span>-</span>Xmx2703m <span>-</span>XX<span>:</span>MaxDirectMemorySize=2703m <span>-</span>Djava.util.prefs.userRoot=/nexus<span>-</span>data/javaprefs\n    <span>ports</span><span>:</span>\n      <span>-</span> 8081<span>:</span><span>8081</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./data<span>:</span>/nexus<span>-</span>data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><ul>\n<li>需要调整挂载目录的权限：<div><pre><code><span>chown</span> -R <span>200</span> <span>.</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>默认用户名为 admin ，初始密码记录在 admin.password 文件中。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"web-ui\"> Web UI</h3>\n<ul>\n<li>\n<p>Nexus 的 Web 页面分为两大区域：</p>\n<ul>\n<li>Browse ：浏览页面，可以对工件进行浏览（呈树形图）、搜索、上传、删除。</li>\n<li>Administration ：后台管理。</li>\n</ul>\n</li>\n<li>\n<p>浏览仓库列表：</p>\n<p><img src=\"./Nexus.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n</ul>\n<h3 id=\"后台管理\"> 后台管理</h3>\n<ul>\n<li>\n<p>在 Repositories 页面可以管理仓库。</p>\n</li>\n<li>\n<p>在 Cleanup Policy 页面可以创建自动清理策略。</p>\n<ul>\n<li>比如 Last Downloaded Before 策略是删除最后下载日期在 n 天以前的工件，但忽略从未下载的工件。</li>\n<li>创建策略之后，需要在某个仓库的配置页面采用。</li>\n</ul>\n</li>\n<li>\n<p>在 Capabilities 页面可以启用一些次要功能。</p>\n</li>\n<li>\n<p>在 Task 页面可以创建多种类型的定时任务，例如：</p>\n<div><pre><code>Admin - Cleanup repositories using their associated policies   <span># 根据 Cleanup Policy 清理各个仓库。默认添加了该任务，每天执行一次</span>\nAdmin - Compact blob store        <span># 压缩 Blob ，这会释放 deleted 文件的存储空间。建议添加该任务</span>\nMaven - Delete SNAPSHOT           <span># 同一快照至少保留 m 个，并根据包名中的时间戳，删除早于 n 天的快照</span>\nMaven - Delete unused SNAPSHOT    <span># 删除超过 n 天未使用（包括上传、下载）的快照</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h3 id=\"仓库\"> 仓库</h3>\n<ul>\n<li>\n<p>根据存储的工件（Component）格式对仓库（Repository）分类：</p>\n<ul>\n<li>关于软件包：\n<ul>\n<li>apt</li>\n<li>conda</li>\n<li>yum</li>\n</ul>\n</li>\n<li>关于代码包：\n<ul>\n<li>go</li>\n<li>maven</li>\n<li>npm</li>\n<li>nuget</li>\n<li>pypi</li>\n<li>r</li>\n<li>rubygems</li>\n</ul>\n</li>\n<li>关于 Docker 镜像：\n<ul>\n<li>docker ：在 Docker 仓库的场景，Nexus 比 Harbor 少了很多功能。</li>\n<li>helm</li>\n</ul>\n</li>\n<li>关于文件：\n<ul>\n<li>gitlfs</li>\n<li>raw ：将工件以二进制形式存储。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>仓库有多种存储类型：</p>\n<ul>\n<li>hosted ：普通仓库。</li>\n<li>proxy ：对远程仓库的代理和缓存。当用户请求下载一个工件时，先尝试从本地缓存获取。如果不存在，则从远程仓库获取并缓存。</li>\n<li>group ：组，可以包含多个任意类型的仓库，在逻辑上合并它们的工件。\n<ul>\n<li>默认创建了 hosted 类型的 maven-releases、maven-snapshots 仓库，proxy 类型的 maven-central 仓库，三者都包含于 group 类型的 maven-public 仓库。</li>\n<li>从 maven-public 仓库下载工件时，会自动到 3 个成员仓库中寻找。但上传工件时，必须区分 maven-releases 和 maven-snapshots 仓库。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>在 Nexus 底层，仓库需要存储在 Blob 中。</p>\n<ul>\n<li>Blob 是在本机或云端创建的存储空间。\n<ul>\n<li>默认创建了一个名为 default 的 Blob ，存储所有仓库。</li>\n</ul>\n</li>\n<li>Blob 采用软删除（soft deleted）。\n<ul>\n<li>删除一个工件时，只是标记为 deleted 状态，但并不会立即释放存储空间。</li>\n</ul>\n</li>\n<li>Blob 分为多种类型：\n<ul>\n<li>File ：存储在本机的文件系统中。</li>\n<li>AWS S3</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"访问控制\"> 访问控制</h3>\n<ul>\n<li>采用基于角色的访问控制。\n<ul>\n<li>默认禁止匿名用户访问。</li>\n<li>每个用户（User）可以分配多个角色（Role），每个角色可以分配多种权限（Privilege）。</li>\n</ul>\n</li>\n<li>权限示例：<div><pre><code>nx-userschangepw      <span># 修改密码</span>\nnx-search-read        <span># 允许搜索</span>\nnx-component-upload   <span># 允许上传</span>\n\nnx-repository-view-*-*-*            <span># 对 nexus 仓库的访问权限：允许对 * 类型的、名为 * 的仓库，进行 * 操作</span>\nnx-repository-view-maven2-*-browse  <span># 允许对 maven2 类型的、名为 * 的仓库，进行 browse 操作</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>对仓库的操作分为：<div><pre><code>browse    <span># 通过 Web UI 浏览</span>\n<span>read</span>      <span># 通过 HTTP 请求读取工件</span>\n<span>add</span>       <span># 通过 HTTP 请求添加工件</span>\nedit\ndelete\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>对于 npm 类型的仓库，需要启用 <code>npm Bearer Token Realm</code> ，提供身份认证的 token 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"restful-api\"> Restful API</h3>\n<ul>\n<li>关于工件的 API ：<div><pre><code>GET     /service/rest/repository/browse/<span>$repository</span>/        <span># 以 HTML 基本视图显示文件列表</span>\n\nGET     /service/rest/v1/components?repository<span>=</span><span>$repository</span>  <span># 列出某个仓库的工件信息，默认只显示第一页</span>\nPOST    /service/rest/v1/components?repository<span>=</span><span>$repository</span>  <span># 上传工件到指定仓库。上传成功时的响应为空</span>\nGET     /service/rest/v1/components/<span>$component_id</span>           <span># 获取指定工件的信息，需要指定工件在所有仓库中的唯一 ID</span>\nDELETE  /service/rest/v1/components/<span>$component_id</span>           <span># 删除工件</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>例：上传一个二进制文件<div><pre><code><span>curl</span> -X POST <span>'http://localhost:8081/service/rest/v1/components?repository=test'</span>\n      -u admin:******\n      -F raw.assetN<span>=</span>@f1         <span># 要上传的文件</span>\n      -F raw.assetN.filename<span>=</span>f1 <span># 上传之后的文件名</span>\n      -F raw.directory<span>=</span>/        <span># 上传之后的保存目录</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "工件仓库",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/WorkpieceWarehouse/",
      "id": "/Hardware/DevOps/WorkpieceWarehouse/",
      "content_html": "<h1 id=\"工件仓库\"> 工件仓库</h1>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "DevOps",
      "url": "https://hsaio.codenoob.top/Hardware/DevOps/",
      "id": "/Hardware/DevOps/",
      "content_html": "<h1 id=\"devops\"> DevOps</h1>\n<p><a href=\"./\">《DevOps》</a></p>\n<ul>\n<li>CI/CD\n<ul>\n<li><a href=\"./CI-CD/Git.html\">Git</a></li>\n<li><a href=\"./CI-CD/GitLab.html\">GitLab</a></li>\n<li><a href=\"./CI-CD/GitHub.html\">GitHub</a></li>\n<li><a href=\"./CI-CD/Jenkins.html\">Jenkins</a>\n<ul>\n<li><a href=\"./CI-CD/Jenkinsfile.html\">Jenkinsfile</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>测试\n<ul>\n<li><a href=\"./Test/Selenium.html\">Selenium</a></li>\n<li><a href=\"./Test/SonarQube.html\">SonarQube</a></li>\n</ul>\n</li>\n<li>容器\n<ul>\n<li><a href=\"./Container/\">简介</a></li>\n<li><a href=\"./Container/Docker/\">Docker</a>\n<ul>\n<li><a href=\"./Container/Docker/Principle.html\">原理</a></li>\n<li><a href=\"./Container/Docker/Container.html\">Container</a></li>\n<li><a href=\"./Container/Docker/mirror.html\">镜像</a></li>\n<li><a href=\"./Container/Docker/Dockerfile.html\">Dockerfile</a></li>\n<li><a href=\"./Container/Docker/Docker-Compose.html\">Docker Compose</a></li>\n</ul>\n</li>\n<li><a href=\"./Container/k8s/Kubernetes.html\">Kubernetes</a>\n<ul>\n<li><a href=\"./Container/k8s/deploy.html\">部署</a></li>\n<li><a href=\"./Container/k8s/Pod.html\">Pod</a></li>\n<li><a href=\"./Container/k8s/Network.html\">Network</a></li>\n<li><a href=\"./Container/k8s/Volume.html\">Volume</a></li>\n<li><a href=\"./Container/k8s/Plugin.html\">插件</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>配置管理\n<ul>\n<li><a href=\"./ConfigurationManagement/\">简介</a></li>\n<li><a href=\"./ConfigurationManagement/Ansible.html\">Ansible</a></li>\n<li><a href=\"./ConfigurationManagement/Jumpserver.html\">Jumpserver</a></li>\n<li><a href=\"./ConfigurationManagement/Supervisor.html\">Supervisor</a></li>\n<li><a href=\"./ConfigurationManagement/Consul.html\">Consul</a></li>\n<li><a href=\"./ConfigurationManagement/Nacos.html\">Nacos</a></li>\n</ul>\n</li>\n<li>工件仓库\n<ul>\n<li><a href=\"./WorkpieceWarehouse/Artifactory.html\">Artifactory</a></li>\n<li><a href=\"./WorkpieceWarehouse/Nexus.html\">Nexus</a></li>\n<li><a href=\"./WorkpieceWarehouse/Harbor.html\">Harbor</a></li>\n</ul>\n</li>\n<li>监控告警\n<ul>\n<li><a href=\"./MonitoringAlarms/\">简介</a></li>\n<li><a href=\"./MonitoringAlarms/Grafana.html\">Grafana</a></li>\n<li><a href=\"./MonitoringAlarms/Zabbix.html\">Zabbix</a></li>\n<li><a href=\"./MonitoringAlarms/Prometheus/\">Prometheus</a>\n<ul>\n<li><a href=\"./MonitoringAlarms/Prometheus/exporter.html\">exporter</a></li>\n<li><a href=\"./MonitoringAlarms/Prometheus/Pushgateway.html\">Pushgateway</a></li>\n<li><a href=\"./MonitoringAlarms/Prometheus/Alertmanager.html\">Alertmanager</a></li>\n<li><a href=\"./MonitoringAlarms/Prometheus/monitorK8s.html\">监控 k8s</a></li>\n</ul>\n</li>\n<li><a href=\"./MonitoringAlarms/ELK/\">ELK</a>\n<ul>\n<li><a href=\"./MonitoringAlarms/ELK/Kibana.html\">Kibana</a></li>\n<li><a href=\"./MonitoringAlarms/ELK/Filebeat.html\">Filebeat</a></li>\n<li><a href=\"./MonitoringAlarms/ELK/Logstash.html\">Logstash</a></li>\n<li><a href=\"./MonitoringAlarms/ELK/OpenSearch.html\">OpenSearch</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>其它\n<ul>\n<li><a href=\"./Other/VSCode.html\">VS Code</a></li>\n<li><a href=\"./Other/YApi.html\">YApi</a></li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "BTC",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Blockchain/BTC.html",
      "id": "/Hardware/Distributed/Blockchain/BTC.html",
      "content_html": "<h1 id=\"btc\"> BTC</h1>\n<p>：比特币（Bitcoin），一种数字货币，由 BTC 区块链发行。</p>\n<ul>\n<li><a href=\"https://developer.bitcoin.org/devguide/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n</ul>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>一些主机根据 BTC 协议相互通信，组成了 BTC 网络。这些主机称为 BTC 节点。</li>\n<li>在区块链中存储所有交易信息。\n<ul>\n<li>每个节点上会存储一个区块链的完整副本。</li>\n<li>一些节点会收集网络上广播的交易，打包写入最新的一个区块，然后将新区块广播给其它节点。</li>\n<li>基于 PoW 共识算法决定哪个节点有权生成最新的一个区块。</li>\n</ul>\n</li>\n<li>用户可以运行专门的程序，作为节点，接入 BTC 网络。然后下载区块链，查询历史交易，或者广播新交易。</li>\n</ul>\n<h2 id=\"区块\"> 区块</h2>\n<ul>\n<li>\n<p>如下图，一条区块链由多个区块串联组成，后一个区块会记录前一个区块的哈希值，构成哈希链。\n<img src=\"./block_chain.jpg\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>哈希运算时采用 SHA256 算法。</li>\n<li>存储字节流时采用小端序。</li>\n<li>每个区块最多允许包含 1MB 的数据，超过则视作无效区块。</li>\n<li>区块高度（Height）：从最早一个区块往后数，给各个区块分配一个从 0 开始递增的编号，用于索引。</li>\n<li>区块深度（Depth）：从最新一个区块往前数，给各个区块分配一个从 1 开始递增的编号。\n<ul>\n<li>假设区块链的总高度为 H ，则对于高度为 h 的区块，其深度为 H-h+1 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>一个区块的数据结构分为两部分：</p>\n<ul>\n<li>header ：用于存储该区块的元数据。</li>\n<li>body ：用于存储交易信息。</li>\n</ul>\n</li>\n<li>\n<p>区块 header 的长度固定为 80 bytes ，按顺序记录以下信息：</p>\n<ul>\n<li>nVersion\n<ul>\n<li>：区块链协议的版本。</li>\n<li>4 bytes ，int32_t 。</li>\n</ul>\n</li>\n<li>previous block header hash\n<ul>\n<li>：上一个区块的 header 的哈希值。用于确保它们不会被篡改。</li>\n<li>32 bytes ，char[32] 。</li>\n</ul>\n</li>\n<li>merkle root hash\n<ul>\n<li>：当前区块 body 中所有交易信息的 Merkle Tree 的根哈希。用于确保它们不会被篡改。</li>\n<li>32 bytes ，char[32] 。</li>\n</ul>\n</li>\n<li>timestamp\n<ul>\n<li>：矿工打包当前区块时的 Unix time 时间戳。必须大于前 11 个区块的平均时间戳、不大于当前实际时间 +2 小时。</li>\n<li>4 bytes ，uint32_t 。</li>\n</ul>\n</li>\n<li>nBits（target threshold）\n<ul>\n<li>：nonce 的目标阈值。</li>\n<li>4 bytes ，uint32_t 。</li>\n</ul>\n</li>\n<li>nonce\n<ul>\n<li>：一个随机数。</li>\n<li>4 bytes ，uint32_t 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"账户\"> 账户</h2>\n<ul>\n<li>\n<p>BTC 协议中，用户可以根据 ECDSA 算法随机生成一对私钥、公钥，代表一个 BTC 账户，相当于一个银行账户的密码、账户名。</p>\n<ul>\n<li>示例：<div><pre><code>0xL3HpQs5M7tZLN1m6zmJ9YSPuFzA4gJDJy8Ru2hd5nAwcZC4tPm1T  <span># 私钥</span>\n0x1N8nCD314Z87BgYsK1y3vwRpAk8S1qbRcg                    <span># 公钥</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>前缀 0x 表示十六进制。</li>\n<li>私钥需要保密，而公钥公开给其他人。</li>\n</ul>\n</li>\n<li>BTC 采用椭圆曲线数字签名算法（ECDSA）生成数字签名，其中采用的椭圆曲线为 secp256k1 。\n<ul>\n<li>用户可以编写一个消息，将消息的哈希值用私钥加密之后公布，称为数字签名。其他人可使用对应的公钥解读数字签名，从而验证该消息的内容没有被篡改，并且是由该公钥对应的私钥签署的。</li>\n</ul>\n</li>\n<li>BTC 协议中，账户之间可以直接转账交易，只需用账户私钥生成交易的数字签名，相当于盖章授权。\n<ul>\n<li>不需要经过银行等第三方平台中转，实现了去中心化交易。</li>\n</ul>\n</li>\n<li>虚荣地址（Vanity Addresses）：虽然 BTC 私钥、公钥是随机的，但用户可以尝试生成大量私钥、公钥，直到公钥中包含有意义的单词，比如 ILoveU 。</li>\n<li><a href=\"https://www.bitaddress.org/\" target=\"_blank\" rel=\"noopener noreferrer\">bitaddress</a> ：一个网站，用于随机生成 BTC 账户，支持离线使用。</li>\n</ul>\n</li>\n<li>\n<p>生成一对私钥、公钥的步骤：</p>\n<ol>\n<li>\n<p>用户生成一个很大的随机整数，作为私钥（private key）。</p>\n<ul>\n<li>私钥的长度为 256 bits = 32 bytes  。通常经过 Base58Check 编码，表示成 52 位长度的十六进制数。</li>\n<li>用户选择私钥时应该尽量随机，避免与其他人相同。</li>\n</ul>\n</li>\n<li>\n<p>根据 ECDSA 算法，计算出私钥在椭圆曲线上对应的一个点，其坐标 x、y 作为公钥。</p>\n<ul>\n<li>通过私钥可以计算出对应的公钥，但不能通过公钥反推出私钥。而且值域庞大，使得穷举几乎不可能。</li>\n<li>未压缩公钥（uncompressed）：由坐标 x、y 的值组成，并加上前缀 0x04 作为标识，总长度为 1+32+32 = 65 bytes 。</li>\n<li>压缩公钥（compressed）：由坐标 x 的值组成，并加上前缀 0x02 或 0x03 表示坐标 y 为偶数或奇数，总长度为 33 bytes 。\n<ul>\n<li>椭圆曲线关于 x 轴对称，一个坐标 x 对应两个 y 点。且在 secp256k1 曲线中，这两个 y 点分别为偶数、奇数，因此需要通过前缀区分。</li>\n<li>使用压缩公钥时，需要给私钥加上后缀 0x01 作为标识，其长度增加 1 字节。</li>\n<li>压缩格式的公钥、私钥更方便记录，是用户通常看到的格式，也是一般钱包采用的导入格式（Wallet Import Format，WIF）。</li>\n<li>钱包软件在实际使用公钥时，会从压缩格式转换成非压缩格式。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>计算压缩公钥的 SHA256 哈希值，再计算其结果的 RIPEMD-160 哈希值。</p>\n</li>\n<li>\n<p>将公钥哈希值（public key hash）经过 Base58Check 编码，表示成 34 位长度的十六进制数，称为账户地址（address）。</p>\n</li>\n</ol>\n</li>\n<li>\n<p>Base58Check 编码是为了将数据表示成更短的值，并加上校验码，并不会加密原数据。过程如下：</p>\n<ol>\n<li>输入原数据 payload 。</li>\n<li>在 payload 之前加上 1 字节的地址版本号 version 。</li>\n<li>对 version、payload 串联成一个字符串，计算两次哈希值，取结果开头的 4 字节作为校验码 checksum 。\n<ul>\n<li>如果网络传输之后，再次计算两次哈希值，发现结果开头与校验码不一致，则说明编码值出错。</li>\n</ul>\n</li>\n<li>将 version、payload、checksum 串联成一个字符串，进行 base58 编码。\n<ul>\n<li>与 base64 相比，base58 的特点：\n<ul>\n<li>移除了 <code>+/</code> 两个特殊字符，只允许使用大小写字母、数字。</li>\n<li>移除了 <code>0OIi</code> 四个容易混淆的字母。</li>\n</ul>\n</li>\n<li>P2PKH 地址的 version 为 0x00 ，因此编码之后，开头为 1 。</li>\n<li>P2SH 地址的 version 为 0x05 ，因此编码之后，开头为 3 。</li>\n<li>BTC 私钥的 version 为 0x80 ，因此编码之后，未压缩格式的开头为 5 ，压缩格式的开头为 K 或 L 。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"交易\"> 交易</h2>\n<ul>\n<li>\n<p>一个交易（transaction）记录成特定格式的数据，像账本中的一条记录，主要包含以下信息：</p>\n<ul>\n<li>version ：交易格式的版本号，占 4 bytes 。</li>\n<li>in-counter ：表示输入项的数量。</li>\n<li>inputs ：包含 n≥1 个输入项。\n<ul>\n<li>每个输入项的主要内容：\n<ul>\n<li>index ：输入项在 inputs 中的序号，从 0 开始递增。</li>\n<li>previous txid ：引用一个历史交易，表示将该交易的 UTXO 全部输入当前交易。</li>\n<li>sigScript</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>out-counter ：表示输出项的数量。</li>\n<li>outputs ：包含 n≥1 个输出项。\n<ul>\n<li>每个输出项的主要内容：\n<ul>\n<li>index</li>\n<li>value ：输出的 BTC 数量。</li>\n<li>pkScript</li>\n</ul>\n</li>\n<li>一个交易的总输入减去总输出的差值，会被矿工当作交易费拿走，即 <code>fee = sum(inputs) – sum(outputs)</code> 。</li>\n</ul>\n</li>\n<li>locktime ：表示允许将该交易打包到区块中的最早时间，占 4 bytes 。\n<ul>\n<li>如果取值小于 5 亿，则视作区块高度。</li>\n<li>如果取值大于 5 亿，则视作 Unix 时间戳。</li>\n<li>交易通常将 locktime 设置为 0x00000000 ，表示不限制。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>区块 body 中可以记录 n≥1 个交易，最大数量取决于区块的容量限制。</p>\n<ul>\n<li>记录的第一个交易必须是 coinbase 交易。\n<ul>\n<li>coinbase 交易不存在输入，凭空产生一定量可以输出的 BTC ，作为打包该区块的网络节点的激励。</li>\n</ul>\n</li>\n<li>coinbase 交易之后可以记录 m≥0 个普通交易。\n<ul>\n<li>通常采用交易的哈希值作为其标识符，称为 txid 。</li>\n<li>BTC 交易时，最小的单位为聪（satoshis），1 BTC = 10^8 聪。</li>\n</ul>\n</li>\n<li>一个交易数据的体积没有上限，只受到区块的容量限制。\n<ul>\n<li>增加交易体积时，通常需要增加交易费，吸引矿工打包该交易。</li>\n<li>通常以 satoshi/Byte 为单位计算平均的交易费。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"发起交易\"> 发起交易</h3>\n<ul>\n<li>\n<p>如果一个账户拥有一些 BTC ，则可以发起一个交易，输入一些 BTC ，然后输出给其它账户。</p>\n<ul>\n<li>所有账户收到的 BTC ，都来自历史交易的输出，且源头都是 coinbase 交易。</li>\n<li>如果一个交易输出的 BTC ，尚未被目标账户花费，则称为未花费交易输出（Unspent TX Output，UTXO）。\n<ul>\n<li>一个账户拥有的所有 UTXO 总和，称为该账户的余额。</li>\n<li>一个交易的 UTXO 要么不被花费，要么被一次性全部花费，不能拆开花费。\n<ul>\n<li>例如 UTXO 为 5 BTC 时，用户可以新建一个交易，发送 1 BTC 给别人，然后将剩下的 BTC 发送给自己，从而实现找零。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>统计 BTC 区块链上所有交易的输入、输出，筛选出所有 UTXO ，保存为一个数据库，就可以知道所有账户的余额。\n<ul>\n<li>BTC 协议并没有直接提供 UTXO 数据库，但一些区块链浏览器提供了这种查询功能。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>用户发起一个交易的步骤：</p>\n<ol>\n<li>编写一个交易。\n<ul>\n<li>此时需要连接到 BTC 网络，获取最新的区块链数据，从中查询账户的历史交易，选择将哪些交易的 UTXO 作为当前交易的输入。</li>\n</ul>\n</li>\n<li>生成交易的 sigScript ，存放在交易的 inputs 中。</li>\n<li>将交易广播到 BTC 网络上，等待矿工将它打包入新区块。</li>\n</ol>\n</li>\n<li>\n<p>用户广播一个交易之后，需要等待矿工将它写入区块，才算交易成功。分为多个阶段：</p>\n<ul>\n<li>0 次确认\n<ul>\n<li>：交易还没有被写入区块。</li>\n</ul>\n</li>\n<li>1 次确认\n<ul>\n<li>：交易被写入最新的一个区块。</li>\n<li>但可能有多个矿工同时打包出不同的最新区块，需要等待哪个最新区块最终被大部分矿工承认，因此交易还不算持久保存到区块链。</li>\n</ul>\n</li>\n<li>2 次确认\n<ul>\n<li>：交易被写入一个区块，该区块的深度为 2 。</li>\n<li>BTC 网络中，篡改最近的两个区块需要超过 50% 的哈希算力，成本很大，因此一般可靠。</li>\n</ul>\n</li>\n<li>6 次确认\n<ul>\n<li>：交易被写入一个区块，该区块的深度为 6 ，几乎不可能被篡改。</li>\n<li>由于 BTC 平均每隔 10 分钟生成一个区块，6 次确认需要等待 60 分钟。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>双花：一种攻击方式，指将同一个 UTXO 花费多次。</p>\n<ul>\n<li>攻击方式举例：\n<ul>\n<li>一个不诚实的用户，同时广播多个交易，重复花费同一个 UTXO 。此时，诚实的矿工只会将其中一个交易写入新区块，将之后的交易视作无效。因此双花攻击无效。</li>\n<li>一个不诚实的矿工，明知当前区块链高度为 N ，但依然从高度 N-i 处重新生成一条区块链，从而重写最近 i 个历史区块中的交易。<br>\n此时网络上同时存在新链和原链。根据 BTC 协议，所有矿工应该在最长的那条区块链上工作。不诚实的矿工需要掌握全网哈希算力的 50% 以上，使得新链生成新区块的速度比原链更快，在一段时间之后长度超越原链。<br>\n因此这种双花攻击几乎不可能，需要消耗大量哈希算力和时间成本。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"pkscript\"> pkScript</h3>\n<p>：公钥脚本（Pubkey Script，pkScript），采用一种专用的脚本语言编写，包含一些指令。</p>\n<ul>\n<li>该脚本语言的特点：\n<ul>\n<li>基于堆栈。</li>\n<li>非图灵完备，不支持循环。因此不能实现复杂的逻辑，但减少了出错的可能性。</li>\n</ul>\n</li>\n<li>pkScript 可以声明一些条件，当 sigScript 满足条件时才能花费其 UTXO 。\n<ul>\n<li>例如 P2PKH 的条件通常是：输出 n 个 BTC ，并指定一个公钥。只有拥有该公钥对应私钥的人，才有权花费该 UTXO 。</li>\n</ul>\n</li>\n<li>pkScript 又称为锁定脚本（locking script），因为它输出的 BTC 一直不可用，直到有人提供满足条件的 sigScript ，又称为解锁脚本。</li>\n</ul>\n<p>pkScript 有多种类型：</p>\n<ul>\n<li>Pay To Pubkey（P2PK）\n<ul>\n<li>：将 BTC 转账给公钥。</li>\n</ul>\n</li>\n<li>Pay To Public Key Hash（P2PKH）\n<ul>\n<li>：将 BTC 转账给公钥哈希。</li>\n<li>P2PK 常用于 BTC 早期的交易，后来被 P2PKH 取代。主要原因：\n<ul>\n<li>P2PKH 地址更短。</li>\n<li>转账给 P2PKH 地址时，采用公钥哈希，隐藏了公钥，提供了额外的安全性。直到用户花费该账户时，才会公开公钥。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Pay To Script Hash（P2SH）\n<ul>\n<li>：将 BTC 转账给脚本哈希。\n<ul>\n<li>如果其他人提供的 sigScript 中，包含与 P2SH 哈希一致的脚本，称为赎回脚本（redeem script），则有权花费该 UTXO 。</li>\n</ul>\n</li>\n<li>基于赎回脚本可实现复杂的功能，例如多重签名、SegWit 兼容地址。</li>\n</ul>\n</li>\n<li>Pay to Witness Pubkey Hash（P2WPKH）\n<ul>\n<li>：与 P2PKH 类似，但启用了 SegWit 。</li>\n</ul>\n</li>\n<li>Pay to Witness Script Hash（P2WSH）</li>\n<li>Null Data（空数据）\n<ul>\n<li>：pkScript 的开头是一个操作符 OP_RETURN ，表示终止脚本执行。\n<ul>\n<li>OP_RETURN 之后可以添加任意内容的数据，反正不会被执行。</li>\n<li>该交易的 UTXO 不能被花费。</li>\n</ul>\n</li>\n<li>BTC 区块链原本用于记录交易信息，但一些用户想用区块链记录自定义的数据，比如一段文字广告。\n<ul>\n<li>有的用户在 coinbase 交易的剩余位置记录自定义数据。</li>\n<li>有的用户在普通交易的 pkScript 位置记录自定义数据，导致该交易被发送到无效地址，不能花费 UTXO 。</li>\n<li>推荐用户使用 OP_RETURN 记录自定义数据，此时将 UTXO 设置为 0 ，只需支付交易费。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"sigscript\"> sigScript</h3>\n<p>：签名脚本（Signature Script，sigScript）。</p>\n<ul>\n<li>sigScript 包含以下内容：\n<ul>\n<li>pubKey ：账户公钥。</li>\n<li>sig ：交易数据的数字签名，使用账户私钥生成。</li>\n</ul>\n</li>\n<li>交易延展性（Transaction Malleability）攻击\n<ul>\n<li>：一种攻击方式，指改变未打包交易中的签名，使得整个交易的哈希值改变，导致引用该交易 txid 的其它交易失效。\n<ul>\n<li>由于椭圆曲线的对称性，可以计算出两个有效的签名，还可以根据其中一个签名推算出另一个签名。因此，可以替换交易中的签名。</li>\n</ul>\n</li>\n<li>常见的解决办法：\n<ul>\n<li>等待一个交易被打包，再引用它的 txid 。但这就不能实现闪电交易。</li>\n<li>规定只采用取值较小的那个签名。</li>\n<li>使用 SegWit 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"segwit\"> SegWit</h3>\n<p>：隔离见证，一种 BTC 的扩容方案，属于软分叉升级。</p>\n<ul>\n<li>\n<p>原理：给区块附加一个称为 witness 的结构，将交易中的见证数据（主要包含 sigScript ）移出，存放在 witness 区域。</p>\n<ul>\n<li>这会减小交易的一大半体积，可以在区块中打包更多交易。</li>\n<li>witness 区域的 tree 哈希记录在 coinbase 交易中，从而嵌入 Merkle Tree 。</li>\n<li>此时的区块称为 SegWit 格式。基础容量（称为 size ）依然限制为 1MB ，附加 witness 数据时的总体积（称为 weight ）限制为 4MB 。</li>\n<li>此时交易的哈希值称为 wtxid 。改变 sigScript 时，不会影响 wtxid ，避免了 Transaction Malleability 攻击。</li>\n</ul>\n</li>\n<li>\n<p>使用 SegWit 时，账户地址有两种格式：</p>\n<ul>\n<li>原生地址（Native）：采用 Bech32 编码格式，只允许使用小写字母、数字，长度为 42 位，开头为 bc1 。</li>\n<li>兼容地址（Nested）：采用 P2SH 地址，开头为 3 。\n<ul>\n<li>原生地址地址的效率比兼容地址更高。</li>\n<li>传统地址（Legacy）不支持与 SegWit 原生地址转账。</li>\n<li>SegWit 兼容地址支持与传统地址、SegWit 原生地址转账。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>SegWit 软分叉还涉及到 BTC 社区的治理问题，相关历史：</p>\n<ul>\n<li>2015 年，Bitcoin Core 开发人员提出了 BIP141 ，提议 SegWit ，是此时 BTC 变动最大的一次软分叉升级。</li>\n<li>2016 年，Bitcoin Core 按 BIP9 方式开始 SegWit 软分叉，但支持 SegWit 的矿工远未达到 95% 的激活阈值，主要原因：\n<ul>\n<li>SegWit 尚未推广，早期升级的收益较小。</li>\n<li>旧区块可通过 AsicBoost 算法提高挖矿的哈希算力。</li>\n<li>SegWit 增加了区块的复杂性，需要修改很多客户端代码，不如硬分叉简单。</li>\n</ul>\n</li>\n<li>2017 年 2 月，社区的开发人员提出了 BIP148 ，提议用户激活软分叉（User Activated Soft Fork，UASF），逼迫矿工激活 SegWit 。\n<ul>\n<li>BIP148 大意为：从 8 月开始，采用 BIP148 的节点会拒绝不支持 SegWit 的新区块，导致发生硬分叉。</li>\n<li>BIP9 让矿工投票决定软分叉升级，而 UASF 使得用户也拥有了控制权。但这更像一个抗议行动，不支持的矿工只是少了打包这部分用户的交易费。</li>\n</ul>\n</li>\n<li>2017 年 4 月，Charlie Lee 与矿工协商之后，成功在 LTC 上激活 SegWit 。</li>\n<li>2017 年 5 月，一些公司和矿池签署了纽约共识（New York Agreement，NYA），表示作为激活 SegWit 的交换，要求也激活 SegWit2x 。\n<ul>\n<li>原理：与 SegWit 不同，直接将区块的基础容量限制从 1MB 增加到 2MB ，属于硬分叉升级</li>\n<li>SegWit2x 与 BCH 的区块扩容类似，受到 Bitcoin Core 开发人员的反对，最终在 11 月放弃了该提议。</li>\n</ul>\n</li>\n<li>2017 年 5 月，一个开发人员提出了 BIP91 ，使得 BIP148 与 SegWit2x 两派可以兼容，避免发生硬分叉。\n<ul>\n<li>BIP91 的内容与 BIP148 相似，但没有限制时间。</li>\n<li>BIP91 部署之后，激活它的阈值为 80% 。当 BIP141 被激活或失败时，BIP91 就会停止。</li>\n</ul>\n</li>\n<li>2017 年 7 月，市场担心 BIP148 硬分叉的风险，BTC 价格从 $2700 跌到 $2000 ，促使矿工们支持 BIP91 并激活它。</li>\n<li>2017 年 8 月，SegWit2x 终于激活。\n<ul>\n<li>此时，大部分矿工、钱包软件依然没有升级 SegWit 。但是采用 SegWit 原生地址的用户越来越多，为了服务这部分用户，矿工、钱包软件会逐渐升级 SegWit 。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"合约交易\"> 合约交易</h2>\n<p>基于 P2SH 脚本可实现一些合约交易，提供多种功能。</p>\n<h3 id=\"多重签名\"> 多重签名</h3>\n<p>：多重签名（multi-signature，multisig），一种基于 P2SH 的交易方式。</p>\n<ul>\n<li>原理：将 BTC 转账到一个 P2SH 地址，通过 pkScript 指定 n 个公钥，要求 sigscript 至少用 m 个对应的私钥签名才有效。\n<ul>\n<li>其中 1≤m≤n≤15 ，又称为 m-of-n 交易。</li>\n</ul>\n</li>\n<li>1of2 是允许两个账户中的任意一个都有权花费 UTXO 。</li>\n<li>2of3 适合三方交易。例如 A 想花费 BTC 从 B 处购买商品，先将 BTC 转账到 2of3 多签地址。\n<ul>\n<li>如果仲裁方判断交易成功，则与 B 一起签名，将 BTC 转账给 B 。</li>\n<li>如果仲裁方判断交易失败，则与 A 一起签名，将 BTC 转账给 A 。</li>\n<li>没有 A 或 B 的同意，仲裁方不能私自转走 BTC 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"闪电交易\"> 闪电交易</h3>\n<p>：闪电交易（Lightning Network，LN），一种 layer2 技术，基于链下交易（Off-Chain）。</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/lightning/bolts\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></p>\n</li>\n<li>\n<p>原理：在区块链下进行任意数量的交易，然后将这些交易的结果保存到区块链。主要步骤如下：</p>\n<ol>\n<li>开启通道：两个账号将一笔 BTC 转账到一个多签地址，暂时锁定，称为开启一个闪电交易通道（channel）。</li>\n<li>使用通道：双方建立对等连接（Peer connection），私下进行一些交易。</li>\n<li>关闭通道：双方根据交易结果，将多签地址的 BTC 分配给双方。</li>\n</ol>\n</li>\n<li>\n<p>在通道中，双方私下进行的交易只需要互相知道，不必公布到区块链上，称为承诺交易（commitment transaction）。</p>\n<ul>\n<li>每个承诺交易，表示此时的通道状态，即双方应该分别拥有通道的多少 UTXO 。</li>\n<li>每创建一个新的承诺交易，就撤销旧的承诺交易。\n<ul>\n<li>为此双方要交换一个承诺撤销密钥，证明它已撤销。</li>\n<li>如果一方将已撤销的承诺交易广播到链上，企图双花攻击。则另一方可以根据撤销密钥，广播一个更新的惩罚交易（Penalty transaction），将通道的全部资产转给自己。</li>\n</ul>\n</li>\n<li>每个承诺交易设置了 locktime ，如果某方离线，则另一方等待 locktime 时间之后就可以将承诺交易公布到链上，从而关闭通道。\n<ul>\n<li>每个承诺交易的 locktime 依次递减，因此越新的承诺交易能越早公布到链上。</li>\n<li>准备关闭通道时，双方签署最后一笔承诺交易，立即公布到链上。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>闪电交易通道只能连通两个账户，但大量相互开启通道的账户可以组成闪电交易网络。</p>\n<ul>\n<li>假设 A 与 B 之间存在通道，B 与 C 之间存在通道，则 A 可以通过 B 间接转账给 C 。此时 B 称为路由节点，像计算机网络的路由转发。</li>\n<li>哈希时间锁定合约（Hash Time Locked Contracts，HTLC）：一种智能合约，用于保证路由节点的可信任。工作流程如下：\n<ol>\n<li>A 创建一个密钥 secret ，私下发送给 C 。</li>\n<li>A 在 A、B 之间的通道，使用 secret 的哈希值签署一个 HTLC 合约，将 BTC 转入合约。合约大意为：如果 B 能在 locktime 时间内发现 secret ，则有权获得合约的 UTXO ，否则资金将返回给 A 。</li>\n<li>B 在 B、C 之间的通道，也创建一个使用同样 secret 哈希值的 HTLC 合约，请求 C 提供 secret 。但是合约锁定的 UTXO 微少一点，因为 B 收取了交易费。locktime 也更短一点。</li>\n<li>C 提供 secret ，完成 B 的 HTLC 合约，得到 UTXO 。然后 B 再提供 secret ，完成 A 的 HTLC 合约。\n<ul>\n<li>即使 B 下线，C 依然可以完成 B 的 HTLC 合约，只有 B 会受到损失。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>一些大型的路由节点可连接大量用户，像中心化网络。</li>\n<li>一些路由节点会担任瞭望塔（watchtower），监控网络，广播惩罚交易。</li>\n</ul>\n</li>\n<li>\n<p>优点：</p>\n<ul>\n<li>能快速处理大量新交易。</li>\n<li>交易费很低：支付给路由节点的费用很低，适合以 satoshis 为单位的小额交易。</li>\n<li>耗时短：每个交易不超过一分钟，不需要等待区块链打包、确认。</li>\n<li>隐私：只有开启通道、关闭通道的两次交易需要公布到链上，期间的交易不会上链，路由节点也不会知道整个交易的源头、终点。</li>\n<li>通道中的交易不必打包到区块链，因此节省了区块空间，降低了区块链的负载。</li>\n</ul>\n</li>\n<li>\n<p>相关历史：</p>\n<ul>\n<li>2017 年 5 月，LTC 区块链进行了第一次闪电交易。</li>\n<li>2019 年 1 月，twitter 用户发起了一场称为闪电火炬（Lightning Torch）的行动，用于推广闪电交易。\n<ul>\n<li>规则：通过闪电交易发送一笔小额 BTC ，收到转账的账户添加 10w satoshis 之后再发送给下一个账户，以此类推。</li>\n<li>这笔 BTC 传递了将近 300 次，最终被捐赠。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"coinjoin\"> CoinJoin</h3>\n<p>：一种混币方案。</p>\n<ul>\n<li>\n<p>原理：n 个账户共同发起一笔 BTC 交易，分别输入 C 数量的 BTC ，然后分别输出 C 数量到 n 个账户。</p>\n<ul>\n<li>如果输出账户与输入账户都是不同的地址，则难以确定它们之间的对应关系。</li>\n<li>n 的数量越大，混淆度越高。</li>\n</ul>\n</li>\n<li>\n<p>假设用户 A 参与了一次 CoinJoin 混币，从自己的一个账户发送 BTC 到自己的另一个账户。</p>\n<ul>\n<li>虽然混币交易是公开的，其他人知道了 A 参与了混币，但并不知道哪个输出账户是由 A 控制，任意一个输出账户是由 A 控制的概率为 1/n 。</li>\n<li>因此即使输入账户暴露了现实身份，输出账户也重新得到了匿名性。</li>\n</ul>\n</li>\n<li>\n<p>BTC 账户具有匿名性，但账户的交易过程、余额都是公开的，难以保护隐私。</p>\n<ul>\n<li>例如用户 A 使用一个 BTC 账户在网上购物，转账记录都是公开的，其他人可以知道他购买的所有商品，推测他的消费习惯、个人喜好。\n<ul>\n<li>如果购物时的 IP 地址、物流信息被泄露，账户就失去了匿名性。即使 A 将 BTC 转入其它账户，其他人也知道新账户的地址，推测新账户很可能属于他。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>混币（Coin Mixing）</p>\n<ul>\n<li>：指混淆多个账户的交易过程，使得难以确定每个账户的收入来自哪个账户、支出去向哪个账户，只能知道每个账户收入、支出的数量以及余额。</li>\n<li>常见的混币方案：\n<ul>\n<li>通过第三方平台转账：比如将币转入中心化交易所，再由从交易所转出到其它账户地址。但这样需要担心交易所的提现风险，而且交易所也能查出交易过程、记录 KYC 信息。</li>\n<li>CoinJoin</li>\n</ul>\n</li>\n<li>闪电交易也加强了隐私，但并不属于混币，而是避免交易过程上链。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"网络\"> 网络</h2>\n<ul>\n<li>\n<p>一些主机根据 BTC 协议相互通信，组成了 BTC 网络。这些主机称为 BTC 节点。</p>\n<ul>\n<li>基于 TCP/IP 协议进行通信。</li>\n<li>通信模式为点对点（P2P），即主机之间两两建立对等连接。\n<ul>\n<li>如果两个节点建立对等连接，则称为相邻节点。</li>\n<li>一个节点可以将消息发送给所有相邻节点，后者再转发给它们的相邻节点，以此类推，就可以将该消息广播给网络的大部分节点。</li>\n</ul>\n</li>\n<li>通常人们使用的是 BTC 主网络，但还有测试网络等其它网络。每个网络中存在一条独立的区块链。</li>\n</ul>\n</li>\n<li>\n<p>节点分类：</p>\n<ul>\n<li>全节点（Full Node）\n<ul>\n<li>：存储了 BTC 区块链的所有区块，是 BTC 网络的基础。</li>\n<li>可以接收并验证网络上广播的交易、区块，如果有效则广播给其它节点。</li>\n<li>允许其它节点连接到自己，从而下载区块链。</li>\n</ul>\n</li>\n<li>挖矿节点（Mining Node）\n<ul>\n<li>：属于全节点，但还会收集交易、打包新区块，即更新区块链。</li>\n</ul>\n</li>\n<li>轻节点（Lightweight Node）\n<ul>\n<li>：只存储所有区块的的 header ，需要读取区块内容时，再从全节点下载。\n<ul>\n<li>可根据自己存储的 header ，验证全节点提供的各个区块是否正确。</li>\n</ul>\n</li>\n<li>全节点能够独立验证一个交易、区块是否有效，而轻节点需要依赖全节点。</li>\n<li>大部分的钱包软件属于轻节点，通过 SPV 验证指定账户的历史交易、UTXO 。\n<ul>\n<li>简单支付验证（Simplified Payment Verification，SPV）：普通节点连接到全节点，发送布隆过滤器（bloom filter），筛选出与指定账户相关的所有历史交易，然后下载这些交易。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>一个全节点的启动步骤：</p>\n<ol>\n<li>与至少一个全节点建立对等连接，加入 BTC 网络。\n<ul>\n<li>通常在本机存储了一些全节点的 IP 地址，可在启动时快速连接它们。</li>\n<li>可以发现并连接新的全节点。也可以广播自己的 IP 地址，供其它节点连接。</li>\n<li>默认监听 TCP 8333 端口，供其它节点连接自己。也可以不监听，只允许自己主动连接其它节点。</li>\n</ul>\n</li>\n<li>从其它全节点下载区块数据，更新本机存储的区块链。\n<ul>\n<li>如果本机之前没有存储区块链，则需要从第一个区块开始下载并验证各个区块。</li>\n<li>如果本机已经存储了旧的区块链，则只需下载并验证最新的一些区块。</li>\n</ul>\n</li>\n<li>保持运行，接收网络上广播的消息。例如：\n<ul>\n<li>接收新产生的区块，如果验证通过则存储到本机。</li>\n<li>接收新的未打包交易，如果验证通过则广播给相邻节点。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>相关概念：</p>\n<ul>\n<li><a href=\"https://bitnodes.io/\" target=\"_blank\" rel=\"noopener noreferrer\">bitnodes</a>\n<ul>\n<li>：一个网站，统计了全球各地的 BTC 全节点的数量。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/bitcoin/bitcoin\" target=\"_blank\" rel=\"noopener noreferrer\">Bitcoin Core</a>\n<ul>\n<li>：一个 C++ 程序，实现了标准、完整的 BTC 协议，可用于运行一个全节点，还提供了挖矿、钱包的功能。\n<ul>\n<li>包含一个守护进程 bitcoind ，进行 RPC 通信。</li>\n<li>包含一个命令行工具 bitcoin-cli ，供用户操作。</li>\n<li>基于 Qt 提供了 GUI 界面，又称为 Bitcoin-Qt 。</li>\n</ul>\n</li>\n<li>最初由中本聪开发，后来作为一个开源项目托管在 GitHub 上。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/bitcoinj/bitcoinj\" target=\"_blank\" rel=\"noopener noreferrer\">bitcoinj</a>\n<ul>\n<li>：一个实现了 BTC 协议的 Java 库，可用于编写钱包软件。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"共识\"> 共识</h3>\n<ul>\n<li>\n<p>所有 BTC 节点遵循一些相同的共识规则，比如如何验证一个交易、区块是否有效。</p>\n</li>\n<li>\n<p>BTC 改进提案（Bitcoin Improvement Proposals，BIP）：BTC 社区通过提案来讨论一些改进方案。</p>\n<ul>\n<li><a href=\"https://github.com/bitcoin/bips\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n</ul>\n</li>\n<li>\n<p>实施一个新的共识规则时，根据兼容性，分为两种情况：</p>\n<ul>\n<li>软分叉（Soft Fork）：新的共识规则向前兼容旧规则，因此旧节点依然接受新节点打包的区块。\n<ul>\n<li>但旧节点打包的区块，要符合新共识规则才会被新节点接受，否则网络分叉成两条区块链。</li>\n</ul>\n</li>\n<li>硬分叉（Hard Fork）：新的共识规则不向前兼容，因此旧节点不会接受新节点打包的区块，导致新、旧网络分叉成两条区块链。</li>\n</ul>\n</li>\n<li>\n<p>根据 BIP9 ，一个软分叉升级的流程如下：</p>\n<ol>\n<li>将软分叉部署到网络上，进入 started 状态。</li>\n<li>矿工们修改新区块的 nVersion 中的标志位，表示是否支持该软分叉。</li>\n<li>如果在超时之前，该软分叉获得 95% 矿工（占全网哈希算力的比例）的支持，则锁定（lock_in）成为共识规则。然后在一段时间之后激活（activate），给其它节点留有准备时间。\n<ul>\n<li>如果超时，则部署失败，变为 failed 状态。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"矿工\"> 矿工</h2>\n<ul>\n<li>\n<p>打包新区块的节点，有权得到 coinbase 交易产生的 BTC 。因此该过程称为挖矿，运行挖矿节点的人们称为矿工（miner）。</p>\n</li>\n<li>\n<p>矿工挖矿的流程：</p>\n<ol>\n<li>接收网络上广播的多个交易，打包成一个候选区块。\n<ul>\n<li>为了收益，矿工会优先打包交易费高、体积小的交易。</li>\n<li>矿工需要验证交易是否有效，比如 sigScript、locktime 。否则打包的区块不符合共识规则，不会被其他矿工承认。</li>\n</ul>\n</li>\n<li>尝试穷举区块的 nonce 值，直到满足挖矿难度，使得候选区块变成有效区块。\n<ul>\n<li>如果发现其他矿工抢先打包了新区块，则放弃打包当前区块，开始打包下一个区块。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>矿工打包一个新区块时，能得到两种收益：</p>\n<ul>\n<li>coinbase 奖励\n<ul>\n<li>BTC 协议规定，BTC 币总量为 2100 万个。初期的每个区块 coinbase 会产生 50 个 BTC 。每隔 4 年，即大概 21 万个区块，新区块的产量减少一半。</li>\n<li>因此 coinbase 奖励会越来越少，矿工越来越依赖交易费的收益。</li>\n</ul>\n</li>\n<li>区块内所有交易的交易费\n<ul>\n<li>假设 coinbase 奖励为 25 个 BTC ，总交易费为 0.1 个，则矿工可以编写 coinbase 交易，将 25.1 个发送到指定账户。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>矿工需要付出一定成本，主要是运行挖矿节点的设备费用、电费、网络费。</p>\n<ul>\n<li>独自挖矿时，矿工自己算力占全网算力的比例，就是挖矿成功率，可能隔很多天才能挖矿成功。</li>\n<li>早期的 BTC 主要采用 CPU 挖矿，后来过渡到效率更高的 GPU 挖矿，再后来过渡到专业矿机，采用特制的集成电路芯片（ASIC）。\n<ul>\n<li>目前的全文哈希算力极高，竞争极大，使用家用电脑独自挖矿的成功概率趋近于零。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>一些矿工会组成一个矿池，一起挖矿。然后根据贡献的算力，分配挖矿收益。</p>\n<ul>\n<li>矿池下的矿工不需要作为节点加入 BTC 网络，而只需要连接到矿池服务器，执行运算、提交工作量证明。</li>\n<li>与独自挖矿相比，矿池每天都能获得稳定收益。而且即使算力较低，也可以到矿池出售。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"挖矿难度\"> 挖矿难度</h3>\n<ul>\n<li>\n<p>矿工打包新区块时，需要尝试指定 nonce 值，比如穷举。如果使得当前 header 的哈希值小于等于 target threshold ，则有权打包该区块，被其他矿工承认。</p>\n<ul>\n<li>SHA256 哈希值的长度为 32 bytes ，而 target threshold 以有损压缩形式存储为 nBits ，长度为 4 bytes 。</li>\n<li>例：根据 nBits 计算出 target threshold<div><pre><code><span>>></span><span>></span> nBits  <span>=</span> <span>int</span><span>(</span><span>'0x170cfecf'</span><span>,</span> <span>16</span><span>)</span>                              <span># 假设 nBits 的取值</span>\n<span>>></span><span>></span> target <span>=</span> <span>256</span><span>**</span><span>(</span><span>int</span><span>(</span><span>'0x17'</span><span>,</span> <span>16</span><span>)</span> <span>-</span> <span>3</span><span>)</span> <span>*</span> <span>int</span><span>(</span><span>'0x0cfecf'</span><span>,</span> <span>16</span><span>)</span>   <span># 将第一个字节作为 256 的幂，再乘以后三个字节</span>\n<span>>></span><span>></span> <span>'0x'</span> <span>+</span> <span>\"{:064x}\"</span><span>.</span><span>format</span><span>(</span>target<span>)</span>\n<span>'0x0000000000000000000cfecf0000000000000000000000000000000000000000'</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>可见 nBits 第一个字节的值越大，会使 taget 越大，开头连续的 0 越少，因此挖矿难度越小。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>difficulty 表示挖矿难度。</p>\n<ul>\n<li>计算公式如下：<div><pre><code>diffculty <span>=</span> difficulty_1_target <span>/</span> target\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>可见 difficulty 与 target 成反比，取值越小则挖矿难度越小，最小为 1 。</li>\n</ul>\n</li>\n<li>difficulty_1_target 表示区块链的初始难度，是一个常数：<div><pre><code><span>>></span><span>></span> difficulty_1_target <span>=</span> <span>2</span><span>**</span><span>(</span><span>256</span><span>-</span><span>32</span><span>)</span><span>-</span><span>1</span>\n<span>>></span><span>></span> <span>'0x'</span> <span>+</span> <span>\"{:064x}\"</span><span>.</span><span>format</span><span>(</span>difficulty_1_target<span>)</span>\n<span>'0x00000000ffffffffffffffffffffffffffffffffffffffffffffffffffffffff'</span>\n<span>>></span><span>></span> difficulty_1_target <span>/</span> target\n<span>21659675333681.926</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>当 difficulty 为 1 时，target 达到允许的最大值 0x1d00FFFF 。因为有损压缩丢失了右侧的所有 0xF ，所以有的程序会将 difficulty_1_target 计算成偏小的值：<div><pre><code><span>>></span><span>></span> _target <span>=</span> <span>256</span><span>**</span><span>(</span><span>int</span><span>(</span><span>'0x1d'</span><span>,</span> <span>16</span><span>)</span> <span>-</span> <span>3</span><span>)</span> <span>*</span> <span>int</span><span>(</span><span>'0x00FFFF'</span><span>,</span> <span>16</span><span>)</span>\n<span>>></span><span>></span> <span>'0x'</span> <span>+</span> <span>\"{:064x}\"</span><span>.</span><span>format</span><span>(</span>_target<span>)</span>\n<span>'0x00000000ffff0000000000000000000000000000000000000000000000000000'</span>\n<span>>></span><span>></span> _target <span>/</span> target\n<span>21659344833264.848</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><ul>\n<li>丢失右侧 0xF 的 difficulty_1_target 常用于快速估算难度，称为 bdiff（Bitcoin difficulty）。</li>\n<li>标准的 difficulty_1_target 常用于正式挖矿，称为 pdiff（Pool difficulty）。</li>\n</ul>\n</li>\n<li>例：根据 nBits 估算出 difficulty<div><pre><code><span>>></span><span>></span> nBits      <span>=</span> <span>int</span><span>(</span><span>'0x170cfecf'</span><span>,</span> <span>16</span><span>)</span>\n<span>>></span><span>></span> difficulty <span>=</span> <span>256</span><span>**</span><span>(</span><span>29</span> <span>-</span> <span>(</span>nBits <span>>></span> <span>24</span><span>)</span><span>)</span><span>*</span><span>(</span><span>65535.0</span> <span>/</span> <span>(</span><span>(</span><span>float</span><span>)</span><span>(</span>nBits <span>&amp;</span> <span>0xFFFFFF</span><span>)</span><span>)</span><span>)</span>\n<span>>></span><span>></span> difficulty\n<span>21659344833264.848</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>BTC 预计每隔 10 分钟生成一个新区块。为了维持这一速率，所有节点会每隔 2016 个区块调整一次挖矿难度，重新计算 nBits ：<div><pre><code>expected_time  <span>=</span> <span>2016</span><span>*</span><span>10</span>    <span># 理论上最近 2016 个区块应该消耗 2016*10 分钟即 2 周</span>\nactual_time    <span>=</span> <span>.</span><span>.</span><span>.</span>        <span># 填入实际上最近 2016 个区块消耗的时长</span>\nnew_difficulty <span>=</span> old_difficulty <span>*</span> <span>(</span> actual_time <span>/</span> expected_time <span>)</span>\nnew_nBits      <span>=</span> <span>.</span><span>.</span><span>.</span>        <span># 根据 new_difficulty 算出 new_nBits</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>理论上，SHA256 哈希值有 2^256 种可能性，而 nonce 只有 2^32 种可能性，因此可能穷举 nonce 的所有值之后依然不满足 target threshold 。</p>\n<ul>\n<li>例如 2020 年发布的蚂蚁矿机 S19 ，额定算力为 95 THash/s ，遍历 nonce 所有值的耗时不超过 1 秒：<div><pre><code><span>>></span><span>></span> <span>(</span><span>2</span><span>**</span><span>32</span><span>)</span> <span>/</span> <span>(</span><span>95</span><span>*</span><span>10</span><span>**</span><span>9</span><span>)</span>\n<span>0.045</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>当 nonce 被穷举完时，矿工通常会在 coinbase 交易中加入一个 4 bytes 的随机数，称为 extraNonce ，从而增加到 2^64 种可能性。</li>\n<li>例如 2020 年 BTC 全网算力达到了 150 EHash/s = 150 * 10^3 PHash/s = 150 * 10^6 THash/s ，遍历 nonce + extraNonce 消耗的秒数为：<div><pre><code><span>>></span><span>></span> <span>round</span><span>(</span><span>(</span><span>2</span><span>**</span><span>64</span><span>)</span> <span>/</span> <span>(</span><span>150</span><span>*</span><span>10</span><span>**</span><span>15</span><span>)</span><span>)</span>\n<span>123</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div>因此挖矿难度自动上调得很大，从而限制产生新区块的耗时依然为 10 分钟。矿工需要增加 extraNonce 的位数到 8 bytes 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关历史\"> 相关历史</h2>\n<ul>\n<li>\n<p>2008 年，一个网名为 Satoshi Nakamoto（中本聪）的人发布了 <a href=\"https://bitcoin.org/bitcoin.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">比特币白皮书</a> ，设计了 BTC 的最初架构：</p>\n<ul>\n<li>去中心化交易：属于点对点的交易系统。用户之间可以直接转账交易，不需要经过第三方机构中转、审批。</li>\n<li>基于区块链，存储已发生的转账交易，防止被篡改。\n<ul>\n<li>所有交易是公开记录的，容易溯源。但账户地址是匿名的，不需绑定身份信息。</li>\n<li>工作量证明（Proof-of-Work）：各节点都可以尝试开采新区块，但只有最先满足挖矿难度的节点有权开采新区块，并提交 nonce 作为哈希运算的工作量证明。</li>\n<li>激励：成功创建新区块的节点，可以获得一定量的 BTC 。</li>\n<li>如果同时存在多条区块链，则最长的那条拥有的工作量证明最多，被各节点接受。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>2009 年 1 月，中本聪生成了第一个 BTC 区块，称为创世区块（Genesis Block）。</p>\n<ul>\n<li>中本聪在该区块的 coinbase 中记录了一个字符串，是泰晤士报的一个新闻标题：<code>The Times 03/Jan/2009 Chancellor on brink of second bailout for banks.</code> ，是指英国政府在 2008 年金融危机后，对银行进行第二次救助。</li>\n<li>这表示中本聪希望发明一种货币，摆脱传统金融机构的弊端。</li>\n</ul>\n</li>\n<li>\n<p>2010 年 5 月，一个美国程序员在 bitcointalk.org 论坛发帖，愿意花费 10000 BTC 换取两个披萨，最后在当地披萨店换取 40 美元左右的披萨。这标志着 BTC 首次兑换实物。</p>\n</li>\n<li>\n<p>2010 年 8 月，有人利用 BTC 协议的一个严重漏洞，在一次交易中向两个地址分别发送了 900 多亿 BTC 。</p>\n<ul>\n<li>该漏洞是因为 BTC 代码没有考虑到交易输出值过大的情况，以至于求和值溢出。</li>\n<li>发现区块中打包了这个错误交易之后，Bitcore 开发者在几个小时之后升级了代码，通过软分叉拒绝这种错误交易。这引发了网络分叉，新区块链很快超过了旧区块链的长度。</li>\n</ul>\n</li>\n<li>\n<p>2011 年 2 月，BTC 单价达到 1 美元，区块高度达到 10w ，已开采 500w 个 BTC ，全网算力达到 10 GHash/s 。</p>\n</li>\n<li>\n<p>2011 年 4 月，中本聪向 Bitcoin Core 一个开发者发送了一封电子邮件作为告别，从此从互联网消失。</p>\n</li>\n<li>\n<p>2011 年 6 月，日本交易所 Mt.Gox 的用户数据库被泄露，导致几百个弱密码哈希的用户被盗号，总共损失 25000 BTC 。几天之后又被黑客登录了一个管理员账户，提取了 2000 BTC 。</p>\n<ul>\n<li>2013 年，Mt.Gox 成为全球最大交易所，交易量占全球 70% 。</li>\n<li>2014 年，Mt.Gox 突然申请破产保护，停止交易、提币，宣称过去几年累计丢失了 85w BTC 。不确定是黑客攻击还是监守自盗。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "ETH",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Blockchain/ETH.html",
      "id": "/Hardware/Distributed/Blockchain/ETH.html",
      "content_html": "<h1 id=\"eth\"> ETH</h1>\n<p>：以太币，一种数字货币，由以太坊（Ethereum）区块链发行。</p>\n<ul>\n<li>\n<p><a href=\"https://ethereum.org/en/developers/docs/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></p>\n</li>\n<li>\n<p>与 BTC 相比，提供了一种图灵完备的脚本语言，允许用户编写去中心化应用程序，部署到 ETH 区块链中。</p>\n</li>\n<li>\n<p>关于 ETH 币：</p>\n<ul>\n<li>总量没有上限。</li>\n<li>最小数量单位为 Wei ，1 ETH = 10^18 Wei 。</li>\n</ul>\n</li>\n<li>\n<p>以太坊存在两种账号地址：</p>\n<ul>\n<li>用户账户</li>\n<li>合约账户</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>以太坊虚拟机 (EVM) ：一个运行时环境，负责执行交易。</li>\n<li>Gas ：指交易费用，通常采用 Gwei 单位，1 ETH = 10^9 Gwei 。</li>\n<li>ERC-20（Ethereum Request for Comments 20）代币标准</li>\n<li>去中心化金融（DeFi）</li>\n<li>以太坊还允许创建独特且不可分割的代币，称为不可替代代币(NFT)</li>\n</ul>\n<h2 id=\"相关历史\"> 相关历史</h2>\n<ul>\n<li>\n<p>2013 年，俄罗斯程序员 Vitalik Buterin 等人开始开发 ETH 项目。</p>\n<ul>\n<li>BTC 的最初目的是提供一种去中心化的货币，实现价值存储功能。而 ETH 的最初目的是实现去中心化应用程序。</li>\n</ul>\n</li>\n<li>\n<p>2015 年 7 月，ETH 主网上线，</p>\n</li>\n<li>\n<p>20016 年 6 月，ETH 开始了 The DAO 项目，众筹了大量 ETH ，但是被黑客通过漏洞转走了 360 万个 ETH 。</p>\n<ul>\n<li>事发后，ETH 开发者的解决方案是，通过硬分叉将区块链回滚到事发之前的状态，从而回滚交易。</li>\n<li>一些社区用户反对该硬分叉，称它违反了区块链的不可篡改特性，因此继续使用原链，称为以太坊经典（ETC）。</li>\n</ul>\n</li>\n<li>\n<p>2018 年 1 月，ETH 成为市值第二大的数字货币，仅次于 BTC 。</p>\n</li>\n<li>\n<p>2019 年 2 月，ETH 实施一次升级，代号为君士坦丁堡。</p>\n</li>\n<li>\n<p>2021 年 8 月，ETH 实施一次升级，代号为伦敦。</p>\n<ul>\n<li>实施了 EIP1559 提案</li>\n</ul>\n</li>\n<li>\n<p>计划升级到 ETH 2.0 ，大幅提高网络吞吐量，分为 3 个阶段：</p>\n<ol>\n<li>2020 年 12 月部署信标链，采用 PoS</li>\n<li>2022 年，将信标链与原链合并</li>\n<li>分片链，将网络分散到 64 条链上</li>\n</ol>\n<ul>\n<li>难度炸弹：从某个区块开始，指数级增加 PoW 挖矿的难度，逼迫矿工转向 PoS 挖矿。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "区块链",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Blockchain/",
      "id": "/Hardware/Distributed/Blockchain/",
      "content_html": "<h1 id=\"区块链\"> 区块链</h1>\n<p>：block chain ，一种分布式数据库技术。</p>\n<ul>\n<li>区块链起源于比特币，用于存储交易信息，每笔交易相当于 SQL 数据库的一个事务。\n<ul>\n<li>区块链也可用于存储任意类型的数据。</li>\n</ul>\n</li>\n<li>与 SQL 等传统数据库相比，区块链偏向于确保历史事务的只读不变、新事务的分布式一致性，注重稳定、安全，但写入新事务的速度慢。</li>\n</ul>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>以区块为单位存储数据。\n<ul>\n<li>已生成的区块是只读的，不允许修改。只能新增区块。</li>\n<li>所有区块以哈希链的形式串联，组成了一条区块链。</li>\n</ul>\n</li>\n<li>由多个主机组成分布式系统，相互通信。每个主机存储一个区块链的完整副本。\n<ul>\n<li>基于 PoW 共识算法决定哪个主机有权生成下一个区块，然后广播给所有主机。</li>\n<li>一个主机可以从其它主机获取区块数据，但自己要验证其是否有效、可信。</li>\n</ul>\n</li>\n<li>关于区块链的具体原理，可参考 BTC 协议。</li>\n</ul>\n<h2 id=\"数字货币\"> 数字货币</h2>\n<ul>\n<li>\n<p>2008 年，中本聪发明了第一种数字货币 BTC 。之后又出现了很多种数字货币。</p>\n</li>\n<li>\n<p>数字货币的特点：</p>\n<ul>\n<li>传统的货币由国家发行，存在纸钞、支票、电子记账等方式。而数字货币在区块链中产生、存储，完全数字化。</li>\n<li>用户并不会实际持有数字货币，而是通过私钥创建并控制一个账户。区块链会记录所有账户的交易信息，像账本，从而可以确定每个账户的余额。</li>\n<li>用户之间可以直接转账交易，不需要经过第三方机构中转、审批，因此不受银行等中心化机构控制。</li>\n</ul>\n</li>\n<li>\n<p>数字货币不与实物挂钩，本来没有价值。不过发展了多年之后，以 BTC 为首的一些数字货币可兑换的美元价格不断增加，用户也不断增加。主要原因：</p>\n<ul>\n<li>任何人都可以自由创建账户，没有监管审批，创建时没有费用、耗时，因此入场门槛几乎没有。</li>\n<li>总量有限，很多人预期它不会贬值，而是会不断升值。在一定程度上实现了黄金的功能，对冲通货膨胀。</li>\n<li>账户是匿名的，虽然交易过程是公开的。在一定程度上保护了用户的隐私。</li>\n<li>通过互联网交易，不受地区、国界影响，可以随时跨国转账。因此接纳了世界各地的用户。</li>\n<li>可以划分出很小的数量单位，比如 0.00000001 个，因此适合小额交易。而且这也使得买入门槛很低，吸引了更多用户，不像股票的最小交易单位为一手。</li>\n</ul>\n</li>\n<li>\n<p>除了 BTC 之外的其它数字货币，统称为山寨币（alternative coin，altcoin）。</p>\n<ul>\n<li>早期的 LTC 等山寨币是模仿 BTC 代码。后来的 ETH 等山寨币与 BTC 的差异越来越大，提供了更多功能。</li>\n</ul>\n</li>\n<li>\n<p>2011 年 10 月，Google 的一个程序员 Charlie Lee 发布了莱特币（Litecoin，LTC）。</p>\n<ul>\n<li>LTC 改编自 BTC 源代码，旨在处理小型交易。</li>\n<li>货币总量增加到 8400 万，出块周期减少为 2.5 分钟。</li>\n<li>区块产量从 50 开始，每四年即 84 万个区块减半一次。</li>\n<li>对于工作流证明，用 scrypt 算法取代 SHA256 算法，使得 GPU 挖矿效率低于 CPU ，但后来也出现了特制的 ASIC 矿机。</li>\n</ul>\n</li>\n<li>\n<p>2017 年 8 月，以比特大陆为主的矿工发起了 BTC 硬分叉，产生一个新币 BCH（Bitcoin Cash）。</p>\n<ul>\n<li>将单个区块的容量限制从 1MB 增加到 8MB ，后来又增加到 32MB 。</li>\n<li>客户端名为 Bitcoin ABC（Adjustable Blocksize Cap）。</li>\n<li>硬分叉之后，之前拥有 BTC 的账户地址依然在 BCH 链上存在，拥有等量的 BCH 币。</li>\n</ul>\n</li>\n<li>\n<p>2018 年 11 月，冒充中本聪的 Craig Wright 从 BCH 硬分叉出一个新币 BSV（Satoshi Vision）。</p>\n<ul>\n<li>将区块容量增加到 128MB ，宣称更符合中本聪的愿景。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"layer2\"> layer2</h2>\n<ul>\n<li>\n<p>BTC、ETH 的使用量变大之后，性能问题越来越严重：</p>\n<ul>\n<li>TPS 低：每个区块能打包的交易数量少，即处理交易的速度慢，导致网络拥堵，大量交易等待被打包。</li>\n<li>费用高：因为网络拥堵，用户要争相付更高的手续费。</li>\n<li>耗时久：每个交易要等待区块打包、多次确认才算成功。</li>\n</ul>\n</li>\n<li>\n<p>layer2 技术是一类解决方案。</p>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>\n<p>参考资料：</p>\n<ul>\n<li><a href=\"https://developer.bitcoin.org/devguide/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">bitcoin.org</a></li>\n<li><a href=\"https://github.com/bitcoinbook/bitcoinbook\" target=\"_blank\" rel=\"noopener noreferrer\">bitcoinbook</a></li>\n</ul>\n</li>\n<li>\n<p>区块链浏览器（Explorer）</p>\n<ul>\n<li>：一种 Web 网站，用于查看、搜索 BTC、ETH 等数字货币的区块链信息，比如每个区块的内容、每笔交易的内容、每个地址的余额。</li>\n<li>例如 blockchain.com 、btc.com 网站，提供了多个主流币种的区块链浏览器。</li>\n</ul>\n</li>\n<li>\n<p>钱包（wallet）</p>\n<ul>\n<li>：一种管理数字货币账户的软件。\n<ul>\n<li>基本功能：生成新账户、使用账户私钥发起转账交易。</li>\n<li>软件形式：可能为 PC 端软件、浏览器插件、手机 app 等。</li>\n</ul>\n</li>\n<li>接收转账只需要公布自己的账户地址，不需要使用钱包软件。</li>\n<li>主要分类：\n<ul>\n<li>冷钱包\n<ul>\n<li>：使用时不需要联网。</li>\n<li>离线交易的流程如下：\n<ol>\n<li>在联网电脑 A 上获取最新的区块链数据，据此生成一笔交易，但不包含签名 sigScript 。</li>\n<li>将未签名的交易拷贝到断网电脑 B 上，生成签名。比如通过 U 盘拷贝。</li>\n<li>将已签名的交易拷贝到联网电脑 A 上，广播到网络。</li>\n</ol>\n</li>\n<li>离线交易保证了私钥不会通过网络泄漏，安全性很高，但是比较麻烦。</li>\n</ul>\n</li>\n<li>分层确定性钱包（Hierarchical Deterministic，HD）\n<ul>\n<li>：随机生成一个主密钥，又称为种子（seed）。然后根据某种单向确定的算法，生成多个私钥，从而生成多个账户。</li>\n<li>用户只需保存主密钥，即可控制多个账户。</li>\n<li>类似的，有的钱包会随机生成一组单词，称为助记词，用于生成私钥。用户只需保存助记词，而不需保存私钥，更方便阅读。</li>\n</ul>\n</li>\n<li>热钱包\n<ul>\n<li>：使用时需要联网。</li>\n<li>用户需要担心账户私钥被热钱包窃取，或因为漏洞被攻击。</li>\n</ul>\n</li>\n<li>硬件钱包\n<ul>\n<li>：一种像 U 盘的电子设备，用于离线存储私钥，连接到电脑之后才提供冷钱包的功能。</li>\n<li>冷钱包软件运行在通用计算机上，而硬件钱包运行在特制的电子设备中，更安全，但携带、存放更麻烦，而且该电子设备也并不一定可靠。</li>\n</ul>\n</li>\n<li>纸钱包\n<ul>\n<li>：将账户私钥记录在一张纸上，或者保存为二维码图片。</li>\n<li>比硬件钱包更安全，成本很低。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>常见矿池：</p>\n<ul>\n<li>BTC.com ：原本由比特大陆公司经营。2021 年，500 彩票网收购该矿池及域名，并将公司改名为比特矿业。</li>\n</ul>\n</li>\n<li>\n<p>Layer2 ：\nhttps://m.8btc.com/article/6699616\nhttps://m.8btc.com/article/6701801\nhttps://m.8btc.com/article/6701437\nhttps://m.8btc.com/article/6709513</p>\n</li>\n<li>\n<p>去中心化交易所</p>\n<ul>\n<li>Uniswap</li>\n<li>1inch ：DEFI 聚合器，可以从其它 DEX 交易所选出滑点最小的用于交易。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Zipkin",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/Zipkin.html",
      "id": "/Hardware/Distributed/DistributedSystem/Zipkin.html",
      "content_html": "<h1 id=\"zipkin\"> Zipkin</h1>\n<p>：一个 Web 服务器，用于分布式链路跟踪。</p>\n<ul>\n<li><a href=\"https://github.com/openzipkin/zipkin/blob/master/zipkin-server/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>由 Twitter 公司开源，采用 Java 开发。</li>\n<li>提供了 Restful API 和 Web UI 。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>zipkin</span><span>:</span>\n    <span>container_name</span><span>:</span> zipkin\n    <span>image</span><span>:</span> openzipkin/zipkin<span>:</span><span>2.20</span>\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span># QUERY_PORT: 9411</span>\n      <span># QUERY_TIMEOUT: 11s              # 查询的超时时间，设置为 0 则不限制</span>\n      <span># QUERY_LOG_LEVEL: INFO</span>\n      <span># COLLECTOR_SAMPLE_RATE: 1.0      # 采样率，作用于全局。默认为 1.0 ，表示 100%</span>\n      <span>SELF_TRACING_ENABLED</span><span>:</span> <span>'true'</span>      <span># 是否启用 Zipkin 的自身跟踪，默认为 false</span>\n      <span>SELF_TRACING_SAMPLE_RATE</span><span>:</span> <span>0.001</span>   <span># 自身跟踪的采样率</span>\n\n      <span>STORAGE_TYPE</span><span>:</span> elasticsearch       <span># 存储后端的类型，默认为 mem ，存储在内存中</span>\n      <span>ES_HOSTS</span><span>:</span> http<span>:</span>//10.0.0.1<span>:</span><span>9200</span>\n      <span># ES_USERNAME:</span>\n      <span># ES_PASSWORD:</span>\n      <span># ES_INDEX: zipkin                # 索引名的前缀，实际创建的索引名会加上日期后缀，比如 zipkin:span-2021-01-01</span>\n      <span># ES_INDEX_SHARDS: 5</span>\n      <span># ES_INDEX_REPLICAS: 0</span>\n      <span># ES_ENSURE_TEMPLATES: true       # 是否自动创建索引模板</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9411<span>:</span><span>9411</span>\n\n  <span>denpendencies</span><span>:</span>                        <span># 该容器需要每天执行一次</span>\n    <span>container_name</span><span>:</span> zipkin<span>-</span>dependencies\n    <span>image</span><span>:</span> openzipkin/zipkin<span>-</span>dependencies<span>:</span><span>2.4</span>\n    <span>entrypoint</span><span>:</span>\n      <span>-</span> /bin/sh\n      <span>-</span> <span>-</span>c\n      <span>-</span> start<span>-</span>zipkin<span>-</span>dependencies `date <span>-</span>ud yesterday +%F`\n    <span>environment</span><span>:</span>\n      <span>STORAGE_TYPE</span><span>:</span> elasticsearch\n      <span>ES_HOSTS</span><span>:</span> http<span>:</span>//10.0.0.1<span>:</span><span>9200</span>\n      <span>ES_NODES_WAN_ONLY</span><span>:</span> <span>'true'</span>         <span># 是否只使用 ES_HOSTS 中列出的 ES 地址。默认为 false ，会连接本机的 9200 端口</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br></div></div><ul>\n<li>Zipkin 的 v2.21 版本更换了 UI ，并且支持的 ES 版本从 v6 改为 v7 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>\n<p>运行流程：</p>\n<ol>\n<li>用户发出一个请求。</li>\n<li>业务系统收到请求，依次传递给前端、后端多个服务处理。每个服务在处理时，都将调用记录发送到 Zipkin 。</li>\n<li>Zipkin 可以实时跟踪请求的调用情况，进行树形图分析。</li>\n</ol>\n</li>\n<li>\n<p>Zipkin 为每个调用链路分配一个全局唯一的 traceId ，对应一个树形图。</p>\n<ul>\n<li>为链路中中的每个请求分配一个 spanId ，对应树形图中的一个节点。</li>\n<li>支持给服务器、客户端分别设置采样率。</li>\n</ul>\n</li>\n<li>\n<p>Zipkin 提供了多种编程语言的客户端，供业务进程调用。</p>\n</li>\n<li>\n<p>业务进程将数据发送到 Zipkin 时，负责发送、接收的模块分别称为 Reporter、Collector 。</p>\n<ul>\n<li>Reporter 有几种通信方式可选：\n<ul>\n<li>HTTP ：默认方式。</li>\n<li>Kafka ：适合传输大量数据。</li>\n<li>Scribe ：用于收集日志。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Zipkin 默认将数据存储在内存中，没有持久化保存。并且默认最多存储 <code>MEM_MAX_SPANS=500000</code> 条记录，超过则删除旧记录。</p>\n<ul>\n<li>可以采用 Cassandra、ES、MySQL 等外部存储后端。</li>\n</ul>\n</li>\n<li>\n<p>Zipkin 默认每天执行一个 Spark Job ，绘制当天（UTC 时区）的 dependencies 依赖图。</p>\n<ul>\n<li>采用外部存储后端时，不会自动执行该 Job 。用户可以主动执行：<div><pre><code>java -jar zipkin-dependencies.jar <span>2021</span>-01-02\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>执行该 jar 包时，默认处理今天的数据，也可以传入指定的日期。</li>\n<li>其它配置参数通过环境变量传入。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"♢-py-zipkin\"> ♢ py-zipkin</h2>\n<p>：Python 的第三方库，用作 Zipkin 客户端。</p>\n<ul>\n<li><a href=\"https://github.com/Yelp/py_zipkin\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>安装：<code>pip install py-zipkin</code></li>\n<li>例：<div><pre><code><span>import</span> requests\n<span>from</span> py_zipkin<span>.</span>zipkin <span>import</span> zipkin_span\n\n<span># 自定义一个函数，用于发送编码后的 span 数据到 Zipkin</span>\n<span>def</span> <span>http_transport</span><span>(</span>encoded_span<span>)</span><span>:</span>\n    zipkin_url <span>=</span> <span>\"http://10.0.0.1:9411/api/v1/spans\"</span>\n    headers <span>=</span> <span>{</span><span>\"Content-Type\"</span><span>:</span> <span>\"application/x-thrift\"</span><span>}</span>\n    requests<span>.</span>post<span>(</span>zipkin_url<span>,</span> data<span>=</span>encoded_span<span>,</span> headers<span>=</span>headers<span>)</span>\n\n<span># 在业务代码中，采集 span 数据</span>\n<span>def</span> <span>func1</span><span>(</span><span>)</span><span>:</span>\n    <span>with</span> zipkin_span<span>(</span>\n        service_name<span>=</span><span>'test_service'</span><span>,</span>\n        span_name<span>=</span><span>'test_span'</span><span>,</span>\n        transport_handler<span>=</span>http_transport<span>,</span>\n        sample_rate<span>=</span><span>100</span><span>,</span>  <span># 采样率，取值为 0.0 ~ 100.0</span>\n    <span>)</span><span>:</span>\n        <span>pass</span>\n\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "原理",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/ZooKeeper/Principle.html",
      "id": "/Hardware/Distributed/DistributedSystem/ZooKeeper/Principle.html",
      "content_html": "<h1 id=\"原理\"> 原理</h1>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>\n<p>zk server 可以只部署单实例，也可以部署多个实例，组成集群。</p>\n<ul>\n<li>每个 server 都拥有整个集群的数据副本，客户端连接到任一 server 即可访问集群。</li>\n</ul>\n</li>\n<li>\n<p>部署多个 zk server 时，需要至少 Quorum 数量的节点正常工作，集群才可用。</p>\n<ul>\n<li>部署的 server 数量建议为奇数，为偶数时并不会提高可用性。</li>\n<li>部署 1 个 server 时，不能组成集群，只能工作在 standalone 模式。</li>\n<li>部署 2 个 server 时，能组成一个最小的 zk 集群，但存在单点故障的风险。\n<ul>\n<li>任一 server 故障时，剩下的 server 不超过集群的半数，不能投票决策。</li>\n</ul>\n</li>\n<li>部署 3 个 server 时，组成的 zk 集群最多允许 1 个 server 故障。</li>\n<li>部署 4 个 server 时，组成的 zk 集群也是最多允许 1 个 server 故障。</li>\n</ul>\n</li>\n<li>\n<p>集群中的 server 分为三种角色：</p>\n<ul>\n<li>\n<p>leader</p>\n<ul>\n<li>：领导者，有权发出提议（Proposal）、投票。</li>\n<li>提议通过之后，就会更新集群的数据。</li>\n<li>可以处理客户端的读、写请求。</li>\n</ul>\n</li>\n<li>\n<p>follower</p>\n<ul>\n<li>：跟随者，有权投票。</li>\n<li>会复制 leader 的数据到本机，因此可以处理客户端的读请求。</li>\n<li>收到客户端的写请求时，会转发给 leader ，相当于反向代理。</li>\n</ul>\n</li>\n<li>\n<p>observer</p>\n<ul>\n<li>：观察者。</li>\n<li>无权投票，只能听从投票结果，因此不会影响集群的可用性，可以允许故障。</li>\n<li>可以像 follower 一样接收客户端的读写请求，因此能提高集群的并发量。</li>\n<li>leader、follower 是 zk 集群在选举时自动分配的角色，而 observer 是由用户指定的可选角色。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"事务\"> 事务</h2>\n<ul>\n<li>每个事务拥有一个十六进制编号，称为 zxid 。\n<ul>\n<li>zxid 用 long 型变量存储，长度为 64 位。</li>\n<li>zxid 的前 32 位用于记录当前的 epoch 编号，后 32 位用于记录这是当前 epoch 中的第几个事务，从 0 开始递增。例如 zxid=0x2000004b2 。</li>\n</ul>\n</li>\n<li>当事务日志达到一定数量时，zk 会将当前全部 znode 的数据保存为磁盘中的一个快照文件，然后创建新的事务日志文件。\n<ul>\n<li>创建快照文件、事务日志文件时，采用当前最新一个 zxid 作为文件后缀名。</li>\n<li>快照文件、事务日志文件默认一直不会删除，因此可以让 zk 数据回滚到历史状态。</li>\n</ul>\n</li>\n<li>保存快照的过程中，如果新产生了事务，也会被加入快照。\n<ul>\n<li>此时事务日志文件的 zxid 会略大于快照文件的 zxid 。</li>\n<li>该快照称为模糊快照，不过 zk 依然可以根据它恢复数据。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"zab\"> ZAB</h2>\n<ul>\n<li>\n<p>zk 采用的分布式共识协议是 ZAB（Zookeeper Atomic Broadcast），与 Raft 协议相似。</p>\n<ul>\n<li>默认采用 FastLeaderElection 选举算法。选举过程很快，一般低于 1 s 。</li>\n<li>Leader 的任期称为 epoch 。\n<ul>\n<li>每个 epoch 拥有一个从 0 开始递增的数字编号。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>ZAB 协议为 zk server 划分了多个运行阶段：</p>\n<ul>\n<li>启动：每个 server 在启动时，不知道自己的角色，需要开始选举，直到选出 leader ，或者发现已有的 leader 。</li>\n<li>election ：选举</li>\n<li>discovery ：发现领导者</li>\n<li>synchronization ：同步跟随者</li>\n<li>broadcast ：广播事务</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"election\"> election</h3>\n<ol>\n<li>有权投票的 server 进入 LOOKING 竞选状态。向其它 server 发送自己的投票，包含以下信息：\n<ul>\n<li>epoch ：本轮投票的编号。</li>\n<li>zxid ：提议的 leader 的最新 zxid 。</li>\n<li>leader ：提议的 leader 的 ID 。默认推举自己。</li>\n</ul>\n</li>\n<li>每个 server 收到其它 server 的投票时，会与自己的投票进行对比。\n<ul>\n<li>依次比较 epoch、zxid、leader 三种值的大小，取值越大则投票的权重越高。</li>\n<li>如果自己投票的权重更大，则发送给对方 server 。否则采用对方的投票作为自己的新投票。</li>\n<li>这样会尽量推举拥有最新事务的 server 作为 leader 。</li>\n</ul>\n</li>\n<li>重复 1-2 步，直到一个 server 发现有 Quorum 数量的 server 推举自己为 leader ，则将 epoch 加 1 ，向所有 server 发送自己成为 leader 的消息。</li>\n<li>投票成功。各个 server 被分配了角色，进入 LEADING、FOLLOWING 或 OBSERVING 状态。\n<ul>\n<li>但此时 follower 不一定能访问到 leader ，也尚未同步数据，要等到 broadcast 阶段才能供客户端访问。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"discovery\"> discovery</h3>\n<ol>\n<li>follower 连接到 leader ，发送 FOLLOWERINFO 消息。</li>\n<li>等 Quorum 数量的 follower 建立连接之后，leader 停止接受新连接。并向已有的 follower 发送 LEADERINFO(e) 消息，提议开始一个新的 epoch ，其 e 值大于这些 follower 的 acceptedEpoch 。\n<ul>\n<li>统计的 Quorum 数量包括了 leader、follower ，不包括 observer 。</li>\n</ul>\n</li>\n<li>follower 收到 LEADERINFO(e) 消息，进行判断：\n<ul>\n<li>如果 e &gt; acceptedEpoch ，则设置 acceptedEpoch = e ，并回复 ACKEPOCH(e) ，表示接受新的 epoch 。</li>\n<li>如果 e == acceptedEpoch ，则跳到执行下一步。</li>\n<li>如果 e &lt; acceptedEpoch ，则断开连接，重新开始选举。</li>\n</ul>\n</li>\n<li>等 Quorum 数量的 follower 回复 ACKEPOCH 之后，leader 开始下一阶段。\n<ul>\n<li>所有 follower 都必须满足以下两个条件之一，否则 leader 断开连接，重新开始选举：<div><pre><code>follower.currentEpoch <span>&lt;</span>  leader.currentEpoch\nfollower.currentEpoch <span>==</span> leader.currentEpoch <span>&amp;&amp;</span> follower.lastZxid <span>&lt;=</span> leader.lastZxid\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>如果上述过程失败或超时，则重新开始选举。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"synchronization\"> synchronization</h3>\n<ol>\n<li>follower 连接到 leader ，加入 Learner 队列。</li>\n<li>leader 给 follower 同步数据。有多种同步模式：\n<ul>\n<li>如果 follower 落后少量事务，则 leader 发送 DIFF 消息，同步缺少的事务。</li>\n<li>如果 follower 落后太多事务，则 leader 发送 SNAP 消息，同步全部 znode 的快照。</li>\n<li>如果 follower 的 zxid 比 leader 还大，则发送 TRUNC 消息，丢弃多出的事务。</li>\n</ul>\n</li>\n<li>当 follower 同步完数据之后，leader 向它发送 NEWLEADER(e) 消息，提议自己作为该 epoch 的 leader 。</li>\n<li>follower 收到 NEWLEADER(e) 消息，停止同步，设置 currentEpoch = e ，然后回复 ACK 消息。</li>\n<li>等 Quorum 数量的 follower 回复 ACK 之后，leader 正式成为该 epoch 的 leader ，向所有 follower 发送 UPTODATE 消息，表示超过 Quorum 数量的 follower 已完成同步。</li>\n<li>follower 收到 UPTODATE 消息，开始接受客户端连接。</li>\n</ol>\n<h3 id=\"broadcast\"> broadcast</h3>\n<ul>\n<li>提交一个新事务的流程如下，类似于两阶段提交：\n<ol>\n<li>leader 开始一个新事务，广播 PROPOSE 消息给所有 follower ，提议该事务。</li>\n<li>follower 收到 PROPOSE 消息，将事务写入磁盘的事务日志文件。然后回复 ACK(zxid) 消息给 leader ，表示直到该 zxid 的事务都已经被接受。</li>\n<li>等 Quorum 数量的 follower 回复 ACK 之后， leader 正式提交该事务。然后广播 COMMIT(zxid) 消息给所有 follower ，表示直到该 zxid 的事务都已经被提交。</li>\n</ol>\n</li>\n<li>leader 确保超过 Quorum 数量的 follower 同步了最新事务之后，才会开始下一个事务。\n<ul>\n<li>尚未同步的 follower 必须按 zxid 顺序执行事务，即优先执行 zxid 最小的事务，且不允许跳过事务。</li>\n<li>如果 follower 与 PROPOSE 消息的 epoch 不同，则不会接受提议，而是先经历 discovery、synchronization 阶段。</li>\n</ul>\n</li>\n<li>如果 follower 在一定时间内没有收到 leader 的 PROPOSE 或 ping 消息，则认为 leader 故障，状态从 FOLLOWING 变为 LOOKING ，重新选举。\n<ul>\n<li>此时原 leader 可能依然处于 LEADING 状态，可以被客户端连接，但它没有 Quorum 数量的 follower ，不能提交事务。</li>\n<li>因此，集群中可能同时存在多个 leader ，但最多只有一个 leader 能拥有 Quorum 数量的 follower ，不会发生脑裂。</li>\n</ul>\n</li>\n<li>如果 leader 在一定时间内没有等到 Quorum 数量的 follower 回复 ACK ，则状态从 LEADING 变为 LOOKING ，重新选举。</li>\n</ul>\n<h2 id=\"源代码\"> 源代码</h2>\n<ul>\n<li>\n<p>QuorumPeer 类负责根据 ZAB 协议管理服务器，定义如下：</p>\n<div><pre><code><span>public</span> <span>class</span> <span>QuorumPeer</span> <span>extends</span> <span>ZooKeeperThread</span> <span>implements</span> <span>QuorumStats<span>.</span>Provider</span> <span>{</span>\n    <span>public</span> <span>static</span> <span>class</span> <span>QuorumServer</span> <span>{</span>    <span>// 服务器对象</span>\n        <span>public</span> <span>long</span> id<span>;</span>\n        <span>public</span> <span>String</span> hostname<span>;</span>\n        <span>public</span> <span>LearnerType</span> type <span>=</span> <span>LearnerType</span><span>.</span>PARTICIPANT<span>;</span>\n        <span>.</span><span>.</span><span>.</span>\n    <span>}</span>\n    <span>public</span> <span>enum</span> <span>ServerState</span> <span>{</span>   <span>// 服务器的状态</span>\n        LOOKING<span>,</span>\n        FOLLOWING<span>,</span>\n        LEADING<span>,</span>\n        OBSERVING\n    <span>}</span>\n    <span>public</span> <span>enum</span> <span>ZabState</span> <span>{</span>      <span>// 服务器在 ZAB 协议中的运行阶段</span>\n        ELECTION<span>,</span>\n        DISCOVERY<span>,</span>\n        SYNCHRONIZATION<span>,</span>\n        BROADCAST\n    <span>}</span>\n    <span>public</span> <span>enum</span> <span>SyncMode</span> <span>{</span>      <span>// synchronization 阶段的同步模式</span>\n        NONE<span>,</span>\n        DIFF<span>,</span>\n        SNAP<span>,</span>\n        TRUNC\n    <span>}</span>\n    <span>public</span> <span>enum</span> <span>LearnerType</span> <span>{</span>   <span>// server 类型。Learner 类是 Followers 类和 Observers 类的父类，用于同步 leader 的数据</span>\n        PARTICIPANT<span>,</span>            <span>// 参选者，在选举之后可以变成 leader 或 follower</span>\n        OBSERVER                <span>// 观察者</span>\n    <span>}</span>\n    <span>public</span> <span>void</span> <span>run</span><span>(</span><span>)</span> <span>{</span>         <span>// zk 会创建一个子线程去执行 QuorumPeer.run()</span>\n        LOG<span>.</span><span>debug</span><span>(</span><span>\"Starting quorum peer\"</span><span>)</span><span>;</span>\n        <span>try</span> <span>{</span>\n            <span>while</span> <span>(</span>running<span>)</span> <span>{</span>   <span>// 循环体，根据 server 的状态执行一些操作</span>\n                <span>switch</span> <span>(</span><span>getPeerState</span><span>(</span><span>)</span><span>)</span> <span>{</span>\n                    <span>case</span> LOOKING<span>:</span>               <span>// LOOKING 状态要进行选举</span>\n                        LOG<span>.</span><span>info</span><span>(</span><span>\"LOOKING\"</span><span>)</span><span>;</span>\n                        <span>.</span><span>.</span><span>.</span>\n                    <span>case</span> OBSERVING<span>:</span>\n                        LOG<span>.</span><span>info</span><span>(</span><span>\"OBSERVING\"</span><span>)</span><span>;</span>\n                        <span>setObserver</span><span>(</span><span>makeObserver</span><span>(</span>logFactory<span>)</span><span>)</span><span>;</span>\n                        observer<span>.</span><span>observeLeader</span><span>(</span><span>)</span><span>;</span>\n                        <span>.</span><span>.</span><span>.</span>\n                    <span>case</span> FOLLOWING<span>:</span>\n                        LOG<span>.</span><span>info</span><span>(</span><span>\"FOLLOWING\"</span><span>)</span><span>;</span>\n                        <span>setFollower</span><span>(</span><span>makeFollower</span><span>(</span>logFactory<span>)</span><span>)</span><span>;</span>\n                        follower<span>.</span><span>followLeader</span><span>(</span><span>)</span><span>;</span>\n                        <span>.</span><span>.</span><span>.</span>\n                    <span>case</span> LEADING<span>:</span>\n                        LOG<span>.</span><span>info</span><span>(</span><span>\"LEADING\"</span><span>)</span><span>;</span>\n                        <span>setLeader</span><span>(</span><span>makeLeader</span><span>(</span>logFactory<span>)</span><span>)</span><span>;</span>\n                        leader<span>.</span><span>lead</span><span>(</span><span>)</span><span>;</span>           <span>// LEADING 状态则作为 leader 角色保持运行</span>\n                        <span>.</span><span>.</span><span>.</span>\n                <span>}</span>\n            <span>}</span>\n\n        <span>}</span> <span>finally</span> <span>{</span>\n            LOG<span>.</span><span>warn</span><span>(</span><span>\"QuorumPeer main thread exited\"</span><span>)</span><span>;</span>\n            <span>.</span><span>.</span><span>.</span>\n        <span>}</span>\n    <span>}</span>\n    <span>.</span><span>.</span><span>.</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br></div></div></li>\n<li>\n<p>QuorumCnxManager 类负责管理服务器之间的通信。</p>\n<ul>\n<li>通信的消息采用以下数据结构：<div><pre><code><span>class</span> <span>QuorumPacket</span> <span>{</span>\n    <span>int</span> type<span>;</span>           <span>// 消息的类型。例如取值为 3 时表示 ACK 类型</span>\n    <span>long</span> zxid<span>;</span>\n    <span>byte</span><span>[</span><span>]</span> data<span>;</span>        <span>// 消息的内容</span>\n    <span>List</span><span><span>&lt;</span><span>Id</span><span>></span></span> authinfo<span>;</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>收、发的消息会放在队列 recvQueue、queueSendMap 中，异步处理。</li>\n<li>FastLeaderElection 选举算法的投票采用以下数据结构：<div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Notification</span> <span>{</span>\n    <span>public</span> <span>static</span> <span>final</span> <span>int</span> CURRENTVERSION <span>=</span> <span>0x2</span><span>;</span>\n    <span>int</span> version<span>;</span>        <span>// 投票格式的版本</span>\n\n    <span>long</span> sid<span>;</span>           <span>// 发送该投票的 server 的 id</span>\n    <span>QuorumPeer<span>.</span>ServerState</span> state<span>;</span>   <span>// 发送该投票的 server 的状态</span>\n    <span>QuorumVerifier</span> qv<span>;</span>\n\n    <span>long</span> leader<span>;</span>        <span>// 提议的 leader</span>\n    <span>long</span> electionEpoch<span>;</span> <span>// 本轮选举的 epoch</span>\n    <span>long</span> peerEpoch<span>;</span>     <span>// 提议的 leader 的 epoch</span>\n    <span>long</span> zxid<span>;</span>          <span>// 提议的 leader 的最新 zxid</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"日志\"> 日志</h2>\n<ul>\n<li>在 3 节点的 zk 集群中，重启其中一个节点，日志示例如下：<div><pre><code><span># 该 server 启动之后，默认监听 TCP 3888 端口，用于选举</span>\nINFO  <span>[</span>ListenerHandler-/0.0.0.0:3888:QuorumCnxManager<span>$Listener</span><span>$ListenerHandler</span>@1065<span>]</span> - <span>1</span> is accepting connections now, my election <span>bind</span> port: /0.0.0.0:3888\n<span># 启动之后处于 LOOKING 状态，发起一轮投票</span>\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@1374<span>]</span> - LOOKING\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:FastLeaderElection@944<span>]</span> - New election. My <span>id</span> <span>=</span> <span>1</span>, proposed <span>zxid</span><span>=</span>0x500000342\n<span># 发送一个投票给其它节点。其中 my state 表示当前节点的状态， n.* 表示 Notification 中的信息</span>\nINFO  <span>[</span>WorkerReceiver<span>[</span>myid<span>=</span><span>1</span><span>]</span>:FastLeaderElection<span>$Messenger</span><span>$WorkerReceiver</span>@389<span>]</span> - Notification: my state:LOOKING<span>;</span> n.sid:1, n.state:LOOKING, n.leader:1, n.round:0x1, n.peerEpoch:0x5, n.zxid:0x500000342, message <span>format</span> version:0x2, n.config version:0x0\n<span># 投票时，各个 server 需要两两连接，但每对 server 之间只需建立一个 TCP 连接。因此只允许由 id 更大的 server 主动建立连接，断开其余连接</span>\nINFO  <span>[</span>QuorumConnectionThread-<span>[</span>myid<span>=</span><span>1</span><span>]</span>-2:QuorumCnxManager@513<span>]</span> - Have smaller server identifier, so dropping the connection: <span>(</span>myId:1 --<span>></span> sid:3<span>)</span>\nINFO  <span>[</span>QuorumConnectionThread-<span>[</span>myid<span>=</span><span>1</span><span>]</span>-1:QuorumCnxManager@513<span>]</span> - Have smaller server identifier, so dropping the connection: <span>(</span>myId:1 --<span>></span> sid:2<span>)</span>\nINFO  <span>[</span>ListenerHandler-/0.0.0.0:3888:QuorumCnxManager<span>$Listener</span><span>$ListenerHandler</span>@1070<span>]</span> - Received connection request from /10.0.0.2:46728\nINFO  <span>[</span>ListenerHandler-/0.0.0.0:3888:QuorumCnxManager<span>$Listener</span><span>$ListenerHandler</span>@1070<span>]</span> - Received connection request from /10.0.0.3:35372\n<span># 收到其它 server 发来的投票。可见它们不处于 LOOKING 状态，已存在 leader</span>\nINFO  <span>[</span>WorkerReceiver<span>[</span>myid<span>=</span><span>1</span><span>]</span>:FastLeaderElection<span>$Messenger</span><span>$WorkerReceiver</span>@389<span>]</span> - Notification: my state:LOOKING<span>;</span> n.sid:3, n.state:LEADING, n.leader:3, n.round:0xa9, n.peerEpoch:0x5, n.zxid:0x400000000, message <span>format</span> version:0x2, n.config version:0x0\nINFO  <span>[</span>WorkerReceiver<span>[</span>myid<span>=</span><span>1</span><span>]</span>:FastLeaderElection<span>$Messenger</span><span>$WorkerReceiver</span>@389<span>]</span> - Notification: my state:LOOKING<span>;</span> n.sid:2, n.state:FOLLOWING, n.leader:3, n.round:0xa9, n.peerEpoch:0\nx5, n.zxid:0x400000000, message <span>format</span> version:0x2, n.config version:0x0\nINFO  <span>[</span>WorkerReceiver<span>[</span>myid<span>=</span><span>1</span><span>]</span>:FastLeaderElection<span>$Messenger</span><span>$WorkerReceiver</span>@389<span>]</span> - Notification: my state:LOOKING<span>;</span> n.sid:3, n.state:LEADING, n.leader:3, n.round:0xa9, n.peerEpoch:0x5\n, n.zxid:0x400000000, message <span>format</span> version:0x2, n.config version:0x0\n<span>..</span>.\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@857<span>]</span> - Peer state changed: following\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@1456<span>]</span> - FOLLOWING\n<span>..</span>.\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:Follower@75<span>]</span> - FOLLOWING - LEADER ELECTION TOOK - <span>23</span> MS\n<span># 该 server 结束选举，接着进入 discovery、synchronization 阶段</span>\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@863<span>]</span> - Peer state changed: following - discovery\nINFO  <span>[</span>LeaderConnector-/10.0.0.3:2888:Learner<span>$LeaderConnector</span>@330<span>]</span> - Successfully connected to leader, using address: /10.0.0.3:2888\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@863<span>]</span> - Peer state changed: following - synchronization\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:Learner@511<span>]</span> - Getting a <span>diff</span> from the leader 0x500000342\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@868<span>]</span> - Peer state changed: following - synchronization - <span>diff</span>\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:Learner@677<span>]</span> - Learner received NEWLEADER message\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:Learner@661<span>]</span> - Learner received UPTODATE message\nINFO  <span>[</span>QuorumPeer<span>[</span>myid<span>=</span><span>1</span><span>]</span><span>(</span>plain<span>=</span><span>0.0</span>.0.0:2181<span>)</span><span>(</span>secure<span>=</span>disabled<span>)</span>:QuorumPeer@863<span>]</span> - Peer state changed: following - broadcast\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "部署",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/ZooKeeper/deploy.html",
      "id": "/Hardware/Distributed/DistributedSystem/ZooKeeper/deploy.html",
      "content_html": "<h1 id=\"部署\"> 部署</h1>\n<h2 id=\"部署-2\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制版：</p>\n<div><pre><code><span>wget</span> https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.7.0/apache-zookeeper-3.7.0-bin.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div><p>解压后运行：</p>\n<div><pre><code>bin/zkServer.sh\n                start               <span># 在后台启动</span>\n                start-foreground    <span># 在前台启动</span>\n                stop\n                restart\n\n                status              <span># 显示状态</span>\n                version             <span># 显示版本信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>zookeeper</span><span>:</span>\n    <span>container_name</span><span>:</span> zookeeper\n    <span>image</span><span>:</span> zookeeper<span>:</span>3.7.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span># JVMFLAGS: -Xmx1G -Xms1G</span>\n      <span>ZOO_MY_ID</span><span>:</span> <span>1</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 2181<span>:</span><span>2181</span>\n      <span>-</span> 2888<span>:</span><span>2888</span>\n      <span>-</span> 3888<span>:</span><span>3888</span>\n      <span># - 8080:8080</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./conf<span>:</span>/conf\n      <span>-</span> ./data<span>:</span>/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div></li>\n</ul>\n<h2 id=\"版本\"> 版本</h2>\n<ul>\n<li>v3.4.0\n<ul>\n<li>于 2011 年发布。</li>\n<li>增加 autopurge 配置参数，用于自动清理数据目录。</li>\n</ul>\n</li>\n<li>v3.5.0\n<ul>\n<li>于 2014 年发布。</li>\n<li>增加 AdminServer 模块，通过内置的 Jetty 服务器提供 HTTP API 。\n<ul>\n<li>比如访问 URL <code>/commands</code> 可获取可用的命令列表，访问 URL <code>/commands/stats</code> 可获取 zk 的状态。</li>\n<li>建议用 AdminServer 代替以前的四字母命令。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>v3.6.0\n<ul>\n<li>于 2020 年发布。</li>\n<li>增加 sessionRequireClientSASLAuth 配置参数，强制客户端进行 SASL 认证。</li>\n</ul>\n</li>\n<li>v3.7.0\n<ul>\n<li>于 2021 年发布。</li>\n<li>增加 enforeQuota 配置参数，让 quota 具有强制性。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<p>配置文件 <code>conf/zoo.cfg</code> 示例：</p>\n<div><pre><code><span># clientPort=2181               # 监听一个供客户端连接的端口</span>\n<span>dataDir</span><span>=</span><span>/data                   # 数据快照的存储目录</span>\n<span># dataLogDir=/datalog           # 事务日志的存储目录，默认与 dataDir 一致。可采用不同的磁盘设备，从而避免竞争磁盘 IO ，提高 zk 的速度、吞吐量</span>\n<span># snapCount=100000              # 记录多少条事务日志时就保存一次快照。实际上会根据随机数提前保存快照，避免多个 zk 节点同时保存快照</span>\n<span>autopurge.purgeInterval</span><span>=</span><span>24      # 每隔 n 小时，自动清理一次快照文件、事务日志文件。默认值为 0 ，禁用该功能</span>\n<span># autopurge.snapRetainCount=3   # 每次 autopurge 时，每种文件只保留 Count 数量。默认值、最小值都为 3</span>\n\n<span># tickTime=2000                 # 时钟间隔，用作 zk 的基本时间单位，单位为 ms 。也是向其它 server、client 发送心跳包的时间间隔，而 TCP 会话超时是 2*tickTime</span>\n<span># initLimit=5                   # 各个 server 初始化连接到 leader 的超时时间，单位为 tickTime</span>\n<span># syncLimit=2                   # 各个 server 与 leader 之间通信（请求、回复）的超时时间，单位为 tickTime 。超过该时间则视作失去同步</span>\n<span># admin.enableServer=true       # 是否启用 AdminServer</span>\n<span># admin.serverPort=8080         # AdminServer 监听的端口</span>\n<span># 4lw.commands.whitelist=srvr,stat  # 一个白名单，声明允许使用哪些四字母命令，可通过 telnet 连接发送命令</span>\n<span>metricsProvider.className</span><span>=</span><span>org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider # 启用 Prometheus Metrics Provider</span>\n<span># metricsProvider.httpPort=7000</span>\n\n<span># 声明 zk 集群的 server 列表，每行的格式为 server.&lt;id>=&lt;host>:&lt;port1>:&lt;port2>[:role];[&lt;external_host>:]&lt;external_port></span>\n<span>#   - id 是一个数字编号，不可重复</span>\n<span>#   - host 是各个 server 的 IP 地址</span>\n<span>#   - port1 是各个 server 连接到 leader 的目标端口，port2 是各个 server 之间进行 leader 选举的端口</span>\n<span>#   - [&lt;external_host>:]&lt;external_port> 是另一个监听的 Socket ，供客户端访问</span>\n<span># 例如：当前 server id 为 1 时，会根据 server.1 的配置来监听 Socket ，根据其它 server 的配置去通信</span>\n<span>server.1</span><span>=</span><span>10.0.0.1:2888:3888;2181  # 对于当前 server 而言，该 IP 地址会用于绑定 Socket ，可改为 0.0.0.0</span>\n<span>server.2</span><span>=</span><span>10.0.0.2:2888:3888;2181</span>\n<span>server.3</span><span>=</span><span>10.0.0.3:2888:3888;2181</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br></div></div><ul>\n<li>zk server 的目录结构示例：<div><pre><code>├── conf\n│   ├── configuration.xsl\n│   ├── log4j.properties\n│   └── zoo.cfg\n└── data\n    ├── myid\n    └── version-2\n        ├── acceptedEpoch       <span># 该文件记录上一次接受的 NEWEPOCH 消息的 epoch 编号。下一次收到 NEWEPOCH 消息时，其 epoch 编号必须更大，才会接受</span>\n        ├── currentEpoch        <span># 该文件记录上一次接受的 NEWLEADER 消息的 epoch 编号。下一次收到 NEWLEADER 消息时，其 epoch 编号必须更大，才会接受</span>\n        ├── log.100000001       <span># 事务日志</span>\n        ├── log.200000001\n        ├── log.2000004b3\n        ├── snapshot.0          <span># 数据快照</span>\n        ├── snapshot.100000000\n        ├── snapshot.100000230\n        └── snapshot.2000004b2\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br></div></div><ul>\n<li>每个 zk server 启动时，会根据 <code>$dataDir/myid</code> 文件的值确定自己的 server 编号。因此初次部署时需要创建该文件：<div><pre><code><span>echo</span> <span>1</span> <span>></span> <span>$dataDir</span>/myid\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>当 zk server 启动时，如果 dataDir 目录不存在，它会自动创建该目录，导致使用错误的 myid 、空的 znode ，可能发生脑裂。</li>\n</ul>\n</li>\n<li>如果想将一个 server 声明为 observer 角色，需要在其配置文件中加入：<div><pre><code><span>peerType</span><span>=</span><span>observer</span>\n</code></pre>\n<div><span>1</span><br></div></div>然后在所有 server 的配置文件中声明：<div><pre><code><span>server.1:1</span><span>=</span><span>10.0.0.1:2888:3888;2181:observer</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h3 id=\"acl\"> ACL</h3>\n<ul>\n<li>\n<p>znode 默认允许任何客户端读写。可以给单个 znode 设置 ACL 规则，控制其访问权限。</p>\n<ul>\n<li>znode 的 ACL 规则不支持递归设置，也不支持继承，因此并不方便，不建议使用。</li>\n</ul>\n</li>\n<li>\n<p>相关命令：</p>\n<div><pre><code>getAcl <span>&lt;</span>path<span>></span>               <span># 读取 znode 的 ACL 规则</span>\nsetAcl <span>&lt;</span>path<span>></span>  <span>&lt;</span>acl<span>></span>        <span># 设置 znode 的 ACL 规则（只能设置一次，再次设置则不生效）</span>\n      -R                    <span># 递归处理子节点</span>\naddauth <span>&lt;</span>scheme<span>></span> <span>&lt;</span>user:pwd<span>></span> <span># 创建用户</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>ACL 规则的格式为 <code>scheme:user:permissions</code></p>\n<ul>\n<li>scheme 表示认证模式，分为以下几种：<div><pre><code>world     <span># 只定义了 anyone 用户，表示所有客户端，包括未登录的</span>\nauth      <span># 通过 addauth digest 创建的用户</span>\ndigest    <span># 与 auth 类似，但需要以哈希值形式输入密码，格式为 digest:&lt;user>:&lt;pwd_hash>:&lt;permissions></span>\n<span>ip</span>        <span># 限制客户端的 IP 地址，比如 ip:10.0.0.0/8:r</span>\nsasl      <span># 要求客户端通过 kerberos 的 SASL 认证</span>\nsuper     <span># 超级管理员，需要在 zk server 的启动命令中声明</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>permissions 是一组权限的缩写：<div><pre><code>Admin     <span># 允许设置 ACL</span>\nCreate    <span># 允许创建子节点</span>\nDelete    <span># 允许删除当前节点</span>\nRead      <span># 允许读取</span>\nWrite     <span># 允许写</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>例：</p>\n<div><pre><code><span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>0</span><span>]</span> getAcl /test    <span># 新建 znode 的 ACL 不会继承父节点，而是默认为 `world:anyone:cdrwa`</span>\n<span>'world,'</span>anyone\n<span>:</span> cdrwa\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>1</span><span>]</span> setAcl /test world:anyone:a\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>2</span><span>]</span> get /test\nInsufficient permission <span>:</span> /test                   <span># 报错表示权限不足</span>\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>3</span><span>]</span> addauth digest tester:123456    <span># 创建用户，如果已存在该用户则是登录</span>\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>4</span><span>]</span> setAcl /test auth:tester:cdrwa\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>5</span><span>]</span> getAcl /test\n<span>'digest,'</span>tester:Sc9QxOxG72+Wzo/j15TxX5UOqQs<span>=</span>                      <span># 密码以哈希值形式保存</span>\n<span>:</span> cdrwa\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>创建一个新终端时，再次执行 addauth 命令，就会登录指定用户。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"sasl\"> SASL</h3>\n<ul>\n<li>\n<p>zk server 支持通过 JAAS 框架启用 SASL 认证。</p>\n<ul>\n<li>默认不要求身份认证，可以被其它 server、client 直接连接，因此不安全。</li>\n<li>可启用以下 SASL 认证机制：\n<ul>\n<li>DIGEST-MD5</li>\n<li>Kerberos</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>例：启用 DIGEST-MD5 认证</p>\n<ol>\n<li>\n<p>在 zoo.cfg 中加入：</p>\n<div><pre><code><span>quorum.auth.enableSasl</span><span>=</span><span>true           # server 之间连接时是否启用 SASL 认证。默认为 false</span>\n<span>quorum.auth.learnerRequireSasl</span><span>=</span><span>true</span>\n<span>quorum.auth.serverRequireSasl</span><span>=</span><span>true    # 强制要求其它 server 连接到当前 server 时进行 SASL 认证。默认为 false</span>\n\n<span>authProvider.1</span><span>=</span><span>org.apache.zookeeper.server.auth.SASLAuthenticationProvider  # 在被 client 连接时启用 SASL 认证</span>\n<span>sessionRequireClientSASLAuth</span><span>=</span><span>true     # 强制要求 client 连接到当前 server 时进行 SASL 认证。默认为 false</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>如果启用了客户端 SASL 认证，但不强制要求认证，则未通过认证的客户端依然可以访问 zk ，读写数据。除非节点设置了 ACL 规则，只允许 SASL 用户访问。</li>\n<li>如果强制要求认证，而客户端未进行认证，则 zk 会拒绝连接，并记录报错日志：<div><pre><code>Client authentication scheme<span>(</span>s<span>)</span> <span>[</span>ip<span>]</span> does not match with any of the expected authentication scheme <span>[</span>sasl<span>]</span>, closing session.\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>创建一个 jaas.conf 配置文件：</p>\n<div><pre><code><span># 定义一些用户。在当前 server 被其它 server 连接时，允许对方使用这些用户</span>\nQuorumServer <span>{</span>\n      org.apache.zookeeper.server.auth.DigestLoginModule required\n      <span># user_test=\"******\"    # 按 user_&lt;NAME>=&lt;PASSWORD> 的格式定义用户</span>\n      <span>user_server</span><span>=</span><span>\"******\"</span><span>;</span>\n<span>}</span><span>;</span>\n<span># 指定当前 server 连接其它 server 时使用的用户</span>\nQuorumLearner <span>{</span>\n      org.apache.zookeeper.server.auth.DigestLoginModule required\n      <span>username</span><span>=</span><span>\"server\"</span>\n      <span>password</span><span>=</span><span>\"******\"</span><span>;</span>\n<span>}</span><span>;</span>\n<span># 定义一些用户。在当前 server 被 client 连接时，允许对方使用这些用户</span>\nServer <span>{</span>\n    org.apache.zookeeper.server.auth.DigestLoginModule required\n    <span>user_client</span><span>=</span><span>\"******\"</span><span>;</span>\n<span>}</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></div></div></li>\n<li>\n<p>将 jaas.conf 拷贝到每个 zk 的配置目录下，并添加 java 启动参数来启用它：</p>\n<div><pre><code><span>export</span> <span>SERVER_JVMFLAGS</span><span>=</span><span>\"-Djava.security.auth.login.config=/conf/jaas.conf\"</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>客户端连接 zk 时，需要使用以下 JAAS 配置文件：</p>\n<div><pre><code>Client <span>{</span>\n    org.apache.zookeeper.server.auth.DigestLoginModule required\n    <span>username</span><span>=</span><span>\"client\"</span>\n    <span>password</span><span>=</span><span>\"******\"</span><span>;</span>\n<span>}</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>可以声明以下环境变量，再执行 zkCli.sh ，试试能否作为客户端连接 zk ：</p>\n<div><pre><code><span>export</span> <span>CLIENT_JVMFLAGS</span><span>=</span><span>\"-Djava.security.auth.login.config=/conf/jaas.conf\"</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "ZooKeeper",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/ZooKeeper/",
      "id": "/Hardware/Distributed/DistributedSystem/ZooKeeper/",
      "content_html": "<h1 id=\"zookeeper\"> ZooKeeper</h1>\n<p>：一个用于协调分布式系统的数据库，简称为 zk 。采用 Java 开发。</p>\n<ul>\n<li><a href=\"https://zookeeper.apache.org/doc/current/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>原本是 Apache Hadoop 的子项目，现在已成为一个独立的 Apache 顶级项目。\n<ul>\n<li>取名为 ZooKeeper 是因为 Yahoo 公司的 Pig 等项目都是以动物命名，ZooKeeper 可以协调它们。</li>\n</ul>\n</li>\n<li>常见用途：\n<ul>\n<li>同步分布式系统中各节点的数据，实现一致性。</li>\n<li>作为注册中心，记录分布式系统中各个服务的信息。</li>\n<li>实现分布式锁。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "用法",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/ZooKeeper/usage.html",
      "id": "/Hardware/Distributed/DistributedSystem/ZooKeeper/usage.html",
      "content_html": "<h1 id=\"用法\"> 用法</h1>\n<h2 id=\"znode\"> znode</h2>\n<ul>\n<li>\n<p>zk 的命名空间中可以创建多个存储数据的寄存器，称为 znode 。</p>\n<ul>\n<li>所有 znode 按树形结构相关联，通过从 / 开始的绝对路径进行定位。</li>\n<li>每个 znode 可以存储一段文本数据，通常为键值对格式、JSON 格式。\n<ul>\n<li>znode 的主要优点是能实现分布式的数据一致性，应该只存储很少量的数据，低于 1 kB 。</li>\n<li>znode 的读写操作具有原子性。</li>\n</ul>\n</li>\n<li>zk 将 znode 数据存储在内存中，因此读取速度快。每次对 znode 进行写操作时，会备份写操作到事务日志中。</li>\n</ul>\n</li>\n<li>\n<p>用 <code>create -e</code> 会创建临时节点（Ephemeral）。</p>\n<ul>\n<li>客户端连接到 zk server 时，会创建一个会话（session）。\n<ul>\n<li>每个会话会被分配一个唯一的 session ID 。</li>\n<li>当客户端断开连接一定时间之后，zk 会认为该 session 失效，删除该 session 及其创建的临时节点。如果客户端重新连接，则需要创建一个新 session 。</li>\n</ul>\n</li>\n<li>临时节点不支持创建子节点。</li>\n</ul>\n</li>\n<li>\n<p>用 <code>create -s</code> 会自动给 znode 名称添加一个编号作为后缀。</p>\n<ul>\n<li>此编号为 10 位十进制数，从 0 开始递增。\n<ul>\n<li>编号与当前父节点关联，分配给各个子节点使用。</li>\n<li>即使子节点被删除，编号也会继续递增。</li>\n</ul>\n</li>\n<li>可以与临时节点搭配使用，创建一组按顺序编号的临时节点：<div><pre><code><span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>0</span><span>]</span> create -e -s /test/a\nCreated /test/a0000000000\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>1</span><span>]</span> create -e -s /test/a\nCreated /test/a0000000001\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>2</span><span>]</span> create -e -s /test/b\nCreated /test/b0000000002\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>支持给 znode 设置配额（quota），限制节点数量、大小。</p>\n<ul>\n<li>quota 并不具有强制性，超过限制时只会打印一条 WARN 级别的日志：<code>Quota exceeded</code></li>\n<li>给一个节点设置了 quota 之后，不允许再给它的祖先节点或子孙节点设置 quota 。</li>\n<li>所有节点的 quota 信息都记录在 <code>/zookeeper/quota/&lt;path&gt;/zookeeper_limits</code> 中。\n<ul>\n<li>当节点被删除时，其 quota 信息并不会自动删除。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"zkcli\"> zkCli</h2>\n<ul>\n<li>\n<p>zk 的 bin 目录下自带了多个 shell 脚本。执行以下脚本可进入 zk 的命令行终端：</p>\n<div><pre><code>bin/zkCli.sh\n    -server <span>[</span>host<span>]</span><span>[</span>:port<span>]</span>   <span># 连接到指定的 zk server 。默认是 localhost:2181</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>常用命令：</p>\n<div><pre><code>connect <span>[</span>host<span>]</span><span>[</span>:port<span>]</span>       <span># 连接到指定的 zk server</span>\nversion                     <span># 显示 zkCli 的版本</span>\n\n<span>ls</span> <span>&lt;</span>path<span>></span>                   <span># 显示指定路径下的所有 znode 。path 中不支持通配符 *</span>\n  -R                        <span># 递归显示子节点</span>\n\ncreate <span>&lt;</span>path<span>></span> <span>[</span>data<span>]</span> <span>[</span>acl<span>]</span>  <span># 创建 znode</span>\n      -e                    <span># 创建临时节点</span>\n      -s                    <span># 给 znode 名称添加一个编号作为后缀</span>\ndelete <span>&lt;</span>path<span>></span>               <span># 删除 znode 。存在子节点时不允许删除，会报错：Node not empty</span>\ndeleteall <span>&lt;</span>path<span>></span>            <span># 删除 znode 及其所有子节点</span>\n\nget    <span>&lt;</span>path<span>></span>               <span># 读取 znode 中的数据</span>\n<span>set</span>    <span>&lt;</span>path<span>></span> <span>&lt;</span>data<span>></span>        <span># 设置 znode 中的数据</span>\n<span>stat</span>   <span>&lt;</span>path<span>></span>               <span># 显示 znode 的状态</span>\n\nlistquota <span>&lt;</span>path<span>></span>            <span># 查看某个节点的配额</span>\nsetquota  <span>&lt;</span>path<span>></span>            <span># 设置配额</span>\n    -b <span>&lt;</span>bytes<span>></span>              <span># 限制该节点及子孙节点的总大小</span>\n    -n <span>&lt;</span>num<span>></span>                <span># 限制该节点及子孙节点的总数</span>\ndelquota  <span>&lt;</span>path<span>></span>            <span># 删除配额</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></li>\n<li>\n<p>例：创建 znode</p>\n<div><pre><code><span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>0</span><span>]</span> create /test\nCreated /test\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>1</span><span>]</span> get /test\nnull\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>命令提示符 <code>[zk: localhost:2181(CONNECTED) 1]</code> 中的数字编号表示这是当前终端执行的第几条命令，从 0 开始递增。</li>\n</ul>\n</li>\n<li>\n<p>例：查看 znode 的状态</p>\n<div><pre><code><span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>0</span><span>]</span> <span>stat</span> /test\ncZxid <span>=</span> 0x1bd                           <span># 创建该节点时的事务编号</span>\nctime <span>=</span> Wed Jul <span>28</span> <span>10</span>:09:01 UTC <span>2021</span>    <span># 创建该节点时的 UTC 时间</span>\nmZxid <span>=</span> 0x1bd\nmtime <span>=</span> Wed Jul <span>28</span> <span>10</span>:09:01 UTC <span>2021</span>\npZxid <span>=</span> 0x1bd\ncversion <span>=</span> <span>0</span>\ndataVersion <span>=</span> <span>0</span>                         <span># 该节点中的数据版本。每次 set 都会递增，即使数据没有变化</span>\naclVersion <span>=</span> <span>0</span>\nephemeralOwner <span>=</span> 0x0                    <span># 对于临时节点，该参数用于存储 Session ID 。对于其它节点，该参数的值为 0</span>\ndataLength <span>=</span> <span>0</span>                          <span># 该节点中的数据长度</span>\nnumChildren <span>=</span> <span>0</span>                         <span># 子节点的数量</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div></li>\n</ul>\n<h2 id=\"watch\"> watch</h2>\n<ul>\n<li>\n<p>zk 提供了 watch 机制，用于当某个节点发生某种事件时，通知客户端。</p>\n<ul>\n<li>用法：\n<ol>\n<li>客户端定义一个 watcher 类，注册到 zk ，监听某个事件。</li>\n<li>zk 记录了所有 watcher 。当相应的事件发生时，就通知客户端，并删除 watcher 。</li>\n</ol>\n</li>\n<li>用 Python 的 kazoo 库注册 watcher 的示例：<div><pre><code><span>@client<span>.</span>DataWatch</span><span>(</span><span>'/test'</span><span>)</span>  <span># 注册一个 watcher ，当目标节点的数据变化时，调用该函数</span>\n<span>def</span> <span>fun1</span><span>(</span>data<span>,</span> stat<span>)</span><span>:</span>\n    <span>print</span><span>(</span><span>'data changed: {}'</span><span>.</span><span>format</span><span>(</span>data<span>)</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>一种基于 zk 实现分布式锁的方案：</p>\n<ol>\n<li>在 zk 中创建一些代表某种资源的 znode ，比如 /mysql/table1/write 。</li>\n<li>多个业务程序同时申请占用某种资源时，需要分别作为客户端连接到 zk ，在相应的 znode 下创建一个子节点，带顺序编号。比如 create -s /mysql/table1/write 。</li>\n<li>每个客户端检查目标 znode 下的所有子节点：\n<ul>\n<li>如果自己创建的子节点编号最小，则代表自己获得了锁，有权占用资源。等使用完资源之后，再删除自己的子节点，代表释放锁。</li>\n<li>否则，注册 watcher ，监听前一个编号的子节点，等它被删除时，代表自己获得了锁。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"♢-kazoo\"> ♢ kazoo</h2>\n<p>：Python 的第三方库，提供了 Zookeeper 客户端的功能。</p>\n<ul>\n<li><a href=\"https://kazoo.readthedocs.io/en/latest/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>安装：<code>pip install kazoo</code></li>\n<li>例：<div><pre><code><span>>></span><span>></span> <span>from</span> kazoo<span>.</span>client <span>import</span> KazooClient\n<span>>></span><span>></span> zk<span>.</span>get_children<span>(</span><span>'/'</span><span>)</span>          <span># 获取子节点，返回一个 list ，包含各个子节点的名称</span>\n<span>[</span><span>'config'</span><span>,</span> <span>'zookeeper'</span><span>,</span> <span>.</span><span>.</span><span>.</span><span>]</span>\n<span>>></span><span>></span> zk<span>.</span>exists<span>(</span><span>'/test'</span><span>)</span>            <span># 判断节点是否存在。存在则返回其 stat ，不存在则返回 None</span>\n<span>>></span><span>></span> zk<span>.</span>create<span>(</span><span>'/test'</span><span>,</span> <span>b'Hello'</span><span>)</span>  <span># 创建节点，值必须为 bytes 类型</span>\n<span>'/test'</span>\n<span>>></span><span>></span> zk<span>.</span><span>set</span><span>(</span><span>'/test'</span><span>,</span> <span>b'Hello'</span><span>)</span>     <span># 设置节点的值，返回其 stat</span>\nZnodeStat<span>(</span>czxid<span>=</span><span>25769805253</span><span>,</span> mzxid<span>=</span><span>25769805254</span><span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>    \n<span>>></span><span>></span> data<span>,</span> stat <span>=</span> zk<span>.</span>get<span>(</span><span>'/test'</span><span>)</span>  <span># 读取节点的值和 stat</span>\n<span>>></span><span>></span> zk<span>.</span>delete<span>(</span><span>'/test'</span><span>)</span>            <span># 删除节点</span>\n<span>True</span>\n<span>>></span><span>></span> zk<span>.</span>delete<span>(</span><span>'/test'</span><span>)</span>            <span># 操作不存在的节点时会报错</span>\nkazoo<span>.</span>exceptions<span>.</span>NoNodeError\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n<li>例：连接时进行 SASL 认证，需要安装 <code>pip install pure-sasl</code><div><pre><code><span>from</span> kazoo<span>.</span>client <span>import</span> KazooClient\nsasl_options <span>=</span> <span>{</span>\n    <span>'mechanism'</span><span>:</span> <span>'DIGEST-MD5'</span><span>,</span>\n    <span>'username'</span><span>:</span> <span>'client'</span><span>,</span>\n    <span>'password'</span><span>:</span> <span>'******'</span>\n<span>}</span>\nzk <span>=</span> KazooClient<span>(</span>hosts<span>=</span><span>'10.0.0.1:2181'</span><span>,</span> timeout<span>=</span><span>3</span><span>,</span> sasl_options<span>=</span>sasl_options<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "简介",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/",
      "id": "/Hardware/Distributed/DistributedSystem/",
      "content_html": "<h1 id=\"简介\"> 简介</h1>\n<h2 id=\"分布式系统\"> 分布式系统</h2>\n<p>：是指将一个软件系统的各个进程分别部署不同主机上。</p>\n<ul>\n<li>小型的软件系统通常只部署在一台计算机上，属于集中式系统。而大型的软件系统通常部署成分布式系统，从而提高性能。</li>\n<li>优点：\n<ul>\n<li>便于横向增加系统节点，提高系统容量、性能，比如处理高并发流量。</li>\n<li>可以将同一个应用运行多个实例，一个实例挂掉了就用其它实例，实现服务的高可用。</li>\n<li>可以将一个数据存储多个副本，实现可靠的备份。</li>\n</ul>\n</li>\n<li>难点：\n<ul>\n<li>系统规模变大、结构变复杂，维护麻烦。</li>\n<li>同一个应用要运行多个实例，占用资源的冗余多。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"共识\"> 共识</h2>\n<p>：Consensus ，指系统中不同节点作出的决策相同。</p>\n<ul>\n<li>脑裂（brain split）\n<ul>\n<li>：指一个系统中存在多个有权决策的节点，并且作出了不同决策。</li>\n</ul>\n</li>\n<li>拜占庭将军问题（Byzantine Generals Problem）\n<ul>\n<li>：多个拜占庭将军自主观察敌情，然后通过投票决定进攻还是撤退。但可能存在不诚实的将军，或者投票信件被丢失、篡改。</li>\n<li>该问题代表系统中某些节点传播虚假的信息，导致其它节点作出了错误决策。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"paxos\"> Paxos</h3>\n<p>：一个共识算法，于 1990 年发布。</p>\n<ul>\n<li>系统中一些节点担任 Proposer ，有权发出提议（Proposal）、投票。\n<ul>\n<li>其它节点担任 Acceptor ，有权投票。</li>\n</ul>\n</li>\n<li>每个提议需要超过半数的节点投票同意，才能通过。\n<ul>\n<li>这属于多数派（Majority）策略，允许低于半数的节点不可用。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"raft\"> Raft</h3>\n<p>：一个共识算法，在 Paxos 算法的基础上作了改进。</p>\n<ul>\n<li>系统中有且仅有一个节点担任 Leader ，有权发出提议（Proposal）、投票。\n<ul>\n<li>其它节点担任 Follower ，有权投票。</li>\n</ul>\n</li>\n<li>每次准备修改集群数据时，Leader 会将该提议发送给所有 Follower ，等超过半数的节点同意并执行之后，才通过该提议，从而达成共识、数据一致性。\n<ul>\n<li>超过半数，又称为达到法定成员数（Quorum）。\n<ul>\n<li>当节点总数为 N 时，法定成员数为 <code>Quorum = N/2 + 1</code> ，其中 / 为整除运算符。</li>\n<li>Quorum 必须超过半数。如果允许 Quorum 等于集群半数，甚至小于半数，则集群就可能同时存在不止一个 leader ，发生脑裂。</li>\n</ul>\n</li>\n<li>并不会等到所有节点都同意，因此属于最终一致性。</li>\n<li>该共识是容错的，允许 Quorum 之外的节点不可用。\n<ul>\n<li>增加节点总数可以提供系统可用性，但是会增加每次达成共识的耗时。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Leader 定期发送心跳包给其它节点。如果心跳超时，则其它节点变为 Candidate 状态，选举一个节点担任新 Leader 。</li>\n<li>每次选出 Leader ，就开始一个新任期，称为 Term 。</li>\n<li>每个节点都信任其它节点发来的信息，因此不能实现拜占庭容错。</li>\n</ul>\n<h3 id=\"bully\"> Bully</h3>\n<p>：一个共识算法，与 Raft 算法相似。</p>\n<ul>\n<li>如果 Leader 节点故障，则由 ID 最大的一个节点担任新 Leader 。</li>\n</ul>\n<h3 id=\"gossip\"> Gossip</h3>\n<p>：一个广播消息的协议，常用于 P2P 服务。</p>\n<ul>\n<li>每个节点定期散播一次消息，最多发送给 k 个节点。\n<ul>\n<li>发送消息之后，不必确保对方接收。</li>\n<li>其它节点收到消息之后，会散播给除了源节点之外的其它节点。</li>\n</ul>\n</li>\n<li>消息被病毒式传播，能实现最终一致性。</li>\n</ul>\n<h3 id=\"pow\"> PoW</h3>\n<p>：工作量证明（Proof of Work），一个区块链的共识算法。</p>\n<ul>\n<li>比特币采用基于哈希函数的 PoW 算法：\n<ul>\n<li>以区块为单位写入数据。</li>\n<li>每个节点需要进行大量哈希运算，穷举猜测下一个区块的 nonce 随机数，第一个猜出来的节点有权生成该区块，然后广播给其它节点。</li>\n</ul>\n</li>\n<li>可实现顺序一致性，并实现拜占庭容错。</li>\n</ul>\n<h3 id=\"pos\"> PoS</h3>\n<p>：权益证明（Proof of Stake），一个区块链的共识算法。</p>\n<ul>\n<li>每个节点拥有的代币越多，则权益越大，有更大概率获得下一个区块的打包权。</li>\n<li>与 PoW 相比，节省了运算成本。</li>\n</ul>\n<h2 id=\"一致性\"> 一致性</h2>\n<p>：Consistency ，指系统中不同节点拥有的数据副本一致（通常还应该是最新的数据）。</p>\n<ul>\n<li>数据库的 ACID 指的是事务的一致性，而分布式系统中主要研究数据的一致性。</li>\n<li>通常，需要各节点先达成共识，才能实现数据一致性。\n<ul>\n<li>不过数据不一致性时，各节点可能因为不同的数据副本而作出不同的决策，不容易达成共识。</li>\n</ul>\n</li>\n<li>每个写操作之后，如果等所有节点复制完新数据，才开始下一个读操作，则称为同步复制，否则称为异步复制。</li>\n<li>常见的几种一致性模型：\n<ul>\n<li>强一致性：采用同步复制，保证各节点的一致性。\n<ul>\n<li>严格一致性（Strict consistency）\n<ul>\n<li>：每个写操作之后，各节点会立即变为一致，即实时复制。比如将写操作复制到各节点上同时执行。</li>\n</ul>\n</li>\n<li>顺序一致性（Sequential consistency）\n<ul>\n<li>：当程序发出多个读写操作时，各节点会按相同顺序执行这些操作。因此某些节点可能因为执行慢而数据滞后，但顺序并不会出错。</li>\n</ul>\n</li>\n<li>线性一致性\n<ul>\n<li>：具有实时性的顺序一致性，各节点同时遵守相同顺序。每个写操作在所有节点都生效之后，才会开始下一个操作。</li>\n<li>又称为可线性化（Linearizability）、原子一致性。</li>\n<li>强弱程度：严格一致性 &gt; 线性一致性 &gt; 顺序一致性</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>弱一致性：采用异步复制，因此各节点可能不一致。\n<ul>\n<li>因果一致性（Causal consistency）\n<ul>\n<li>：具有因果关系的多个操作（比如读写同一个数据），才保证顺序一致性，而其它并发操作则不限制。</li>\n</ul>\n</li>\n<li>最终一致性（Eventual consistency）\n<ul>\n<li>：允许各节点暂时不一致，但保证在一定时间内实现一致。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"可用性\"> 可用性</h2>\n<ul>\n<li>\n<p>服务可用（Available）</p>\n<ul>\n<li>：指客户端发出请求时，能收到正常的响应。\n<ul>\n<li>响应时长不能超过正常范围。</li>\n<li>响应的内容不能是错误的，但可以不是最新的数据。</li>\n</ul>\n</li>\n<li>服务不可用时，又称为服务中断、故障。</li>\n</ul>\n</li>\n<li>\n<p>可用性（Availability）</p>\n<ul>\n<li>：又称为可用率。如果服务可用的时长，占提供服务的总时长的比例接近 100% ，则称为可用性高，否则称为可用性低。</li>\n<li>采用负载均衡、健康检查等措施可以实现服务的高可用性（High Availability，HA）。</li>\n</ul>\n</li>\n<li>\n<p>SLA （Service Level Agreement ，服务等级协议）</p>\n<ul>\n<li>：由服务提供商承诺的服务质量指标，如果未达到则给客户一定赔偿。</li>\n<li>比如承诺服务的全年可用性为 99% ，即不可用的时长低于 3.65 天；全年可用性为 99.9% ，即不可用时长低于 0.365*24=8.76 小时。</li>\n</ul>\n</li>\n<li>\n<p>提高系统性能的常见方案：</p>\n<ul>\n<li>垂直扩展：增加单个服务的性能，比如增加服务器的 CPU 、内存等资源。</li>\n<li>水平扩展：增加服务实例的数量，比如在一组服务器上分别部署一个服务实例。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见问题\"> 常见问题</h3>\n<ul>\n<li>\n<p>单点故障（Single Point of Failure）</p>\n<ul>\n<li>：单个模块不可用，导致整个服务不可用。或者单个服务不可用，导致整个系统不可用。</li>\n</ul>\n</li>\n<li>\n<p>级联故障（Cascading failure）</p>\n<ul>\n<li>：上游服务故障，导致下游调用它的服务故障。</li>\n</ul>\n</li>\n<li>\n<p>服务雪崩</p>\n<ul>\n<li>：级联故障导致大量服务不可用。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见措施\"> 常见措施</h3>\n<ul>\n<li>\n<p>服务熔断</p>\n<ul>\n<li>：当上游服务可用性降低时，下游服务停止调用它，避免级联故障。</li>\n<li>服务熔断之后，下游服务可以拒绝提供服务，也可以开始服务降级。</li>\n</ul>\n</li>\n<li>\n<p>服务降级</p>\n<ul>\n<li>：降低给客户端的响应质量，从而降低服务器的负载。</li>\n<li>例如停止次要功能、延时处理请求、减少响应内容、使用旧的响应内容，甚至拒绝服务。</li>\n<li>可以在配置平台增加一个参数开关，启用它则开始服务降级。</li>\n</ul>\n</li>\n<li>\n<p>服务限流</p>\n<ul>\n<li>：属于服务降级，指服务限制一定时间内处理的请求数量，拒绝超过限制的请求，避免因为负载过大而故障。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"健康检查\"> 健康检查</h4>\n<p>：Health Check ，通过软件检查集群中各个服务器的状态，自动发现故障的服务器。</p>\n<ul>\n<li>\n<p>发现故障节点之后，需要及时将它下线，避免客户端访问它而服务不可用。或者通过重启等方式修复。</p>\n</li>\n<li>\n<p>keepalived ：一个命令行工具，用于对多个服务器进行健康检查，自动去除故障服务器。</p>\n<ul>\n<li>在集群的每个服务器上部署一份，相互之间通过 VRRP（Virtual Router Redundancy Protocol ，虚拟路由冗余协议）通信，实现路由的高可用。</li>\n<li>工作在第三层时，是基于 ICMP 协议检查服务器是否在线。</li>\n<li>工作在第四层时，是基于 TCP 协议检查服务器的端口是否开通。</li>\n<li>工作在第七层时，是基于 HTTP 协议检查服务器是否正常工作。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"负载均衡\"> 负载均衡</h4>\n<p>：Load Balance ，将服务器部署多个实例，用一个反向代理服务器接收所有客户端的访问流量，然后按特定的策略分发给各个实例。</p>\n<ul>\n<li>优点：\n<ul>\n<li>容易横向扩容。</li>\n<li>均衡各个服务器的负载压力，降低单点故障的风险。</li>\n<li>有的负载均衡服务器能对各个服务器进行健康检查，避免将流量转发给故障的服务器，从而避免单点故障。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"分区容错性\"> 分区容错性</h2>\n<p>：Partition tolerance ，指系统出现网络分区时，能否继续提供服务。</p>\n<ul>\n<li>如果任意两个节点之间不能在指定时间内将数据同步一致（比如网络延迟较大、节点故障），则视作网络中断，出现了网络分区。</li>\n</ul>\n<h2 id=\"cap-定理\"> CAP 定理</h2>\n<p>：一个流行的理论，认为在分布式系统中，一致性（C）、可用性（A）、分区容错性（P） 三种性能通常不能同时满足，最多满足两种。</p>\n<ul>\n<li>假设分布式系统中存在两个节点 N1、N2 ，两者的网络通信必然存在一定延迟。先在 N1 处写入数据 D ，然后在 N2 处读取数据 D 。此时：\n<ul>\n<li>如果 N2 等同步 N1 的数据之后再返回响应，则满足了 C ，但不满足 A 。</li>\n<li>如果 N2 不同步 N1 的数据就返回响应，则必然是错误的响应，满足了 A ，但不满足 C 。</li>\n<li>如果 N1 或 N2 因为网络分区而不能提供服务，则满足了 C ，但不满足 A、P 。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "etcd",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/DistributedSystem/etcd.html",
      "id": "/Hardware/Distributed/DistributedSystem/etcd.html",
      "content_html": "<h1 id=\"etcd\"> etcd</h1>\n<p>：一个用于协调分布式系统的数据库，以键值对的形式存储数据。</p>\n<ul>\n<li><a href=\"https://etcd.io/docs/v3.5/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>由 CoreOS 团队于 2013 年开源，采用 Golang 开发。</li>\n<li>采用 Raft 算法实现分布式一致性，因此需要部署奇数个实例。</li>\n</ul>\n<blockquote>\n<p>TODO：了解原理</p>\n</blockquote>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "大数据",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Introduction/bigData.html",
      "id": "/Hardware/Distributed/Introduction/bigData.html",
      "content_html": "<h1 id=\"大数据\"> 大数据</h1>\n<ul>\n<li>大数据是指大规模的数据集合。</li>\n<li>使用传统的数据管理系统难以存储、处理大数据，通常采用分布式存储、分布式计算等技术。</li>\n</ul>\n<h2 id=\"数据结构\"> 数据结构</h2>\n<ul>\n<li>结构化数据：每条数据的内容类似，可以分成多个字段。一般整理成二维表，存储在关系型数据库中。</li>\n<li>半结构化数据：比如 JSON 文档中，key 是结构化数据，value 是非结构化数据。</li>\n<li>非结构化数据：每条数据的内容差异大，不能分成多个字段，一般按整体存储。比如图像、音频、视频。</li>\n</ul>\n<h2 id=\"hadoop\"> Hadoop</h2>\n<p>：一个分布式系统，用于存储、处理大数据。</p>\n<ul>\n<li>历史：\n<ul>\n<li>2004 年，Doug Cutting 基于 Lucenne 开发了一个 Web 搜索引擎 Nutch ，类似于 Google 。它包含爬虫功能，并开发了 HDFS、MapReduce 软件。</li>\n<li>2006 年，Doug Cutting 入职 Yahoo 公司，发布了 Hadoop ，后来交给 ASF 管理。</li>\n</ul>\n</li>\n<li>Hadoop 系统包含的主要软件：\n<ul>\n<li>Hadoop Common</li>\n<li>ZooKeeper</li>\n<li>HDFS\n<ul>\n<li>：一个分布式文件系统，起源于 Google 的论文 Google File System 。</li>\n</ul>\n</li>\n<li>HBase\n<ul>\n<li>：一个分布式列式数据库。起源于 Google 的论文 BigTable 。</li>\n</ul>\n</li>\n<li>Hive\n<ul>\n<li>：一个数据仓库，可以将结构化的数据文件映射为一张数据库表，支持 SQL 查询。</li>\n</ul>\n</li>\n<li>MapReduce\n<ul>\n<li>：一个大数据处理框架，起源于 Google 的同名论文。</li>\n<li>支持批处理，支持分布式并行处理。</li>\n</ul>\n</li>\n<li>Yarn\n<ul>\n<li>：一个资源调度器，负责将 CPU、内存等集群资源分配给各种应用。</li>\n</ul>\n</li>\n<li>Pig\n<ul>\n<li>：一个基于 MapReduce 的大数据处理框架。用户使用 Pig Latin 语言编写一些脚本，会被自动转换成 MapReduce 任务。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>CDH（Cloudera's Distribution Including Apache Hadoop）\n<ul>\n<li>：一个 Hadoop 发行版，由 Cloudera 公司发布。</li>\n</ul>\n</li>\n<li>CM（Cloudera Manager）\n<ul>\n<li>：一个管理 CDH 集群的软件。</li>\n<li>采用 C/S 架构：\n<ul>\n<li>在一台主机上运行 cloudera-scm-server 进程，提供 Web 端管理网站。</li>\n<li>在其它主机上运行 cloudera-scm-agent 进程，基于 supervisor 启动、停止进程，还会修改服务配置、监控主机。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Storm\n<ul>\n<li>：一个大数据处理框架。由 Twitter 公司开源，采用 Clojure 语言开发。</li>\n<li>不支持批处理，只支持流处理。</li>\n</ul>\n</li>\n<li>Spark\n<ul>\n<li>：一个大数据处理框架。采用 scala 语言开发。</li>\n<li>支持批处理，通过小型批处理来实现流处理。</li>\n<li>将数据存放在内存中，因此比 MapReduce 快很多。</li>\n</ul>\n</li>\n<li>Flink\n<ul>\n<li>：一个大数据处理框架。采用 Java 语言开发。</li>\n<li>支持批处理、流处理。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "云计算",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Introduction/cloudComputing.html",
      "id": "/Hardware/Distributed/Introduction/cloudComputing.html",
      "content_html": "<h1 id=\"云计算\"> 云计算</h1>\n<ul>\n<li>在传统模式下，用户想部署一个 Web 网站时，需要自己购买服务器裸机，然后安装操作系统、Web 服务器、依赖软件。</li>\n<li>在云计算时代，用户可以直接使用云服务商提供的 Web、数据库等服务器，省掉一些亲自动手的工作量。</li>\n</ul>\n<h2 id=\"服务模式\"> 服务模式</h2>\n<p>云计算的服务模式包括：</p>\n<ul>\n<li>IaaS ：基础设施即服务（Infrastructure as a Service），云端提供一些基础设施供用户使用，比如服务器裸机。</li>\n<li>Paas ：平台即服务（Platform as a Service），云端提供平台资源供用户使用，比如 Linux 服务器、硬盘。</li>\n<li>SaaS ：软件即服务（Software as a Service），云端提供一些软件供用户使用，比如给开发者提供已部署的 MySQL、Nginx ，给普通用户提供电商网站。</li>\n<li>BaaS ：后端即服务（Backend as a Service），云端提供一些后端服务供用户使用，比如数据库、对象存储。</li>\n<li>FaaS ：函数即服务（Function as a Service），云端支持直接运行用户编写的函数代码。\n<ul>\n<li>FaaS 将应用拆解成比微服务更小的单位，且具有无状态、即写即用等特点。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关概念\"> 相关概念</h2>\n<ul>\n<li>VPS（Virtual Private Servers，虚拟专用服务器）\n<ul>\n<li>：又称为虚拟机。可以在一台物理服务器上通过 Hypervisor 技术运行多个虚拟服务器，分配给多个用户私自使用。</li>\n</ul>\n</li>\n<li>CVM（Cloud Virtual Machine，云虚拟机）\n<ul>\n<li>：指云平台提供的 VPS 。</li>\n<li>有的云平台将它称为 ECS（Elastic Compute Service ，弹性计算服务器）。</li>\n</ul>\n</li>\n<li>VPC（Virtual Private Cloud，虚拟私有云）\n<ul>\n<li>：云平台上一种小的逻辑分区，管理一组 VPS ，专门供某个用户或企业使用，像一个 Paas 层的私有云。</li>\n</ul>\n</li>\n<li>VDC（Virtual Data Center，虚拟数据中心）\n<ul>\n<li>：云平台上一种大的逻辑分区，管理一组 VPS、CPU、内存、硬盘等资源，像一个 IaaS 层的私有云。</li>\n</ul>\n</li>\n<li>OpenStack\n<ul>\n<li>：一个开源的云平台框架，采用 Python 开发，常用于搭建云平台并管理服务器等资源，提供 IaaS 服务。</li>\n</ul>\n</li>\n<li>云原生（Cloud Native）\n<ul>\n<li>：将软件的开发、测试、运维等过程都迁移到云平台上进行，充分利用云平台的优势。</li>\n</ul>\n</li>\n<li>Serverless\n<ul>\n<li>：一种设计模式，又称为无服务器架构。是让软件开发人员专注于代码开发，不必关注在服务器上如何构建、部署、运维。</li>\n<li>云计算的 BaaS 和 FaaS 都属于 Serverless 。</li>\n<li>例如微信小程序实现了 Serverless ，开发者写好代码之后就可以直接发布。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"vpc-组网\"> VPC 组网</h2>\n<ul>\n<li>一个 VPC 中包含的各个 VPS ，默认位于同一个局域网，可以使用内网 IP 相互通信。\n<ul>\n<li>不同 VPC 之间网络隔离，需要添加路由表才能相互通信。</li>\n<li>一个 VPC 中还可以划分多个子网，但这些子网之间并没有网络隔离。</li>\n</ul>\n</li>\n<li>安全组：相当于防火墙规则，用于控制主机的出入流量。\n<ul>\n<li>主机的出入流量先受到主机上 firewalld 防火墙的控制，再受到云平台安全组的控制。</li>\n<li>可以给一个或多个 VPS 绑定一个或多个安全组。</li>\n</ul>\n</li>\n</ul>\n<p>VPC 内部的主机与外部通信的方法：</p>\n<ul>\n<li>可以给 VPC 添加 NAT 网关，让 VPC 能与公网通信。此时网络包的流向为：VPC 主机 → NAT 网关 → 公网主机 。</li>\n<li>可以给 VPC 添加 VPN ，让 VPC 能与本地网络通信。此时网络包的流向为：VPC 主机 → VPC 网关 → 公网中转 → VPN 服务器 → 公网中转 → 本地网关 → 本地主机 。</li>\n<li>可以给 VPC 中的一个主机绑定外部某个网络的 IP ，使其能够与该网络的主机通信。这个 IP 在不用的时候可以解绑，因此称为 &quot;弹性 IP&quot; 。\n<ul>\n<li>例如，使用弹性公网 IP ，就可以让 VPC 中的主机与公网通信。</li>\n<li>一个弹性 IP 只能让 VPC 中的一个主机与外部通信，而一个 NAT 网关可以让 VPC 中的所有主机与外部通信。</li>\n<li>如果将一个弹性公网 IP 给 NAT 网关使用，就可以让 VPC 中的所有主机都能访问公网。</li>\n</ul>\n</li>\n</ul>\n<p>下图是腾讯云的网络架构：</p>\n<p><img src=\"./frame.jpg\" alt=\"\" loading=\"lazy\"></p>\n<ul>\n<li>CVM 部署在 region1 的 VPC 中，不具备公网 IP ，不能主动与公网通信，对外网不可见。</li>\n<li>当公网中的主机主动访问集群时，要将请求发送到 LBS 的公网 IP 地址、80 端口。\n<ul>\n<li>LBS 会将从 80 端口收到的流量转发给 VPC 中的几个 CVM——将数据包的目的 IP、目的端口改为某台 CVM 的内网 IP、端口。CVM 收到该包之后，会把它转发到相应的容器端口。</li>\n<li>当 CVM 处理完请求之后，会将回复的数据包通过 LBS 返回给公网的主机。</li>\n</ul>\n</li>\n<li>当 CVM 主动访问公网时，要将请求发送到 NAT 网关，由 NAT 网关进行代理。</li>\n<li>当 CVM1 主动访问同一个 VPC 内的另一个 CVM2 时，需要先配置从 CVM1 到 CVM2 的路由表。</li>\n<li>当 CVM1 主动访问另一个 VPC 内的 CVM 时，需要先通过 &quot;对等连接&quot; 功能将两个 VPC 的网络连通，然后配置两个 VPC 之间的路由表。</li>\n<li>在腾讯云购买一个 VPS 之后，如果需要连通公网，有两种计费模式：\n<ul>\n<li>按带宽计费 ：限制公网出带宽的最大值，即 VPS 发向公网的流量。\n<ul>\n<li>公网入带宽与公网出带宽相等，但至少会分配 10 Mbps ，因为能共享机房的入带宽。</li>\n</ul>\n</li>\n<li>按流量计费 ：每隔一个小时，按实际使用的公网出流量计费。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "简介",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Introduction/",
      "id": "/Hardware/Distributed/Introduction/",
      "content_html": "<h1 id=\"简介\"> 简介</h1>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "ActiveMQ",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/ActiveMQ.html",
      "id": "/Hardware/Distributed/MessageQueue/ActiveMQ.html",
      "content_html": "<h1 id=\"activemq\"> ActiveMQ</h1>\n<p>：一个消息队列服务器。</p>\n<ul>\n<li><a href=\"http://activemq.apache.org/components/classic/documentation\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Java 开发，由 ASF 管理。</li>\n<li>功能丰富，支持 JMS、AMQP、STOMP、MQTT 等多种协议。</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<h3 id=\"单示例\"> 单示例</h3>\n<ul>\n<li>先安装 JRE 1.7+ 环境，然后下载二进制版：<div><pre><code><span>wget</span> https://archive.apache.org/dist/activemq/5.16.0/apache-activemq-5.16.0-bin.tar.gz\n</code></pre>\n<div><span>1</span><br></div></div>解压后运行：<div><pre><code>bin/activemq\n            console   <span># 启动（在前台运行）</span>\n            start     <span># 启动（以 daemon 方式运行）</span>\n            stop\n            restart\n            status    <span># 显示运行状态</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"集群\"> 集群</h3>\n<p>ActiveMQ 集群主要有两种架构：</p>\n<ul>\n<li>Master-Slave 集群\n<ul>\n<li>：一个节点为 Master ，其它节点为 slave 。由 Master 节点提供服务。当 Master 节点宕机后，选出一个 Slave 节点作为新的 Master 节点。</li>\n<li>优点是可以保证服务的高可用性，缺点是不能解决负载均衡和分布式的问题。</li>\n</ul>\n</li>\n<li>Broker Cluster 集群\n<ul>\n<li>：各个 broker 互相连通，共享消息队列，同时提供服务。</li>\n<li>优点是可以解决负载均衡和分布式的问题，缺点是不能保证服务的高可用性。</li>\n<li>一般将 Master-Slave 和 Broker Cluster 两种方式结合使用。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>\n<p>ActiveMQ 会运行一个 jetty 服务器，提供 Web 管理页面。</p>\n<ul>\n<li>访问 <a href=\"http://127.0.0.1:8161/admin/\" target=\"_blank\" rel=\"noopener noreferrer\">http://127.0.0.1:8161/admin/</a> 即可，默认账号、密码为 admin、admin 。</li>\n<li>在 <code>conf/jetty-realm.properties</code> 中可以自定义账号、密码：<div><pre><code><span># username: password [,rolename ...]</span>\nleo: <span>123456</span>, admin\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>在 <code>conf/activemq.xml</code> 的 broker 区块中可以配置各种通信协议对应的 URI ：</p>\n<div><pre><code><span><span><span>&lt;</span>transportConnectors</span><span>></span></span>\n    <span><span><span>&lt;</span>transportConnector</span> <span>name</span><span><span>=</span><span>\"</span>openwire<span>\"</span></span> <span>uri</span><span><span>=</span><span>\"</span>tcp://0.0.0.0:61616?maximumConnections=1000<span title=\"&amp;\">&amp;amp;</span>wireFormat.maxFrameSize=104857600<span>\"</span></span><span>/></span></span>\n    <span><span><span>&lt;</span>transportConnector</span> <span>name</span><span><span>=</span><span>\"</span>amqp<span>\"</span></span> <span>uri</span><span><span>=</span><span>\"</span>amqp://0.0.0.0:5672?maximumConnections=1000<span title=\"&amp;\">&amp;amp;</span>wireFormat.maxFrameSize=104857600<span>\"</span></span><span>/></span></span>\n    <span><span><span>&lt;</span>transportConnector</span> <span>name</span><span><span>=</span><span>\"</span>stomp<span>\"</span></span> <span>uri</span><span><span>=</span><span>\"</span>stomp://0.0.0.0:61613?maximumConnections=1000<span title=\"&amp;\">&amp;amp;</span>wireFormat.maxFrameSize=104857600<span>\"</span></span><span>/></span></span>\n    <span><span><span>&lt;</span>transportConnector</span> <span>name</span><span><span>=</span><span>\"</span>mqtt<span>\"</span></span> <span>uri</span><span><span>=</span><span>\"</span>mqtt://0.0.0.0:1883?maximumConnections=1000<span title=\"&amp;\">&amp;amp;</span>wireFormat.maxFrameSize=104857600<span>\"</span></span><span>/></span></span>\n    <span><span><span>&lt;</span>transportConnector</span> <span>name</span><span><span>=</span><span>\"</span>ws<span>\"</span></span> <span>uri</span><span><span>=</span><span>\"</span>ws://0.0.0.0:61614?maximumConnections=1000<span title=\"&amp;\">&amp;amp;</span>wireFormat.maxFrameSize=104857600<span>\"</span></span><span>/></span></span>\n<span><span><span>&lt;/</span>transportConnectors</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><p>通常使用 TCP 端口 61616 。</p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "原理",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/Kafka/Principle.html",
      "id": "/Hardware/Distributed/MessageQueue/Kafka/Principle.html",
      "content_html": "<h1 id=\"原理\"> 原理</h1>\n<h2 id=\"架构\"> 架构</h2>\n<ul>\n<li>基本架构：\n<ul>\n<li>运行一些 Kafka 服务器，组成集群。</li>\n<li>用户运行客户端程序，连接到 Kafka 服务器，作为 Producer 生产消息，或者作为 consumer 消费消息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"broker\"> Broker</h3>\n<p>：Kafka 服务器，负责存储、管理消息。</p>\n<ul>\n<li>\n<p>broker 会将消息以日志文件的形式存储，存放在 <code>logs/&lt;topic&gt;-&lt;partition&gt;/</code> 目录下，因此会受到文件系统的影响。</p>\n</li>\n<li>\n<p>虽然 broker 将消息保存在磁盘中，但采取以下措施提高了读写速度：</p>\n<ul>\n<li>生产消息、消费消息时，是按顺序读写磁盘，因此比随机读写的速度快很多。</li>\n<li>生产消息时，先将消息写入 MMAP 内存映射文件，然后再 flush 到磁盘。因此写入速度更快。</li>\n<li>消费消息时，用 sendfile 快速发送文件。</li>\n</ul>\n</li>\n<li>\n<p>Kafka 集群中会选出一个 broker 作为 Controller 。</p>\n<ul>\n<li>每个 broker 在启动之后，都会尝试到 zk 中创建 <code>/controller</code> 节点，创建成功则当选。</li>\n<li>Controller 负责管理整个集群，比如在每个 partition 的所有副本中选出一个作为 leader replica 。</li>\n<li>增加 broker 的数量，就可以对 Kafka 集群横向扩容。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"producer\"> Producer</h3>\n<p>：生产者，即生产消息的客户端，负责发布消息到 broker 。</p>\n<ul>\n<li>Producer 向某个 topic 发布消息时，默认会将消息随机分配到不同的 partition 。\n<ul>\n<li>可以指定 partition ，也可以指定均衡策略来自动分配 partition 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"consumer\"> Consumer</h3>\n<p>：消费者，即消费消息的客户端，负责从 broker 消费消息。</p>\n<ul>\n<li>consumer 消费消息的步骤：\n<ol>\n<li>发送请求到 broker ，订阅一个或多个 topic 。</li>\n<li>定时发送请求到 broker ，轮询自己订阅的 topic 。如果存在可消费的消息，则拉取到本机。</li>\n</ol>\n</li>\n<li>consumer 消费消息的过程类似于下载文件，消息被 &quot;消费&quot; 之后并不会被删除，除非超过 broker 的存储限制。</li>\n</ul>\n<h3 id=\"consumer-group\"> Consumer Group</h3>\n<p>：消费者组，用于在逻辑上对 consumer 分组管理。</p>\n<ul>\n<li>客户端运行 consumer 实例时，可以指定其所属的 consumer group 。\n<ul>\n<li>如果不指定，则该 consumer 的 group 为空，不会被 Coordinator 协调。</li>\n</ul>\n</li>\n<li>一个 consumer 同时只能消费一个 partition ，因此通常用一组 consumer 同时消费一个 topic 下的不同 partition ，通过并行消费来提高消费速度。\n<ul>\n<li>当一个 group 消费一个 topic 时，如果 partition 的数量小于 consumer 的数量，就会有 consumer 空闲。\n<ul>\n<li>因此，最好将 partition 的数量设置成与 consumer 数量相同，或者为 consumer 数量的整数倍，以便于平均分配。</li>\n</ul>\n</li>\n<li>不同 group 之间相互独立，即使同时消费同一个 topic 下的同一个 partition 也互不影响。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"coordinator\"> Coordinator</h3>\n<ul>\n<li>\n<p>Kafka 会根据 consumer group ID 的哈希值，分配 topic: __consumer_offsets 中的一个 partition ，用于存储该 group 的 offset 信息。</p>\n<ul>\n<li>该 partition 的 leader replica 所在的 broker 运行的 GroupCoordinator 类，负责管理该 group 的 consumer、offset 。</li>\n</ul>\n</li>\n<li>\n<p>Coordinator 管理的 consumer group 分为多个状态（group state）：</p>\n<div><pre><code>PreparingRebalance    <span># 准备开始 Rebalance</span>\nCompletingRebalance   <span># 即将完成 Rebalance ，正在发送分配方案</span>\nStable                <span># 已完成 Rebalance ，可以正常消费</span>\nEmpty                 <span># 组内没有成员</span>\nDead                  <span># 组内没有成员，且 offset 等 metadata 已删除，不能响应请求</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n<li>\n<p>consumer 启动时，如果指定了所属的 consumer group ，则会发送带有 UNKNOWN_MEMBER_ID 标志的 JoinGroup 请求给 Coordinator ，请求加入指定的 group ，并请求分配 member id 。</p>\n<ul>\n<li>GroupCoordinator 会给每个 consumer 分配一个 member id ，格式为 <code>client.id-UUID</code> ，其中 UUID 为随机生成的十六进制编号。\n<ul>\n<li>第一个加入 group 的 consumer 会担任组长（Group Leader）。</li>\n<li>每个 consumer 会定时向 Coordinator 发送 Heartbeat 请求，以维持在线。否则 Coordinator 会从该 group 删除该 consumer 。</li>\n</ul>\n</li>\n<li>组长负责分配各个 consumer 消费的 partition ，该过程称为 Consumer Rebalance 。流程如下：\n<ol>\n<li>组长从 Coordinator 获取该组的 consumer 列表，分配各个 consumer 消费的 partition 。</li>\n<li>组长发送 SyncGroup 请求给 Coordinator ，告知分配方案。</li>\n<li>Coordinator 等收到 consumer 的 Heartbeat 请求时，在响应中告知已发生 Rebalance 。</li>\n<li>consumer 删掉内存中的 UUID 等成员信息，重新加入该 group ，进入新的 generation 。</li>\n</ol>\n</li>\n<li>当 group 的 consumer 或 partition 数量变化时，都会自动触发一次 Rebalance 。</li>\n<li>每次 Rebalance 时，group 就开始一个新时代（generation）。\n<ul>\n<li>每个 generation 拥有一个从 0 递增的编号。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>日志示例：</p>\n<div><pre><code><span># broker 1 的 Coordinator 被分配了任务，开始管理 __consumer_offsets partition 对应的 consumer group</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Elected as the group coordinator <span>for</span> partition <span>28</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Elected as the group coordinator <span>for</span> partition <span>1</span>\n<span># broker 1 的 Coordinator 被取消分配，停止管理一些 consumer group</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Resigned as the group coordinator <span>for</span> partition <span>3</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Resigned as the group coordinator <span>for</span> partition <span>0</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Resigned as the group coordinator <span>for</span> partition <span>24</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><div><pre><code><span># 一个成员加入 stable 状态的 consumer group ，被分配了 member id</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Dynamic Member with unknown member <span>id</span> joins group test_group_1 <span>in</span> Stable state. Created a new member <span>id</span> consumer-1-5ee75316-16c0-474f-9u2d-6e57f4b238b3 <span>for</span> this member and <span>add</span> to the group.\n<span># 准备开始 rebalance ，原因是加入一个新成员，其 group instance id 为 None ，说明不是 Static Member</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Preparing to rebalance group test_group_1 <span>in</span> state PreparingRebalance with old generation <span>38</span> <span>(</span>__consumer_offsets-21<span>)</span> <span>(</span>reason: Adding new member consumer-1-5ee75316-16c0-474f-9u2d-6e57f4b238b3 with group instance <span>id</span> None<span>)</span>\n<span># group 进入 stable 状态，开始一个新 generation ，拥有 3 个成员</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Stabilized group test_group_1 generation <span>39</span> <span>(</span>__consumer_offsets-21<span>)</span> with <span>3</span> members\n<span># Coordinator 收到 leader 发来的分配方案</span>\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Assignment received from leader <span>for</span> group test_group_1 <span>for</span> generation <span>39</span>. The group has <span>3</span> members, <span>0</span> of <span>which</span> are static.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>Preparing to rebalance 的几种 reason 示例：<div><pre><code>Adding new member <span>$memberId</span> with group instance <span>id</span> <span>$groupInstanceId</span>     <span># 加入一个新成员</span>\nremoving member <span>$memberId</span> on LeaveGroup                                 <span># 一个成员发出 LeaveGroup 请求，主动离开 group</span>\nremoving member <span>$memberId</span> on heartbeat expiration                       <span># 一个成员因为 Heartbeat 超时，被移出 group</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>Rebalance 期间，所有 consumer 都要暂停消费，开销较大。因此应该尽量避免触发 Rebalance ，比如重启 consumer 时。</p>\n<ul>\n<li>consumer 重启之后，会发送 JoinGroup 请求重新加入 group ，被分配一个新的 member id ， 触发一次 Rebalance 。\n<ul>\n<li>而旧的 member id 不再使用，等到 Heartbeat 超时，又会触发一次 Rebalance 。</li>\n</ul>\n</li>\n<li>Kafka v2.3 开始，consumer 增加了配置参数 <code>group.instance.id</code> 。启用该参数时，consumer 会从默认的 Dynamic Member 变成 Static Member 类型。\n<ul>\n<li>consumer 重启之后发送 JoinGroup 请求时，Coordinator 会识别出它是 Static Member ，会分配一个新 UUID ，并删除之前的 member id 。因此不会触发 Rebalance ，除非 Heartbeat 超时。</li>\n<li>日志示例：<div><pre><code>INFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Static member Some<span>(</span>static_member_1<span>)</span> of group test_group_1 with unknown member <span>id</span> rejoins, assigning new member <span>id</span> static_member_1-cdf1c4ea-2f1c-4f4d-bc46-bf443e5f7322, <span>while</span> old member <span>id</span> static_member_1-8b5d89b3-0757-4441-aeaa-50e7f9f55cee will be removed.\nINFO\t<span>[</span>GroupCoordinator <span>1</span><span>]</span>: Static member <span>which</span> joins during Stable stage and doesn't affect selectProtocol will not trigger rebalance.\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"zookeeper\"> Zookeeper</h3>\n<ul>\n<li>Kafka 采用 Zookeeper 作为分布式框架，记录 broker、topic、consumer 等信息。\n<ul>\n<li>每个 broker 启动时，会到 zk 记录自己的 IP 和端口，供其它 broker 发现和访问。</li>\n<li>根据 broker.id 识别每个 broker ，即使 IP 和端口变化也会自动发现。</li>\n<li>Kafka 集群第一次启动时会生成一个随机的 cluster ID ，保存到 zk 中。\n<ul>\n<li>broker 每次连接 zk 时都会检查 cluster ID 是否一致，因此一个 zk 集群不能供多个 Kafka 集群使用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kafka 在 zk 中使用的 znode 示例：<div><pre><code>/\n├── admin               <span># 用于传递一些管理命令</span>\n│   └── delete_topics   <span># 默认为 null</span>\n├── cluster\n│   └── <span>id</span>              <span># 记录 Kafka 集群的 id</span>\n├── brokers\n│   ├── ids             <span># 记录 broker 的信息。各个 broker 会在其下创建临时节点，当 broker 下线时会被自动删除</span>\n│   ├── seqid\n│   └── topics          <span># 记录 topic 的信息</span>\n├── config\n├── consumers\n├── controller          <span># 记录当前的 controller ，这是一个临时节点</span>\n├── controller_epoch    <span># 记录 controller 当选的 epoch</span>\n<span>..</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br></div></div><ul>\n<li>例：<div><pre><code><span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>0</span><span>]</span> get /brokers/ids/1\n<span>{</span><span>\"listener_security_protocol_map\"</span>:<span>{</span><span>\"PLAINTEXT\"</span><span>:</span><span>\"PLAINTEXT\"</span><span>}</span>,<span>\"endpoints\"</span>:<span>[</span><span>\"PLAINTEXT://10.0.0.1:9092\"</span><span>]</span>,<span>\"jmx_port\"</span>:-1,<span>\"features\"</span>:<span>{</span><span>}</span>,<span>\"host\"</span><span>:</span><span>\"10.0.0.1\"</span>,<span>\"timestamp\"</span><span>:</span><span>\"1627960927890\"</span>,<span>\"port\"</span>:9092,<span>\"version\"</span>:5<span>}</span>\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>1</span><span>]</span> get /brokers/topics/__consumer_offsets/partitions/0/state\n<span>{</span><span>\"controller_epoch\"</span>:1,<span>\"leader\"</span>:2,<span>\"version\"</span>:1,<span>\"leader_epoch\"</span>:0,<span>\"isr\"</span>:<span>[</span><span>2,3</span>,1<span>]</span><span>}</span>\n<span>[</span>zk: localhost:2181<span>(</span>CONNECTED<span>)</span> <span>3</span><span>]</span> get /controller\n<span>{</span><span>\"version\"</span>:1,<span>\"brokerid\"</span>:1,<span>\"timestamp\"</span><span>:</span><span>\"1627960928034\"</span><span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消息\"> 消息</h2>\n<ul>\n<li>Kafka 处理数据的基本单位为消息（message），又称为 record 。</li>\n<li>消息采用 Kafka 自定的格式封装，类似于 TCP 报文。</li>\n</ul>\n<h3 id=\"topic\"> Topic</h3>\n<p>：主题，用于在逻辑上对消息分组管理。</p>\n<ul>\n<li>不同 topic 之间相互独立，它们的消息互不影响。</li>\n</ul>\n<h3 id=\"partition\"> Partition</h3>\n<p>：分区。</p>\n<ul>\n<li>\n<p>topic 在存储时会拆分成一个或多个 partition 。</p>\n<ul>\n<li>每个 partition 可以存储多个副本。</li>\n<li>partition 存储到磁盘时，每隔一定时间或大小就划分出一个日志段（LogSegment）文件。</li>\n</ul>\n</li>\n<li>\n<p>broker 每收到一条新消息时，先看它属于哪个 topic ，然后考虑分配到哪个 partition 中存储。</p>\n<ul>\n<li>Kafka 会尽量将同一 topic 的各个 partition 存储到不同的 broker 上，从而分散负载。</li>\n<li>Kafka 会尽量将同一 partition 的各个 replica 存储到不同的 broker 上，从而抵抗单点故障。</li>\n<li>客户端只需要连接 broker 就能生产、消费消息，不需要关心消息的实际存储位置。</li>\n</ul>\n</li>\n<li>\n<p>Kafka 数据目录的结构如下：</p>\n<div><pre><code>/data/kafka-logs/                     <span># 数据日志的存储目录，其下每个子目录的命名格式为 &lt;topic>-&lt;partition id></span>\n├── test-0/                           <span># 该目录用于存储 test 主题的 0 号分区</span>\n│   ├── 00000000000000000000.index    <span># 第一个 LogSegment 的索引文件，其中第一个消息的 offset 为 0</span>\n│   ├── 00000000000000000000.log      <span># 第一个 LogSegment 的数据日志文件</span>\n│   ├── 00000000000000367814.index    <span># 第二个 LogSegment 的索引文件，其中第一个消息的 offset 为 367814</span>\n│   ├── 00000000000000367814.log\n│   ├── leader-epoch-checkpoint       <span># 记录每一任 leader 当选时的 epoch 和 offset</span>\n│   └── partition.metadata\n├── test-2/\n└── test-3/\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>partition 采用稀疏索引，避免单个索引文件的体积过大。读取某个 offset 的消息时，需要先找到它对应的 LogSegment ，再根据该 LogSegment 的 index 文件找到消息。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"replica\"> Replica</h3>\n<ul>\n<li>\n<p>每个 partition 会存储多个副本（replica），从而备份数据。</p>\n</li>\n<li>\n<p>Kafka 会自动在每个 partition 的所有副本中选出一个作为 <code>leader replica</code> ，而其它副本称为 <code>follower replica</code> 。</p>\n<ul>\n<li>leader 可以进行读写操作，负责处理客户端的访问请求。</li>\n<li>follower 只能进行读操作，负责与 leader 的数据保持一致，从而备份数据。</li>\n<li>客户端读写 partition 时看到的总是 leader ，看不到 follower 。</li>\n</ul>\n</li>\n<li>\n<p><code>Assigned Replicas</code></p>\n<ul>\n<li>：指一个 partition 拥有的所有 replica 。</li>\n</ul>\n</li>\n<li>\n<p><code>Preferred replica</code></p>\n<ul>\n<li>：指 assigned replicas 中的第一个 replica 。</li>\n<li>新建一个 partition 时，一般由 preferred replica 担任 leader replica 。\n<ul>\n<li>当所在的 broker 故障时，会选出其它 replica 担任 leader 。</li>\n<li>当 preferred replica 恢复时，会担任普通的 replica 。但 kafka 会自动尝试让 preferred replica 重新担任 leader ，该过程称为 preferred-replica-election、Partition Rebalance 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><code>In Sync Replicas (ISR)</code></p>\n<ul>\n<li>：指一个 partition 中与 leader 保持同步的所有 replica 。</li>\n<li>如果一个 follower 的滞后时间超过 <code>replica.lag.time.max.ms</code> ，或者 leader 连续这么长时间没有收到该 follower 的 fetch 请求，则认为它失去同步，从 ISR 中移除。\n<ul>\n<li>例如：IO 速度过慢，使得 follower 从 leader 复制数据的速度，比 leader 新增数据的速度慢，就会导致 lastCaughtUpTimeMs 一直没有更新，最终失去同步。</li>\n</ul>\n</li>\n<li>leader 本身也属于 ISR 。</li>\n<li>只有 ISR 中的 replica 可以被选举为 leader 。</li>\n</ul>\n</li>\n<li>\n<p><code>Under-replicated Replicas Set</code></p>\n<ul>\n<li>：指一个 partition 中与 leader 没有同步的 replica 。</li>\n<li>当一个 follower 将 leader 的最后一条消息（Log End Offset）之前的日志全部成功复制之后，则认为该 follower 已经赶上了 leader ，记录此时的时刻作为该 follower 的 <code>lastCaughtUpTimeMs</code> 。</li>\n<li>Kafka 的 ReplicaManager 会定期计算每个 follower 的 lastCaughtUpTimeMs 与当前时刻的差值，作为该 follower 对 leader 的滞后时间。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"offset\"> Offset</h3>\n<ul>\n<li>\n<p>partition 中存储的每个消息都有一个唯一的偏移量（offset），用于索引。</p>\n<ul>\n<li>offset 的值采用 Long 型变量存储，容量为 64 bit 。</li>\n<li>生产者生产消息时、消费者消费消息时，offset 都会自动递增。\n<ul>\n<li>因此，partition 类似于先入先出的队列，先生产的消息会先被消费。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><code>Log Start Offset</code></p>\n<ul>\n<li>：partition 中第一个消息的偏移量。刚创建一个 topic 时，该值为 0 。每次 broker 清理消息日志之后，该值会增大一截。</li>\n</ul>\n</li>\n<li>\n<p><code>Log End Offset (LEO)</code></p>\n<ul>\n<li>：partition 中最新一个消息的偏移量。</li>\n</ul>\n</li>\n<li>\n<p><code>High Watemark (HW)</code></p>\n<ul>\n<li>：partition 允许被 consumer 看到的最高偏移量。</li>\n<li>partition 的 leader 新增一个消息时，会更新 LEO 的值，并传给 follower 进行同步。因此 HW 的值总是小于等于 LEO 。</li>\n<li>consumer 只能看到 HW ，不知道 LEO 的值。</li>\n</ul>\n</li>\n<li>\n<p><code>Consumer Committed Offset</code></p>\n<ul>\n<li>：某个 consumer 在某个 partition 中最后一次消费的消息的偏移量。</li>\n<li>它由 Coordinator 记录，可以保证在 Rebalance 之后 consumer 不会重复消费。</li>\n<li>Kafka 能确保一个消息成功生产，但不能确保消息被消费，需要客户端主动更新 Committed Offset 。</li>\n</ul>\n</li>\n<li>\n<p><code>Consumer Current Offset</code></p>\n<ul>\n<li>：某个 consumer 在某个 partition 中下一次希望消费的消息的偏移量。</li>\n<li>它由 consumer 自己记录，可以保证在多次调用 poll() 方法时不会重复消费。\n<ul>\n<li>如果记录的 offset 偏小，就会重复消费。如果记录的 offset 偏大，就会遗漏消费。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><code>Consumer Lag</code></p>\n<ul>\n<li>：consumer 在消费某个 partition 时的滞后量，即还有多少个消息未消费。</li>\n<li>它的值等于 <code>HW - Consumer Committed Offset</code> 。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "部署",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/Kafka/deploy.html",
      "id": "/Hardware/Distributed/MessageQueue/Kafka/deploy.html",
      "content_html": "<h1 id=\"部署\"> 部署</h1>\n<h2 id=\"部署-2\"> 部署</h2>\n<ul>\n<li>\n<p>下载二进制版：</p>\n<div><pre><code><span>wget</span> https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.6.0/kafka_2.13-2.6.0.tgz\n</code></pre>\n<div><span>1</span><br></div></div><p>解压后运行：</p>\n<div><pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties   <span># 启动 zookeeper 服务器</span>\nbin/kafka-server-start.sh     config/server.properties      <span># 启动 kafka broker 服务器</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>部署 Kafka 集群时，需要先部署 zk 集群，然后让每个 broker 服务器连接到 zk ，即可相互发现，组成集群。\n<ul>\n<li>Kafka 发行版包含了 zk 的可执行文件，可以同时启动 kafka、zk 服务器，也可以在其它地方启动 zk 服务器。</li>\n</ul>\n</li>\n<li>Kafka 会尽快将数据写入磁盘存储，因此占用的内存一般不超过 6G ， CPU 平均负载为 2~4 核。\n<ul>\n<li>kafka-server-start.sh 中默认配置了以下环境变量，限制 Kafka 占用的内存：<div><pre><code><span>export</span> <span>KAFKA_HEAP_OPTS</span><span>=</span><span>\"-Xmx1G -Xms1G\"</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>声明以下环境变量，即可让 broker 开启 JMX 监控，监听一个端口：<div><pre><code><span>export</span> <span>JMX_PORT</span><span>=</span><span>9093</span>\n<span># export JMX_OPTS=\"-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false\"</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>或者用 docker-compose 部署：</p>\n<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>kafka</span><span>:</span>\n    <span>container_name</span><span>:</span> kafka\n    <span>image</span><span>:</span> bitnami/kafka<span>:</span>2.8.0\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>environment</span><span>:</span>\n      <span># KAFKA_HEAP_OPTS: -Xmx1G -Xms1G</span>\n      <span>ALLOW_PLAINTEXT_LISTENER</span><span>:</span> <span>'yes'</span>\n    <span>ports</span><span>:</span>\n      <span>-</span> 9092<span>:</span><span>9092</span>\n    <span>volumes</span><span>:</span>\n      <span>-</span> ./config<span>:</span>/bitnami/kafka/config\n      <span>-</span> ./data<span>:</span>/bitnami/kafka/data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>Kafka 官方没有提供 Docker 镜像，这里采用社区提供的一个镜像。\n<ul>\n<li>该镜像会根据环境变量配置 server.properties 文件，这里直接挂载配置目录，通过 CUSTOM_INIT_SCRIPT 执行命令还原配置文件。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"版本\"> 版本</h2>\n<ul>\n<li><a href=\"https://kafka.apache.org/downloads\" target=\"_blank\" rel=\"noopener noreferrer\">Kafka 的版本列表</a>\n<ul>\n<li>例如 kafka_2.13-2.6.0.tgz ，前面的 2.13 是指 Scala 编译器的版本，后面的 2.6.0 是指 Kafka 的版本。</li>\n<li>使用 Kafka 时，应该尽量让客户端与服务器的版本一致，避免不兼容。</li>\n</ul>\n</li>\n<li>v0.10.0.0\n<ul>\n<li>：于 2016 年发布。新增了 Kafka Streams API ，用于流处理。</li>\n</ul>\n</li>\n<li>v0.11.0.0\n<ul>\n<li>：于 2017 年发布。改进了消息格式。支持事务、幂等性。</li>\n</ul>\n</li>\n<li>v1.0.0\n<ul>\n<li>：于 2017 年发布。</li>\n</ul>\n</li>\n<li>v1.1.0\n<ul>\n<li>：于 2018 年发布。</li>\n<li>改进了 Controller ，提高更改 leader replica 的效率，将 broker 正常终止的耗时从几分钟减少到几秒。</li>\n</ul>\n</li>\n<li>v2.0.0\n<ul>\n<li>：于 2018 年发布。</li>\n</ul>\n</li>\n<li>v2.8.0\n<ul>\n<li>：于 2021 年发布。支持用内置的 KRaft 协议取代 zookeeper ，提高 Kafka 的稳定性、内部通信效率。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"配置\"> 配置</h2>\n<ul>\n<li>kafka 的配置目录示例：<div><pre><code>config/\n├── consumer.properties       <span># 消费者的配置文件</span>\n├── log4j.properties          <span># Java 日志的配置文件</span>\n├── producer.properties       <span># 生产者的配置文件</span>\n├── server.properties         <span># broker 的配置文件</span>\n└── zookeeper.properties      <span># zk 的配置文件</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>启动 broker 时只需读取 server.properties、log4j.properties 文件。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"server-properties\"> server.properties</h3>\n<p>配置示例：</p>\n<div><pre><code><span># 关于 kafka 集群</span>\n<span>broker.id</span><span>=</span><span>0                               # 该 broker 在 Kafka 集群中的唯一标识符，默认为 -1 ，必须赋值为一个非负整数</span>\n<span>listeners</span><span>=</span><span>PLAINTEXT://0.0.0.0:9092        # broker 监听的 Socket 地址</span>\n<span>advertised.listeners</span><span>=</span><span>PLAINTEXT://10.0.0.1:9092  # 当前 broker 供其它 broker 和客户端访问的地址。它会在 zk 中公布，默认采用 listeners 的值</span>\n\n<span># 关于 zk</span>\n<span>zookeeper.connect</span><span>=</span><span>10.0.0.1:2181,10.0.0.2:2181,10.0.0.3:2181   # 要连接的 zk 节点，多个地址之间用逗号分隔</span>\n<span># zookeeper.connection.timeout.ms=6000</span>\n\n<span># 保存数据日志</span>\n<span>log.dirs</span><span>=</span><span>/data/kafka-logs                 # broker 存放数据日志的目录，如果有多个目录则用逗号分隔</span>\n<span># log.roll.ms=null                        # 每个 LogSegment 的最长写入时间，超过该值则会创建一个新的 LogSegment 用于写入。默认未设置，采用 log.roll.hours 的值</span>\n<span># log.roll.hours=168                      # 默认为 7*24h</span>\n<span># log.segment.bytes=1073741824            # 每个 LogSegment 的最大体积，超过该值则会创建一个新的 LogSegment 用于写入。默认为 1G</span>\n<span># log.flush.interval.messages=null        # 每个日志分区，每接收多少个消息就 flush 一次，即将内存中的数据写入磁盘</span>\n<span># log.flush.interval.ms=null              # 每个日志分区，每经过多少毫秒就 flush 一次</span>\n<span># log.flush.offset.checkpoint.interval.ms=60000 # 每隔多少毫秒，刷新一次 checkpoint</span>\n\n<span># 清理数据日志</span>\n<span># log.cleanup.policy=delete               # LogSegment 的清理策略，可以是 delete、compact</span>\n<span># log.retention.check.interval.ms=300000  # 每隔多久检查一次各个 LogSegment 是否应该清理。默认为 5min</span>\n<span>log.retention.bytes</span><span>=</span><span>10737418240           # 限制单个 partition 的大小，超过则删除其中最旧的 LogSegment 。默认为 -1 ，即不限制</span>\n<span># log.retention.ms=null                   # 限制单个 LogSegment 的保存时长，超过则删除。默认未设置，采用 log.retention.minutes 的值。如果设置为 -1 ，则不限制</span>\n<span># log.retention.minutes=null              # 默认未设置，采用 log.retention.hours 的值</span>\n<span>log.retention.hours</span><span>=</span><span>24                    # 默认为 7*24h</span>\n\n<span># 关于 topic</span>\n<span># auto.create.topics.enable=true          # 当客户端生产、消费一个不存在的 topic 时，是否自动创建该 topic</span>\n<span># delete.topic.enable=true                # 是否允许删除 topic</span>\n<span># compression.type=producer               # broker 对消息的压缩格式。取值为 producer 则采用与生产者相同的压缩格式</span>\n<span>message.max.bytes</span><span>=</span><span>10485760                # 允许接收的最大 batch.size ，默认为 1M ，这里设置为 10M 。该参数作用于所有 topic ，也可以对每个 topic 分别设置 max.message.bytes</span>\n\n<span># 关于 partition</span>\n<span>num.partitions</span><span>=</span><span>6                          # 新建 topic 的默认 partition 数，默认为 3 。这里设置为 6 ，当 consumer group 包含 1、2、3 个成员时都可以平均分配</span>\n<span>default.replication.factor</span><span>=</span><span>2              # 新建 partition 的默认副本数，默认为 1</span>\n<span># offsets.topic.num.partitions=50         # __consumer_offsets 主题的 partition 数</span>\n<span># offsets.topic.replication.factor=3      # __consumer_offsets 主题的每个 partition 的副本数。部署单节点时必须减至 1</span>\n<span># auto.leader.rebalance.enable=true           # 是否自动进行 Partition Rebalance</span>\n<span># leader.imbalance.check.interval.seconds=300 # Controller 每隔多久检查一次是否执行 Partition Rebalance</span>\n<span># leader.imbalance.per.broker.percentage=10   # 如果该 broker 上的非 preferred leader 超过该百分比，则进行 Partition Rebalance</span>\n\n<span># 关于进程</span>\n<span># background.threads=10                   # broker 处理后台任务的线程数</span>\n<span># num.network.threads=3                   # broker 处理网络请求的线程数</span>\n<span># num.io.threads=8                        # broker 处理磁盘 IO 的线程数，应该不小于磁盘数</span>\n\n<span># 关于网络</span>\n<span>session.timeout.ms</span><span>=</span><span>60000                  # 会话超时，默认为 10s 。如果在该时长内 broker 一直没有收到 consumer 的 heartbeat 请求，则认为 consumer 下线</span>\n<span># heartbeat.interval.ms=3000              # broker 等待 heartbeat 请求的超时时间。通常设置为 session.timeout.ms 的 1/3 ，以允许超时两次</span>\n<span># socket.send.buffer.bytes=102400         # socket 发送消息的缓冲区大小，默认为 100K</span>\n<span># socket.receive.buffer.bytes=102400      # socket 接收消息的缓冲区大小，默认为 100K 。网络延迟高于 1ms 时，增加 buffer 有利于提高传输效率，但会占用更多内存</span>\n<span># socket.request.max.bytes=104857600      # socket 允许接收的单个消息的最大大小，默认为 100M</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br></div></div><ul>\n<li>可以让 broker 监听多个地址：<div><pre><code><span>listeners</span><span>=</span>PLAINTEXT://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093             <span># 定义两个 listener 。当客户端通过某个 listener 连接时，就采用相应的 advertised.listeners</span>\nadvertised.listeners<span>=</span>PLAINTEXT://10.0.0.1:9092,OUTSIDE://1.1.1.1:9093\nlistener.security.protocol.map<span>=</span>PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT  <span># advertised.listeners 的解析格式</span>\ninter.broker.listener.name<span>=</span>PLAINTEXT                                  <span># broker 之间通信时采用的 listener</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>增加 partition 数量有利于提高并发规模，但会增加 zk 的负载。\n<ul>\n<li>Kafka v1.1.0 改进了 Controller ，每个 broker 建议最多存储 4k 个 partition（包括副本数），每个集群最多 20w 个。</li>\n<li>如果用 KRaft 协议取代 zookeeper ，则可以支持数百万的 partition 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"producer-properties\"> producer.properties</h3>\n<p>配置示例：</p>\n<div><pre><code><span>bootstrap.servers</span><span>=</span><span>10.0.0.1:9092,10.0.0.2:9092   # 初始连接的 broker 地址。先通过它获取所有 broker 的 advertised.listeners 地址，再实际连接</span>\n<span># client.id=''                  # 客户端的 ID</span>\n\n<span># acks=1                        # 判断消息发送成功的策略</span>\n  <span># 取值为 0 ，则不等待 broker 的回复，直接认为消息已发送成功</span>\n  <span># 取值为 1 ，则等待 leader replica 确认接收消息</span>\n  <span># 取值为 all ，则等待消息被同步到所有 replica</span>\n<span># retries=2147483647            # 发送消息失败时，如果不超过 delivery.timeout.ms 时长，则尝试重发多少次</span>\n\n<span># batch.size=16384              # 限制每个 batch 的大小，默认为 16K</span>\n<span># buffer.memory=33554432        # 限制生产者用于发送消息的缓冲区大小，默认为 32M</span>\n<span># compression.type=none         # 发送消息时，batch 采用的压缩格式，默认不压缩</span>\n<span>max.request.size</span><span>=</span><span>10485760       # 限制生产者向 broker 发送的每个请求的大小，这限制了每个请求包含的 batch （压缩之后）数量。默认为 1M ，这里设置为 10M</span>\n<span># max.block.ms=60000            # 生产者调用 send() 等方法时，如果 buffer.memory 不足或 metadata 获取不到，阻塞等待的超时时间</span>\n\n<span># linger.ms=0                   # 生产者创建每个 batch 时，等待多久才发送。调大该值，有助于让每个 batch 包含更多消息。特别是当新增消息的速度，比发送消息的速度更快时</span>\n<span># request.timeout.ms=30000      # 发送请求给 broker 时，等待响应的超时时间</span>\n<span># delivery.timeout.ms=120000    # 生产者调用 send() 方法发送消息的超时时间，该值应该不低于 linger.ms + request.timeout.ms</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>\n<p>producer 向同一个 partition 生产多个消息时，会打包为一批（batch）再发送。</p>\n<ul>\n<li>如果出现的第一个消息就超过 batch.size 限制，则依然会打包成一个 batch ，但只包含该消息。</li>\n<li>Kafka 生产消息、消费消息、同步 replica 时，都会将消息打包成 batch 再传输，从而提高传输效率。\n<ul>\n<li>每个 batch 可能包含 1~N 个消息，每次网络请求可能传输 0~N 个 batch 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>batch.size 不能大于 producer 的 max.request.size ，否则过大的 batch 不能装载到请求中。</p>\n<ul>\n<li>不能大于 broker 的 message.max.bytes ，否则请求不能被接收。</li>\n<li>不能大于 consumer 的 fetch.max.bytes ，否则不能被消费。</li>\n</ul>\n</li>\n<li>\n<p>Kafka 支持将生产的消息进行压缩。</p>\n<ul>\n<li>一般流程：\n<ol>\n<li>producer 将消息 batch 以某种压缩格式发送。\n<ul>\n<li>增加 batch.size 有利于增加重复的消息内容，提高压缩率。</li>\n</ul>\n</li>\n<li>broker 接收消息，默认以同种压缩格式存储。</li>\n<li>consumer 拉取消息，自动识别其压缩格式，解压。</li>\n</ol>\n</li>\n<li>优点：\n<ul>\n<li>减少占用的磁盘空间。</li>\n<li>减少网络 IO 量，提高 Kafka 吞吐量。</li>\n<li>如果 CPU 足够、网速不足，则采用压缩会减少生产、消费的耗时。否则会增加耗时。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>占用更多 CPU 。</li>\n</ul>\n</li>\n<li>支持多种压缩格式：<div><pre><code>none      <span># 不压缩</span>\n<span>gzip</span>      <span># 压缩率大概为 20% ，CPU 负载较高</span>\nlz4       <span># 压缩率较低，CPU 负载较低，推荐使用</span>\nsnappy    <span># 性能比 lz4 较差</span>\nzstd      <span># 压缩率比 gzip 更低</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"consumer-properties\"> consumer.properties</h3>\n<p>配置示例：</p>\n<div><pre><code><span>bootstrap.servers</span><span>=</span><span>10.0.0.1:9092,10.0.0.2:9092</span>\n\n<span># group.id=null                     # 消费者组的名称</span>\n<span># group.instance.id=null            # 给该参数赋值为非空字符串时， consumer 会声明为 Static Member 类型，并采用该参数的值作为 client.id</span>\n<span># allow.auto.create.topics=false    # 订阅或主动分配 topic 时，如果该 topic 不存在，是否自动创建</span>\n<span># auto.offset.reset=latest          # 如果 Coordinator 没有记录 Consumer Committed Offset （可能是未创建、已过期删除），则从哪个 offset 处开始消费</span>\n    <span># 可选的取值：</span>\n    <span># earliest : 采用 partition 可见范围内最老的 offset</span>\n    <span># latest   : 采用 partition 最新的 offset ，即 High Watemark</span>\n    <span># none     ：让 consumer 抛出异常</span>\n<span># enable.auto.commit=true           # 是否自动在后台提交 Consumer Committed Offset 。可以关闭该功能，由用户主动提交，更可靠</span>\n<span># auto.commit.interval.ms=5000      # 自动提交的间隔时长</span>\n\n<span># max.poll.records=500              # consumer 每次调用 poll() 方法，最多拉取多少个消息。这会影响，但不会决定 fetch 请求的数量</span>\n<span># max.partition.fetch.bytes=1048576 # 每次发出 fetch 请求时，从每个 partition 最多获取多少数据。默认为 1M 。如果获取的第一个消息就超过该限制，则只返回该消息</span>\n<span># fetch.min.bytes=1                 # 每次发出 fetch 请求时，broker 应该至少累积多少数据才返回响应</span>\n<span># fetch.max.wait.ms=500             # 每次发出 fetch 请求时，broker 如果没有满足 fetch.min.bytes 的数据，则最多等待指定时长就返回响应</span>\n<span># fetch.max.bytes=57671680          # 每次发出 fetch 请求时，预期 broker 最多返回的数据量。默认为 55M</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></div></div><ul>\n<li>生产者、消费者都有 client.id ，允许重复。消费者还有 group.id 。</li>\n<li>用户调用 consumer 的 poll() 方法，即可消费消息。\n<ul>\n<li>consumer 会在后台向 broker 发送 fetch 请求，拉取数据，暂存到内存中的队列中，直到用户消费之后才删除。</li>\n<li>consumer 占用的最大内存大概为 max.partition.fetch.bytes * partition_count ，或则 fetch.min.bytes * broker_count 。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"sasl\"> SASL</h3>\n<ul>\n<li>\n<p>Kafka broker 支持通过 JAAS 框架启用 SASL 认证。</p>\n<ul>\n<li>默认不要求身份认证，可以被其它 broker、client 直接连接，因此不安全。</li>\n<li>可启用以下 SASL 认证机制：\n<ul>\n<li>PLAIN</li>\n<li>GSSAPI (Kerberos)</li>\n<li>OAUTHBEARER</li>\n<li>SCRAM-SHA-256</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>对于通过身份认证的用户，Kafka 支持配置 ACL 规则，控制用户的访问权限。</p>\n<ul>\n<li>默认的 ACL 规则为空，因此不允许用户访问任何资源，除非是 super 用户。</li>\n</ul>\n</li>\n<li>\n<p>Kafka 的通信数据默认为 PLAINTEXT 形式，即未加密。</p>\n<ul>\n<li>可以启用 SSL 加密通信，但会增加通信延迟。</li>\n<li>是否启用 SSL ，与是否启用 SASL 认证无关。</li>\n</ul>\n</li>\n<li>\n<p>例：启用 PLAIN 认证</p>\n<ol>\n<li>\n<p>修改 server.properties ，将通信协议从默认的 <code>PLAINTEXT://</code> 改为 <code>SASL_PLAINTEXT://</code> ，即采用 SASL 认证 + 未加密通信。</p>\n<div><pre><code><span>listeners</span><span>=</span><span>SASL_PLAINTEXT://0.0.0.0:9092</span>\n<span>advertised.listeners</span><span>=</span><span>SASL_PLAINTEXT://10.0.0.1:9092</span>\n\n<span>security.inter.broker.protocol</span><span>=</span><span>SASL_PLAINTEXT     # broker 之间的通信协议。默认为 PLAINTEXT ，即不启用 SASL 认证 + 未加密传输</span>\n<span>sasl.mechanism.inter.broker.protocol</span><span>=</span><span>PLAIN        # broker 之间连接时的 SASL 认证机制，默认为 GSSAPI</span>\n<span>sasl.enabled.mechanisms</span><span>=</span><span>PLAIN                     # broker 启用的 SASL 认证机制列表</span>\n<span>authorizer.class.name</span><span>=</span><span>kafka.security.auth.SimpleAclAuthorizer # 开启 ACL</span>\n<span>super.users</span><span>=</span><span>User:broker;User:client               # 将一些用户声明为超级用户</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>\n<p>创建一个 jaas.conf 配置文件：</p>\n<div><pre><code>KafkaServer <span>{</span>\n    org.apache.kafka.common.security.plain.PlainLoginModule required\n    <span># 指定当前 broker 连接其它 broker 时使用的用户</span>\n    <span>username</span><span>=</span><span>\"broker\"</span>\n    <span>password</span><span>=</span><span>\"******\"</span>\n    <span># 按 user_&lt;NAME>=&lt;PASSWORD> 的格式定义用户。在当前 broker 被其它 broker 或 client 连接时，允许对方使用这些用户</span>\n    <span>user_broker</span><span>=</span><span>\"******\"</span>\n    <span>user_client</span><span>=</span><span>\"******\"</span><span>;</span>   <span># 注意这是一条语句，末尾要加分号</span>\n<span>}</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n<li>\n<p>将 jaas.conf 拷贝到每个 broker 的配置目录下，并添加 java 启动参数来启用它：</p>\n<div><pre><code><span>export</span> <span>KAFKA_OPTS</span><span>=</span><span>'-Djava.security.auth.login.config=/kafka/config/jaas.conf'</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>执行 kafka-server-start.sh、kafka-console-producer.sh 等脚本时会自动应用该配置。</p>\n</li>\n<li>\n<p>客户端连接 broker 时，需要在 producer.properties、consumer.properties 中加入配置：</p>\n<div><pre><code><span>security.protocol</span><span>=</span><span>SASL_PLAINTEXT</span>\n<span>sasl.mechanism</span><span>=</span><span>PLAIN</span>\n<span>sasl.jaas.config</span><span>=</span><span>org.apache.kafka.common.security.plain.PlainLoginModule required \\</span>\n    <span>username</span><span>=</span><span>\"client\" \\</span>\n    <span>password</span><span>=</span><span>\"******\";</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>其中的账号密码也可以配置在 jaas.conf 中：</p>\n<div><pre><code>KafkaClient <span>{</span>\n    org.apache.kafka.common.security.plain.PlainLoginModule required\n    <span>username</span><span>=</span><span>\"client\"</span>\n    <span>password</span><span>=</span><span>\"******\"</span><span>;</span>\n<span>}</span><span>;</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ol>\n</li>\n<li>\n<p>上述为 broker 被其它 broker、client 连接时的身份认证。而 broker 连接到 zk 时，也可启用 SASL 认证，配置方法见 zk 文档。</p>\n<ul>\n<li>此时建议在 server.properties 中加入：<div><pre><code><span>zookeeper.set.acl</span><span>=</span><span>true  # 将 Kafka 在 zk 中存储的数据设置 ACL 规则：允许被所有用户读取，但只允许 Kafka 编辑</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Kafka",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/Kafka/",
      "id": "/Hardware/Distributed/MessageQueue/Kafka/",
      "content_html": "<h1 id=\"kafka\"> Kafka</h1>\n<p>：一个消息队列服务器。</p>\n<ul>\n<li><a href=\"http://kafka.apache.org/documentation/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Scala 开发。</li>\n<li>2011 年由 LinkedIn 公司开源，后来捐献给了 ASF 。\n<ul>\n<li>主要开发者离职后创建了 Confluent 公司，提供功能更多的 Kafka 发行版，分为开源版、企业版。</li>\n</ul>\n</li>\n<li>容易横向扩展，吞吐量的上限很高。</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "工具",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/Kafka/usage.html",
      "id": "/Hardware/Distributed/MessageQueue/Kafka/usage.html",
      "content_html": "<h1 id=\"工具\"> 工具</h1>\n<h2 id=\"shell-脚本\"> shell 脚本</h2>\n<p>kafka 的 bin 目录下自带了多个 shell 脚本，可用于管理 Kafka 。</p>\n<ul>\n<li>\n<p><code>kafka-server-stop.sh</code> 用于停止 broker 进程。</p>\n<ul>\n<li>它会查找本机上的所有 broker 进程，发送 SIGTERM 信号。\n<ul>\n<li>broker 进程收到终止信号后，会将所有数据保存到磁盘中，才退出，该过程需要几秒甚至几十秒。</li>\n</ul>\n</li>\n<li>如果强制杀死 broker 进程，可能导致数据丢失。重启时会发出警告：<div><pre><code>WARN  Found a corrupted index file, xxxx/0000000000000000xxxx.index, deleting and rebuilding index<span>..</span>. <span>(</span>kafka.log.Log<span>)</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p><code>kafka-topics.sh</code> 用于管理 topic 。</p>\n<ul>\n<li>例：连接到 zk ，查询 topic 列表。<div><pre><code>bin/kafka-topics.sh  --zookeeper localhost:2181  --list\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>例：连接到 zk ，请求创建 topic ，并指定分区数、每个分区的副本数。<div><pre><code>bin/kafka-topics.sh <span>\\</span>\n    --zookeeper localhost:2181 <span>\\</span>\n    --create <span>\\</span>\n    --topic topic_1 <span>\\</span>\n    --partitions <span>1</span> <span>\\</span>\n    --replication-factor <span>1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>例：连接到 zk ，请求删除 topic 。<div><pre><code>bin/kafka-topics.sh <span>\\</span>\n    --zookeeper localhost:2181 <span>\\</span>\n    --delete <span>\\</span>\n    --topic topic_1\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><ul>\n<li>这里将 --delete 选项改为 --describe ，就是查询 topic 的状态。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>运行生产者终端，从 stdin 读取消息并发送到 broker ：</p>\n<div><pre><code>bin/kafka-console-producer.sh <span>\\</span>\n    --broker-list localhost:9092 <span>\\</span>\n    --topic topic_1\n    <span># --producer.config config/producer.properties</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>运行消费者终端，读取消息并输出到 stdout ：</p>\n<div><pre><code>bin/kafka-console-consumer.sh <span>\\</span>\n    --bootstrap-server localhost:9092 <span>\\</span>\n    --topic topic_1\n    <span># --group group_1     # 指定 consumer group 的 ID ，不指定则随机生成</span>\n    <span># --from-beginning    # 从第一条消息开始消费</span>\n    <span># --consumer.config config/consumer.properties</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>运行生产者的性能测试：</p>\n<div><pre><code>bin/kafka-producer-perf-test.sh\n    --producer.config config/producer.properties\n    --topic topic_1\n    --num-records <span>10000</span>   <span># 发送多少条消息</span>\n    --record-size <span>1024</span>    <span># 每条消息的大小</span>\n    --throughput <span>10000</span>    <span># 限制每秒种发送的消息数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p><code>kafka-consumer-groups.sh</code> 用于管理消费组。用法：</p>\n<div><pre><code>bin/kafka-consumer-groups.sh --bootstrap-server <span>10.1</span>.6.151:9092\n    --list            <span># 列出所有消费组</span>\n\n    --group <span>&lt;</span>name<span>></span>    <span># 指定消费组。可多次使用该参数，也可用 --all-groups 指定所有</span>\n      --delete        <span># 删除消费组，这会删除其所有 offset</span>\n      --describe\n        --members     <span># 查看所有成员</span>\n        --offsets     <span># 查看对各个 topic partition 的 Committed Offset</span>\n\n      --topic <span>&lt;</span>name<span>></span>  <span># 指定一个 topic 。可多次使用该参数，也可用 --all-topics 指定所有</span>\n        --delete-offsets            <span># 删除 offset</span>\n        --execute --reset-offsets   <span># 调整对某个 topic 的 offset</span>\n          --to-offset <span>&lt;</span>n<span>></span>\n          --to-earliest\n          --to-latest\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><ul>\n<li>当一个消费组的所有成员都停止运行时，才支持修改 offset 。</li>\n<li>如果一个消费组停止运行，则超过 log.retention.hours 时间之后 Kafka 会从 __consumer_offsets 中删除其 offset 记录。</li>\n<li>如果一个消费组取消订阅某个 topic ，则 Kafka 依然会在 __consumer_offsets 中记录旧订阅的 offset 。除非主动删除 group 或 offset 。</li>\n</ul>\n</li>\n<li>\n<p>给 Kafka 集群新增 broker 之后，可能被自动用于存储新创建的 topic ，但不会影响已有的 topic 。可以采取以下两种措施：</p>\n<ul>\n<li>使用 <code>kafka-reassign-partitions.sh</code> 脚本，将指定 topic 的所有分区迁移到指定 broker 上。</li>\n<li>使用 Kafka Manager ，在网页上迁移 topic ，更方便。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"kafka-manager\"> Kafka Manager</h2>\n<p>：一个 Web 服务器，用于管理 Kafka 。</p>\n<ul>\n<li><a href=\"https://github.com/yahoo/CMAK\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>主要用于监控、管理 topic、partition ，不支持查看 Kafka 消息。</li>\n<li>由 Yahoo 公司开源，采用 Java 开发。</li>\n<li>2020 年，发布 v3 版本。为了避免与 Kafka 版权冲突而改名为 Cluster Manager for Apache Kafka ，简称为 CMAK 。</li>\n</ul>\n<h3 id=\"部署\"> 部署</h3>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>kafka-manager</span><span>:</span>\n    <span>container_name</span><span>:</span> kafka<span>-</span>manager\n    <span>image</span><span>:</span> kafkamanager/kafka<span>-</span>manager<span>:</span>3.0.0.4\n    <span>restart</span><span>:</span> unless<span>-</span>stopped\n    <span>ports</span><span>:</span>\n      <span>-</span> 9000<span>:</span><span>9000</span>\n    <span>environment</span><span>:</span>\n      <span>ZK_HOSTS</span><span>:</span> 10.0.0.1<span>:</span><span>2181</span>\n      <span># JAVA_OPTS: -Xmx1g -Xms1g -Djava.security.auth.login.config=/opt/jaas.conf</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br></div></div><ul>\n<li>Kafka Manager 本身需要使用一个 zk 集群存储数据。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"用法\"> 用法</h3>\n<ul>\n<li>\n<p>访问 Kafka Manager 的 Web 页面，即可创建一个 Cluster ，表示 Kafka 集群。</p>\n<ul>\n<li>需要指定该 Kafka 集群对应的 zk 集群的地址。</li>\n<li>可以勾选 &quot;JMX Polling&quot; ，连接到 Kafka 的 JMX 端口，监控消息的传输速度。</li>\n<li>可以勾选 &quot;Poll consumer information&quot;，监控消费者的 offset 。</li>\n</ul>\n</li>\n<li>\n<p>支持查看、创建、配置 topic、partition 。</p>\n<ul>\n<li>topic 的统计信息示例：<div><pre><code>Replication                 <span>3</span>       <span># 每个分区的的副本数</span>\nNumber of Partitions        <span>3</span>       <span># 该 topic 的分区数</span>\nSum of partition offsets    <span>0</span>\nTotal number of Brokers     <span>3</span>       <span># Kafka 集群存在的 Broker 数</span>\nNumber of Brokers <span>for</span> Topic <span>2</span>       <span># 该 topic 存储时占用的 Broker 数</span>\nPreferred Replicas %        <span>100</span>     <span># Leader replica 为 Preferred replica 的分区，所占百分比</span>\nBrokers Skewed %            <span>0</span>       <span># 存储的副本过多的 Broker 所占百分比</span>\nBrokers Leader Skewed %     <span>0</span>       <span># 存储的 Leader replica 过多的 Broker 所占百分比</span>\nBrokers Spread %            <span>66</span>      <span># 该 topic 占用的 Kafka 集群的 Broker 百分比，这里等于 2/3 * 100%</span>\nUnder-replicated %          <span>0</span>       <span># 存在未同步副本的那些分区，所占百分比</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div><ul>\n<li>上例中的 topic 总共有 3×3 个副本，占用 2 个 Broker 。为了负载均衡，每个 Broker 应该存储 3×3÷2 个副本，取整后可以为 4 或 5 。如果某个 Broker 实际存储的副本数超过该值，则视作 Skewed 。</li>\n</ul>\n</li>\n<li>Broker 的统计信息示例：<div><pre><code>Broker      <span># of Partitions     # as Leader     Partitions    Skewed?     Leader Skewed?</span>\n<span>0</span>           <span>3</span>                   <span>1</span>               <span>(</span><span>0,1</span>,2<span>)</span>       <span>false</span>       <span>false</span>\n<span>1</span>           <span>3</span>                   <span>2</span>               <span>(</span><span>0,1</span>,2<span>)</span>       <span>false</span>       <span>true</span>\n<span>2</span>           <span>3</span>                   <span>0</span>               <span>(</span><span>0,1</span>,2<span>)</span>       <span>false</span>       <span>false</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div>每行表示一个 Broker 的信息，各列分别表示该 Broker 的：\n<ul>\n<li>ID</li>\n<li>存储的分区副本数</li>\n<li>存储的 Leader replica 数</li>\n<li>存储的各个分区 ID</li>\n<li>存储的副本是否过多</li>\n<li>存储的 Leader replica 是否过多</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>支持 preferred-replica-election 。</p>\n</li>\n<li>\n<p>支持 Reassign Partitions 。用法如下：</p>\n<ol>\n<li>在 topic 详情页面，点击 <code>Generate Partition Assignments</code> ，设置允许该 topic 分配到哪些 broker 上的策略。</li>\n<li>点击 <code>Run Partition Assignments</code> ，执行自动分配的策略。</li>\n</ol>\n<ul>\n<li>如果不满足策略，则自动迁移 replica 到指定的 broker 上，并重新选举 leader 。\n<ul>\n<li>迁移 replica 时会导致客户端短暂无法访问。</li>\n<li>同时迁移多个 replica 时，可能负载过大，导致 Kafka broker 卡死。</li>\n</ul>\n</li>\n<li>如果已满足策略，则不会进行迁移。因此该操作具有幂等性。</li>\n<li>也可以点击 <code>Manual Partition Assignments</code> ，进行手动分配。</li>\n</ul>\n<ol start=\"3\">\n<li>到菜单栏的 <code>Reassign Partitions</code> 页面，查看正在执行的分配操作。</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"kafka-eagle\"> Kafka Eagle</h2>\n<p>：一个 Web 服务器，用于 管理 Kafka 。</p>\n<ul>\n<li><a href=\"https://github.com/smartloli/kafka-eagle\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>与 Kafka Manager 相比，多了查询消息、生产消息、配置告警的功能，但缺少关于 Preferred Replica 的功能。</li>\n<li>采用 Java 开发，占用大概 1G 内存。</li>\n</ul>\n<h2 id=\"kowl\"> Kowl</h2>\n<p>：一个 Web 服务器，用于 管理 Kafka 。</p>\n<ul>\n<li><a href=\"https://github.com/cloudhut/kowl\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>与 Kafka Manager 相比，页面更整洁，多了查看 topic 体积、查看消息内容、查看 consumer 详情的功能。但缺少 Brokers Skewed 等负载均衡的功能。</li>\n<li>采用 Golang 开发，只占用几十 MB 内存。</li>\n<li>用 Docker 部署：<div><pre><code><span>docker</span> run -d --name kowl -p <span>8080</span>:8080 -e <span>KAFKA_BROKERS</span><span>=</span><span>10.0</span>.0.1:9092 quay.io/cloudhut/kowl:v1.4.0\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n<h2 id=\"offset-explorer\"> Offset Explorer</h2>\n<p>：旧名为 Kafka Tool ，是一个 GUI 工具，可用作 Kafka 客户端。</p>\n<ul>\n<li><a href=\"https://www.kafkatool.com/\" target=\"_blank\" rel=\"noopener noreferrer\">官网</a></li>\n<li>支持查看、管理 topic ，支持查看消息、生产消息，缺少关于监控的功能。</li>\n</ul>\n<h2 id=\"♢-kafka-python\"> ♢ kafka-python</h2>\n<p>：Python 的第三方库，提供了 Kafka 客户端的功能。</p>\n<ul>\n<li>\n<p><a href=\"https://kafka-python.readthedocs.io/en/master/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></p>\n</li>\n<li>\n<p>安装：<code>pip install kafka-python</code></p>\n</li>\n<li>\n<p>例：生产消息</p>\n<div><pre><code><span>from</span> kafka <span>import</span> KafkaProducer\n\n<span># 创建一个 Producer ，连接到 broker</span>\nproducer <span>=</span> KafkaProducer<span>(</span>bootstrap_servers<span>=</span><span>'localhost:9092'</span><span>)</span>\n\n<span># 生产一个消息到指定的 topic</span>\nmsg <span>=</span> <span>'Hello'</span>\nfuture <span>=</span> producer<span>.</span>send<span>(</span>topic<span>=</span><span>'topic_1'</span><span>,</span>\n                       value<span>=</span>msg<span>.</span>encode<span>(</span><span>)</span><span>,</span>  <span># 消息的内容，必须为 bytes 类型</span>\n                       <span># partition=None,    # 指定分区。默认为 None ，会自动分配一个分区</span>\n                       <span># key=None,          # 指定 key ，bytes 类型。用于根据 key 的哈希值分配一个分区，比如相同 key 的消息总是分配到相同分区</span>\n                      <span>)</span>\n<span>try</span><span>:</span>\n    metadata <span>=</span> future<span>.</span>get<span>(</span>timeout<span>=</span><span>1</span><span>)</span>  <span># 等待服务器的回复</span>\n<span>except</span> Exception <span>as</span> e<span>:</span>\n    <span>print</span><span>(</span><span>str</span><span>(</span>e<span>)</span><span>)</span>\n\n<span>print</span><span>(</span><span>'sent: '</span><span>,</span> msg<span>)</span>\n<span>print</span><span>(</span><span>'offset: '</span><span>,</span> metadata<span>.</span>offset<span>)</span>\n<span>print</span><span>(</span><span>'topic: '</span><span>,</span>  metadata<span>.</span>topic<span>)</span>\n<span>print</span><span>(</span><span>'partition: '</span><span>,</span> metadata<span>.</span>partition<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></li>\n<li>\n<p>例：消费消息</p>\n<div><pre><code><span>from</span> kafka <span>import</span> KafkaConsumer\n\n<span># 创建一个 Consumer ，连接到 broker ，订阅指定的 topic</span>\nconsumer <span>=</span> KafkaConsumer<span>(</span><span>'topic_1'</span><span>,</span> bootstrap_servers<span>=</span><span>'localhost:9092'</span><span>)</span>\n\n<span># Consumer 对象支持迭代。默认从最新 offset 处开始迭代，没有收到消息时会一直阻塞等待，除非设置了 consumer_timeout_ms</span>\n<span>for</span> msg <span>in</span> consumer<span>:</span>\n    <span>print</span><span>(</span><span>'got: '</span><span>,</span> msg<span>.</span>value<span>.</span>decode<span>(</span><span>)</span><span>)</span>\n    <span>print</span><span>(</span><span>'offset: '</span><span>,</span> msg<span>.</span>offset<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><div><pre><code><span>from</span> kafka <span>import</span> TopicPartition\n\nconsumer<span>.</span>subscribe<span>(</span><span>'topic_1'</span><span>)</span>\nconsumer<span>.</span>seek<span>(</span>TopicPartition<span>(</span>topic<span>=</span><span>'topic_1'</span><span>,</span> partition<span>=</span><span>1</span><span>)</span><span>,</span> <span>0</span><span>)</span>    <span># 调整消费的 offset</span>\nconsumer<span>.</span>seek_to_beginning<span>(</span>TopicPartition<span>(</span>topic<span>=</span><span>'topic_1'</span><span>,</span> partition<span>=</span><span>0</span><span>)</span><span>)</span>\nmsg_set <span>=</span> consumer<span>.</span>poll<span>(</span>max_records<span>=</span><span>10</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>\n<p>KafkaConsumer 的定义：</p>\n<div><pre><code><span>class</span> <span>KafkaConsumer</span><span>(</span>six<span>.</span>Iterator<span>)</span><span>:</span>\n    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> <span>*</span>topics<span>,</span> <span>**</span>configs<span>)</span>\n        <span>\"\"\" 先输入要消费的 topics 。可用的 configs 参数如下：\n        # 关于 broker\n        bootstrap_servers='localhost',  # 可以指定一个列表，例如 ['10.0.0.1:9092', '10.0.0.2:9092']\n\n        # 关于 SASL 认证\n        sasl_mechanism='PLAIN',\n        security_protocol='SASL_PLAINTEXT',\n        sasl_plain_username='admin',\n        sasl_plain_password='******',\n\n        # 关于客户端\n        client_id='client_1',           # 客户端的名称，默认为 kafka-python-$version\n        group_id='group_1',             # 消费者组的名称，默认为 None ，即不加入消费者组\n        consumer_timeout_ms=5000,       # 迭代消息时，持续一定时长未收到新消息则结束迭代。默认无限制\n        \"\"\"</span>\n\n    <span>def</span> <span>assign</span><span>(</span>self<span>,</span> partitions<span>)</span>\n        <span>\"\"\" 主动分配当前 consumer 消费的 TopicPartition 。\n        此时不会被 Coordinator 处理，不会触发 Rebalance 。但不能与 subscribe() 同时使用，否则报错。\n        例： consumer.assign([TopicPartition(topic='topic_1', partition=0), TopicPartition(topic='topic_1', partition=1)])\n        \"\"\"</span>\n\n    <span>def</span> <span>assignment</span><span>(</span>self<span>)</span>\n        <span>\"\"\" 返回一个集合，包含当前 consumer 被分配的所有 TopicPartition \"\"\"</span>\n\n    <span>def</span> <span>close</span><span>(</span>self<span>,</span> autocommit<span>=</span><span>True</span><span>)</span>\n        <span>\"\"\" 关闭 consumer \"\"\"</span>\n\n    <span>def</span> <span>commit</span><span>(</span>self<span>,</span> offsets<span>=</span><span>None</span><span>)</span>\n        <span>\"\"\" 提交 offsets 。这会阻塞 consumer 直到成功提交 \"\"\"</span>\n\n    <span>def</span> <span>committed</span><span>(</span>self<span>,</span> partition<span>,</span> metadata<span>=</span><span>False</span><span>)</span>\n        <span>\"\"\" 返回指定 TopicPartition 的 Committed Offset \"\"\"</span>\n\n    <span>def</span> <span>commit_async</span><span>(</span>self<span>,</span> offsets<span>=</span><span>None</span><span>,</span> callback<span>=</span><span>None</span><span>)</span>\n        <span>\"\"\" 异步地提交 offsets \"\"\"</span>\n\n    <span>def</span> <span>poll</span><span>(</span>self<span>,</span> timeout_ms<span>=</span><span>0</span><span>,</span> max_records<span>=</span><span>None</span><span>,</span> update_offsets<span>=</span><span>True</span><span>)</span>\n        <span>\"\"\" 从当前 consumer 被分配的 partition 拉取消息，组成一个集合并返回。\n        update_offsets：是否自动递增 offset 以便下一次拉取。\n        \"\"\"</span>\n\n    <span>def</span> <span>seek</span><span>(</span>self<span>,</span> partition<span>,</span> offset<span>)</span>\n        <span>\"\"\" 调整当前消费的 offset ，用于下一次 poll \"\"\"</span>\n\n    <span>def</span> <span>seek_to_beginning</span><span>(</span>self<span>,</span> <span>*</span>partitions<span>)</span>\n        <span>\"\"\" 将 offset 调整到可见的最老 offset \"\"\"</span>\n\n    <span>def</span> <span>seek_to_end</span><span>(</span>self<span>,</span> <span>*</span>partitions<span>)</span>\n        <span>\"\"\" 将 offset 调整到可见的最新 offset \"\"\"</span>\n\n    <span>def</span> <span>subscribe</span><span>(</span>self<span>,</span> topics<span>=</span><span>(</span><span>)</span><span>,</span> pattern<span>=</span><span>None</span><span>,</span> listener<span>=</span><span>None</span><span>)</span>\n        <span>\"\"\" 订阅一组 topics ，或者订阅与正则表达式匹配的 topics ，这会自动分配 TopicPartition 。\n        不支持增加订阅，新的订阅列表会覆盖旧的订阅列表。\n        可以订阅不存在的 topic ，此时不会被分配 partition ，调用 poll() 的结果为空集合 。\n        \"\"\"</span>\n\n    <span>def</span> <span>subscription</span><span>(</span>self<span>)</span>\n        <span>\"\"\" 返回一个集合，包含当前 consumer 订阅的所有 topic 的名称 \"\"\"</span>\n\n    <span>def</span> <span>unsubscribe</span><span>(</span>self<span>)</span>\n        <span>\"\"\" 取消订阅的所有 topics \"\"\"</span>\n    <span>.</span><span>.</span><span>.</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br><span>37</span><br><span>38</span><br><span>39</span><br><span>40</span><br><span>41</span><br><span>42</span><br><span>43</span><br><span>44</span><br><span>45</span><br><span>46</span><br><span>47</span><br><span>48</span><br><span>49</span><br><span>50</span><br><span>51</span><br><span>52</span><br><span>53</span><br><span>54</span><br><span>55</span><br><span>56</span><br><span>57</span><br><span>58</span><br><span>59</span><br><span>60</span><br><span>61</span><br><span>62</span><br><span>63</span><br><span>64</span><br><span>65</span><br></div></div></li>\n</ul>\n<h2 id=\"♢-confluent-kafka\"> ♢ confluent-kafka</h2>\n<p>：Python 的第三方库，提供了 Kafka 客户端的功能，比 kafka-python 的功能更多。</p>\n<ul>\n<li><a href=\"https://github.com/confluentinc/confluent-kafka-python\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>安装：<code>pip install confluent-kafka</code></li>\n<li>例：消费消息<div><pre><code><span>from</span> confluent_kafka <span>import</span> Consumer\n\n<span># 创建消费者，传入配置参数，兼容 Kafka 原生的 properties</span>\nconsumer <span>=</span> Consumer<span>(</span><span>{</span>\n    <span>'bootstrap.servers'</span><span>:</span> <span>'10.0.0.1,10.0.0.2,10.0.0.3'</span><span>,</span>\n    <span>'group.id'</span><span>:</span> <span>'test_group_1'</span><span>,</span>\n    <span>'group.instance.id'</span><span>:</span> <span>'static_member_1'</span><span>,</span>\n    <span>'auto.offset.reset'</span><span>:</span> <span>'earliest'</span>\n<span>}</span><span>)</span>\n\nconsumer<span>.</span>subscribe<span>(</span><span>[</span><span>'topic_1'</span><span>]</span><span>)</span>\nmsg <span>=</span> consumer<span>.</span>poll<span>(</span>timeout<span>=</span><span>1</span><span>)</span>    <span># 消费一条消息。如果超过 timeout 依然未获取到消息，则返回 None</span>\nconsumer<span>.</span>close<span>(</span><span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "简介",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/MessageQueue/",
      "id": "/Hardware/Distributed/MessageQueue/",
      "content_html": "<h1 id=\"简介\"> 简介</h1>\n<h2 id=\"消息队列\"> 消息队列</h2>\n<p>：（Message Queue ，MQ），一种用于程序之间通信的中间件，可以暂存消息。先由发送方将消息放入消息队列，再由接收方从中获取消息。</p>\n<ul>\n<li>优点：\n<ul>\n<li>解耦    ：每个程序只需要考虑对 MQ 的访问，不必直接与其它程序通信，因此耦合度低。</li>\n<li>异步    ：消息的发送方和接收方异步工作，避免了等待对方回复的时间。</li>\n<li>削峰    ：即使发送方突然发出了大量消息，接收方也依然是按照自己的速度从 MQ 获取消息，因此可以削弱消息数量的峰值。</li>\n</ul>\n</li>\n<li>缺点：\n<ul>\n<li>增加了系统的规模，需要多考虑一个中间件。</li>\n<li>需要考虑一致性问题，保证消息不会被重复发布、消费。</li>\n<li>需要考虑收发消息的顺序。</li>\n</ul>\n</li>\n<li>提供 MQ 服务的软件有多种，大多借鉴了 JMS 规范。</li>\n</ul>\n<p>使用消息队列的主要难点：</p>\n<ul>\n<li>如何保证消息不被重复消费\n<ul>\n<li>可以给每个消息分配一个唯一 ID ，客户端记录自己获得的所有消息 ID ，如果收到重复的消息就忽略。或者服务器记录每个客户端获得的所有消息 ID ，不发送重复的消息。</li>\n</ul>\n</li>\n<li>如何保证不丢失消息\n<ul>\n<li>可能原因：客户端发布或接收消息时丢失、消息队列存储消息时丢失。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"jms\"> JMS</h2>\n<p>JMS（Java Message Service ，Java 消息服务）：Java 平台上消息中间件的 API 规范。</p>\n<p>基本概念：</p>\n<ul>\n<li>客户端          ：连接到 MQ 服务器的程序，可以作为消息的发送方（Sender）或接收方（Receiver）。</li>\n<li>消息            ：程序之间的通信内容。</li>\n</ul>\n<p>JMS 定义了两种传输消息的模式：</p>\n<ul>\n<li>点对点模式（Point to Point ，P2P）：一条消息只能被一个客户端接收。\n<ul>\n<li>消息的发送方、接收方分别称为生产者（Producer）、消费者（Consumer）。</li>\n<li>Producer 将消息发送到某个队列（Queue）中，而消费者到某个 Queue 中获取消息（该过程称为消费）。</li>\n<li>队列会长时间保存消息，直到它被消费或超时。</li>\n</ul>\n</li>\n<li>发布/订阅模式（Pub/Sub)：一条消息可以被多个客户端接收。\n<ul>\n<li>消息的发送方、接收方分别称为发布者（Publisher）、订阅者（Subscriber）。</li>\n<li>Publisher 将消息发布到某个主题（Topic）下，而 MQ 会立即将该消息推送给订阅该 Topic 的所有 Subscriber 。</li>\n<li>一个 Subscriber 可以订阅任意个 Topic ，但是只会收到订阅之后新发布的消息，不会收到历史消息，因为 MQ 不会长时间保存消息。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"常见的消息队列\"> 常见的消息队列</h2>\n<ul>\n<li>\n<p>ActiveMQ</p>\n</li>\n<li>\n<p>RabbitMQ</p>\n<ul>\n<li>采用 erlang 开发，实现了高级消息队列（Advanced Message Queuing Protocol ，AMQP）协议。</li>\n<li>并发能力强，延迟很低。</li>\n<li>生产者发送的消息，会由 exchange（交换机）转发到某个或某些队列。</li>\n</ul>\n</li>\n<li>\n<p>RocketMQ</p>\n<ul>\n<li>采用 Java 开发，由阿里巴巴公司开源，捐献给了 ASF 。</li>\n<li>它借鉴了 Kafka ，但功能更强。</li>\n</ul>\n</li>\n<li>\n<p>Kafka</p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Ceph",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/Ceph.html",
      "id": "/Hardware/Distributed/Storage/Ceph.html",
      "content_html": "<h1 id=\"ceph\"> Ceph</h1>\n<p>：一个分布式存储系统。可以将多个主机的磁盘联网组合成一个资源池，提供块存储、文件存储、对象存储服务。</p>\n<ul>\n<li><a href=\"https://docs.ceph.com/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>读音为 <code>/ˈsɛf/</code></li>\n<li>采用 C++ 开发。</li>\n<li>2006 年由 Sage Weil 发布，2014 年被红帽公司收购。</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<ul>\n<li>\n<p>Ceph 集群分布式部署在多个主机上，运行多种服务进程：</p>\n<ul>\n<li>Monitor（MON）\n<ul>\n<li>负责存储、维护 Cluster Map ，比如各个服务的地址、配置、状态等信息。</li>\n<li>支持部署多个实例，基于 Paxos 算法实现一致性。</li>\n<li>每个实例占用 1GB 以上内存。</li>\n<li>客户端一般通过访问 Monitor 来与 Ceph 集群交互。</li>\n</ul>\n</li>\n<li>Manager（MGR）\n<ul>\n<li>负责管理一些功能模块，比如 Dashboard 。</li>\n<li>每个实例都会运行 Dashboard 模块，提供 Web 管理页面。集成了一套 grafana、prometheus、node_exporter、alertmanager 监控进程。</li>\n</ul>\n</li>\n<li>Object Storage Daemon（OSD）\n<ul>\n<li>负责将数据存储到设备中，供用户读写。</li>\n<li>通常在每个主机上，将存储设备格式化为 LVM 逻辑卷，并部署一个 OSD 进程来管理。\n<ul>\n<li>将 OSD 元数据保存在 LVM label 中，方便发现与逻辑卷关联的 OSD 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Crash\n<ul>\n<li>负责收集其它服务的崩溃信息。</li>\n</ul>\n</li>\n<li>Meta Data Server（MDS）\n<ul>\n<li>负责存储 CephFS 文件系统的元数据，比如文件权限、属性。</li>\n<li>启用文件存储时才需要。将文件的内容存储在 OSD ，而元数据存储在 MDS 服务器。</li>\n</ul>\n</li>\n<li>RADOS Gateway（RGW）\n<ul>\n<li>通过 RESTful API 提供对象存储功能。</li>\n<li>启用对象存储时才需要。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>RADOS ：Ceph 的存储层，以对象存储的形式存储所有数据，因此存储数据的基本单位为 object 。</p>\n<ul>\n<li>每个 object 的默认大小为 4MB ，拥有一个在集群内唯一的 object id 。</li>\n<li>Ceph 会将 object 根据哈希值分配到一些 pg（Placement Group） 中，从而方便分组管理大量 object 。</li>\n<li>支持创建多个存储池（Pool），对 pg 进行分组管理。</li>\n</ul>\n</li>\n<li>\n<p>应用程序可通过 librados 库访问 RADOS 。librados 库提供了三种常用的存储接口：</p>\n<ul>\n<li>librbd\n<ul>\n<li>：用于块存储。</li>\n<li>Ceph 不依赖其它文件系统，可以用自带的存储后端 BlueStore 直接管理 HDD、SSD 硬盘。</li>\n</ul>\n</li>\n<li>MDS\n<ul>\n<li>：用于文件存储。</li>\n<li>提供了一种网络文件系统 CephFS ，兼容 POSIX 文件系统。</li>\n</ul>\n</li>\n<li>RADOS Gateway\n<ul>\n<li>：用于对象存储，兼容 S3、Swift 。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Ceph 新增数据的流程：</p>\n<ol>\n<li>应用程序访问 Monitor ，获知所有 OSD 的信息。</li>\n<li>将数据分割为以 object 为单位，再以 pg 为单位分组。</li>\n<li>将 pg 分配到一些 OSD 中存储。\n<ul>\n<li>应用程序直接与 OSD 进程通信，不需要经过 Monitor 中转，因此分散了负载压力。</li>\n<li>应用程序和 OSD 进程都能根据 CRUSH 算法计算出每个 pg 应该存储到哪个 OSD 的哪个位置，不需要查表，因此效率更高。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<p>Ceph 有多种部署方式：</p>\n<ul>\n<li>ceph-ansible ：基于 ansible playbook 部署 Ceph 集群。</li>\n<li>ceph-deploy ：一个命令行工具，已停止维护。</li>\n<li>Cephadm ：一个 Python3 脚本，用于以容器形式部署 Ceph 集群，通过编排（Orchestrator，orch）接口控制 Ceph 。</li>\n<li>Rook ：用于在 k8s 中部署 Ceph 集群。</li>\n</ul>\n<h3 id=\"版本\"> 版本</h3>\n<p>大概每年发布一个大版本：</p>\n<ul>\n<li>v9 ：版本名为 Infernalis ，2015 年发布。</li>\n<li>v15 ：版本名为 Octopus ，2020 年发布。</li>\n<li>v16 ：版本名为 Pacific ，2021 年发布。</li>\n</ul>\n<h3 id=\"cephadm\"> Cephadm</h3>\n<p>部署步骤：</p>\n<ol>\n<li>\n<p>下载 Cephadm 脚本：</p>\n<div><pre><code><span>version</span><span>=</span>pacific\n<span>wget</span> https://github.com/ceph/ceph/raw/<span>${version}</span>/src/cephadm/cephadm\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>在当前主机上部署一个初始化的 Ceph 集群：</p>\n<div><pre><code>python3 cephadm bootstrap --mon-ip <span>&lt;</span>ip<span>></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>该命令会：</p>\n<ul>\n<li>采用指定 IP 作为当前主机的 IP 。</li>\n<li>检查本机是否安装了依赖软件，没有则自动安装：\n<ul>\n<li>docker 或 podman 容器引擎</li>\n<li>systemctl</li>\n<li>lvcreate</li>\n<li>chronyd</li>\n</ul>\n</li>\n<li>以容器形式运行一个 Monitor 和 Manager 进程，并在防火墙开通相应端口。</li>\n<li>为 Ceph 集群生成一个新的 SSH 密钥。\n<ul>\n<li>密钥保存到 /etc/ceph/ceph.client.admin.keyring 文件。</li>\n<li>公钥保存到 /etc/ceph/ceph.pub 文件，并添加到 /root/.ssh/authorized_keys 文件。</li>\n</ul>\n</li>\n<li>给当前主机添加 _admin 标签。\n<ul>\n<li>如果主机带有 _admin 标签，则会自动拷贝私钥文件和 /etc/ceph/ceph.conf 到该主机，允许它们管理集群。</li>\n<li>如果主机带有 _no_schedule 标签，则不会在该主机部署服务进程。</li>\n</ul>\n</li>\n<li>启动 Ceph Dashboard ，并在终端打印初始的账号、密码。\n<ul>\n<li>默认监听 HTTPS 8443 端口，可以禁用 SSL 协议：<div><pre><code>ceph config <span>set</span> mgr mgr/dashboard/ssl <span>false</span>\nceph config <span>set</span> mgr mgr/dashboard/server_port <span>8080</span>\nceph config <span>set</span> mgr mgr/dashboard/ssl_server_port <span>8443</span>\nceph mgr module disable dashboard\nceph mgr module <span>enable</span> dashboard\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>进入 ceph shell ：</p>\n<div><pre><code>python3 cephadm shell\nceph status\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><ul>\n<li>也可以执行 <code>yum install ceph-common</code> ，在宿主机上安装 ceph 命令。</li>\n</ul>\n</li>\n<li>\n<p>添加其它主机</p>\n<div><pre><code>ceph orch <span>host</span> <span>add</span> host2 <span>10.0</span>.0.2\n</code></pre>\n<div><span>1</span><br></div></div><ul>\n<li>需要先拷贝 SSH 公钥到目标主机：<div><pre><code>ssh-copy-id -f -i /etc/ceph/ceph.pub root@10.0.0.2\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ul>\n</li>\n<li>\n<p>部署 OSD 进程：</p>\n<div><pre><code>ceph-volume lvm zap /dev/vdb --destroy    <span># 擦除一个磁盘</span>\nceph orch daemon <span>add</span> osd host1:/dev/vdb   <span># 创建 OSD 进程，管理磁盘</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n</ol>\n<p>命令：</p>\n<div><pre><code>python3 cephadm\n                version\n                check-host                        <span># 检查本机是否安装了 cephadm 依赖</span>\n                bootstrap --mon-ip <span>&lt;</span>ip<span>></span>           <span># 引导启动一个新集群，重复执行则会部署多个集群</span>\n                rm-cluster --fsid <span>&lt;</span>fsid<span>></span> --force  <span># 删除集群，需要指定集群 ID</span>\n                shell                             <span># 打开 ceph shell ，这会创建一个临时的 ceph 容器</span>\n                <span>ls</span>                                <span># 列出当前主机上的服务进程</span>\n                logs --name <span>&lt;</span>name<span>></span>                <span># 查看指定服务进程的日志</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><ul>\n<li>cephadm 将日志保存到 journalctl ，也可以直接看容器日志。</li>\n</ul>\n<h2 id=\"管理命令\"> 管理命令</h2>\n<h3 id=\"集群\"> 集群</h3>\n<div><pre><code><span># 查看集群</span>\nceph -v\nceph status\n\n<span># 升级集群</span>\nceph orch upgrade start --ceph-version <span>16.2</span>.6   <span># 升级到指定版本</span>\nceph orch upgrade status                        <span># 查看升级任务的状态。执行 ceph status 还会显示升级的进度条</span>\nceph orch upgrade stop                          <span># 停止升级任务</span>\n\n<span># 配置集群</span>\nceph config dump                    <span># 输出集群的配置参数，不包括默认的配置参数</span>\nceph config <span>ls</span>                      <span># 列出所有可用的配置参数</span>\nceph config log <span>[</span>n<span>]</span>                 <span># 查看配置参数最近 n 次的变更记录</span>\nceph config get <span>&lt;</span>who<span>></span> <span>[</span>key<span>]</span>         <span># 读取配置参数，who 表示服务类型</span>\nceph config <span>set</span> <span>&lt;</span>who<span>></span> <span>&lt;</span>key<span>></span> <span>&lt;</span>value<span>></span> <span># 设置配置参数</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div><h3 id=\"主机\"> 主机</h3>\n<div><pre><code>ceph orch <span>host</span> <span>add</span> <span>&lt;</span>hostname<span>></span> <span>[</span>addr<span>]</span> <span>[</span>label<span>]</span><span>..</span>. <span># 添加一个主机，指定名称和 IP 地址，还可以附加标签</span>\nceph orch <span>host</span> <span>rm</span>  <span>&lt;</span>hostname<span>></span>\nceph orch <span>host</span> <span>ls</span>\nceph orch <span>host</span> set-addr  <span>&lt;</span>hostname<span>></span> <span>&lt;</span>addr<span>></span>      <span># 更新主机的地址</span>\nceph orch <span>host</span> label <span>add</span> <span>&lt;</span>hostname<span>></span> <span>&lt;</span>label<span>></span>     <span># 给一个主机添加标签</span>\nceph orch <span>host</span> label <span>rm</span>  <span>&lt;</span>hostname<span>></span> <span>&lt;</span>label<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><h3 id=\"服务\"> 服务</h3>\n<div><pre><code>ceph orch status                              <span># 显示编排器的状态，比如 cephadm</span>\nceph orch <span>ls</span> <span>[</span>service_type<span>]</span> <span>[</span>service_name<span>]</span>    <span># 列出集群中的服务</span>\n              --export                        <span># 导出 spec 配置</span>\nceph orch <span>ps</span> <span>[</span>hostname<span>]</span> <span>[</span>service_name<span>]</span>        <span># 列出主机上的服务进程实例</span>\nceph orch <span>rm</span> <span>&lt;</span>service_name<span>></span>                   <span># 删除一个服务，这会终止其所有进程实例</span>\nceph orch apply -i <span>&lt;</span>xx.yml<span>></span>                   <span># 导入服务的 spec 配置</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>每种服务可能运行多个进程实例。\n<ul>\n<li>服务的名称采用小写的服务类型，例如 mon 。</li>\n<li>服务进程以守护进程的形式运行，称为 daemon 。\n<ul>\n<li>daemon 的命名格式为 <code>&lt;service_name&gt;.&lt;hostname&gt;</code> ，例如 mon.host1 。</li>\n<li>daemon 的容器命名格式为 <code>ceph-&lt;fsid&gt;-&lt;process_name&gt;</code> 。</li>\n</ul>\n</li>\n<li>没有直接重启服务的命令，管理不方便。</li>\n</ul>\n</li>\n<li>同种服务的 daemon 采用同一份配置（Specification，spec）。例如 mon 服务的配置如下：<div><pre><code><span>service_type</span><span>:</span> mon\n<span>service_name</span><span>:</span> mon\n<span>placement</span><span>:</span>              <span># 关于部署的配置</span>\n  <span>count</span><span>:</span> <span>5</span>              <span># 指定需要部署的实例数</span>\n  <span># count_per_host: 1   # 每个主机上部署的实例数</span>\n  <span># hosts:              # 或者指定用于部署的主机名</span>\n  <span># - host-1</span>\n  <span># label: null         # 根据标签筛选用于部署的主机名</span>\n<span># unmanaged: false      # 是否禁止 Orchestrator 管理该服务</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div></li>\n</ul>\n<h3 id=\"osd\"> OSD</h3>\n<div><pre><code>ceph osd <span>ls</span>                                   <span># 列出所有 OSD</span>\nceph osd tree                                 <span># 以树形结构列出所有 OSD</span>\nceph orch device <span>ls</span> <span>[</span>hostname<span>]</span>                <span># 列出主机上的存储设备</span>\n                    --wide                    <span># 显示详细信息</span>\nceph orch daemon <span>add</span> osd <span>&lt;</span>hostname<span>></span>:<span>&lt;</span>device<span>></span>  <span># 创建 OSD 进程，管理指定的存储设备</span>\nceph orch apply osd --all-available-devices   <span># 添加 spec 配置：自动为所有可用的存储设备部署 OSD 进程</span>\n                    --unmanaged<span>=</span>true          <span># 禁止编排 OSD 进程，不允许自动部署、手动部署</span>\nceph orch osd <span>rm</span> <span>&lt;</span>osd_id<span>></span><span>..</span>.                  <span># 移除 OSD 进程，这会添加一个计划任务</span>\nceph orch osd <span>rm</span> status                       <span># 查看移除任务的状态</span>\nceph orch osd <span>rm</span> stop <span>&lt;</span>osd_id<span>></span><span>..</span>.             <span># 停止移除任务</span>\n\n<span># ceph-volume 是一个更底层的命令</span>\nceph-volume lvm list                          <span># 列出所有已关联 OSD 的 logical volume</span>\nceph-volume lvm zap <span>&lt;</span>device<span>></span><span>..</span>.               <span># 擦除一个 device 的内容。这会通过 dd if=/dev/zero of=&lt;device> 命令销毁其中的分区表</span>\n                    --destroy                 <span># 擦除一个 raw device 时，销毁其中的 volume group 和 logical volume</span>\nceph-volume lvm prepare --data <span>&lt;</span>device<span>></span>       <span># 为一个 device 创建 OSD</span>\nceph-volume lvm activate\n                    <span>&lt;</span>osd_id<span>></span> <span>&lt;</span>uuid<span>></span>           <span># 启动 OSD 进程，需要指定其编号和 uuid</span>\n                    --all                     <span># 自动发现所有 device 已关联的 OSD ，并启动</span>\nceph-volume lvm deactivate <span>&lt;</span>osd_id<span>></span> <span>&lt;</span>uuid<span>></span>    <span># 停止 OSD 进程</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><ul>\n<li>ceph-volume 会自动发现主机上的存储设备，满足以下条件才视作可用，允许创建 OSD ：\n<ul>\n<li>大于 5 GB 。</li>\n<li>没有挂载。</li>\n<li>不包含文件系统。</li>\n<li>没有磁盘分区（partition）。因此通常使用以下两种存储设备：\n<ul>\n<li>raw device ：原始存储设备，比如磁盘。</li>\n<li>logical volume ：LVM 逻辑卷。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"pool\"> Pool</h3>\n<div><pre><code>ceph osd pool <span>ls</span>                        <span># 列出所有 pool</span>\nceph osd pool create <span>&lt;</span>pool<span>></span>             <span># 创建一个 pool ，指定名称</span>\n                    <span>[</span>pg_num<span>]</span> <span>[</span>pgp_num<span>]</span>\n                    <span>[</span>replicated<span>|</span>erasure<span>]</span>\nceph osd pool <span>rm</span>  <span>&lt;</span>pool<span>></span> <span>&lt;</span>pool<span>></span> --yes-i-really-really-mean-it   <span># 删除一个 pool ，需要两次指定其名称</span>\nceph osd pool get <span>&lt;</span>pool<span>></span> <span>&lt;</span>key<span>></span>          <span># 读取配置参数</span>\nceph osd pool <span>set</span> <span>&lt;</span>pool<span>></span> <span>&lt;</span>key<span>></span> <span>&lt;</span>value<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><ul>\n<li>pool 分为两种类型：\n<ul>\n<li>replicated ：复制池，默认采用。将 object 保存多份，从而实现数据备份。\n<ul>\n<li>假设全部 OSD 的磁盘容量为 100G ，存储的 pool size 为 3 ，则 pool 最多允许写入 33G 数据。</li>\n</ul>\n</li>\n<li>erasure ：纠错码池。通过占用大概 1.5 倍的存储空间来实现数据备份。\n<ul>\n<li>比复制池占用的存储空间更少，但是读取时占用更多 CPU 和内存来解码，读取延迟较大，适合冷备份。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>pool 常见的配置参数：<div><pre><code>size              <span># 该 pool 中每个 object 的副本数，即将所有数据保存 size 份。默认为 3</span>\nmin_size          <span># 读写 object 时需要的最小副本数。默认为 2</span>\npg_num            <span># 该 pool 包含的 pg 数，默认为 32 。应该根据 osd_count*100/pool_size 估算，并取最近的一个 2^n 幂值</span>\npgp_num           <span># 用于 CRUSH 计算的 pg 数，取值应该等于 pg_num</span>\ncrush_rule        <span># 采用的 CRUSH 规则。默认为 replicated_rule</span>\nquota_max_bytes   <span># 存储容量。默认为 0 ，不限制</span>\nquota_max_objects <span># 存储的 object 数。默认为 0 ，不限制</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>mon 服务关于 pool 的配置参数：<div><pre><code>mon_allow_pool_delete       <span># 是否允许删除 pool ，默认为 false</span>\nmon_allow_pool_size_one     <span># 是否允许 pool size 设置为 1 。默认为 false ，因此 size 至少要为 2</span>\n\n<span># pool 配置参数的默认值</span>\nosd_pool_default_size\nosd_pool_default_min_size\nosd_pool_default_pg_num\nosd_pool_default_pgp_num\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></li>\n<li>pool 中 pg 的常见状态：<div><pre><code><span># 正常状态</span>\nactive        <span># 可以读写</span>\nclean         <span># pg 不存在故障的 object</span>\n\n<span># 异常状态</span>\ndown          <span># pg 离线</span>\nundersized    <span># pg 实际运行的副本数少于 pool size</span>\ndegraded      <span># 降级了，pg 中存在一些 object ，其副本数少于 pool size</span>\nstale         <span># pg 的状态没有更新到 Monitor ，可能是存储该 pg 的所有 OSD 都故障了</span>\n\n<span># 关于检查、恢复</span>\ndeep          <span># 根据 checksum 检查 pg 的数据是否一致</span>\npeer          <span># 存储该 pg 的所有 OSD 互相通信，将该 pg 的状态同步一致</span>\nrecovery      <span># 根据操作日志找出 pg 中与其它副本不一致的 object ，进行同步。常见于 OSD 重启时</span>\nbackfill      <span># 检查并同步 pg 中的全部 object ，常见于新增 pg、OSD 时</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></div></div></li>\n</ul>\n<h3 id=\"cephfs\"> CephFS</h3>\n<div><pre><code>ceph fs <span>ls</span>                                    <span># 列出已创建的 fs</span>\nceph fs status\nceph fs new <span>&lt;</span>fs_name<span>></span> <span>&lt;</span>meta<span>></span> <span>&lt;</span>data<span>></span>           <span># 创建一个 fs，指定其用于存储元数据、数据的 pool</span>\nceph fs <span>rm</span>  <span>&lt;</span>fs_name<span>></span> --yes-i-really-mean-it  <span># 删除一个 fs</span>\nceph fs add_data_pool <span>&lt;</span>fs_name<span>></span> <span>&lt;</span>pool<span>></span>        <span># 给 CephFS 增加数据池</span>\nceph fs get <span>&lt;</span>fs_name<span>></span>                         <span># 读取全部配置参数</span>\nceph fs <span>set</span> <span>&lt;</span>fs_name<span>></span> <span>&lt;</span>key<span>></span> <span>&lt;</span>value<span>></span>           <span># 修改一个配置参数</span>\n\nceph mds <span>stat</span>                                 <span># 显示 mds 的状态</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><ul>\n<li>Ceph 集群中可以创建多个 CephFS 文件系统实例，简称为 fs 。\n<ul>\n<li>每个 fs 需要使用至少两个 pool ，分别用于存储数据、元数据。</li>\n<li>每个 fs 需要使用至少一个 MDS 服务器。</li>\n</ul>\n</li>\n<li>fs 常见的配置参数：<div><pre><code>max_file_size   <span># 单个文件的最大体积，默认为 1024^4</span>\ndown            <span># 是否停止服务。通过设置该参数为 true 或 false ，可以停止或启动 fs</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>例：创建 fs<div><pre><code>ceph osd pool create cephfs1.data\nceph osd pool create cephfs1.meta\nceph fs new cephfs1 cephfs1.meta cephfs1.data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></li>\n<li>Linux 内核已经内置了 ceph 模块，因此可以直接用 mount 命令挂载 CephFS 文件系统：<div><pre><code><span>mount</span> -t ceph <span>&lt;</span>mon_ip:port<span>></span>:<span>&lt;</span>src_dir<span>></span> <span>&lt;</span>dst_dir<span>></span>  <span># 访问 mon 服务器，将 CephFS 文件系统的 src_dir 挂载到当前主机的 dst_dir</span>\n        <span>[</span>-o options<span>]</span>              <span># 可加上一些逗号分隔的选项，如下：</span>\n            <span>name</span><span>=</span>guest            <span># CephX 用户</span>\n            <span>secret</span><span>=</span>xxx            <span># CephX 密钥</span>\n            <span>secretfile</span><span>=</span>xxx        <span># CephX 密钥文件</span>\n            <span>fs</span><span>=</span>cephfs1            <span># 默认挂载第一个 fs</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><ul>\n<li>secretfile、fs 选项需要安装 ceph 软件包才能使用，其提供了功能更多的 mount.ceph 命令。</li>\n<li>例：<div><pre><code><span>mkdir</span> /mnt/cephfs\n<span>mount</span> -t ceph   <span>10.0</span>.0.1:/  /mnt/cephfs   -o <span>name</span><span>=</span>admin,secret<span>=</span>xxx\n<span>echo</span> <span>'10.0.0.1:/  /mnt/cephfs    ceph    name=admin,secret=xxx    0   0'</span> <span>>></span> /etc/fstab\n\n<span>dmesg</span> <span>|</span> <span>tail</span>          <span># 查看挂载日志</span>\n<span>umount</span> /mnt/cephfs    <span># 卸载</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n<li>如果停止 fs ，则客户端访问已挂载的 fs 时会出错，比如无响应、umount 失败。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"volume\"> volume</h3>\n<div><pre><code>ceph fs volume <span>ls</span>                             <span># 列出已创建的 volume</span>\nceph fs volume create <span>&lt;</span>volume<span>></span>                <span># 创建一个 volume</span>\nceph fs volume <span>rm</span> <span>&lt;</span>volume<span>></span> --yes-i-really-mean-it\n\nceph fs subvolume <span>ls</span>\nceph fs subvolume create <span>&lt;</span>vol_name<span>></span> <span>&lt;</span>sub_name<span>></span> <span>[</span>group_name<span>]</span>\nceph fs subvolume <span>rm</span>     <span>&lt;</span>vol_name<span>></span> <span>&lt;</span>sub_name<span>></span> <span>[</span>group_name<span>]</span>\n\nceph fs subvolumegroup <span>ls</span>\nceph fs subvolumegroup create <span>&lt;</span>vol_name<span>></span> <span>&lt;</span>group_name<span>></span>\nceph fs subvolumegroup <span>rm</span>     <span>&lt;</span>vol_name<span>></span> <span>&lt;</span>group_name<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><ul>\n<li>CephFS volume 是对一种快速创建 fs 的方式。\n<ul>\n<li>创建一个 volume 时，会自动创建：\n<ul>\n<li>一个同名的 fs 。</li>\n<li>两个 pool ，命名格式为 <code>cephfs.&lt;volume&gt;.data</code> 和 <code>cephfs.&lt;volume&gt;.meta</code> 。</li>\n<li>两个 MDS 服务器。</li>\n</ul>\n</li>\n<li>删除一个 volume 时，会自动删除关联的 fs、pool 和 MDS 。</li>\n<li>每个 volume 中可以创建多个子卷（subvolume）或子卷组（subvolume group），相当于文件夹。</li>\n</ul>\n</li>\n<li>例：查看 mds.volume1 的配置<div><pre><code><span>[</span>ceph: root@CentOS /<span>]</span><span># ceph orch ls mds mds.volume1 --export</span>\nservice_type: mds\nservice_id: volume1\nservice_name: mds.volume1\nplacement:\n  count: <span>2</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h3 id=\"cephx\"> CephX</h3>\n<div><pre><code>ceph auth <span>ls</span>            <span># 列出已创建的凭证</span>\nceph auth get <span>&lt;</span>name<span>></span>    <span># 读取指定的凭证</span>\nceph auth <span>rm</span>  <span>&lt;</span>name<span>></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><ul>\n<li>Ceph 集群采用 CephX 协议进行身份认证。</li>\n<li>凭证示例：<div><pre><code>client.admin                                            <span># 用户名</span>\n        key: AQD9O45hiBQrDBAAsMYpN0ddCF/apJpYIoLokg<span>==</span>   <span># 密钥，采用 base64 编码</span>\n        caps: <span>[</span>mds<span>]</span> allow *                             <span># 权限</span>\n        caps: <span>[</span>mgr<span>]</span> allow *\n        caps: <span>[</span>mon<span>]</span> allow *\n        caps: <span>[</span>osd<span>]</span> allow *\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "FastDFS",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/FastDFS.html",
      "id": "/Hardware/Distributed/Storage/FastDFS.html",
      "content_html": "<h1 id=\"fastdfs\"> FastDFS</h1>\n<p>：一个文件服务器，不提供 Web UI 。</p>\n<ul>\n<li><a href=\"https://github.com/happyfish100/fastdfs\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>2008 年，由国内开发者发布，采用 C 开发。</li>\n<li>基于 TCP 通信。</li>\n<li>特点：\n<ul>\n<li>提供了文件存储、上传、下载等功能，适合存储大量的小型文件。</li>\n<li>支持分布式部署。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"原理\"> 原理</h2>\n<p>FastDFS 的服务器分为两种角色：</p>\n<ul>\n<li>tracker server\n<ul>\n<li>：负责处理客户端的访问请求，并将请求经过负载均衡之后重定向到某个 storage 。</li>\n<li>当客户端发出下载文件的请求时，tracker 会回复该文件存储在哪个 storage 上的哪个路径。然后，客户端再访问相应的 storage ，下载文件。</li>\n<li>可以部署多个 tracker 实例，提高可用性。</li>\n<li>部署了多个 tracker 时，应该再部署一个 Nginx 对它们进行反向代理、负载均衡，让客户端统一访问该 Nginx 。</li>\n</ul>\n</li>\n<li>storage server\n<ul>\n<li>：负责存储文件，并提供上传文件、下载文件的 HTTP API 。</li>\n<li>基于操作系统本身的文件系统，将文件直接存储到主机的某个目录下。</li>\n<li>可以部署一组或多组 storage 实例，组成 storage 集群。\n<ul>\n<li>每组存储集群的一部分文件。因此增加组的数量，就可以横向扩展集群的存储容量。</li>\n<li>组内的每个实例都存储该组文件的一个副本，从而实现冗余备份，还可以分担用户的访问流量，提高负载能力。</li>\n<li>往某组加入一个新实例时，它会自动与同组的其它 storage 通信，同步文件。</li>\n</ul>\n</li>\n<li>可以部署 Nginx 代理 storage 的 store_path 目录下的文件，从而允许客户端以文件的 path 作为 URI ，直接通过 Nginx 下载文件。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ol>\n<li>\n<p>用 Docker 运行 tracker server ：</p>\n<div><pre><code><span>docker</span> run -d --name tracker    <span>\\</span>\n         -p <span>22122</span>:22122         <span>\\</span>\n         <span># -v /opt/fdfs/tracker.conf:/etc/fdfs/tracker.conf           \\  # 挂载配置文件</span>\n         delron/fastdfs tracker\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n<li>\n<p>用 Docker 运行 storage server ：</p>\n<div><pre><code><span>docker</span> run -d --name storage                <span>\\</span>\n    -p <span>23000</span>:23000 -p <span>8888</span>:8888             <span>\\</span>\n    -e <span>TRACKER_SERVER</span><span>=</span><span>10.0</span>.0.1:22122        <span>\\</span>   <span># 声明 tracker server 的地址，该配置会保存到配置文件中</span>\n    <span># -v /opt/fdfs:/var/fdfs                                     \\  # 挂载数据目录</span>\n    <span># -v /opt/fdfs/storage.conf:/etc/fdfs/storage.conf           \\  # 挂载配置文件</span>\n    <span># -v /opt/fdfs/nginx.conf:/usr/local/nginx/conf/nginx.conf   \\  # 挂载 Nginx 的配置文件</span>\n    delron/fastdfs storage\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></li>\n<li>\n<p>storage.conf 的配置示例：</p>\n<div><pre><code><span>bind_addr</span><span>=</span><span>0.0.0.0</span>\n<span>port</span><span>=</span><span>23000</span>\n\n<span>group_name</span><span>=</span><span>group1               # 该 storage 属于哪个组</span>\n<span>base_path</span><span>=</span><span>/var/fdfs             # 工作目录，用于存储数据和日志</span>\n<span>store_path0</span><span>=</span><span>/var/fdfs           # 存储文件的目录。该参数可以设置多个，从 0 开始编号</span>\n<span># store_path1=/var/fdfs2</span>\n\n<span>tracker_server</span><span>=</span><span>10.0.0.1:22122   # tracker 的地址。该参数可以配置多个</span>\n<span># tracker_server=10.0.0.2:22122</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></div></div></li>\n<li>\n<p>nginx.conf 的配置示例：</p>\n<div><pre><code>server <span>{</span>\n    listen       <span>8888</span><span>;</span>\n    location ~ /group<span>[</span><span>0</span>-9<span>]</span>/ <span>{</span>\n        ngx_fastdfs_module<span>;</span>     <span># 该模块用于对 storage 进行代理，其配置文件是 /etc/fdfs/mod_fastdfs.conf</span>\n    <span>}</span>\n<span>}</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ol>\n<h2 id=\"用法\"> 用法</h2>\n<h3 id=\"上传文件\"> 上传文件</h3>\n<ol>\n<li>\n<p>进入 fastdfs 容器，执行 <code>vi /etc/fdfs/client.conf</code> ，修改配置文件：</p>\n<div><pre><code><span>tracker_server</span><span>=</span><span>10.0.0.1:22122</span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>通过客户端上传文件：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># /usr/bin/fdfs_upload_file /etc/fdfs/client.conf test.txt</span>\ngroup1/M00/00/00/lRyeml-QA76AWkC1AAAAAAAAAAA357.txt\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>上传成功之后会返回该文件的逻辑存储路径 path ，其格式为：</p>\n<ul>\n<li><code>group1</code> ：表示 storage 所属组。</li>\n<li><code>M00</code>    ：表示 store_path 的编号。</li>\n<li><code>00/00/</code> ： 表示 store_path 之下的子目录，总共有两级，取值为十六进制的 00~FF 。</li>\n<li><code>lRyeml-QA76AWkC1AAAAAAAAAAA357.txt</code> ：按特定规则生成的文件名。</li>\n</ul>\n<p>storage 不支持文件去重，重复上传同一个文件时，会存储到不同的 path 。</p>\n</li>\n<li>\n<p>可以查看文件信息：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># /usr/bin/fdfs_file_info /etc/fdfs/client.conf group1/M00/00/00/lRyeml-QA76AWkC1AAAAAAAAAAA357.txt</span>\n<span>source</span> storage id: <span>0</span>\n<span>source</span> <span>ip</span> address: <span>10.0</span>.0.1\n<span>file</span> create timestamp: <span>2020</span>-10-30 <span>12</span>:42:49\n<span>file</span> size: <span>49</span>\n<span>file</span> crc32: <span>1050033651</span> <span>(</span>0x3E963DF3<span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ol>\n<h3 id=\"下载文件\"> 下载文件</h3>\n<ol>\n<li>\n<p>通过客户端下载文件：</p>\n<div><pre><code>/usr/bin/fdfs_download_file /etc/fdfs/client.conf <span>&lt;</span>path<span>></span>\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>也可以直接通过 Nginx 下载：</p>\n<div><pre><code><span>wget</span> http://10.0.0.1:8888/<span>&lt;</span>path<span>></span> -O test.txt\n</code></pre>\n<div><span>1</span><br></div></div></li>\n</ol>\n<h3 id=\"常用命令\"> 常用命令</h3>\n<div><pre><code>fdfs_trackerd       <span>&lt;</span>config_file<span>></span>                           <span># 启动 tracker server</span>\nfdfs_storaged       <span>&lt;</span>config_file<span>></span> <span>[</span>start<span>|</span>stop<span>|</span>restart<span>]</span>      <span># 启动或停止 storage server</span>\nfdfs_monitor        <span>&lt;</span>config_file<span>></span>                           <span># 查询服务器的状态信息</span>\n\nfdfs_upload_file    <span>&lt;</span>config_file<span>></span> <span>&lt;</span>filename<span>></span> <span>[</span>storage_ip:port<span>]</span> <span>[</span>store_path_index<span>]</span>           <span># 上传文件</span>\nfdfs_append_file    <span>&lt;</span>config_file<span>></span> <span>&lt;</span>path<span>></span> <span>&lt;</span>filename<span>></span>                                         <span># 追加上传文件</span>\nfdfs_download_file  <span>&lt;</span>config_file<span>></span> <span>&lt;</span>path<span>></span> <span>[</span>filename<span>]</span> <span>[</span><span>&lt;</span>download_offset<span>></span> <span>&lt;</span>download_bytes<span>></span><span>]</span>    <span># 下载文件</span>\nfdfs_delete_file    <span>&lt;</span>config_file<span>></span> <span>&lt;</span>path<span>></span>                    <span># 删除文件</span>\nfdfs_file_info      <span>&lt;</span>config_file<span>></span> <span>&lt;</span>path<span>></span>                    <span># 查询文件的信息</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div>",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "MinIO",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/MinIO.html",
      "id": "/Hardware/Distributed/Storage/MinIO.html",
      "content_html": "<h1 id=\"minio\"> MinIO</h1>\n<p>：一个 Web 服务器，提供了对象存储的功能。</p>\n<ul>\n<li><a href=\"https://docs.min.io/docs/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 Go 开发，基于 TCP 通信。</li>\n<li>特点：\n<ul>\n<li>轻量级，读写速度快，云原生架构。</li>\n<li>支持生成文件的下载链接。</li>\n<li>提供了命令行客户端 <code>mc</code> ，支持 ls、cp、rm、find 等多种 Unix 风格的命令。</li>\n<li>提供了 Python、Go、Java 等语言的 SDK 。</li>\n<li>兼容 Amazon S3 的 API 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 Docker 部署：<div><pre><code><span>docker</span> run -d -p <span>9000</span>:9000 <span>\\</span>\n        --name minio <span>\\</span>\n        -e <span>\"MINIO_ACCESS_KEY=admin\"</span> <span>\\</span>     <span># 账号</span>\n        -e <span>\"MINIO_SECRET_KEY=******\"</span> <span>\\</span>    <span># 密码</span>\n        -v /opt/minio:/data <span>\\</span>\n        minio/minio server /data\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div></li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>Web 页面示例：</p>\n<p><img src=\"./MinIO.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n<li>\n<p>用户可以创建多个 Bucket（存储桶），每个 Bucket 中可以存储多个文件。</p>\n<ul>\n<li>每个用户拥有一个独立的存储空间，用户之间不支持分享文件。</li>\n<li>默认只有一个用户。</li>\n</ul>\n</li>\n<li>\n<p>Bucket 可以启用版本控制。</p>\n</li>\n<li>\n<p>基于纠删码（Erasure Code）算法存储数据，即使丢失 N/2 个硬盘，也可以恢复数据。</p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Nextcloud",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/Nextcloud.html",
      "id": "/Hardware/Distributed/Storage/Nextcloud.html",
      "content_html": "<h1 id=\"nextcloud\"> Nextcloud</h1>\n<p>：一个 Web 服务器，提供了企业级的网盘功能，基于 HTTP 通信。</p>\n<ul>\n<li><a href=\"https://docs.nextcloud.com/server/10/user_manual/contents.html\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>特点：\n<ul>\n<li>可以通过浏览器访问，也提供了 Linux、MacOS、Windows、Android、IOS 版的客户端。</li>\n<li>支持全局搜索，支持在线预览文本文件、图片、音频、视频。</li>\n<li>不能生成文件的下载链接，只能在用户之间共享文件。</li>\n<li>提供了插件市场，功能丰富。</li>\n</ul>\n</li>\n<li>同类产品：\n<ul>\n<li>Seafile  ：国产开源网盘，功能很少。</li>\n<li>ownCloud ：可以生成文件的下载链接。提供了插件市场，功能比 Nextcloud 略少。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 docker-compose 部署：<div><pre><code><span>version</span><span>:</span> <span>'3'</span>\n\n<span>services</span><span>:</span>\n  <span>mysql</span><span>:</span>\n    <span>image</span><span>:</span> percona\n    <span>environment</span><span>:</span>\n    <span>-</span> MYSQL_ROOT_PASSWORD=<span>******</span>    <span># 设置 root 密码</span>\n    <span>-</span> MYSQL_DATABASE==nextcloud\n    <span>-</span> MYSQL_USER=nextcloud\n    <span>-</span> MYSQL_PASSWORD=<span>******</span>         <span># 设置密码</span>\n    <span>networks</span><span>:</span>\n    <span>-</span> net\n    <span>volumes</span><span>:</span>\n    <span>-</span> ./mysql<span>:</span>/var/lib/mysql\n\n  <span>web</span><span>:</span>\n    <span>image</span><span>:</span> nextcloud\n    <span>depends_on</span><span>:</span>\n    <span>-</span> mysql\n    <span>ports</span><span>:</span>\n    <span>-</span> <span>80:80</span>\n    <span>networks</span><span>:</span>\n    <span>-</span> net\n    <span>volumes</span><span>:</span>\n    <span>-</span> ./html<span>:</span>/var/www/html\n\n<span>networks</span><span>:</span>\n  <span>net</span><span>:</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br></div></div></li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>Web 页面示例：</p>\n<p><img src=\"./Nextcloud.jpg\" alt=\"\" loading=\"lazy\"></p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "go-fastdfs",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/go-fastdfs.html",
      "id": "/Hardware/Distributed/Storage/go-fastdfs.html",
      "content_html": "<h1 id=\"go-fastdfs\"> go-fastdfs</h1>\n<p>：一个与 fastdfs 类似的文件服务器，但功能更多。</p>\n<ul>\n<li><a href=\"https://github.com/sjqzhang/go-fastdfs\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a></li>\n<li>由国内开发者发布，采用 Golang 开发。</li>\n<li>功能：\n<ul>\n<li>采用 HTTP 协议通信，支持通过浏览器或 curl 命令上传、下载文件。</li>\n<li>上传的文件会自动去重。</li>\n<li>上传文件时，如果以存在与它哈希值相同的文件则自动秒传。</li>\n<li>支持断点续传。</li>\n<li>可以部署多个集群，通过 group 划分集群，从而横向扩容。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<ul>\n<li>用 Docker 部署：<div><pre><code><span>docker</span> run -d --name go-fastdfs <span>\\</span>\n          -p <span>8080</span>:8080 <span>\\</span>\n          -v go-fastdfs:/usr/local/go-fastdfs/data <span>\\</span>\n          sjqzhang/go-fastdfs\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></li>\n</ul>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>上传文件：</p>\n<div><pre><code><span>[</span>root@CentOS ~<span>]</span><span># curl http://127.0.0.1:8080/group1/upload -F file=@f1</span>\nhttp://127.0.0.1:8080/group1/default/20210101/15/22/2/f1?name<span>=</span>f1<span>&amp;</span><span>download</span><span>=</span><span>1</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></li>\n<li>\n<p>下载文件：</p>\n<div><pre><code><span>wget</span> http://127.0.0.1:8080/group1/default/20210101/15/22/2/f1\n</code></pre>\n<div><span>1</span><br></div></div></li>\n<li>\n<p>在浏览器上访问服务器，会显示一个简单的上传文件的页面：</p>\n<p><img src=\"./go-fastdfs.png\" alt=\"\" loading=\"lazy\"></p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "h5ai",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/h5ai.html",
      "id": "/Hardware/Distributed/Storage/h5ai.html",
      "content_html": "<h1 id=\"h5ai\"> h5ai</h1>\n<p>：HTML5 Apache Index ，一个轻量级的文件索引服务器，基于 HTTP 通信，常用于公开展示文件。</p>\n<ul>\n<li><a href=\"https://larsjung.de/h5ai/\" target=\"_blank\" rel=\"noopener noreferrer\">官方文档</a></li>\n<li>采用 PHP 5.5 开发。</li>\n<li>特点：\n<ul>\n<li>它本身不存储文件，而是索引多个目录的文件，供用户读取、下载。但是不支持上传文件、修改文件。</li>\n<li>提供了 Web 页面，左侧显示一个目录树，右侧显示当前目录的文件列表。</li>\n<li>支持全局搜索，支持在线预览文本文件、图片、音频、视频，还可以根据文件的 URL 生成二维码。</li>\n<li>所有文件都可以公开访问，不支持用户权限控制，但可以通过 Nginx 代理加上 HTTP Basic Auth 。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"部署\"> 部署</h2>\n<p>见官方文档。</p>\n<h2 id=\"用法\"> 用法</h2>\n<ul>\n<li>\n<p>Web 页面示例：</p>\n<p><img src=\"./h5ai.jpg\" alt=\"\" loading=\"lazy\"></p>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "简介",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/Storage/",
      "id": "/Hardware/Distributed/Storage/",
      "content_html": "<h1 id=\"简介\"> 简介</h1>\n<h2 id=\"存储类型\"> 存储类型</h2>\n<ul>\n<li>\n<p>块存储</p>\n<ul>\n<li>：不管数据内容，只管提供一定容量的存储空间。</li>\n<li>比如硬盘等块设备。</li>\n</ul>\n</li>\n<li>\n<p>文件存储</p>\n<ul>\n<li>：按目录树存储文件，每个文件通过唯一的路径寻址。</li>\n<li>主要用于存储非结构化数据，比如视频、图片，而结构化数据通常用数据库存储。</li>\n<li>比如 FTP、HTTP、NFS 等服务器。</li>\n</ul>\n</li>\n<li>\n<p>对象存储</p>\n<ul>\n<li>：将文件以 key-value 形式存储。\n<ul>\n<li>用文件名作为 key ，不使用目录树，这样可以避免路径寻址的耗时。</li>\n<li>用文件内容作为 value ，且分成多个部分存储，这样可以通过并行读写提高访问速度，但不支持修改文件。</li>\n</ul>\n</li>\n<li>Amazon S3（Simple Storage Service）是目前最流行的对象存储协议，用户可通过 RESTful API 或 aws 命令进行访。</li>\n<li>对象存储是新一代的存储方案，介于块存储与文件存储之间，优点较多，但成本也较高。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"相关软件\"> 相关软件</h2>\n<ul>\n<li>Ceph ：同时支持块存储、文件存储、对象存储。</li>\n<li>GlusterFS ：用于文件存储。2011 年被红帽公司收购。</li>\n<li>GoogleFS ：用于文件存储。由 Google 开发，闭源。</li>\n<li>HDFS ：用于文件存储，借鉴了 GoogleFS 。</li>\n<li>FastDFS ：用于文件存储。</li>\n<li>Swift ：用于对象存储。</li>\n<li>MinIO ：用于对象存储。</li>\n</ul>\n<h3 id=\"nfs\"> NFS</h3>\n<p>：网络文件系统（Network File System），一个用于共享文件系统的网络协议，工作在表示层。</p>\n<ul>\n<li>1984 年由 Sun 公司发布。</li>\n<li>采用 C/S 架构。\n<ul>\n<li>客户端需要通过 RPC 协议访问服务器的 UDP 111 端口，查询到 NFS 各项服务进程当前监听的端口，然后与其建立 TCP 连接。</li>\n<li>客户端可以挂载服务器上共享的文件系统，直接读写其中的文件，像读写本机文件一样方便。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"iscsi\"> iSCSI</h3>\n<p>：因特网小型计算机系统接口（Internet Small Computer System Interface），一个用于共享存储设备的网络协议。</p>\n<ul>\n<li>2003 年由 IBM 公司发布。</li>\n<li>采用 C/S 架构，基于 TCP/IP 协议通信。</li>\n<li>比 NFS 更底层，可以将远程主机的存储设备（比如磁盘）挂载到本机。\n<ul>\n<li>原理：将本机发出的 SCSI 命令，传输到远程主机上执行。</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-28T09:28:24.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "分布式",
      "url": "https://hsaio.codenoob.top/Hardware/Distributed/",
      "id": "/Hardware/Distributed/",
      "content_html": "<h1 id=\"分布式\"> 分布式</h1>\n<p><a href=\"./\">《分布式》</a></p>\n<ul>\n<li>简介\n<ul>\n<li><a href=\"./Introduction/cloudComputing.html\">云计算</a></li>\n<li><a href=\"./Introduction/bigData.html\">大数据</a></li>\n</ul>\n</li>\n<li>分布式系统\n<ul>\n<li><a href=\"./DistributedSystem/\">简介</a></li>\n<li><a href=\"./DistributedSystem/ZooKeeper/ZooKeeper.html\">ZooKeeper</a>\n<ul>\n<li><a href=\"./DistributedSystem/ZooKeeper/Principle.html\">原理</a></li>\n<li><a href=\"./DistributedSystem/ZooKeeper/deploy.html\">部署</a></li>\n<li><a href=\"./DistributedSystem/ZooKeeper/usage.html\">用法</a></li>\n</ul>\n</li>\n<li><a href=\"./DistributedSystem/etcd.html\">etcd</a></li>\n<li><a href=\"./DistributedSystem/Zipkin.html\">Zipkin</a></li>\n</ul>\n</li>\n<li>消息队列\n<ul>\n<li><a href=\"./MessageQueue/\">简介</a></li>\n<li><a href=\"./MessageQueue/ActiveMQ.html\">ActiveMQ</a></li>\n<li><a href=\"./MessageQueue/Kafka/Kafka.html\">Kafka</a>\n<ul>\n<li><a href=\"./MessageQueue/Kafka/Principle.html\">原理</a></li>\n<li><a href=\"./MessageQueue/Kafka/deploy.html\">部署</a></li>\n<li><a href=\"./MessageQueue/Kafka/usage.html\">工具</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>存储\n<ul>\n<li><a href=\"./Storage/\">简介</a></li>\n<li><a href=\"./Storage/Ceph.html\">Ceph</a></li>\n<li><a href=\"./Storage/FastDFS.html\">FastDFS</a></li>\n<li><a href=\"./Storage/go-fastdfs.html\">go-fastdfs</a></li>\n<li><a href=\"./Storage/h5ai.html\">h5ai</a></li>\n<li><a href=\"./Storage/MinIO.html\">MinIO</a></li>\n<li><a href=\"./Storage/Nextcloud.html\">Nextcloud</a></li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "机械硬盘",
      "url": "https://hsaio.codenoob.top/Hardware/HDD.html",
      "id": "/Hardware/HDD.html",
      "content_html": "<p>现代计算机大部分文件存储功能都是由机械硬盘这种设备提供的。(现在的 SSD 和闪存从概念和逻辑上都部分继承自机械硬盘，所以使用机械硬盘来进行理解也是没有问题的)</p>\n<p>机械硬盘能实现信息存储的功能基于: 磁性存储介质能够被磁化，且磁化后会长久保留被磁化的状态，这种被磁化状态能够被读取出来，同时这种磁化状态还能够不断被修改，磁化正好有两个方向，所以可以表示 0 和 1。\n于是硬盘就是把这种磁性存储介质做成一个个盘片，每一个盘片上都分布着数量巨大的磁性存储单位，使用磁性读写头对盘片进行写入和读取(从原理上类似黑胶唱片的播放)。</p>\n<p>一个硬盘中的磁性存储单位数以亿计(1T 硬盘就有约 80 亿个)，所以需要一套规则来规划信息如何存取(比如一本存储信息的书我们还会分为页，每一页从上到下从左到右读取，同时还有章节目录)\n于是就有了这些物理、逻辑概念:</p>\n<ol>\n<li>\n<p>一个硬盘有多张盘片叠成，不同盘片有编号</p>\n</li>\n<li>\n<p>每张盘片上的存储颗粒成环形一圈圈地排布，每一圈称为磁道，有编号</p>\n</li>\n<li>\n<p>每条磁道上都有一圈存储颗粒，每 512 * 8(512 字节，0.5KB)个存储颗粒作为一个扇区，扇区是硬盘上存储的最小物理单位</p>\n</li>\n<li>\n<p>N 个扇区可以组成簇，N 取决于不同的文件系统或是文件系统的配置，簇是此文件系统中的最小存储单位</p>\n</li>\n<li>\n<p>所有盘面上的同一磁道构成一个圆柱，称为柱面，柱面是系统分区的最小单位</p>\n</li>\n</ol>\n<p>磁头读写文件的时候，首先是分区读写的，由 inode 编号(区内唯一的编号)找到对应的磁道和扇区，然后一个柱面一个柱面地进行读写。机械硬盘的读写控制系统是一个令人叹为观止的精密工程(一个盘面上有几亿个存储单位，每个磁道宽度不到几十纳米，磁盘每分钟上万转)，同时关于读写的逻辑也是有诸多细节(比如扇区的编号并不是连续的)，非常有意思，可以自行搜索文章拓展阅读。</p>\n",
      "date_published": "2020-06-05T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "硬件"
      ]
    },
    {
      "title": "硬件相关",
      "url": "https://hsaio.codenoob.top/Hardware/",
      "id": "/Hardware/",
      "summary": "<h1 id=\"硬件相关\"> 硬件相关</h1>\n<p>这里是一些常见的硬件相关的问题总结，供访客查阅。</p>\n",
      "content_html": "<h1 id=\"硬件相关\"> 硬件相关</h1>\n<p>这里是一些常见的硬件相关的问题总结，供访客查阅。</p>\n\n",
      "date_published": "2022-03-27T07:58:55.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "CPU 的架构",
      "url": "https://hsaio.codenoob.top/Hardware/structure.html",
      "id": "/Hardware/structure.html",
      "content_html": "<p>CPU 内部已经含有一些微指令，我们所使用的软件都要经过 CPU 内部的微指令集来达成才行。那这些指令集的设计主要又被分为两种设计理念，这就是目前世界上常见到的两种主要 CPU 架构，分别是: 精简指令集(RISC)与复杂指令集(CISC) 系统。</p>\n<h2 id=\"精简指令集\"> 精简指令集</h2>\n<p>精简指令集，(Reduced Instruction Set Computer, RISC) 的设计中，微指令集较为精简。每个指令的执行时间都很短，完成的动作也很单纯，指令的执行性能较佳；但是若要做复杂的事情，就要由多个指令来完成。常见的 RISC 微指令集 CPU 主要例如甲骨文(Oracle) 公司的 SPARC 系列、IBM 公司的 Power Architecture (包括 PowerPC) 系列、与 ARM 公司(ARM Holdings) 的 ARM CPU 系列等。</p>\n<p>在应用方面，SPARC CPU 的电脑常用于学术领域的大型工作站中，包括银行金融体系的主要伺服器也都有这类的电脑架构；至于 PowerPC 架构的应用上，例如索尼(Sony)公司出产的 Play Station 3(PS3)就是使用 PowerPC 架构的 Cell 处理器；那 ARM 的 ARM 呢? 您常使用的各厂牌手机、PDA、导航系统、网络设备(交换器、路由器等)等，几乎都是使用 ARM 架构的 CPU。目前世界上使用范围最广的 CPU 可能就是 ARM 这种架构。</p>\n<h2 id=\"复杂指令集\"> 复杂指令集</h2>\n<p>复杂指令集，(Complex Instruction Set Computer, CISC)。与 RISC 不同的，CISC 在微指令集的每个小指令可以执行一些较低阶的硬体操作，指令数目多而且复杂，每条指令的长度并不相同。因为指令执行较为复杂所以每条指令花费的时间较长，但每条个别指令可以处理的工作较为丰富。常见的 CISC 微指令集 CPU 主要有 AMD、Intel、VIA 等的 x86 架构的 CPU。</p>\n<p>由于 AMD、Intel、VIA 所开发出来的 x86 架构 CPU 被大量使用于个人电脑(Personal computer)用途上面，因此，个人电脑常被称为 x86 架构的电脑! 那为何称为 x86 架构呢? 这是因为最早的那颗 Intel 发展出来的 CPU 代号称为 8086，后来依此架构又开发出 80286, 80386...，因此这种架构的 CPU 就被称为 x86 架构了。</p>\n<p>在 2003 年以前由 Intel 所开发的 x86 架构 CPU 由 8 位数升级到 16、32 位数，后来 AMD 依此架构修改新一代的 CPU 为 64 位数， 为了区别两者的差异，因此 64 位数的个人电脑 CPU 又被统称为 x86_64 的架构。</p>\n<div><p>提示</p>\n<p>所谓的位数指的是 CPU 一次资料读取的最大量! 64 位数 CPU 代表 CPU 一次可以读写 64bits 这么多的资料，32 位数 CPU 则是 CPU 一次只能读取 32 位数的意思。因为 CPU 读取资料量有限制，因此能够从记忆体中读写的资料也就有所限制。所以，一般 32 位数的 CPU 所能读写的最大资料量是 4GB。</p>\n</div>\n<p>那么不同的 x86 架构的 CPU 有什么差异呢? 除了 CPU 的整体结构(如第二层快取、每次运行可执行的指令数等)之外， 主要是在于微指令集的不同。新的 x86 的 CPU 大多含有很先进的微指令集， 这些微指令集可以加速多媒体程序的运行，也能够加强虚拟化的性能，而且某些微指令集更能够增加能源效率，降低 CPU 耗电量。</p>\n",
      "date_published": "2020-06-05T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "硬件"
      ]
    },
    {
      "title": "Home",
      "url": "https://hsaio.codenoob.top/author.html",
      "id": "/author.html",
      "content_html": "<h1 id=\"简介\"> 简介</h1>\n<div><p>介绍</p>\n<p>我是ChouCOng，热爱编程，乐于分享</p>\n<p>现在的个人博客，读者和作者都越来越少，坚持写自己的东西，是一种总结更是一种锻炼，如果别人能懂得我的转述，我才是真的会了</p>\n<p>感谢你的关注，你可点击<a href=\"/timeline/\">时光机</a>来了解我在做什么，查看更多的信息 点击查看本站的<a href=\"/category/\">分类</a>结构更为清晰！</p>\n</div>\n<h2 id=\"我的bilibili\"> 我的bilibili</h2>\n<p>在年疫情期间，我上传了我的第一个视屏，是分享一个使用来编写实时疫情界面的教程，第一次收获了点赞和关注 随后我在每周更新自己想要分享的东西，如果你感兴趣可以来我的个人空间瞧一瞧<a href=\"https://space.bilibili.com/372366303/\" target=\"_blank\" rel=\"noopener noreferrer\">ChouCong的个人空间</a></p>\n<h2 id=\"我的订阅号\"> 我的订阅号</h2>\n<p>我开通订阅号啦！以后视频发哔哩哔哩，文章发订阅号，当然博客会同步，博客更适合观看文档！</p>\n<p><img src=\"/assets/img/qr_weixin.png\" alt=\"公众号二维码，扫一扫有惊喜！\" loading=\"lazy\"></p>\n<h2 id=\"目前技术栈\"> 目前技术栈</h2>\n<p>本来花了很多的时间学习相关，但是目前从事前端也比较喜欢，所以说就是都会点，也可以说是全都不会</p>\n<p>特别喜欢移动端的开发，但是生不逢时没有入行，现在也只是爱好</p>\n<h2 id=\"未来计划\"> 未来计划</h2>\n<ul>\n<li>保持学习算法和数据结构</li>\n<li>做一个自己的开源项目</li>\n<li>更新一些简单的教程</li>\n<li>精彩的生活</li>\n</ul>\n<h2 id=\"联系我\"> 联系我</h2>\n<p>有什么好的意见，或者是想要咨询一些事情可以通过以下找到我</p>\n<ul>\n<li>QQ：<a href=\"https://qm.qq.com/cgi-bin/qm/qr?k=hH6gqBpGrQ80a0kBI-69N6OWXMIJ7825&amp;noverify=0\" target=\"_blank\" rel=\"noopener noreferrer\">3518439599</a></li>\n<li>邮箱：<a href=\"mailto:ChouCong912@gmial.com\">ChouCong912@gmial.com</a></li>\n</ul>\n<CatalogGraph />",
      "image": "https://hsaio.codenoob.top/assets/img/qr_weixin.png",
      "date_published": "2022-03-23T15:00:14.000Z",
      "date_modified": "2022-03-24T14:25:35.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Markdown高级技巧",
      "url": "https://hsaio.codenoob.top/guide/markdown-enhance.html",
      "id": "/guide/markdown-enhance.html",
      "summary": "Markdown高级技巧",
      "content_html": "<br>\n<h2 id=\"支持的-html-元素\"> 支持的 HTML 元素</h2>\n<p>不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。</p>\n<p>目前支持的 HTML 元素有：<code>&lt;kbd&gt;</code>、 <code>&lt;b&gt;</code>、 <code>&lt;i&gt;</code>、 <code>&lt;em&gt;</code>、 <code>&lt;sup&gt;</code>、 <code>&lt;sub&gt;</code>、 <code>&lt;br&gt;</code>等 ，如：</p>\n<blockquote>\n<p>使用 <code>&lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;Alt&lt;/kbd&gt;+&lt;kbd&gt;Del&lt;/kbd&gt;</code> 重启电脑</p>\n</blockquote>\n<p>输出结果为：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/image/Snipaste_2021-10-06_12-33-31.png\" alt=\"键盘\" loading=\"lazy\"></p>\n<h2 id=\"公式\"> 公式</h2>\n<p>当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。如：</p>\n<div><pre><code>$$\n\\mathbf{V}_1 \\times \\mathbf{V}_2 =  \\begin{vmatrix} \n\\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k} \\\\\n\\frac{\\partial X}{\\partial u} &amp;  \\frac{\\partial Y}{\\partial u} &amp; 0 \\\\\n\\frac{\\partial X}{\\partial v} &amp;  \\frac{\\partial Y}{\\partial v} &amp; 0 \\\\\n\\end{vmatrix}\n${$tep1}{\\style{visibility:hidden}{(x+1)(x+1)}}\n$$\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><p>输出结果为：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/image/Snipaste_2021-10-06_12-47-07.png\" alt=\"公式\" loading=\"lazy\"></p>\n<h2 id=\"typora-画流程图、时序图-顺序图-、甘特图\"> typora 画流程图、时序图(顺序图)、甘特图</h2>\n<p>复制以下代码使用 typora 的源码模式粘贴到编辑器中查看效果：</p>\n<p>以下几个实例效果图如下：</p>\n<h3 id=\"横向流程图源码格式\"> 横向流程图源码格式</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-54-22.png\" alt=\"横向流程图\" loading=\"lazy\"></p>\n<div><pre><code>```mermaid\ngraph LR\nA[方形] --&gt;B(圆角)\n    B --&gt; C{条件a}\n    C --&gt;|a=1| D[结果1]\n    C --&gt;|a=2| E[结果2]\n    F[横向流程图]\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><h3 id=\"竖向流程图源码格式\"> 竖向流程图源码格式</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-54-50.png\" alt=\"竖向流程图\" loading=\"lazy\"></p>\n<div><pre><code>```mermaid\ngraph TD\nA[方形] --&gt; B(圆角)\n    B --&gt; C{条件a}\n    C --&gt; |a=1| D[结果1]\n    C --&gt; |a=2| E[结果2]\n    F[竖向流程图]\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><h3 id=\"标准流程图源码格式\"> 标准流程图源码格式</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-54-58.png\" alt=\"标准流程图\" loading=\"lazy\"></p>\n<div><pre><code>```flow\nst=&gt;start: 开始框\nop=&gt;operation: 处理框\ncond=&gt;condition: 判断框(是或否?)\nsub1=&gt;subroutine: 子流程\nio=&gt;inputoutput: 输入输出框\ne=&gt;end: 结束框\nst-&gt;op-&gt;cond\ncond(yes)-&gt;io-&gt;e\ncond(no)-&gt;sub1(right)-&gt;op\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><h3 id=\"标准流程图源码格式-横向\"> 标准流程图源码格式（横向）</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-55-05.png\" alt=\"标准流程图-横向\" loading=\"lazy\"></p>\n<div><pre><code>```flow\nst=&gt;start: 开始框\nop=&gt;operation: 处理框\ncond=&gt;condition: 判断框(是或否?)\nsub1=&gt;subroutine: 子流程\nio=&gt;inputoutput: 输入输出框\ne=&gt;end: 结束框\nst(right)-&gt;op(right)-&gt;cond\ncond(yes)-&gt;io(bottom)-&gt;e\ncond(no)-&gt;sub1(right)-&gt;op\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div><h3 id=\"uml标准时序图样例\"> UML标准时序图样例</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-55-31.png\" alt=\"UML标准时序图\" loading=\"lazy\"></p>\n<div><pre><code>```sequence\nTitle: 标题：复杂使用\n对象A-&gt;对象B: 对象B你好吗?（请求）\nNote right of 对象B: 对象B的描述\nNote left of 对象A: 对象A的描述(提示)\n对象B--&gt;对象A: 我很好(响应)\n对象B-&gt;小三: 你好吗\n小三--&gt;&gt;对象A: 对象B找我了\n对象A-&gt;对象B: 你真的好吗？\nNote over 小三,对象B: 我们是朋友\nparticipant C\nNote right of C: 没人陪我玩\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><h3 id=\"uml时序图源码样例\"> UML时序图源码样例</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-55-14.png\" alt=\"UML时序图\" loading=\"lazy\"></p>\n<div><pre><code>```sequence\n对象A-&gt;对象B: 对象B你好吗?（请求）\nNote right of 对象B: 对象B的描述\nNote left of 对象A: 对象A的描述(提示)\n对象B--&gt;对象A: 我很好(响应)\n对象A-&gt;对象B: 你真的好吗？\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><h3 id=\"uml时序图源码复杂样例\"> UML时序图源码复杂样例</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/note/Snipaste_2021-11-03_22-55-21.png\" alt=\"UML时序图源码-复杂\" loading=\"lazy\"></p>\n<div><pre><code>```sequence\nTitle: 标题：复杂使用\n对象A-&gt;对象B: 对象B你好吗?（请求）\nNote right of 对象B: 对象B的描述\nNote left of 对象A: 对象A的描述(提示)\n对象B--&gt;对象A: 我很好(响应)\n对象B-&gt;小三: 你好吗\n小三--&gt;&gt;对象A: 对象B找我了\n对象A-&gt;对象B: 你真的好吗？\nNote over 小三,对象B: 我们是朋友\nparticipant C\nNote right of C: 没人陪我玩\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br></div></div><h3 id=\"甘特图样例\"> 甘特图样例</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/image/Snipaste_2021-10-06_13-00-16.png\" alt=\"甘特图\" loading=\"lazy\"></p>\n<div><pre><code>```mermaid\n%% 语法示例\n        gantt\n        dateFormat  YYYY-MM-DD\n        title 软件开发甘特图\n        section 设计\n        需求                      :done,    des1, 2014-01-06,2014-01-08\n        原型                      :active,  des2, 2014-01-09, 3d\n        UI设计                     :         des3, after des2, 5d\n    未来任务                     :         des4, after des3, 5d\n        section 开发\n        学习准备理解需求                      :crit, done, 2014-01-06,24h\n        设计框架                             :crit, done, after des2, 2d\n        开发                                 :crit, active, 3d\n        未来任务                              :crit, 5d\n        耍                                   :2d\n        section 测试\n        功能测试                              :active, a1, after des3, 3d\n        压力测试                               :after a1  , 20h\n        测试报告                               : 48h\n```\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div>",
      "image": "https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto/image/Snipaste_2021-10-06_12-33-31.png",
      "date_published": "2020-06-26T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "Markdown介绍",
      "url": "https://hsaio.codenoob.top/guide/markdown.html",
      "id": "/guide/markdown.html",
      "summary": "Markdown介绍",
      "content_html": "<p>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。</p>\n<p>Markdown的目标是实现「易读易写」。</p>\n<h2 id=\"概述\"> 概述</h2>\n<p>不过最需要强调的便是它的可读性。</p>\n<p>一份使用Markdown格式撰写的文件应该可以直接以纯文字发佈，并且看起来不会像是由许多标签或是格式指令所构成。</p>\n<p>Markdown语法受到一些既有text-to-HTML格式的影响，包括<a href=\"http://docutils.sourceforge.net/mirror/setext.html\" target=\"_blank\" rel=\"noopener noreferrer\">Setext</a>、<a href=\"http://www.aaronsw.com/2002/atx/\" target=\"_blank\" rel=\"noopener noreferrer\">atx</a>、<a href=\"http://textism.com/tools/textile/\" target=\"_blank\" rel=\"noopener noreferrer\">Textile</a>、<a href=\"http://docutils.sourceforge.net/rst.html\" target=\"_blank\" rel=\"noopener noreferrer\">reStructuredText</a>、<a href=\"http://www.triptico.com/software/grutatxt.html\" target=\"_blank\" rel=\"noopener noreferrer\">Grutatext</a>和<a href=\"http://ettext.taint.org/doc/\" target=\"_blank\" rel=\"noopener noreferrer\">EtText</a>，然而最大灵感来源其实是纯文字的电子邮件格式。</p>\n<p>因此Markdown的语法全由标点符号所组成，并经过严谨慎选，是为了让它们看起来就像所要表达的意思。像是在文字两旁加上星号，看起来就像<strong>强调</strong>。</p>\n<p>Markdown的列表看起来，嗯，就是列表。假如你有使用过电子邮件，引言写法看起来就真的像是引用一段文字。</p>\n<p>Markdown具有一系列衍生版本，用于扩展Markdown的功能(如表格、脚注、内嵌HTML等等)，这些功能原初的Markdown尚不具备，它们能让Markdown转换成更多的格式，例如LaTeX，Docbook。Markdown增强版中比较有名的有MarkdownExtra、MultiMarkdown、Maruku等。</p>\n<p>这些衍生版本要么基于工具，如Pandoc；要么基于网站，如GitHub和Wikipedia，在语法上基本兼容，但在一些语法和渲染效果上有改动。</p>\n<h2 id=\"用途\"> 用途</h2>\n<p>Markdown的语法有个主要的目的:用来作为一种网络内容的写作用语言。Markdown的重点在于，它能让文件更容易阅读、编写。因此，Markdown的格式语法只涵盖纯文字可以涵盖的范围。</p>\n<p>Markdown的语法简洁明了、学习容易，而且功能比纯文本更强，因此有很多人用它写博客。</p>\n<p>世界上最流行的博客平台WordPress能很好的支持Markdown。用于编写说明文档，并且以“README.md”的文件名保存在软件的目录下面。除此之外，我们还可以快速将Markdown转化为演讲PPT、Word产品文档、LaTex论文甚至是用非常少量的代码完成最小可用原型。</p>\n<p>在数据科学领域，Markdown已经广泛使用，极大地推进了动态可重复性研究的历史进程。</p>\n<h2 id=\"行内html\"> 行内HTML</h2>\n<p>不在Markdown涵盖范围之外的标签，都可以直接在文件里面用HTML撰写。不需要额外标注这是HTML或是Markdown；只要直接加标签就可以了。</p>\n<p>只有块元素──比如<code>&lt;div&gt;</code>、<code>&lt;table&gt;</code>、<code>&lt;pre&gt;</code>、<code>&lt;p&gt;</code>等标签，必须在前后加上空行，以利与内容区隔。而且这些(元素)的开始与结尾标签，不可以用tab或是空白来缩进。Markdown的解析器有智慧型判断，可以避免在块标签前后加上没有必要的<code>&lt;p&gt;</code>标签。</p>\n<p>举例来说，在Markdown文件里加上一段HTML表格:</p>\n<div><pre><code>This is a regular paragraph.\n\n<span><span><span>&lt;</span>table</span><span>></span></span>\n    <span><span><span>&lt;</span>tr</span><span>></span></span>\n        <span><span><span>&lt;</span>td</span><span>></span></span>Foo<span><span><span>&lt;/</span>td</span><span>></span></span>\n    <span><span><span>&lt;/</span>tr</span><span>></span></span>\n<span><span><span>&lt;/</span>table</span><span>></span></span>\n\nThis is another regular paragraph.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><p>请注意，Markdown语法在HTML块标签中将不会被进行处理。例如，你无法在HTML块内使用Markdown形式的<code>**强调**</code>。</p>\n<h2 id=\"特殊字元自动转换\"> 特殊字元自动转换</h2>\n<p>在HTML文件中，有两个字元需要特殊处理:<code>&lt;</code>和<code>&amp;</code>。<code>&lt;</code>符号用于起始标签，<code>&amp;</code>符号则用于标记HTML实体，如果你只是想要使用这些符号，你必须要使用实体的形式，像是<code>&amp;lt</code>;和<code>&amp;amp;</code>。</p>\n<p><code>&amp;</code>符号其实很容易让写作网络文件的人感到困扰，如果你要打「AT&amp;T」，你必须要写成「<code>AT&amp;amp;T</code>」，还得转换网址内的<code>&amp;</code>符号，如果你要链接到<code>http://images.google.com/images?num=30&amp;q=larry+bird</code>\n你必须要把网址转成:</p>\n<div><pre><code>http://images.google.com/images?num=30<span title=\"&amp;\">&amp;amp;</span>q=larry+bird\n</code></pre>\n<div><span>1</span><br></div></div><p>才能放到链接标签的<code>href</code>属性里。不用说也知道这很容易忘记，这也可能是HTML标准检查所检查到的错误中，数量最多的。</p>\n<p>Markdown允许你直接使用这些符号，但是你要小心跳脱字元的使用，如果你是在HTML实体中使用<code>&amp;</code>符号的话，它不会被转换，而在其它情形下，它则会被转换成<code>&amp;amp;</code>。所以你如果要在文件中插入一个著作权的符号，你可以这样写:</p>\n<div><pre><code><span title=\"&copy;\">&amp;copy;</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>1Markdown将不会对这段文字做修改，但是如果你这样写:</p>\n<div><pre><code>AT&amp;T\n</code></pre>\n<div><span>1</span><br></div></div><p>Markdown就会将它转为:</p>\n<div><pre><code>AT<span title=\"&amp;\">&amp;amp;</span>T\n</code></pre>\n<div><span>1</span><br></div></div><p>类似的状况也会发生在<code>&lt;</code>符号上，因为Markdown支持<a href=\"https://vuepress-theme-hope.github.io/zh/basic/markdown/#%E8%A1%8C%E5%86%85-HTML\" target=\"_blank\" rel=\"noopener noreferrer\">行内HTML</a>，如果你是使用<code>&lt;</code>符号作为HTML标签使用，那Markdown也不会对它做任何转换，但是如果你是写:</p>\n<div><pre><code>4 &lt; 5\n</code></pre>\n<div><span>1</span><br></div></div><p>Markdown将会把它转换为:</p>\n<div><pre><code>4 <span title=\"&lt;\">&amp;lt;</span> 5\n</code></pre>\n<div><span>1</span><br></div></div><p>不过需要注意的是，code范围内，不论是行内还是块，<code>&lt;</code>和<code>&amp;</code>两个符号都一定会被转换成HTML实体，这项特性让你可以很容易地用Markdown写HTMLcode(和HTML相对而言，HTML语法中，你要把所有的<code>&lt;</code>和<code>&amp;</code>都转换为HTML实体，才能在HTML文件里面写出HTMLcode。)</p>\n<h2 id=\"块元素\"> 块元素</h2>\n<h3 id=\"段落和换行\"> 段落和换行</h3>\n<p>一个段落是由一个以上相连接的行句组成，而一个以上的空行则会切分出不同的段落(空行的定义是显示上看起来像是空行，便会被视为空行。比方说，若某一行只包含空白和tab，则该行也会被视为空行)，一般的段落不需要用空白或断行缩进。</p>\n<p>「一个以上相连接的行句组成」这句话其实暗示了Markdown允许段落内的强迫断行，这个特性和其他大部分的text-to-HTML格式不一样(包括MovableType的「ConvertLineBreaks」选项)，其它的格式会把每个断行都转成<code>&lt;br/&gt;</code>标签。</p>\n<p>如果你真的想要插入<code>&lt;br/&gt;</code>标签的话，在行尾加上两个以上的空白，然后按enter。</p>\n<p>是的，这确实需要花比较多功夫来插入<code>&lt;br/&gt;</code>，但是「每个换行都转换为<code>&lt;br/&gt;</code>」的方法在Markdown中并不适合，Markdown中email式的<a href=\"https://vuepress-theme-hope.github.io/zh/basic/markdown/#blockquote\" target=\"_blank\" rel=\"noopener noreferrer\">块引言</a>和多段落的<a href=\"https://vuepress-theme-hope.github.io/zh/basic/markdown/#list\" target=\"_blank\" rel=\"noopener noreferrer\">列表</a>在使用换行来排版的时候，不但更好用，还更好阅读。</p>\n<h3 id=\"标题\"> 标题</h3>\n<p>标题能显示出文章的结构。</p>\n<p>Markdown支持两种标题的语法，<a href=\"http://docutils.sourceforge.net/mirror/setext.html\" target=\"_blank\" rel=\"noopener noreferrer\">Setext</a>和<a href=\"http://www.aaronsw.com/2002/atx/\" target=\"_blank\" rel=\"noopener noreferrer\">atx</a>形式。</p>\n<p>Setext形式是用底线的形式，利用<code>=</code>(最高阶标题)和<code>-</code>(第二阶标题)，例如:</p>\n<div><pre><code><span><span>#</span> This is an H1</span>\n\n<span><span>##</span> This is an H2</span>\n\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>123任何数量的<code>=</code>和<code>-</code>都可以有效果。</p>\n<p>Atx(推荐)形式则是在行首插入1到6个<code>#</code>，对应到标题1到6阶，例如:</p>\n<ul>\n<li>H1:<code># Header</code></li>\n<li>H2:<code>## Header 2</code></li>\n<li>H3:<code>### Header 3</code></li>\n<li>H4:<code>#### Header 4</code></li>\n<li>H5:<code>##### Header 5</code></li>\n<li>H6:<code>###### Header 6</code></li>\n</ul>\n<h3 id=\"区块-blockquotes\"> 区块(Blockquotes)</h3>\n<p>Markdown使用email形式的块引言，如果你很熟悉如何在email信件中引言，你就知道怎麽在Markdown文件中建立一个块引言，那会看起来像是你强迫断行，然后在每行的最前面加上<code>&gt;</code>:</p>\n<div><pre><code><span>></span> This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,\n<span>></span> consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.\n<span>></span> Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\n<span>></span>\n<span>></span> Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse\n<span>></span> id sem consectetuer libero luctus adipiscing.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>Markdown也允许你只在整个段落的第一行最前面加上<code>&gt;</code>:</p>\n<div><pre><code><span>></span> This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,\n<span>></span> consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.\n<span>></span> Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\n\n<span>></span> Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse\n<span>></span> id sem consectetuer libero luctus adipiscing.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>块引言可以有阶层(例如:引言内的引言)，只要根据层数加上不同数量的<code>&gt;</code>:</p>\n<div><pre><code>&gt; This is the first level of quoting.\n&gt;\n&gt; &gt; This is nested blockquote.\n&gt;\n&gt; Back to the first level.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>引言的块内也可以使用其他的Markdown语法，包括标题、列表、代码块等:</p>\n<div><pre><code>&gt; ## This is a header.\n&gt;\n&gt;. This is the first list item.\n&gt; 2. This is the second list item.\n&gt;\n&gt; Here’s some example code:\n&gt;\n&gt;     return shell_exec(&quot;echo $input | $markdown_script&quot;);\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div><p>任何标准的文字编辑器都能简单地建立email样式的引言，例如BBEdit，你可以选取文字后然后从选单中选择<em>增加引言阶层</em>。</p>\n<h3 id=\"列表\"> 列表</h3>\n<p>Markdown支持有序列表和无序列表。</p>\n<p>无序列表使用减号作为列表标记(也可使用星号、加号):</p>\n<div><pre><code><span>-</span> Red\n<span>-</span> Green\n<span>-</span> Blue\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>也可以(不建议):</p>\n<div><pre><code><span>-</span> Red\n<span>-</span> Green\n<span>-</span> Blue\n\n<span>*</span> Red\n<span>*</span> Green\n<span>*</span> Blue\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><p>有序列表则使用数字接著一个英文句点:</p>\n<div><pre><code><span>1.</span> Bird\n<span>2.</span> McHale\n<span>3.</span> Parish\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>很重要的一点是，你在列表标记上使用的数字并不会影响输出的HTML结果，上面的列表所产生的HTML标记为:</p>\n<div><pre><code><span><span><span>&lt;</span>ol</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span>Bird<span><span><span>&lt;/</span>li</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span>McHale<span><span><span>&lt;/</span>li</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span>Parish<span><span><span>&lt;/</span>li</span><span>></span></span>\n<span><span><span>&lt;/</span>ol</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>如果你的列表标记写成:</p>\n<div><pre><code><span>1.</span> Bird\n<span>1.</span> McHale\n<span>1.</span> Parish\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>你都会得到完全相同的HTML输出。重点在于，你可以让Markdown文件的列表数字和输出的结果相同，或是你懒一点都写作<code>1</code>你可以完全不用在意数字的正确性。</p>\n<p>列表项目标记通常是放在最左边，但是其实也可以缩进，最多三个空白，项目标记后面则一定要接著至少一个空白或tab。</p>\n<p>要让列表看起来更漂亮，你可以把内容用固定的缩进整理好:</p>\n<div><pre><code><span>-</span> Lorem ipsum dolor sit amet, consectetuer adipiscing elit.\n  Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,\n  viverra nec, fringilla in, laoreet vitae, risus.\n<span>-</span> Donec sit amet nisl. Aliquam semper ipsum sit amet velit.\n  Suspendisse id sem consectetuer libero luctus adipiscing.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>但是如果你很懒，那也不一定需要:</p>\n<div><pre><code><span>-</span> Lorem ipsum dolor sit amet, consectetuer adipiscing elit.\n  Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,\n  viverra nec, fringilla in, laoreet vitae, risus.\n<span>-</span> Donec sit amet nisl. Aliquam semper ipsum sit amet velit.\n  Suspendisse id sem consectetuer libero luctus adipiscing.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>如果列表项目间用空行分开，Markdown会把项目的内容在输出时用<code>&lt;p&gt;</code>标签包起来，举例来说:</p>\n<div><pre><code><span>-</span> Bird\n<span>-</span> Magic\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>会被转换为:</p>\n<div><pre><code><span><span><span>&lt;</span>ul</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span>Bird<span><span><span>&lt;/</span>li</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span>Magic<span><span><span>&lt;/</span>li</span><span>></span></span>\n<span><span><span>&lt;/</span>ul</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>但是这个:</p>\n<div><pre><code><span>-</span> Bird\n\n<span>-</span> Magic\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>会被转换为:</p>\n<div><pre><code><span><span><span>&lt;</span>ul</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span><span><span><span>&lt;</span>p</span><span>></span></span>Bird<span><span><span>&lt;/</span>p</span><span>></span></span><span><span><span>&lt;/</span>li</span><span>></span></span>\n  <span><span><span>&lt;</span>li</span><span>></span></span><span><span><span>&lt;</span>p</span><span>></span></span>Magic<span><span><span>&lt;/</span>p</span><span>></span></span><span><span><span>&lt;/</span>li</span><span>></span></span>\n<span><span><span>&lt;/</span>ul</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空白或是一个 tab :</p>\n<div><pre><code><span>1.</span>  This is a list item with two paragraphs. Lorem ipsum dolor\n    sit amet, consectetuer adipiscing elit. Aliquam hendrerit\n    mi posuere lectus.\n\n<span>    Vestibulum enim wisi, viverra nec, fringilla in, laoreet\n    vitae, risus. Donec sit amet nisl. Aliquam semper ipsum\n    sit amet velit.</span>\n\n<span>2.</span>  Suspendisse id sem consectetuer libero luctus adipiscing.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></div></div><p>如果你每行都有缩进，看起来会看好很多，当然，再次地，如果你很懒惰，Markdown 也允许:</p>\n<div><pre><code><span>-</span> This is a list item with two paragraphs.\n\n  This is the second paragraph in the list item. You're\n  only required to indent the first line. Lorem ipsum dolor\n  sit amet, consectetuer adipiscing elit.\n\n<span>-</span> Another item in the same list.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><p>如果要在列表项目内放进引言，那 <code>&gt;</code>就需要缩进:</p>\n<div><pre><code> <span>-</span> A list item with a blockquote:\n\n  > This is a blockquote\n  > inside a list item.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><p>当然，项目列表很可能会不小心产生，像是下面这样的写法:</p>\n<div><pre><code><span>1986.</span> What a great season.\n</code></pre>\n<div><span>1</span><br></div></div><p>换句话说，也就是在行首出现<em>数字-句点-空白</em>，要避免这样的状况，你可以在句点前面加上反斜线。</p>\n<div><pre><code>1986\\. What a great season.\n</code></pre>\n<div><span>1</span><br></div></div><h3 id=\"代码块\"> 代码块</h3>\n<p>和代码相关的写作或是标签语言原始码通常会有已经排版好的代码块，通常这些块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 <code>&lt;pre&gt;</code> 和 <code>&lt;code&gt;</code> 标签来把代码块包起来。</p>\n<p>要在 Markdown 中建立代码块很简单，只要简单地缩进 4 个空白或是 个 tab 就可以，例如，下面的输入:</p>\n<div><pre><code>This is a normal paragraph:\n\nThis is a code block.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>Markdown 会转换成:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>This is a normal paragraph:<span><span><span>&lt;/</span>p</span><span>></span></span>\n\n<span><span><span>&lt;</span>pre</span><span>></span></span>\n  <span><span><span>&lt;</span>code</span><span>></span></span>This is a code block.<span><span><span>&lt;/</span>code</span><span>></span></span>\n<span><span><span>&lt;/</span>pre</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>这里的缩进 (4 个空白或是 个 tab) ，都会被移除，例如:</p>\n<div><pre><code>Here is an example of AppleScript:\n\ntell application \"Foo\"\nbeep\nend tell\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>会被转换为:</p>\n<div><pre><code>&lt;p&gt;Here is an example of AppleScript:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;tell application &quot;Foo&quot;\n  beep\nend tell\n&lt;/code&gt;&lt;/pre&gt;\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>一个代码块会一直持续到没有缩进的那一行 (或是文件结尾) 。</p>\n<p>在代码块里面， <code>&amp;</code> 、 <code>&lt;</code> 和 <code>&gt;</code> 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制粘贴，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如:</p>\n<div><pre><code><span><span>```</span>\n<span>&lt;div>\n  &amp;copy; 2004 Foo Corporation\n&lt;/div></span>\n<span>```</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>会被转换为:</p>\n<div><pre><code><span><span><span>&lt;</span>pre</span><span>></span></span>\n  <span><span><span>&lt;</span>code</span><span>></span></span><span title=\"&lt;\">&amp;lt;</span>div<span title=\"&gt;\">&amp;gt;</span>\n  <span title=\"&amp;\">&amp;amp;</span>copy; 2004 Foo Corporation\n<span title=\"&lt;\">&amp;lt;</span>/div<span title=\"&gt;\">&amp;gt;</span><span><span><span>&lt;/</span>code</span><span>></span></span>\n<span><span><span>&lt;/</span>pre</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>代码块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。</p>\n<p>如果你想要在代码块里输入用 Markdown 表示的代码库，你可以进行嵌套。</p>\n<div><pre><code><span><span>```</span><span>`md</span>\n<span>```js\nconst a =;</span>\n<span>```</span></span>\n````\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><p>会渲染为</p>\n<div><pre><code><span><span>```</span><span>js</span>\n<span><span>const</span> a <span>=</span><span>;</span></span>\n<span>```</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><h3 id=\"分隔线\"> 分隔线</h3>\n<p>你可以在一行中用三个或以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号中间插入空白。</p>\n<p>下面每种写法都可以建立分隔线:</p>\n<div><pre><code>---(建议) * * * *** ***** - - - ---------------------------------------\n</code></pre>\n<div><span>1</span><br></div></div><h2 id=\"行内元素\"> 行内元素</h2>\n<h3 id=\"链接\"> 链接</h3>\n<p>Markdown 支持两种形式的链接语法: 行内和参考两种形式。 不管是哪一种，链接的文字都是用 <code>[方括号]</code> 来标记。 要建立一个行内形式的链接，只要在方块括号后面马上接著括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如:</p>\n<div><pre><code>This is [an example](http://example.com/ \"Title\") inline link. [This\nlink](http://example.net/) has no title attribute.\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>会产生:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>\n  This is <span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://example.com/<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>Title<span>\"</span></span><span>></span></span> an example<span><span><span>&lt;/</span>a</span><span>></span></span> inline\n  link.\n<span><span><span>&lt;/</span>p</span><span>></span></span>\n\n<span><span><span>&lt;</span>p</span><span>></span></span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://example.net/<span>\"</span></span><span>></span></span>This link<span><span><span>&lt;/</span>a</span><span>></span></span> has no title attribute.<span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>如果你是要链接到同样主机的资源，你可以使用相对路径:</p>\n<div><pre><code>See my <span>[<span>About</span>](<span>/about/</span>)</span> page for details.\n</code></pre>\n<div><span>1</span><br></div></div><p>参考形式的链接使用另外一个方括号接在链接文字的括号后面，而在第二个方括号里面要填入用以辨识链接的标签:</p>\n<div><pre><code>This is <span>[<span>an example</span>][<span>id</span>]</span> reference-style link.\n</code></pre>\n<div><span>1</span><br></div></div><p>接著，在文件的任意处，你可以把这个标签的链接内容定义出来:</p>\n<div><pre><code><span><span>[</span><span>id</span><span>]</span><span>:</span> http://example.com/ <span>\"Optional Title Here\"</span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>链接定义的形式为:</p>\n<ul>\n<li>\n<p>方括号，输入链接的标识 ID</p>\n</li>\n<li>\n<p>冒号</p>\n</li>\n<li>\n<p>一个以上的空白或 tab</p>\n</li>\n<li>\n<p>链接的网址 选择性地添加 title 内容，可以用单引号、双引号或是括号包括</p>\n</li>\n</ul>\n<p>下面这三种链接的定义相同:</p>\n<div><pre><code><span><span>[</span><span>foo</span><span>]</span><span>:</span> http://example.com/ <span>\"Optional Title Here\"</span></span>\n<span><span>[</span><span>foo</span><span>]</span><span>:</span> http://example.com/ <span>\"Optional Title Here\"</span></span>\n<span><span>[</span><span>foo</span><span>]</span><span>:</span> http://example.com/ <span>\"Optional Title Here\"</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p><strong>请注意</strong>: 有一个已知的问题是 Markdown.pl.0.1 会忽略单引号包起来的链接 title。</p>\n<p>链接网址也可以用方括号包起来:</p>\n<div><pre><code><span><span>[</span><span>id</span><span>]</span><span>:</span> http://example.com/ <span>\"Optional Title Here\"</span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>你也可以把 title 属性放到下一行，也可以加一些缩进，网址太长的话，这样会比较好看:</p>\n<div><pre><code><span><span>[</span><span>id</span><span>]</span><span>:</span> http://example.com/longish/path/to/resource/here <span>\"Optional Title Here\"</span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>网址定义只有在产生链接的时候用到，并不会直接出现在文件之中。</p>\n<p>链接辨识标签可以有字母、数字、空白和标点符号，但是并不区分大小写，因此下面两个链接是一样的:</p>\n<div><pre><code><span>[<span>link text</span>][<span>a</span>]</span>\n<span>[<span>link text</span>][<span>a</span>]</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p><em>预设的链接标签</em>功能让你可以省略指定链接标签，这种情形下，链接标签和链接文字会视为相同，要用预设链接标签只要在链接文字后面加上一个空的方括号，如果你要让 &quot;Google&quot; 链接到 google.com，你可以简化成:</p>\n<div><pre><code>[Google][]\n</code></pre>\n<div><span>1</span><br></div></div><p>然后定义链接内容:</p>\n<div><pre><code><span><span>[</span><span>google</span><span>]</span><span>:</span> http://google.com/</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>由于链接文字可能包含空白，所以这种简化的标签内也可以包含多个文字:</p>\n<div><pre><code>Visit [Daring Fireball][] for more information.\n</code></pre>\n<div><span>1</span><br></div></div><p>然后接著定义链接:</p>\n<div><pre><code><span><span>[</span><span>daring fireball</span><span>]</span><span>:</span> http://daringfireball.net/</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>链接的定义可以放在文件中的任何一个地方，我比较偏好直接放在链接出现段落的后面，你也可以把它放在文件最后面，就像是注解一样。</p>\n<p>下面是一个参考式链接的范例:</p>\n<div><pre><code>I get0 times more traffic from <span>[<span>Google</span>][<span>1</span>]</span> than from\n<span>[<span>Yahoo</span>][<span>2</span>]</span> or <span>[<span>MSN</span>][<span>3</span>]</span>.\n\n<span><span>[</span><span>1</span><span>]</span><span>:</span> http://google.com/ <span>\"Google\"</span></span>\n<span><span>[</span><span>2</span><span>]</span><span>:</span> http://search.yahoo.com/ <span>\"Yahoo Search\"</span></span>\n<span><span>[</span><span>3</span><span>]</span><span>:</span> http://search.msn.com/ <span>\"MSN Search\"</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>如果改成用链接名称的方式写:</p>\n<div><pre><code>I get0 times more traffic from [Google][] than from\n[Yahoo][] or [MSN][].\n\n<span><span>[</span><span>google</span><span>]</span><span>:</span> http://google.com/ <span>\"Google\"</span></span>\n<span><span>[</span><span>yahoo</span><span>]</span><span>:</span> http://search.yahoo.com/ <span>\"Yahoo Search\"</span></span>\n<span><span>[</span><span>msn</span><span>]</span><span>:</span> http://search.msn.com/ <span>\"MSN Search\"</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>上面两种写法都会产生下面的 HTML。</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>\n  I get0 times more traffic from\n  <span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://google.com/<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>Google<span>\"</span></span><span>></span></span>Google<span><span><span>&lt;/</span>a</span><span>></span></span> than from\n  <span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://search.yahoo.com/<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>Yahoo Search<span>\"</span></span><span>></span></span>Yahoo<span><span><span>&lt;/</span>a</span><span>></span></span>\n  or <span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://search.msn.com/<span>\"</span></span> <span>title</span><span><span>=</span><span>\"</span>MSN Search<span>\"</span></span><span>></span></span>MSN<span><span><span>&lt;/</span>a</span><span>></span></span>.\n<span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></div></div><p>下面是用行内形式写的同样一段内容的 Markdown 文件，提供作为比较之用:</p>\n<div><pre><code>I get0 times more traffic from <span>[<span>Google</span>](<span>http://google.com/</span> <span>\"Google\"</span>)</span>\nthan from <span>[<span>Yahoo</span>](<span>http://search.yahoo.com/</span> <span>\"Yahoo Search\"</span>)</span> or\n<span>[<span>MSN</span>](<span>http://search.msn.com/</span> <span>\"MSN Search\"</span>)</span>.\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>参考式的链接其实重点不在于它比较好写，而是它比较好读，比较一下上面的范例，使用参考式的文章本身只有 81 个字元，但是用行内形式的链接却会增加到76 个字元，如果是用纯 HTML 格式来写，会有 234 个字元，在 HTML 格式中，标签比文字还要多。</p>\n<p>使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的资讯移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断。</p>\n<h3 id=\"强调\"> 强调</h3>\n<p>Markdown 使用星号 (<code>*</code>) 和底线 (<code>_</code>) 作为标记强调字词的符号，被 <code>*</code> 或 <code>_</code> 包围的字词会被转成用 <code>&lt;em&gt;</code> 标签包围，用两个 <code>*</code> 或 <code>_</code> 包起来的话，则会被转成 <code>&lt;strong&gt;</code>，例如:</p>\n<div><pre><code><span><span>**</span><span>double asterisks</span><span>**</span></span> (建议)\n\n<span><span>**</span><span>double underscores</span><span>**</span></span> (建议)\n\n<span><span>_</span><span>single asterisks</span><span>_</span></span>\n\n<span><span>_</span><span>single underscores</span><span>_</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><p>会转成:</p>\n<div><pre><code><span><span><span>&lt;</span>em</span><span>></span></span>single asterisks<span><span><span>&lt;/</span>em</span><span>></span></span>\n\n<span><span><span>&lt;</span>em</span><span>></span></span>single underscores<span><span><span>&lt;/</span>em</span><span>></span></span>\n\n<span><span><span>&lt;</span>strong</span><span>></span></span>double asterisks<span><span><span>&lt;/</span>strong</span><span>></span></span>\n\n<span><span><span>&lt;</span>strong</span><span>></span></span>double underscores<span><span><span>&lt;/</span>strong</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div><p>你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。</p>\n<p>强调也可以直接插在文字中间:</p>\n<div><pre><code>un<span><span>*</span><span>frigging</span><span>*</span></span>believable\n</code></pre>\n<div><span>1</span><br></div></div><p>但是如果你的 <code>*</code> 和 <code>_</code> 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线:</p>\n<div><pre><code>\\*this text is surrounded by literal asterisks\\*\n</code></pre>\n<div><span>1</span><br></div></div><h3 id=\"代码\"> 代码</h3>\n<p>如果要标记一小段行内代码，你可以用反引号把它包起来 (<code>`</code>) ，例如:</p>\n<div><pre><code>Use the <span>`printf()`</span> function.\n</code></pre>\n<div><span>1</span><br></div></div><p>会产生:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>Use the <span><span><span>&lt;</span>code</span><span>></span></span>printf()<span><span><span>&lt;/</span>code</span><span>></span></span> function.<span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>如果要在代码内插入反引号，你可以用多个反引号来开启和结束行内代码:</p>\n<div><pre><code><span>`` There is a literal backtick (`) here. ``</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>这段语法会产生:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span><span><span><span>&lt;</span>code</span><span>></span></span>There is a literal backtick (`) here.<span><span><span>&lt;/</span>code</span><span>></span></span><span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>代码码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号:</p>\n<div><pre><code>A single backtick in a code span: <span>`` ` ``</span>\n\nA backtick-delimited string in a code span: <span>`` `foo` ``</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>会产生:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>A single backtick in a code span: <span><span><span>&lt;</span>code</span><span>></span></span>`<span><span><span>&lt;/</span>code</span><span>></span></span><span><span><span>&lt;/</span>p</span><span>></span></span>\n\n<span><span><span>&lt;</span>p</span><span>></span></span>A backtick-delimited string in a code span: <span><span><span>&lt;</span>code</span><span>></span></span>`foo`<span><span><span>&lt;/</span>code</span><span>></span></span><span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>在代码码区段内，<code>&amp;</code> 和方括号都会被转成 HTML 实体，这样会比较容易插入 HTML 原始码，Markdown 会把下面这段:</p>\n<div><pre><code>Please don’t use any <span>`&lt;blink>`</span> tags.\n</code></pre>\n<div><span>1</span><br></div></div><p>转为:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>Please don’t use any <span><span><span>&lt;</span>code</span><span>></span></span><span title=\"&lt;\">&amp;lt;</span>blink<span title=\"&gt;\">&amp;gt;</span><span><span><span>&lt;/</span>code</span><span>></span></span> tags.<span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>你也可以这样写:</p>\n<div><pre><code><span>`&amp;#8212;`</span> is the decimal-encoded equivalent of <span>`&amp;mdash;`</span>.\n</code></pre>\n<div><span>1</span><br></div></div><p>以产生:</p>\n<div><pre><code><span><span><span>&lt;</span>p</span><span>></span></span>\n  <span><span><span>&lt;</span>code</span><span>></span></span><span title=\"&amp;\">&amp;amp;</span>#8212;<span><span><span>&lt;/</span>code</span><span>></span></span> is the decimal-encoded equivalent of\n  <span><span><span>&lt;</span>code</span><span>></span></span><span title=\"&amp;\">&amp;amp;</span>mdash;<span><span><span>&lt;/</span>code</span><span>></span></span>.\n<span><span><span>&lt;/</span>p</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div><h3 id=\"图片\"> 图片</h3>\n<p>很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。</p>\n<p>Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式: <em>行内和参考</em>。 行内图片的语法看起来像是:</p>\n<div><pre><code><span><span>!</span>[<span>Alt text</span>](<span>/path/to/img.jpg</span>)</span>\n\n<span><span>!</span>[<span>Alt text</span>](<span>/path/to/img.jpg</span> <span>\"Optional title\"</span>)</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><p>详细叙述如下:</p>\n<ul>\n<li>一个惊叹号 !</li>\n<li>一个方括号，里面放上图片的替代文字</li>\n<li>一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 title 文字。</li>\n</ul>\n<p>参考式的图片语法则长得像这样:</p>\n<div><pre><code><span><span>!</span>[<span>Alt text</span>][<span>id</span>]</span>\n</code></pre>\n<div><span>1</span><br></div></div><p>「id」是图片参考的名称，图片参考的定义方式则和链接参考一样: <code>[id]</code>:</p>\n<div><pre><code>url/to/image \"Optional title attribute\"\n</code></pre>\n<div><span>1</span><br></div></div><p>到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 <code>&lt;img&gt;</code> 标签。</p>\n<h3 id=\"其他文本样式\"> 其他文本样式</h3>\n<ul>\n<li>删除:<s>delete</s></li>\n<li>段落: 段落之间空一行</li>\n<li>换行符: 一行结束时输入两个空格</li>\n</ul>\n<h2 id=\"其它\"> 其它</h2>\n<h3 id=\"自动链接\"> 自动链接</h3>\n<p>Markdown 支持比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用方括号包起来,Markdown 就会自动把它转成链接，链接的文字就和链接位置一样，例如:</p>\n<div><pre><code>&lt;http://example.com/>\n</code></pre>\n<div><span>1</span><br></div></div><p>Markdown 会转为:</p>\n<div><pre><code><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span>http://example.com/<span>\"</span></span><span>></span></span>http://example.com/<span><span><span>&lt;/</span>a</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>自动的邮件链接也很类似，只是 Markdown 会先做一个编码转换的过程，把文字字元转成6 进位码的 HTML 实体，这样的格式可以混淆一些不好的信箱地址收集机器人，例如:</p>\n<div><pre><code><span><span><span>&lt;</span>address@example.com</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br></div></div><p>Markdown 会转成:</p>\n<div><pre><code><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>\"</span><span title=\"&#x6D;\">&amp;#x6D;</span><span title=\"&#x61;\">&amp;#x61;</span>i<span title=\"&#x6C;\">&amp;#x6C;</span><span title=\"&#x74;\">&amp;#x74;</span><span title=\"&#x6F;\">&amp;#x6F;</span>:<span title=\"&#x61;\">&amp;#x61;</span><span title=\"&#x64;\">&amp;#x64;</span><span title=\"&#x64;\">&amp;#x64;</span><span title=\"&#x72;\">&amp;#x72;</span><span title=\"&#x65;\">&amp;#x65;</span><span title=\"&#115;\">&amp;#115;</span><span title=\"&#115;\">&amp;#115;</span><span title=\"&#64;\">&amp;#64;</span><span title=\"&#101;\">&amp;#101;</span><span title=\"&#120;\">&amp;#120;</span><span title=\"&#x61;\">&amp;#x61;</span><span title=\"&#109;\">&amp;#109;</span><span title=\"&#x70;\">&amp;#x70;</span><span title=\"&#x6C;\">&amp;#x6C;</span>e<span title=\"&#x2E;\">&amp;#x2E;</span><span title=\"&#99;\">&amp;#99;</span><span title=\"&#111;\">&amp;#111;</span><span title=\"&#109;\">&amp;#109;</span><span>\"</span></span><span>></span></span><span title=\"&#x61;\">&amp;#x61;</span><span title=\"&#x64;\">&amp;#x64;</span><span title=\"&#x64;\">&amp;#x64;</span><span title=\"&#x72;\">&amp;#x72;</span><span title=\"&#x65;\">&amp;#x65;</span><span title=\"&#115;\">&amp;#115;</span><span title=\"&#115;\">&amp;#115;</span><span title=\"&#64;\">&amp;#64;</span><span title=\"&#101;\">&amp;#101;</span><span title=\"&#120;\">&amp;#120;</span><span title=\"&#x61;\">&amp;#x61;</span><span title=\"&#109;\">&amp;#109;</span><span title=\"&#x70;\">&amp;#x70;</span><span title=\"&#x6C;\">&amp;#x6C;</span>e<span title=\"&#x2E;\">&amp;#x2E;</span><span title=\"&#99;\">&amp;#99;</span><span title=\"&#111;\">&amp;#111;</span><span title=\"&#109;\">&amp;#109;</span>\n<span><span><span>&lt;/</span>a</span><span>></span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><p>在浏览器里面，这段字串会变成一个可以点击的「address@example.com」链接。</p>\n<p>(这种作法虽然可以混淆不少的机器人，但并无法全部挡下来，不过这样也比什么都不做好些。无论如何，公开你的信箱终究会引来广告信件的。)</p>\n<h3 id=\"转义字符\"> 转义字符</h3>\n<p>Markdown 可以利用反斜线来插入一些在语法中有其它意义的符号，例如: 如果你想要用星号加在文字旁边的方式来做出强调效果 (但不用 <code>&lt;em&gt;</code> 标签) ，你可以在星号的前面加上反斜线:</p>\n<div><pre><code>\\*literal asterisks\\*\n</code></pre>\n<div><span>1</span><br></div></div><p>Markdown 支持在下面这些符号前面加上反斜线来帮助插入普通的符号:</p>\n<ul>\n<li><code>\\</code> 反斜线</li>\n<li><code>`</code> 反引号</li>\n<li><code>*</code> 星号</li>\n<li><code>_</code> 底线</li>\n<li><code>{}</code> 大括号</li>\n<li><code>[]</code> 方括号</li>\n<li><code>()</code> 括号</li>\n<li><code>#</code> 井字号</li>\n<li><code>+</code>加号</li>\n<li><code>-</code> 减号</li>\n<li><code>.</code> 英文句点</li>\n<li><code>!</code> 惊叹号</li>\n</ul>\n<h3 id=\"快捷键\"> 快捷键</h3>\n<table>\n<thead>\n<tr>\n<th>输出后的效果</th>\n<th>Markdown</th>\n<th>快捷键</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Bold</td>\n<td><code>**text**</code></td>\n<td>Ctrl/⌘ + B</td>\n</tr>\n<tr>\n<td>Emphasize</td>\n<td><code>*text*</code></td>\n<td>Ctrl/⌘ + I</td>\n</tr>\n<tr>\n<td><code>Inline Code</code></td>\n<td>`code`</td>\n<td>选中后 <code>`</code></td>\n</tr>\n</tbody>\n</table>\n<div><pre><code><span><span><span>|</span><span> 输出后的效果 </span><span>|</span><span> Markdown </span><span>|</span><span> 快捷键  </span><span>|</span><span> </span>\n</span><span><span>|</span> <span>----</span> <span>|</span> <span>----</span> <span>|</span> <span>----</span> <span>|</span>\n</span><span><span>|</span><span> Bold  </span><span>|</span><span> <span>`**text**`</span>  </span><span>|</span><span> Ctrl/⌘ + B </span><span>|</span>\n<span>|</span><span> Emphasize  </span><span>|</span><span> <span>`*text*`</span>  </span><span>|</span><span> Ctrl/⌘ + I </span><span>|</span>\n<span>|</span><span> <span>`Inline Code`</span>  </span><span>|</span><span> \\`code\\`  </span><span>|</span><span> 选中后 <span>`` ` ``</span></span><span>|</span>\n</span></span></code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><h3 id=\"表格\"> 表格</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">居中</th>\n<th style=\"text-align:right\">右对齐</th>\n<th style=\"text-align:left\">左对齐</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">居中使用<code>:-:</code></td>\n<td style=\"text-align:right\">右对齐使用<code>-:</code></td>\n<td style=\"text-align:left\">左对齐使用<code>:-</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">b</td>\n<td style=\"text-align:right\">aaaaaaaaa</td>\n<td style=\"text-align:left\">aaaa</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">c</td>\n<td style=\"text-align:right\">aaaa</td>\n<td style=\"text-align:left\">a</td>\n</tr>\n</tbody>\n</table>\n<div><pre><code><span><span><span>|</span><span> 居中  </span><span>|</span><span> 右对齐  </span><span>|</span><span> 左对齐 </span><span>|</span>\n</span><span><span>|</span> <span>:-----:</span> <span>|</span> <span>-----:</span> <span>|</span> <span>:-----</span> <span>|</span>\n</span><span><span>|</span><span> 居中使用<span>`:-:`</span> </span><span>|</span><span> 右对齐使用<span>`-:`</span> </span><span>|</span><span> 左对齐使用<span>`:-`</span> </span><span>|</span>\n<span>|</span><span> b  </span><span>|</span><span> aaaaaaaaa  </span><span>|</span><span> aaaa </span><span>|</span>\n<span>|</span><span> c  </span><span>|</span><span> aaaa  </span><span>|</span><span> a </span><span>|</span>\n</span></span></code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br></div></div><h3 id=\"emoji\"> Emoji</h3>\n<p><code>:emoji名称:</code>\nExample: <code>:smile:</code> 😄\n你可以在 <a href=\"https://vuepress-theme-hope.github.io/zh/basic/markdown/emoji/\" target=\"_blank\" rel=\"noopener noreferrer\">Emoji</a> 列表 找到所有可用的 Emoji。</p>\n<h2 id=\"markdown增强\"> Markdown增强</h2>\n<p>关于<strong>MarkDown</strong>还有一些高级技巧，快来看呀 😄 <a href=\"./markdown-enhance.html\">点这里</a></p>\n",
      "image": "https://hsaio.codenoob.top/path/to/img.jpg",
      "date_published": "2020-06-26T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "基础认知",
      "url": "https://hsaio.codenoob.top/guide/",
      "id": "/guide/",
      "content_html": "<br>\n<h2 id=\"主要如下\"> 主要如下</h2>\n<ul>\n<li>\n<p><a href=\"./tutorial.html\">基础认知</a></p>\n</li>\n<li>\n<p><a href=\"./vuepress.html\">VuePress</a></p>\n</li>\n<li>\n<p><a href=\"./markdown.html\">Markdown</a></p>\n</li>\n<li>\n<p><a href=\"./markdown-enhance.html\">Markdown增强</a></p>\n</li>\n<li>\n<p><a href=\"./themeself-markdown-enhance.html\">本主题Markdown增强</a></p>\n</li>\n</ul>\n",
      "date_published": "2020-06-20T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "本主题Markdown增强",
      "url": "https://hsaio.codenoob.top/guide/themeself-markdown-enhance.html",
      "id": "/guide/themeself-markdown-enhance.html",
      "summary": "本主题Markdown增强",
      "content_html": "<p><code>vuepress-theme-hope</code> 通过内置 <a href=\"https://vuepress-theme-hope.github.io/md-enhance\" target=\"_blank\" rel=\"noopener noreferrer\">md-enhance</a>，在 Markdown 中新增了更多的语法与新功能。</p>\n\n<h2 id=\"上下角标\"> 上下角标</h2>\n<p>19<sup>th</sup>   H<sub>2</sub>O</p>\n<details><summary>代码</summary>\n<div><pre><code>19^th^ H<span><span>~</span><span>2</span><span>~</span></span>O\n</code></pre>\n<div><span>1</span><br></div></div></details>\n<h2 id=\"自定义对齐\"> 自定义对齐</h2>\n<div>\n<p>我是居中的</p>\n</div>\n<div>\n<p>我在右对齐</p>\n</div>\n<details><summary>代码</summary>\n<div><pre><code>::: center\n\n我是居中的\n\n:::\n\n::: right\n\n我在右对齐\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></div></div></details>\n<h2 id=\"脚注\"> 脚注</h2>\n<p>此文字有脚注<sup></sup>.</p>\n<details><summary>代码</summary>\n<div><pre><code>此文字有脚注[^first].\n\n<span><span>[</span><span>^first</span><span>]</span><span>:</span> 这是脚注内容</span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div></details>\n<h2 id=\"标记\"> 标记</h2>\n<p>你可以标记 <mark>重要的内容</mark> 。</p>\n<details><summary>代码</summary>\n<div><pre><code>你可以标记 ==重要的内容== 。\n</code></pre>\n<div><span>1</span><br></div></div></details>\n<h2 id=\"任务列表\"> 任务列表</h2>\n<ul>\n<li><input type=\"checkbox\" checked=\"checked\" disabled=\"disabled\" id=\"task-item-0\"><label for=\"task-item-0\"> 计划 1</label></li>\n<li><input type=\"checkbox\"  disabled=\"disabled\" id=\"task-item-1\"><label for=\"task-item-1\"> 计划 2</label></li>\n</ul>\n<details><summary>Code</summary>\n<div><pre><code><span>-</span> [x] 计划 1\n<span>-</span> [ ] 计划 2\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div></details>\n<h2 id=\"流程图\"> 流程图</h2>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-16-34.png\" alt=\"流程图\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code><span><span>```</span><span>flow</span>\n<span>cond=>condition: Process?\nprocess=>operation: Process\ne=>end: End\n\ncond(yes)->process->e\ncond(no)->e</span>\n<span>```</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></div></div></details>\n<ul>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/guide/markdown/flowchart/\" target=\"_blank\" rel=\"noopener noreferrer\">点击查看</a></li>\n</ul>\n<h2 id=\"mermaid\"> Mermaid</h2>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-16-44.png\" alt=\"Mermaid\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code><span><span>```</span><span>mermaid</span>\n<span>graph TD;\n    A-->B;\n    A-->C;\n    B-->D;\n    C-->D;</span>\n<span>```</span></span>\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></div></div></details>\n<ul>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/guide/markdown/mermaid/\" target=\"_blank\" rel=\"noopener noreferrer\">点击查看</a></li>\n</ul>\n<h2 id=\"tex-语法\"> Tex 语法</h2>\n<p class='katex-block'><span><span><span><i>Not supported content</i></span><span aria-hidden=\"true\"><span><span style=\"height:2.4em;vertical-align:-0.95em;\"></span><span><span></span><span><span><span><span style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span style=\"height:3em;\"></span><span><span style=\"margin-right:0.05556em;\">∂</span><span><span style=\"margin-right:0.03588em;\">ω</span><span><span><span><span style=\"height:0.5904em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span style=\"margin-right:0.02778em;\">r</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span style=\"height:3em;\"></span><span style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span style=\"height:3em;\"></span><span><span><span style=\"margin-right:0.05556em;\">∂</span><span><span><span><span style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span style=\"margin-right:0.02778em;\">r</span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span style=\"height:0.686em;\"><span></span></span></span></span></span><span></span></span><span style=\"margin-right:0.1667em;\"></span><span><span style=\"top:0em;\"><span>(</span></span><span><span></span><span><span><span><span style=\"height:1.3414em;\"><span style=\"top:-2.314em;\"><span style=\"height:3em;\"></span><span><span style=\"margin-right:0.03588em;\">ω</span></span></span><span style=\"top:-3.23em;\"><span style=\"height:3em;\"></span><span style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span style=\"height:3em;\"></span><span><span><span style=\"margin-right:0.03588em;\">y</span><span><span><span><span style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span><span style=\"margin-right:0.03588em;\">ω</span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span style=\"height:0.686em;\"><span></span></span></span></span></span><span></span></span><span style=\"top:0em;\"><span>)</span></span></span><span style=\"margin-right:0.2778em;\"></span><span>=</span><span style=\"margin-right:0.2778em;\"></span></span><span><span style=\"height:3.0277em;vertical-align:-1.2777em;\"></span><span><span style=\"top:0em;\"><span>(</span></span><span><span></span><span><span><span><span style=\"height:1.3414em;\"><span style=\"top:-2.314em;\"><span style=\"height:3em;\"></span><span><span style=\"margin-right:0.03588em;\">ω</span></span></span><span style=\"top:-3.23em;\"><span style=\"height:3em;\"></span><span style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span style=\"height:3em;\"></span><span><span><span style=\"margin-right:0.03588em;\">y</span><span><span><span><span style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span><span style=\"margin-right:0.03588em;\">ω</span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span style=\"height:0.686em;\"><span></span></span></span></span></span><span></span></span><span style=\"top:0em;\"><span>)</span></span></span><span style=\"margin-right:0.1667em;\"></span><span><span style=\"top:0em;\"><span>{</span></span><span>(</span><span>lo<span style=\"margin-right:0.01389em;\">g</span></span><span style=\"margin-right:0.1667em;\"></span><span style=\"margin-right:0.03588em;\">y</span><span><span>)</span><span><span><span><span style=\"height:0.7144em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span style=\"margin-right:0.02778em;\">r</span></span></span></span></span></span></span></span><span style=\"margin-right:0.2222em;\"></span><span>+</span><span style=\"margin-right:0.2222em;\"></span><span><span><span><span style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span style=\"height:3.05em;\"></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span style=\"top:-3.05em;\"><span style=\"height:3.05em;\"></span><span><span>∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span style=\"height:3.05em;\"></span><span><span style=\"margin-right:0.02778em;\">r</span></span></span></span><span>​</span></span><span><span style=\"height:1.2777em;\"><span></span></span></span></span></span><span style=\"margin-right:0.1667em;\"></span><span><span></span><span><span><span><span style=\"height:1.5017em;\"><span style=\"top:-2.314em;\"><span style=\"height:3em;\"></span><span><span><span style=\"margin-right:0.03588em;\">ω</span><span><span><span><span style=\"height:0.7507em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span>i</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span style=\"height:3em;\"></span><span style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span style=\"height:3em;\"></span><span><span>(</span><span>−</span><span>1</span><span><span>)</span><span><span><span><span style=\"height:0.8247em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span>i</span></span></span></span></span></span></span></span><span style=\"margin-right:0.02778em;\">r</span><span style=\"margin-right:0.1667em;\"></span><span>⋯</span><span style=\"margin-right:0.1667em;\"></span><span>(</span><span style=\"margin-right:0.02778em;\">r</span><span style=\"margin-right:0.2222em;\"></span><span>−</span><span style=\"margin-right:0.2222em;\"></span><span>i</span><span style=\"margin-right:0.2222em;\"></span><span>+</span><span style=\"margin-right:0.2222em;\"></span><span>1</span><span>)</span><span>(</span><span>lo<span style=\"margin-right:0.01389em;\">g</span></span><span style=\"margin-right:0.1667em;\"></span><span style=\"margin-right:0.03588em;\">y</span><span><span>)</span><span><span><span><span style=\"height:0.8247em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span style=\"height:2.7em;\"></span><span><span><span style=\"margin-right:0.02778em;\">r</span><span>−</span><span>i</span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span style=\"height:0.686em;\"><span></span></span></span></span></span><span></span></span><span style=\"top:0em;\"><span>}</span></span></span></span></span></span></span></p>\n<details><summary>代码</summary>\n<div><pre><code>$$\n\\frac {\\partial^r} {\\partial \\omega^r} \\left(\\frac {y^{\\omega}} {\\omega}\\right)\n= \\left(\\frac {y^{\\omega}} {\\omega}\\right) \\left\\{(\\log y)^r + \\sum_{i=1}^r \\frac {(-1)^i r \\cdots (r-i+1) (\\log y)^{r-i}} {\\omega^i} \\right\\}\n$$\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></div></div></details>\n<h2 id=\"代码案例\"> 代码案例</h2>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-18-02.png\" alt=\"一个普通 Demo\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code>::: demo 一个普通 Demo\n\n<span><span>```</span><span>html</span>\n<span><span><span><span>&lt;</span>h1</span><span>></span></span>ChouCong<span><span><span>&lt;/</span>h1</span><span>></span></span>\n<span><span><span>&lt;</span>p</span><span>></span></span><span><span><span>&lt;</span>span</span> <span>id</span><span><span>=</span><span>\"</span>very<span>\"</span></span><span>></span></span>十分<span><span><span>&lt;/</span>span</span><span>></span></span> 帅<span><span><span>&lt;/</span>p</span><span>></span></span></span>\n<span>```</span></span>\n\n<span><span>```</span><span>js</span>\n<span>document<span>.</span><span>querySelector</span><span>(</span><span>\"#very\"</span><span>)</span><span>.</span><span>addEventListener</span><span>(</span><span>\"click\"</span><span>,</span> <span>(</span><span>)</span> <span>=></span> <span>{</span>\n  <span>alert</span><span>(</span><span>\"十分帅\"</span><span>)</span><span>;</span>\n<span>}</span><span>)</span><span>;</span></span>\n<span>```</span></span>\n\n<span><span>```</span><span>css</span>\n<span><span>span</span> <span>{</span>\n  <span>color</span><span>:</span> red<span>;</span>\n<span>}</span></span>\n<span>```</span></span>\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div></details>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-18-14.png\" alt=\"一个 React Demo\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code>::: demo [react] 一个 React Demo\n\n<span><span>```</span><span>js</span>\n<span><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>\n  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>\n    <span>super</span><span>(</span>props<span>)</span><span>;</span>\n    <span>this</span><span>.</span>state <span>=</span> <span>{</span> <span>message</span><span>:</span> <span>\"十分帅\"</span> <span>}</span><span>;</span>\n  <span>}</span>\n  <span>render</span><span>(</span><span>)</span> <span>{</span>\n    <span>return</span> <span>(</span>\n      <span>&lt;</span>div className<span>=</span><span>\"box-react\"</span><span>></span>\n        ChouCong <span>&lt;</span>span<span>></span><span>{</span><span>this</span><span>.</span>state<span>.</span>message<span>}</span><span>&lt;</span><span>/</span>span<span>></span>\n      <span>&lt;</span><span>/</span>div<span>></span>\n    <span>)</span><span>;</span>\n  <span>}</span>\n<span>}</span></span>\n<span>```</span></span>\n\n<span><span>```</span><span>css</span>\n<span><span>.box-react span</span> <span>{</span>\n  <span>color</span><span>:</span> red<span>;</span>\n<span>}</span></span>\n<span>```</span></span>\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br></div></div></details>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-18-34.png\" alt=\"一个 Vue Demo\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code>::: demo [vue] 一个 Vue Demo\n\n<span><span>```</span><span>vue</span>\n<span>&lt;template>\n  &lt;div>\n    ChouCong &lt;span>{{ message }}&lt;/span>\n  &lt;/div>\n&lt;/template>\n&lt;script>\nexport default {\n  data: () => ({ message: \"十分帅\" }),\n};\n&lt;/script>\n&lt;style>\n.box span {\n  color: red;\n}\n&lt;/style></span>\n<span>```</span></span>\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></div></div></details>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-26-47.png\" alt=\"一个使用浏览器不支持解析语言 Demo\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code>::: demo 一个使用浏览器不支持解析语言 Demo\n\n<span><span>```</span><span>md</span>\n<span><span><span>#</span> 标题</span>\n\n十分帅</span>\n<span>```</span></span>\n\n<span><span>```</span><span>ts</span>\n<span>const message: string = \"ChouCong\";\n\ndocument.querySelector(\"h1\").innerHTML = message;</span>\n<span>```</span></span>\n\n<span><span>```</span><span>scss</span>\n<span>h1 {\n  font-style: italic;\n\n  + p {\n    color: red;\n  }\n}</span>\n<span>```</span></span>\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br></div></div></details>\n<ul>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/guide/markdown/demo/\" target=\"_blank\" rel=\"noopener noreferrer\">点击查看</a></li>\n</ul>\n<h2 id=\"幻灯片\"> 幻灯片</h2>\n<p><img src=\"https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-26-30.png\" alt=\"幻灯片\" loading=\"lazy\"></p>\n<details><summary>代码</summary>\n<div><pre><code>@slidestart\n\n<span><span>##</span> 幻灯片 1</span>\n\n一个有文字和 <span>[<span>链接</span>](<span>https://codenoob.top</span>)</span> 的段落\n\n<span>---</span>\n\n<span><span>##</span> 幻灯片 2</span>\n\n<span>-</span> 列表 1\n<span>-</span> 列表 2\n\n<span>---</span>\n\n<span><span>##</span> 幻灯片 3.1</span>\n\n<span><span>```</span><span>js</span>\n<span><span>const</span> a <span>=</span> <span>1</span><span>;</span></span>\n<span>```</span></span>\n\n--\n\n<span><span>##</span> 幻灯片 3.2</span>\n\n$$\nJ(\\theta_0,\\theta_1) = \\sum_{i=0}\n$$\n\n@slideend\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br></div></div></details>\n<ul>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/guide/markdown/presentation/\" target=\"_blank\" rel=\"noopener noreferrer\">点击查看</a></li>\n</ul>\n<h2 id=\"其他语法\"> 其他语法</h2>\n<div><p>自定义标题</p>\n<p>信息容器</p>\n</div>\n<div><p>自定义标题</p>\n<p>提示容器</p>\n</div>\n<div><p>自定义标题</p>\n<p>警告容器</p>\n</div>\n<div><p>自定义标题</p>\n<p>危险容器</p>\n</div>\n<details><summary>自定义标题</summary>\n<p>详情容器</p>\n</details>\n<details><summary>代码</summary>\n<div><pre><code>::: info 自定义标题\n\n信息容器\n\n:::\n\n::: tip 自定义标题\n\n提示容器\n\n:::\n\n::: warning 自定义标题\n\n警告容器\n\n:::\n\n::: danger 自定义标题\n\n危险容器\n\n:::\n\n::: details 自定义标题\n\n详情容器\n\n:::\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br></div></div></details>\n<hr>\n<section>\n<ol>\n<li id=\"footnote1\"><p>这是脚注内容 </p>\n</li>\n</ol>\n</section>\n",
      "image": "https://cdn.jsdelivr.net/gh/Smart-Chou/webphoto@latest/note/Snipaste_2021-12-04_21-16-34.png",
      "date_published": "2020-05-20T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "初接触指南",
      "url": "https://hsaio.codenoob.top/guide/tutorial.html",
      "id": "/guide/tutorial.html",
      "summary": "初接触指南",
      "content_html": "<div><p>提示</p>\n<p>本教程是一个针对初接触者手把手教程。</p>\n</div>\n<h2 id=\"环境安装\"> 环境安装</h2>\n<p>你需要安装最新的 Node.js 长期支持版 和 Yarn。</p>\n<p>下载地址:</p>\n<ul>\n<li>Node.js 长期支持版: <a href=\"https://nodejs.org/zh-cn/\" target=\"_blank\" rel=\"noopener noreferrer\">下载地址</a></li>\n</ul>\n<blockquote>\n<p>请点击左侧的绿色按钮。</p>\n</blockquote>\n<p>在安装过程中，保持所有的默认设置，一路下一步即可。</p>\n<div><p>注意</p>\n<p>如果你真的是个初接触者，请不要改默认安装目录，以免你在出现问题时找不到对应的文件夹。</p>\n<p>Node.js 本身只会占据几十 M 的空间!</p>\n</div>\n<ul>\n<li>Yarn: 在安装 Node.js 后，打开终端，执行:</li>\n</ul>\n<div><pre><code>npm i -g yarn\n\nyarn config set registry https://registry.npm.taobao.org\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br></div></div><h2 id=\"创建模板\"> 创建模板</h2>\n<p>在一个合适的位置创建一个文件夹，并在该文件夹下打开终端。</p>\n<blockquote>\n<p>对于 Windows 请使用文件管理器打开对应文件夹，之后在上方的地址栏中输入 <code>cmd</code> 之后按下回车。</p>\n</blockquote>\n<p>在终端中执行:</p>\n<div><pre><code>yarn create vuepress-theme-hope docs\n</code></pre>\n<div><span>1</span><br></div></div><p>稍等片刻，你就可以在浏览器地址栏输入 <code>localhost:8080/zh/</code> 访问开发服务器了。</p>\n<div><p>提示</p>\n<p>启动开发服务器，请在终端输入 <code>yarn run docs:dev</code> 并回车。 如果你需要终止开发服务器，请点击终端，并连续两次按下 <code>Ctrl + C</code>。</p>\n</div>\n<h2 id=\"添加或修改页面\"> 添加或修改页面</h2>\n<p><code>docs</code>文件夹下除 <code>.vuepress</code> 文件夹之外的文件都会渲染为网页，渲染后的链接与文件夹结构和文件名称一一对应。只有 <code>readme.md</code> 是特例，它会显示为文件夹下的默认网页 (默认主页)。这应该很好理解。</p>\n<p>比如你想要创建一个 <code>/a/b/</code>，你就可以创建 <code>docs/a/b.md</code> 或 <code>docs/a/b/readme.md</code>，但切记不要同时创建它们两个！</p>\n<p>Markdown 的内容会渲染为网页的内容。关于 Markdown 教程，请见 <a href=\"https://vuepress-theme-hope.github.io/zh/basic/markdown/\" target=\"_blank\" rel=\"noopener noreferrer\">Markdown教程</a> 。大概十五分钟，你就可以学会 Markdown 的内容，看完之后记得回来！</p>\n<p>学会 Markdown 之后你就可以尝试自己编辑 Markdown 文件来修改模板的内容。</p>\n<h2 id=\"配置-vuepress\"> 配置 VuePress</h2>\n<p>学会 Markdown 之后，如果你没有学过 JavaScript 的话，学习它可能有些困难。所以请将配置文件切换为 YAML。 请删除 <code>.vuepress/config.js</code> 并创建 <code>.vuepress/config.yml</code>，复制以下内容并粘贴至该文件中。</p>\n<div><pre><code><span># 站点名称</span>\n<span>title</span><span>:</span> 主题演示\n<span># 站点描述</span>\n<span>description</span><span>:</span> vuepress<span>-</span>theme<span>-</span>hope 的演示\n<span># 输出目录</span>\n<span>dest</span><span>:</span> ./dist\n<span># 设置根目录语言</span>\n<span>locales</span><span>:</span>\n  <span>/</span><span>:</span>\n    <span>lang</span><span>:</span> zh<span>-</span>CN\n<span># 使用本主题</span>\n<span>theme</span><span>:</span> hope\n<span># 主题配置</span>\n<span>themeConfig</span><span>:</span>\n  <span># 导航栏图标</span>\n  <span>logo</span><span>:</span> /logo.svg\n  <span># 请设置为你的部署站点</span>\n  <span>hostname</span><span>:</span> https<span>:</span>//mister<span>-</span>hope.github.io\n  <span># 请改成你的名字</span>\n  <span>author</span><span>:</span> XXX\n</code></pre>\n<div><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br></div></div><p>你应该学习一些 YAML 的小知识，我们推荐你查看 <a href=\"https://mrhope.site/code/language/yaml/\" target=\"_blank\" rel=\"noopener noreferrer\">YAML教程</a></p>\n<div><p>YAML局限性</p>\n<p>使用 YAML 作为配置文件有一定的局限性，比如无法使用加密功能。</p>\n<p>如果你希望体验全部的功能，请不要执行以上替换操作，并阅读 <a href=\"https://mrhope.site/code/language/js/guide/\" target=\"_blank\" rel=\"noopener noreferrer\">JS快速上手教程</a>。</p>\n</div>\n<p>接下来你就可以阅读本文档 VuePress 基础，大致了解 VuePress 是什么和如何使用它。</p>\n<p>如果你觉得已经掌握，接下来就是阅读 VuePress 官方文档   和本主题文档，根据你想要的对本主题进行配置。</p>\n<div><p>注意</p>\n<p>请务必先阅读官方文档再阅读本主题文档。</p>\n<p>本主题文档并没有针对官方文档已有的内容做过多的重复介绍，所以如果你不阅读官方文档，你可能无法掌握某些配置，比如模板中使用的多语言。</p>\n</div>\n<h2 id=\"构建网站\"> 构建网站</h2>\n<p>在你初步配置好项目之后，你就可以使用<code>yarn run docs:build</code>命令将网站构建输出到 dist 文件夹下。 你可以将文件夹的内容部署到你网站的服务器上。最简单的做法是上传到 GitHub 并开启 GitHub Pages。 关于 GitHub 的相关教程，你可以参考 <a href=\"https://mrhope.site/code/github/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub简介</a>。</p>\n",
      "date_published": "2020-06-16T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "VuePress",
      "url": "https://hsaio.codenoob.top/guide/vuepress.html",
      "id": "/guide/vuepress.html",
      "summary": "VuePress",
      "content_html": "<p>VuePress 是一个 Vue 驱动的静态网站生成器。它遵循:</p>\n<ul>\n<li>简洁至上\n以 Markdown 为中心的项目结构，以最少的配置帮助你专注于写作。</li>\n<li>Vue 驱动\n享受 Vue + webpack 的开发体验，可以在 Markdown 中使用 Vue 组件，又可以使用 Vue 来开发自定义主题。</li>\n<li>高性能\nVuePress 会为每个页面预渲染生成静态的 HTML，同时，每个页面被加载的时候，将作为 SPA 运行。</li>\n</ul>\n<h2 id=\"像数-1-2-3-一样容易\"> 像数 1, 2, 3 一样容易</h2>\n<div><pre><code># 在 docs 文件夹创建 vuepress 项目\nnpm init vuepress-theme-hope docs\n</code></pre>\n<div><span>1</span><br><span>2</span><br></div></div><h2 id=\"vuepress-介绍\"> VuePress 介绍</h2>\n<ul>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/basic/vuepress/file/\" target=\"_blank\" rel=\"noopener noreferrer\">文件结构简介</a></li>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/basic/vuepress/plugin/\" target=\"_blank\" rel=\"noopener noreferrer\">插件</a></li>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/basic/vuepress/theme/\" target=\"_blank\" rel=\"noopener noreferrer\">主题</a></li>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/basic/vuepress/command/\" target=\"_blank\" rel=\"noopener noreferrer\">使用指令</a></li>\n<li><a href=\"https://vuepress-theme-hope.github.io/zh/basic/vuepress/case/\" target=\"_blank\" rel=\"noopener noreferrer\">案例</a></li>\n</ul>\n<h2 id=\"vuepress-官方文档\"> VuePress 官方文档</h2>\n<ul>\n<li><a href=\"https://v1.vuepress.vuejs.org/zh/guide/\" target=\"_blank\" rel=\"noopener noreferrer\">VuePress指南</a></li>\n<li><a href=\"https://v1.vuepress.vuejs.org/zh/config/\" target=\"_blank\" rel=\"noopener noreferrer\">VuePress配置</a></li>\n<li><a href=\"https://v1.vuepress.vuejs.org/zh/plugin/\" target=\"_blank\" rel=\"noopener noreferrer\">VuePress插件</a></li>\n<li><a href=\"https://v1.vuepress.vuejs.org/zh/theme/\" target=\"_blank\" rel=\"noopener noreferrer\">VuePress主题</a></li>\n</ul>\n",
      "date_published": "2020-06-23T00:00:00.000Z",
      "date_modified": "2022-03-27T07:58:55.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": [
        "Start"
      ]
    },
    {
      "title": "欢迎大家在下方留言",
      "url": "https://hsaio.codenoob.top/message.html",
      "id": "/message.html",
      "summary": "想吐嘈的啥，快留下你的槽点！",
      "content_html": "<br>\n<h2 id=\"想吐嘈的啥-快留下你的槽点\"> 想吐嘈的啥，快留下你的槽点</h2>\n<p>可以的话，可以互相交换<a href=\"https://codenoob.top/friends.html\" target=\"_blank\" rel=\"noopener noreferrer\">友链</a>吗QAQ~</p>\n",
      "date_published": "2022-03-23T15:00:14.000Z",
      "date_modified": "2022-03-24T14:25:35.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "Home",
      "url": "https://hsaio.codenoob.top/",
      "id": "/",
      "content_html": "<Tech />\n",
      "date_published": "2022-03-23T15:00:14.000Z",
      "date_modified": "2022-03-24T14:25:35.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    },
    {
      "title": "关于网站",
      "url": "https://hsaio.codenoob.top/site.html",
      "id": "/site.html",
      "summary": "关于网站",
      "content_html": "<form-weather />\n<p>网站使用 <a href=\"https://v1.vuepress.vuejs.org/zh/guide/\" target=\"_blank\" rel=\"noopener noreferrer\">VuePress</a> 建站工具构建，使用主题 <a href=\"https://github.com/Mister-Hope/vuepress-theme-hope/\" target=\"_blank\" rel=\"noopener noreferrer\">vuepress-theme-hope</a></p>\n<h2 id=\"免责声明\"> 免责声明</h2>\n<p>此博客包含 <a href=\"https://github.com/ruanyf\" target=\"_blank\" rel=\"noopener noreferrer\">阮一峰</a> 和 <a href=\"https://weibo.com/liaoxuefeng\" target=\"_blank\" rel=\"noopener noreferrer\">廖雪峰</a> 两位老师的博客和书籍。</p>\n<p>在这里给他们致以诚挚的感谢。</p>\n",
      "date_published": "2020-05-20T00:00:00.000Z",
      "date_modified": "2022-03-28T09:28:24.000Z",
      "authors": [
        {
          "name": "MIFSH"
        }
      ],
      "tags": []
    }
  ]
}